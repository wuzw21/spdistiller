nohup: ignoring input
[2025-01-30 07:09:14,837] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[2025-01-30 07:09:16,502] [INFO] [runner.py:585:main] cmd = /home/donglinbai/miniconda3/envs/sparse/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=localhost --master_port=1321 --node_rank=0 --enable_each_rank_log=None train.py --model_name_or_path /data/wzw/models/Meta-Llama-3-8B --data_path /home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/datasets/Meta-Llama-3-8B/mix_alpaca_c4_9000.json --threshold_path ../threshold/llama-3-0.7.txt --model_max_length 512 --output_dir /home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/ckpts/Meta-Llama-3-8B/int4-g64/ --logging_dir /home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/logs/Meta-Llama-3-8B/int4-g64/ --num_train_epochs 4 --bf16 True --seed 42 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 1 --gradient_checkpointing True --load_best_model_at_end False --save_strategy epoch --save_total_limit 1 --learning_rate 5e-5 --lr_scheduler_type constant --weight_decay 0. --logging_steps 1 --report_to none --deepspeed config/zero3.json --bits 4 --quant_type Q4_0 --q_group_size 64 --train_kd False --kd_loss_type cakld --max_train_samples 999999 --max_memory 24000MB --evaluation_strategy steps --eval_steps 500
[2025-01-30 07:09:18,405] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-01-30 07:09:20,313] [INFO] [launch.py:139:main] 0 NCCL_SOCKET_IFNAME=lo
[2025-01-30 07:09:20,313] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2025-01-30 07:09:20,313] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=4, node_rank=0
[2025-01-30 07:09:20,314] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2025-01-30 07:09:20,314] [INFO] [launch.py:164:main] dist_world_size=4
[2025-01-30 07:09:20,314] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
[2025-01-30 07:09:20,336] [INFO] [launch.py:256:main] process 3946385 spawned with command: ['/home/donglinbai/miniconda3/envs/sparse/bin/python', '-u', 'train.py', '--local_rank=0', '--model_name_or_path', '/data/wzw/models/Meta-Llama-3-8B', '--data_path', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/datasets/Meta-Llama-3-8B/mix_alpaca_c4_9000.json', '--threshold_path', '../threshold/llama-3-0.7.txt', '--model_max_length', '512', '--output_dir', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/ckpts/Meta-Llama-3-8B/int4-g64/', '--logging_dir', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/logs/Meta-Llama-3-8B/int4-g64/', '--num_train_epochs', '4', '--bf16', 'True', '--seed', '42', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '1', '--gradient_checkpointing', 'True', '--load_best_model_at_end', 'False', '--save_strategy', 'epoch', '--save_total_limit', '1', '--learning_rate', '5e-5', '--lr_scheduler_type', 'constant', '--weight_decay', '0.', '--logging_steps', '1', '--report_to', 'none', '--deepspeed', 'config/zero3.json', '--bits', '4', '--quant_type', 'Q4_0', '--q_group_size', '64', '--train_kd', 'False', '--kd_loss_type', 'cakld', '--max_train_samples', '999999', '--max_memory', '24000MB', '--evaluation_strategy', 'steps', '--eval_steps', '500']
[2025-01-30 07:09:20,360] [INFO] [launch.py:256:main] process 3946397 spawned with command: ['/home/donglinbai/miniconda3/envs/sparse/bin/python', '-u', 'train.py', '--local_rank=1', '--model_name_or_path', '/data/wzw/models/Meta-Llama-3-8B', '--data_path', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/datasets/Meta-Llama-3-8B/mix_alpaca_c4_9000.json', '--threshold_path', '../threshold/llama-3-0.7.txt', '--model_max_length', '512', '--output_dir', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/ckpts/Meta-Llama-3-8B/int4-g64/', '--logging_dir', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/logs/Meta-Llama-3-8B/int4-g64/', '--num_train_epochs', '4', '--bf16', 'True', '--seed', '42', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '1', '--gradient_checkpointing', 'True', '--load_best_model_at_end', 'False', '--save_strategy', 'epoch', '--save_total_limit', '1', '--learning_rate', '5e-5', '--lr_scheduler_type', 'constant', '--weight_decay', '0.', '--logging_steps', '1', '--report_to', 'none', '--deepspeed', 'config/zero3.json', '--bits', '4', '--quant_type', 'Q4_0', '--q_group_size', '64', '--train_kd', 'False', '--kd_loss_type', 'cakld', '--max_train_samples', '999999', '--max_memory', '24000MB', '--evaluation_strategy', 'steps', '--eval_steps', '500']
[2025-01-30 07:09:20,382] [INFO] [launch.py:256:main] process 3946399 spawned with command: ['/home/donglinbai/miniconda3/envs/sparse/bin/python', '-u', 'train.py', '--local_rank=2', '--model_name_or_path', '/data/wzw/models/Meta-Llama-3-8B', '--data_path', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/datasets/Meta-Llama-3-8B/mix_alpaca_c4_9000.json', '--threshold_path', '../threshold/llama-3-0.7.txt', '--model_max_length', '512', '--output_dir', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/ckpts/Meta-Llama-3-8B/int4-g64/', '--logging_dir', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/logs/Meta-Llama-3-8B/int4-g64/', '--num_train_epochs', '4', '--bf16', 'True', '--seed', '42', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '1', '--gradient_checkpointing', 'True', '--load_best_model_at_end', 'False', '--save_strategy', 'epoch', '--save_total_limit', '1', '--learning_rate', '5e-5', '--lr_scheduler_type', 'constant', '--weight_decay', '0.', '--logging_steps', '1', '--report_to', 'none', '--deepspeed', 'config/zero3.json', '--bits', '4', '--quant_type', 'Q4_0', '--q_group_size', '64', '--train_kd', 'False', '--kd_loss_type', 'cakld', '--max_train_samples', '999999', '--max_memory', '24000MB', '--evaluation_strategy', 'steps', '--eval_steps', '500']
[2025-01-30 07:09:20,401] [INFO] [launch.py:256:main] process 3946421 spawned with command: ['/home/donglinbai/miniconda3/envs/sparse/bin/python', '-u', 'train.py', '--local_rank=3', '--model_name_or_path', '/data/wzw/models/Meta-Llama-3-8B', '--data_path', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/datasets/Meta-Llama-3-8B/mix_alpaca_c4_9000.json', '--threshold_path', '../threshold/llama-3-0.7.txt', '--model_max_length', '512', '--output_dir', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/ckpts/Meta-Llama-3-8B/int4-g64/', '--logging_dir', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/logs/Meta-Llama-3-8B/int4-g64/', '--num_train_epochs', '4', '--bf16', 'True', '--seed', '42', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '1', '--gradient_checkpointing', 'True', '--load_best_model_at_end', 'False', '--save_strategy', 'epoch', '--save_total_limit', '1', '--learning_rate', '5e-5', '--lr_scheduler_type', 'constant', '--weight_decay', '0.', '--logging_steps', '1', '--report_to', 'none', '--deepspeed', 'config/zero3.json', '--bits', '4', '--quant_type', 'Q4_0', '--q_group_size', '64', '--train_kd', 'False', '--kd_loss_type', 'cakld', '--max_train_samples', '999999', '--max_memory', '24000MB', '--evaluation_strategy', 'steps', '--eval_steps', '500']
Meta-Llama-3-8B
Create and load preditor...
Local device: cuda:2
Checkpoint dir: /data/wzw/models/predictor-data/Meta-Llama-3-8B-c4
Init Reset
Init sparsity: attn 0.0, mlp 0.0, w 0.0
Meta-Llama-3-8B
Create and load preditor...
Local device: cuda:0
Checkpoint dir: /data/wzw/models/predictor-data/Meta-Llama-3-8B-c4
Init Reset
Init sparsity: attn 0.0, mlp 0.0, w 0.0
Meta-Llama-3-8B
Create and load preditor...
Local device: cuda:3
Checkpoint dir: /data/wzw/models/predictor-data/Meta-Llama-3-8B-c4
Init Reset
Init sparsity: attn 0.0, mlp 0.0, w 0.0
Meta-Llama-3-8B
Create and load preditor...
Local device: cuda:1
Checkpoint dir: /data/wzw/models/predictor-data/Meta-Llama-3-8B-c4
Init Reset
Init sparsity: attn 0.0, mlp 0.0, w 0.0
/home/donglinbai/Projects/wzw/transformers-pred/src/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[2025-01-30 07:09:23,942] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/donglinbai/Projects/wzw/transformers-pred/src/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[2025-01-30 07:09:24,025] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/donglinbai/Projects/wzw/transformers-pred/src/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[2025-01-30 07:09:24,257] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
/home/donglinbai/Projects/wzw/transformers-pred/src/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[2025-01-30 07:09:24,831] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-01-30 07:09:25,237] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-30 07:09:25,238] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[2025-01-30 07:09:25,294] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-01-30 07:09:25,470] [INFO] [comm.py:637:init_distributed] cdb=None
loading /data/wzw/models/Meta-Llama-3-8B model
loading /data/wzw/models/Meta-Llama-3-8B model
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-01-30 07:09:26,083] [INFO] [comm.py:637:init_distributed] cdb=None
loading /data/wzw/models/Meta-Llama-3-8B model
loading /data/wzw/models/Meta-Llama-3-8B model
[2025-01-30 07:09:33,416] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 291, num_elems = 8.03B
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.62s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.62s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.74s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.76s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.65s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.67s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.68s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.72s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.67s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.67s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.70s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.39s/it]
Set sparsity: attn 0.5, mlp 0.5, w 0.0
Set pre-prediction: 0
threshold_path ../threshold/llama-3-0.7.txt
Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.40s/it]
Set sparsity: attn 0.5, mlp 0.5, w 0.0
Set pre-prediction: 0
threshold_path ../threshold/llama-3-0.7.txt
Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.22s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.40s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.40s/it]
Set sparsity: attn 0.5, mlp 0.5, w 0.0
Set pre-prediction: 0
threshold_path ../threshold/llama-3-0.7.txt
Set sparsity: attn 0.5, mlp 0.5, w 0.0
Set pre-prediction: 0
threshold_path ../threshold/llama-3-0.7.txt
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
tokenizer has not padding token
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
tokenizer has not padding token
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
tokenizer has not padding token
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
tokenizer has not padding token
Using 7271 samples to train
Example Data
sources: 
 The information is provided by Indianapolis Air Conditioning Repair and while we endeavor to keep the information up to date and
targets: 
  correct, we make no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, suitability or availability with respect to the website or the information, products, services, or related graphics contained on the website for any purpose. Any reliance you place on such information is therefore strictly at your own risk.
Through this website you are able to link to other websites which are not under the control of Indianapolis Air Conditioning Repair. We have no control over the nature, content and availability of those sites. The inclusion of any links does not necessarily imply a recommendation or endorse the views expressed within them.
Every effort is made to keep the website up and running smoothly. However, Indianapolis Air Conditioning Repair takes no responsibility for, and will not be liable for, the website being temporarily unavailable due to technical issues beyond our control.<|end_of_text|>
Using 7271 samples to train
Example DataUsing 7271 samples to train

sources: 
Example Data 
The information is provided by Indianapolis Air Conditioning Repair and while we endeavor to keep the information up to date andsources: 

 targets: 
The information is provided by Indianapolis Air Conditioning Repair and while we endeavor to keep the information up to date and 
 correct, we make no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, suitability or availability with respect to the website or the information, products, services, or related graphics contained on the website for any purpose. Any reliance you place on such information is therefore strictly at your own risk.
Through this website you are able to link to other websites which are not under the control of Indianapolis Air Conditioning Repair. We have no control over the nature, content and availability of those sites. The inclusion of any links does not necessarily imply a recommendation or endorse the views expressed within them.
Every effort is made to keep the website up and running smoothly. However, Indianapolis Air Conditioning Repair takes no responsibility for, and will not be liable for, the website being temporarily unavailable due to technical issues beyond our control.<|end_of_text|>targets: 

  correct, we make no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, suitability or availability with respect to the website or the information, products, services, or related graphics contained on the website for any purpose. Any reliance you place on such information is therefore strictly at your own risk.
Through this website you are able to link to other websites which are not under the control of Indianapolis Air Conditioning Repair. We have no control over the nature, content and availability of those sites. The inclusion of any links does not necessarily imply a recommendation or endorse the views expressed within them.
Every effort is made to keep the website up and running smoothly. However, Indianapolis Air Conditioning Repair takes no responsibility for, and will not be liable for, the website being temporarily unavailable due to technical issues beyond our control.<|end_of_text|>
Using 7271 samples to train
Example Data
sources: 
 The information is provided by Indianapolis Air Conditioning Repair and while we endeavor to keep the information up to date and
targets: 
  correct, we make no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, suitability or availability with respect to the website or the information, products, services, or related graphics contained on the website for any purpose. Any reliance you place on such information is therefore strictly at your own risk.
Through this website you are able to link to other websites which are not under the control of Indianapolis Air Conditioning Repair. We have no control over the nature, content and availability of those sites. The inclusion of any links does not necessarily imply a recommendation or endorse the views expressed within them.
Every effort is made to keep the website up and running smoothly. However, Indianapolis Air Conditioning Repair takes no responsibility for, and will not be liable for, the website being temporarily unavailable due to technical issues beyond our control.<|end_of_text|>
Using 1817 samples to evaluation
Using 1817 samples to evaluation
Using 1817 samples to evaluation
converting the model to qat, this may take a while...
converting the model to qat, this may take a while...
converting the model to qat, this may take a while...
Using 1817 samples to evaluation
converting the model to qat, this may take a while...
/home/donglinbai/Projects/wzw/transformers-pred/src/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/donglinbai/Projects/wzw/transformers-pred/src/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/donglinbai/Projects/wzw/transformers-pred/src/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/donglinbai/Projects/wzw/transformers-pred/src/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Installed CUDA version 12.3 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /data/donglinbai/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Installed CUDA version 12.3 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /data/donglinbai/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Installed CUDA version 12.3 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /data/donglinbai/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Emitting ninja build file /data/donglinbai/.cache/torch_extensions/py39_cu121/cpu_adam/build.ninja...
Building extension module cpu_adam...
Using envvar MAX_JOBS (16) as the number of workers...
Installed CUDA version 12.3 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /data/donglinbai/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.9370036125183105 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.009891986846924 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.6499199867248535 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.795675039291382 seconds
Parameter Offload: Total persistent parameters: 266240 in 65 params
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 0/7272 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
  0%|          | 1/7272 [00:19<40:01:28, 19.82s/it]                                                   {'loss': 0.5187, 'grad_norm': 4.783746719360352, 'learning_rate': 5e-05, 'epoch': 0.0, 'step': 1, 'max_steps': 7272}
  0%|          | 1/7272 [00:19<40:01:28, 19.82s/it]  0%|          | 2/7272 [00:36<36:27:02, 18.05s/it]                                                   {'loss': 1.7912, 'grad_norm': 23.88525390625, 'learning_rate': 5e-05, 'epoch': 0.0, 'step': 2, 'max_steps': 7272}
  0%|          | 2/7272 [00:36<36:27:02, 18.05s/it]  0%|          | 3/7272 [00:51<33:43:26, 16.70s/it]                                                   {'loss': 1.5536, 'grad_norm': 11.398698806762695, 'learning_rate': 5e-05, 'epoch': 0.0, 'step': 3, 'max_steps': 7272}
  0%|          | 3/7272 [00:51<33:43:26, 16.70s/it]  0%|          | 4/7272 [01:07<33:15:57, 16.48s/it]                                                   {'loss': 1.0425, 'grad_norm': 6.214449405670166, 'learning_rate': 5e-05, 'epoch': 0.0, 'step': 4, 'max_steps': 7272}
  0%|          | 4/7272 [01:07<33:15:57, 16.48s/it]  0%|          | 5/7272 [01:23<32:41:10, 16.19s/it]                                                   {'loss': 0.8752, 'grad_norm': 6.1555352210998535, 'learning_rate': 5e-05, 'epoch': 0.0, 'step': 5, 'max_steps': 7272}
  0%|          | 5/7272 [01:23<32:41:10, 16.19s/it]  0%|          | 6/7272 [01:39<32:40:56, 16.19s/it]                                                   {'loss': 0.7282, 'grad_norm': 5.570962905883789, 'learning_rate': 5e-05, 'epoch': 0.0, 'step': 6, 'max_steps': 7272}
  0%|          | 6/7272 [01:39<32:40:56, 16.19s/it]  0%|          | 7/7272 [01:54<32:03:22, 15.88s/it]                                                   {'loss': 0.9336, 'grad_norm': 6.660167217254639, 'learning_rate': 5e-05, 'epoch': 0.0, 'step': 7, 'max_steps': 7272}
  0%|          | 7/7272 [01:54<32:03:22, 15.88s/it]  0%|          | 8/7272 [02:10<31:49:23, 15.77s/it]                                                   {'loss': 2.5681, 'grad_norm': 17.936491012573242, 'learning_rate': 5e-05, 'epoch': 0.0, 'step': 8, 'max_steps': 7272}
  0%|          | 8/7272 [02:10<31:49:23, 15.77s/it]  0%|          | 9/7272 [02:25<31:20:22, 15.53s/it]                                                   {'loss': 1.5463, 'grad_norm': 14.650358200073242, 'learning_rate': 5e-05, 'epoch': 0.0, 'step': 9, 'max_steps': 7272}
  0%|          | 9/7272 [02:25<31:20:22, 15.53s/it]  0%|          | 10/7272 [02:40<31:15:56, 15.50s/it]                                                    {'loss': 1.1322, 'grad_norm': 7.838280200958252, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 10, 'max_steps': 7272}
  0%|          | 10/7272 [02:40<31:15:56, 15.50s/it]  0%|          | 11/7272 [02:56<31:04:26, 15.41s/it]                                                    {'loss': 1.0084, 'grad_norm': 7.924332141876221, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 11, 'max_steps': 7272}
  0%|          | 11/7272 [02:56<31:04:26, 15.41s/it]  0%|          | 12/7272 [03:11<31:00:50, 15.38s/it]                                                    {'loss': 1.6992, 'grad_norm': 9.922284126281738, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 12, 'max_steps': 7272}
  0%|          | 12/7272 [03:11<31:00:50, 15.38s/it]  0%|          | 13/7272 [03:26<30:53:04, 15.32s/it]                                                    {'loss': 3.3884, 'grad_norm': 21.44132423400879, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 13, 'max_steps': 7272}
  0%|          | 13/7272 [03:26<30:53:04, 15.32s/it]  0%|          | 14/7272 [03:41<30:30:32, 15.13s/it]                                                    {'loss': 1.4875, 'grad_norm': 6.420513153076172, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 14, 'max_steps': 7272}
  0%|          | 14/7272 [03:41<30:30:32, 15.13s/it]  0%|          | 15/7272 [03:57<31:24:02, 15.58s/it]                                                    {'loss': 1.4921, 'grad_norm': 9.06559944152832, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 15, 'max_steps': 7272}
  0%|          | 15/7272 [03:57<31:24:02, 15.58s/it]  0%|          | 16/7272 [04:12<30:56:46, 15.35s/it]                                                    {'loss': 2.388, 'grad_norm': 15.33724308013916, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 16, 'max_steps': 7272}
  0%|          | 16/7272 [04:12<30:56:46, 15.35s/it]  0%|          | 17/7272 [04:27<30:31:03, 15.14s/it]                                                    {'loss': 2.432, 'grad_norm': 17.53638458251953, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 17, 'max_steps': 7272}
  0%|          | 17/7272 [04:27<30:31:03, 15.14s/it]  0%|          | 18/7272 [04:42<30:10:52, 14.98s/it]                                                    {'loss': 0.9035, 'grad_norm': 7.195465087890625, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 18, 'max_steps': 7272}
  0%|          | 18/7272 [04:42<30:10:52, 14.98s/it]  0%|          | 19/7272 [04:56<29:56:03, 14.86s/it]                                                    {'loss': 1.8937, 'grad_norm': 21.245540618896484, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 19, 'max_steps': 7272}
  0%|          | 19/7272 [04:56<29:56:03, 14.86s/it]  0%|          | 20/7272 [05:11<29:43:52, 14.76s/it]                                                    {'loss': 1.2157, 'grad_norm': 5.430379390716553, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 20, 'max_steps': 7272}
  0%|          | 20/7272 [05:11<29:43:52, 14.76s/it]  0%|          | 21/7272 [05:25<29:42:37, 14.75s/it]                                                    {'loss': 1.5861, 'grad_norm': 9.421772956848145, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 21, 'max_steps': 7272}
  0%|          | 21/7272 [05:25<29:42:37, 14.75s/it]  0%|          | 22/7272 [05:40<29:31:38, 14.66s/it]                                                    {'loss': 1.785, 'grad_norm': 15.283791542053223, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 22, 'max_steps': 7272}
  0%|          | 22/7272 [05:40<29:31:38, 14.66s/it]  0%|          | 23/7272 [05:54<29:15:04, 14.53s/it]                                                    {'loss': 0.7385, 'grad_norm': 7.05551290512085, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 23, 'max_steps': 7272}
  0%|          | 23/7272 [05:54<29:15:04, 14.53s/it]  0%|          | 24/7272 [06:08<28:58:43, 14.39s/it]                                                    {'loss': 2.5854, 'grad_norm': 13.928200721740723, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 24, 'max_steps': 7272}
  0%|          | 24/7272 [06:08<28:58:43, 14.39s/it]  0%|          | 25/7272 [06:23<28:59:10, 14.40s/it]                                                    {'loss': 0.6984, 'grad_norm': 4.354633808135986, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 25, 'max_steps': 7272}
  0%|          | 25/7272 [06:23<28:59:10, 14.40s/it]  0%|          | 26/7272 [06:37<28:50:25, 14.33s/it]                                                    {'loss': 0.7256, 'grad_norm': 5.442692756652832, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 26, 'max_steps': 7272}
  0%|          | 26/7272 [06:37<28:50:25, 14.33s/it]  0%|          | 27/7272 [06:51<28:48:28, 14.31s/it]                                                    {'loss': 1.0013, 'grad_norm': 5.670286655426025, 'learning_rate': 5e-05, 'epoch': 0.01, 'step': 27, 'max_steps': 7272}
  0%|          | 27/7272 [06:51<28:48:28, 14.31s/it]  0%|          | 28/7272 [07:05<28:39:25, 14.24s/it]                                                    {'loss': 0.6687, 'grad_norm': 5.7249603271484375, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 28, 'max_steps': 7272}
  0%|          | 28/7272 [07:05<28:39:25, 14.24s/it]  0%|          | 29/7272 [07:20<28:50:49, 14.34s/it]                                                    {'loss': 1.6932, 'grad_norm': 17.583690643310547, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 29, 'max_steps': 7272}
  0%|          | 29/7272 [07:20<28:50:49, 14.34s/it]  0%|          | 30/7272 [07:34<28:42:53, 14.27s/it]                                                    {'loss': 1.9011, 'grad_norm': 6.2685980796813965, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 30, 'max_steps': 7272}
  0%|          | 30/7272 [07:34<28:42:53, 14.27s/it]  0%|          | 31/7272 [07:48<28:31:53, 14.18s/it]                                                    {'loss': 1.5542, 'grad_norm': 11.25602912902832, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 31, 'max_steps': 7272}
  0%|          | 31/7272 [07:48<28:31:53, 14.18s/it]  0%|          | 32/7272 [08:02<28:29:36, 14.17s/it]                                                    {'loss': 1.9052, 'grad_norm': 15.367141723632812, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 32, 'max_steps': 7272}
  0%|          | 32/7272 [08:02<28:29:36, 14.17s/it]  0%|          | 33/7272 [08:16<28:25:08, 14.13s/it]                                                    {'loss': 0.7041, 'grad_norm': 4.502663612365723, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 33, 'max_steps': 7272}
  0%|          | 33/7272 [08:16<28:25:08, 14.13s/it]  0%|          | 34/7272 [08:30<28:31:04, 14.18s/it]                                                    {'loss': 2.3632, 'grad_norm': 13.25306510925293, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 34, 'max_steps': 7272}
  0%|          | 34/7272 [08:30<28:31:04, 14.18s/it]  0%|          | 35/7272 [08:45<29:05:53, 14.47s/it]                                                    {'loss': 1.8076, 'grad_norm': 16.892297744750977, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 35, 'max_steps': 7272}
  0%|          | 35/7272 [08:45<29:05:53, 14.47s/it]  0%|          | 36/7272 [09:00<29:08:35, 14.50s/it]                                                    {'loss': 1.9301, 'grad_norm': 15.421035766601562, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 36, 'max_steps': 7272}
  0%|          | 36/7272 [09:00<29:08:35, 14.50s/it]  1%|          | 37/7272 [09:15<29:12:07, 14.53s/it]                                                    {'loss': 1.7536, 'grad_norm': 11.536026954650879, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 37, 'max_steps': 7272}
  1%|          | 37/7272 [09:15<29:12:07, 14.53s/it]  1%|          | 38/7272 [09:29<29:19:13, 14.59s/it]                                                    {'loss': 2.2893, 'grad_norm': 14.300580024719238, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 38, 'max_steps': 7272}
  1%|          | 38/7272 [09:29<29:19:13, 14.59s/it]  1%|          | 39/7272 [09:43<29:05:09, 14.48s/it]                                                    {'loss': 1.315, 'grad_norm': 11.836496353149414, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 39, 'max_steps': 7272}
  1%|          | 39/7272 [09:43<29:05:09, 14.48s/it]  1%|          | 40/7272 [09:58<29:05:20, 14.48s/it]                                                    {'loss': 1.3543, 'grad_norm': 8.541991233825684, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 40, 'max_steps': 7272}
  1%|          | 40/7272 [09:58<29:05:20, 14.48s/it]  1%|          | 41/7272 [10:12<28:51:33, 14.37s/it]                                                    {'loss': 1.1883, 'grad_norm': 6.710367202758789, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 41, 'max_steps': 7272}
  1%|          | 41/7272 [10:12<28:51:33, 14.37s/it]  1%|          | 42/7272 [10:26<28:53:34, 14.39s/it]                                                    {'loss': 1.4875, 'grad_norm': 8.070938110351562, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 42, 'max_steps': 7272}
  1%|          | 42/7272 [10:26<28:53:34, 14.39s/it]  1%|          | 43/7272 [10:41<28:56:27, 14.41s/it]                                                    {'loss': 1.5825, 'grad_norm': 6.940113544464111, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 43, 'max_steps': 7272}
  1%|          | 43/7272 [10:41<28:56:27, 14.41s/it]  1%|          | 44/7272 [10:56<29:04:47, 14.48s/it]                                                    {'loss': 1.7074, 'grad_norm': 11.414283752441406, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 44, 'max_steps': 7272}
  1%|          | 44/7272 [10:56<29:04:47, 14.48s/it]  1%|          | 45/7272 [11:10<29:00:48, 14.45s/it]                                                    {'loss': 1.3805, 'grad_norm': 8.493293762207031, 'learning_rate': 5e-05, 'epoch': 0.02, 'step': 45, 'max_steps': 7272}
  1%|          | 45/7272 [11:10<29:00:48, 14.45s/it]  1%|          | 46/7272 [11:25<29:08:29, 14.52s/it]                                                    {'loss': 0.3294, 'grad_norm': 3.4089205265045166, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 46, 'max_steps': 7272}
  1%|          | 46/7272 [11:25<29:08:29, 14.52s/it]  1%|          | 47/7272 [11:39<28:50:44, 14.37s/it]                                                    {'loss': 0.3784, 'grad_norm': 2.5168142318725586, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 47, 'max_steps': 7272}
  1%|          | 47/7272 [11:39<28:50:44, 14.37s/it]  1%|          | 48/7272 [11:53<28:33:55, 14.24s/it]                                                    {'loss': 1.362, 'grad_norm': 8.509907722473145, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 48, 'max_steps': 7272}
  1%|          | 48/7272 [11:53<28:33:55, 14.24s/it]  1%|          | 49/7272 [12:07<28:35:09, 14.25s/it]                                                    {'loss': 1.0954, 'grad_norm': 6.2115960121154785, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 49, 'max_steps': 7272}
  1%|          | 49/7272 [12:07<28:35:09, 14.25s/it]  1%|          | 50/7272 [12:21<28:28:22, 14.19s/it]                                                    {'loss': 3.4823, 'grad_norm': 26.71868324279785, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 50, 'max_steps': 7272}
  1%|          | 50/7272 [12:21<28:28:22, 14.19s/it]  1%|          | 51/7272 [12:36<28:48:34, 14.36s/it]                                                    {'loss': 1.7816, 'grad_norm': 16.1679744720459, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 51, 'max_steps': 7272}
  1%|          | 51/7272 [12:36<28:48:34, 14.36s/it]  1%|          | 52/7272 [12:50<28:54:41, 14.42s/it]                                                    {'loss': 1.6535, 'grad_norm': 9.029306411743164, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 52, 'max_steps': 7272}
  1%|          | 52/7272 [12:50<28:54:41, 14.42s/it]  1%|          | 53/7272 [13:04<28:43:56, 14.33s/it]                                                    {'loss': 1.8431, 'grad_norm': 15.73061466217041, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 53, 'max_steps': 7272}
  1%|          | 53/7272 [13:04<28:43:56, 14.33s/it]  1%|          | 54/7272 [13:19<28:56:05, 14.43s/it]                                                    {'loss': 1.8764, 'grad_norm': 11.776331901550293, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 54, 'max_steps': 7272}
  1%|          | 54/7272 [13:19<28:56:05, 14.43s/it]  1%|          | 55/7272 [13:34<29:06:13, 14.52s/it]                                                    {'loss': 0.761, 'grad_norm': 6.093793869018555, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 55, 'max_steps': 7272}
  1%|          | 55/7272 [13:34<29:06:13, 14.52s/it]  1%|          | 56/7272 [13:49<29:21:02, 14.64s/it]                                                    {'loss': 2.1167, 'grad_norm': 11.2433500289917, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 56, 'max_steps': 7272}
  1%|          | 56/7272 [13:49<29:21:02, 14.64s/it]  1%|          | 57/7272 [14:04<29:49:45, 14.88s/it]                                                    {'loss': 1.7039, 'grad_norm': 12.941010475158691, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 57, 'max_steps': 7272}
  1%|          | 57/7272 [14:04<29:49:45, 14.88s/it]  1%|          | 58/7272 [14:20<30:14:22, 15.09s/it]                                                    {'loss': 0.858, 'grad_norm': 4.39797306060791, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 58, 'max_steps': 7272}
  1%|          | 58/7272 [14:20<30:14:22, 15.09s/it]  1%|          | 59/7272 [14:35<30:36:14, 15.27s/it]                                                    {'loss': 0.8304, 'grad_norm': 5.178464889526367, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 59, 'max_steps': 7272}
  1%|          | 59/7272 [14:35<30:36:14, 15.27s/it]  1%|          | 60/7272 [14:51<30:47:42, 15.37s/it]                                                    {'loss': 1.0815, 'grad_norm': 6.461503028869629, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 60, 'max_steps': 7272}
  1%|          | 60/7272 [14:51<30:47:42, 15.37s/it]  1%|          | 61/7272 [15:07<30:52:58, 15.42s/it]                                                    {'loss': 1.1891, 'grad_norm': 6.143331050872803, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 61, 'max_steps': 7272}
  1%|          | 61/7272 [15:07<30:52:58, 15.42s/it]  1%|          | 62/7272 [15:22<31:10:58, 15.57s/it]                                                    {'loss': 0.6397, 'grad_norm': 2.8891897201538086, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 62, 'max_steps': 7272}
  1%|          | 62/7272 [15:22<31:10:58, 15.57s/it]  1%|          | 63/7272 [15:38<31:05:55, 15.53s/it]                                                    {'loss': 1.3278, 'grad_norm': 7.506391525268555, 'learning_rate': 5e-05, 'epoch': 0.03, 'step': 63, 'max_steps': 7272}
  1%|          | 63/7272 [15:38<31:05:55, 15.53s/it]  1%|          | 64/7272 [15:54<31:37:58, 15.80s/it]                                                    {'loss': 1.3961, 'grad_norm': 4.9149394035339355, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 64, 'max_steps': 7272}
  1%|          | 64/7272 [15:54<31:37:58, 15.80s/it]  1%|          | 65/7272 [16:10<31:42:08, 15.84s/it]                                                    {'loss': 2.4108, 'grad_norm': 7.7547078132629395, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 65, 'max_steps': 7272}
  1%|          | 65/7272 [16:10<31:42:08, 15.84s/it]  1%|          | 66/7272 [16:26<31:37:30, 15.80s/it]                                                    {'loss': 1.7001, 'grad_norm': 6.24376106262207, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 66, 'max_steps': 7272}
  1%|          | 66/7272 [16:26<31:37:30, 15.80s/it]  1%|          | 67/7272 [16:42<31:50:20, 15.91s/it]                                                    {'loss': 0.9114, 'grad_norm': 5.334648609161377, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 67, 'max_steps': 7272}
  1%|          | 67/7272 [16:42<31:50:20, 15.91s/it]  1%|          | 68/7272 [16:58<31:39:01, 15.82s/it]                                                    {'loss': 1.7973, 'grad_norm': 9.55251407623291, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 68, 'max_steps': 7272}
  1%|          | 68/7272 [16:58<31:39:01, 15.82s/it]  1%|          | 69/7272 [17:13<31:25:07, 15.70s/it]                                                    {'loss': 1.2392, 'grad_norm': 8.15335750579834, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 69, 'max_steps': 7272}
  1%|          | 69/7272 [17:13<31:25:07, 15.70s/it]  1%|          | 70/7272 [17:29<31:12:32, 15.60s/it]                                                    {'loss': 1.9948, 'grad_norm': 5.930074214935303, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 70, 'max_steps': 7272}
  1%|          | 70/7272 [17:29<31:12:32, 15.60s/it]  1%|          | 71/7272 [17:43<30:34:59, 15.29s/it]                                                    {'loss': 1.6139, 'grad_norm': 5.829500198364258, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 71, 'max_steps': 7272}
  1%|          | 71/7272 [17:43<30:34:59, 15.29s/it]  1%|          | 72/7272 [17:58<30:35:07, 15.29s/it]                                                    {'loss': 1.7694, 'grad_norm': 6.800116539001465, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 72, 'max_steps': 7272}
  1%|          | 72/7272 [17:58<30:35:07, 15.29s/it]  1%|          | 73/7272 [18:13<30:05:03, 15.04s/it]                                                    {'loss': 1.4714, 'grad_norm': 7.006480693817139, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 73, 'max_steps': 7272}
  1%|          | 73/7272 [18:13<30:05:03, 15.04s/it]  1%|          | 74/7272 [18:27<29:45:17, 14.88s/it]                                                    {'loss': 1.9116, 'grad_norm': 21.47118377685547, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 74, 'max_steps': 7272}
  1%|          | 74/7272 [18:27<29:45:17, 14.88s/it]  1%|          | 75/7272 [18:42<29:43:04, 14.87s/it]                                                    {'loss': 1.2216, 'grad_norm': 5.816470623016357, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 75, 'max_steps': 7272}
  1%|          | 75/7272 [18:42<29:43:04, 14.87s/it]  1%|          | 76/7272 [18:57<29:41:06, 14.85s/it]                                                    {'loss': 1.3221, 'grad_norm': 6.657635688781738, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 76, 'max_steps': 7272}
  1%|          | 76/7272 [18:57<29:41:06, 14.85s/it]  1%|          | 77/7272 [19:12<30:01:22, 15.02s/it]                                                    {'loss': 1.4734, 'grad_norm': 14.00998306274414, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 77, 'max_steps': 7272}
  1%|          | 77/7272 [19:12<30:01:22, 15.02s/it]  1%|          | 78/7272 [19:27<29:57:01, 14.99s/it]                                                    {'loss': 1.3257, 'grad_norm': 6.495275020599365, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 78, 'max_steps': 7272}
  1%|          | 78/7272 [19:27<29:57:01, 14.99s/it]  1%|          | 79/7272 [19:42<29:50:13, 14.93s/it]                                                    {'loss': 1.048, 'grad_norm': 4.293525218963623, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 79, 'max_steps': 7272}
  1%|          | 79/7272 [19:42<29:50:13, 14.93s/it]  1%|          | 80/7272 [19:57<29:42:06, 14.87s/it]                                                    {'loss': 1.253, 'grad_norm': 4.671467304229736, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 80, 'max_steps': 7272}
  1%|          | 80/7272 [19:57<29:42:06, 14.87s/it]  1%|          | 81/7272 [20:12<29:46:33, 14.91s/it]                                                    {'loss': 1.2212, 'grad_norm': 4.309096336364746, 'learning_rate': 5e-05, 'epoch': 0.04, 'step': 81, 'max_steps': 7272}
  1%|          | 81/7272 [20:12<29:46:33, 14.91s/it]  1%|          | 82/7272 [20:26<29:30:22, 14.77s/it]                                                    {'loss': 1.2463, 'grad_norm': 6.4849348068237305, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 82, 'max_steps': 7272}
  1%|          | 82/7272 [20:26<29:30:22, 14.77s/it]  1%|          | 83/7272 [20:41<29:16:20, 14.66s/it]                                                    {'loss': 1.2621, 'grad_norm': 8.138957023620605, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 83, 'max_steps': 7272}
  1%|          | 83/7272 [20:41<29:16:20, 14.66s/it]  1%|          | 84/7272 [20:56<29:47:32, 14.92s/it]                                                    {'loss': 2.5275, 'grad_norm': 11.951085090637207, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 84, 'max_steps': 7272}
  1%|          | 84/7272 [20:56<29:47:32, 14.92s/it]  1%|          | 85/7272 [21:11<29:57:13, 15.00s/it]                                                    {'loss': 1.5907, 'grad_norm': 7.596208572387695, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 85, 'max_steps': 7272}
  1%|          | 85/7272 [21:11<29:57:13, 15.00s/it]  1%|          | 86/7272 [21:27<30:01:13, 15.04s/it]                                                    {'loss': 1.5866, 'grad_norm': 11.823038101196289, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 86, 'max_steps': 7272}
  1%|          | 86/7272 [21:27<30:01:13, 15.04s/it]  1%|          | 87/7272 [21:42<29:57:57, 15.01s/it]                                                    {'loss': 0.5672, 'grad_norm': 2.6828622817993164, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 87, 'max_steps': 7272}
  1%|          | 87/7272 [21:42<29:57:57, 15.01s/it]  1%|          | 88/7272 [21:56<29:42:28, 14.89s/it]                                                    {'loss': 1.5891, 'grad_norm': 12.864365577697754, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 88, 'max_steps': 7272}
  1%|          | 88/7272 [21:56<29:42:28, 14.89s/it]  1%|          | 89/7272 [22:11<29:25:12, 14.74s/it]                                                    {'loss': 2.0503, 'grad_norm': 11.320478439331055, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 89, 'max_steps': 7272}
  1%|          | 89/7272 [22:11<29:25:12, 14.74s/it]  1%|          | 90/7272 [22:25<29:20:51, 14.71s/it]                                                    {'loss': 0.3022, 'grad_norm': 2.282909631729126, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 90, 'max_steps': 7272}
  1%|          | 90/7272 [22:25<29:20:51, 14.71s/it]  1%|▏         | 91/7272 [22:40<29:13:26, 14.65s/it]                                                    {'loss': 1.7469, 'grad_norm': 12.687270164489746, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 91, 'max_steps': 7272}
  1%|▏         | 91/7272 [22:40<29:13:26, 14.65s/it]  1%|▏         | 92/7272 [22:54<29:05:45, 14.59s/it]                                                    {'loss': 0.9017, 'grad_norm': 6.042360305786133, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 92, 'max_steps': 7272}
  1%|▏         | 92/7272 [22:54<29:05:45, 14.59s/it]  1%|▏         | 93/7272 [23:09<29:01:31, 14.56s/it]                                                    {'loss': 0.5392, 'grad_norm': 2.952047348022461, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 93, 'max_steps': 7272}
  1%|▏         | 93/7272 [23:09<29:01:31, 14.56s/it]  1%|▏         | 94/7272 [23:24<29:29:03, 14.79s/it]                                                    {'loss': 2.1246, 'grad_norm': 9.164588928222656, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 94, 'max_steps': 7272}
  1%|▏         | 94/7272 [23:24<29:29:03, 14.79s/it]  1%|▏         | 95/7272 [23:38<29:21:36, 14.73s/it]                                                    {'loss': 0.8515, 'grad_norm': 3.4137654304504395, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 95, 'max_steps': 7272}
  1%|▏         | 95/7272 [23:38<29:21:36, 14.73s/it]  1%|▏         | 96/7272 [23:53<29:18:29, 14.70s/it]                                                    {'loss': 0.7006, 'grad_norm': 4.340089797973633, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 96, 'max_steps': 7272}
  1%|▏         | 96/7272 [23:53<29:18:29, 14.70s/it]  1%|▏         | 97/7272 [24:08<29:14:18, 14.67s/it]                                                    {'loss': 0.9178, 'grad_norm': 3.652066707611084, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 97, 'max_steps': 7272}
  1%|▏         | 97/7272 [24:08<29:14:18, 14.67s/it]  1%|▏         | 98/7272 [24:22<29:14:55, 14.68s/it]                                                    {'loss': 3.1268, 'grad_norm': 11.428723335266113, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 98, 'max_steps': 7272}
  1%|▏         | 98/7272 [24:22<29:14:55, 14.68s/it]  1%|▏         | 99/7272 [24:37<29:23:11, 14.75s/it]                                                    {'loss': 2.0526, 'grad_norm': 7.93104362487793, 'learning_rate': 5e-05, 'epoch': 0.05, 'step': 99, 'max_steps': 7272}
  1%|▏         | 99/7272 [24:37<29:23:11, 14.75s/it]  1%|▏         | 100/7272 [24:52<29:25:29, 14.77s/it]                                                     {'loss': 0.7175, 'grad_norm': 8.75078296661377, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 100, 'max_steps': 7272}
  1%|▏         | 100/7272 [24:52<29:25:29, 14.77s/it]  1%|▏         | 101/7272 [25:07<29:24:05, 14.76s/it]                                                     {'loss': 0.7252, 'grad_norm': 4.788392066955566, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 101, 'max_steps': 7272}
  1%|▏         | 101/7272 [25:07<29:24:05, 14.76s/it]  1%|▏         | 102/7272 [25:21<29:11:40, 14.66s/it]                                                     {'loss': 1.9301, 'grad_norm': 11.021084785461426, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 102, 'max_steps': 7272}
  1%|▏         | 102/7272 [25:21<29:11:40, 14.66s/it]  1%|▏         | 103/7272 [25:35<28:52:25, 14.50s/it]                                                     {'loss': 1.8701, 'grad_norm': 11.849499702453613, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 103, 'max_steps': 7272}
  1%|▏         | 103/7272 [25:35<28:52:25, 14.50s/it]  1%|▏         | 104/7272 [25:50<28:38:29, 14.38s/it]                                                     {'loss': 1.601, 'grad_norm': 5.66234827041626, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 104, 'max_steps': 7272}
  1%|▏         | 104/7272 [25:50<28:38:29, 14.38s/it]  1%|▏         | 105/7272 [26:04<28:54:11, 14.52s/it]                                                     {'loss': 2.048, 'grad_norm': 7.522005081176758, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 105, 'max_steps': 7272}
  1%|▏         | 105/7272 [26:04<28:54:11, 14.52s/it]  1%|▏         | 106/7272 [26:19<29:12:40, 14.67s/it]                                                     {'loss': 2.0746, 'grad_norm': 13.51560115814209, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 106, 'max_steps': 7272}
  1%|▏         | 106/7272 [26:19<29:12:40, 14.67s/it]  1%|▏         | 107/7272 [26:35<29:26:39, 14.79s/it]                                                     {'loss': 1.7219, 'grad_norm': 14.72028923034668, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 107, 'max_steps': 7272}
  1%|▏         | 107/7272 [26:35<29:26:39, 14.79s/it]  1%|▏         | 108/7272 [26:49<29:27:26, 14.80s/it]                                                     {'loss': 1.4414, 'grad_norm': 6.993624687194824, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 108, 'max_steps': 7272}
  1%|▏         | 108/7272 [26:49<29:27:26, 14.80s/it]  1%|▏         | 109/7272 [27:04<29:09:47, 14.66s/it]                                                     {'loss': 1.6391, 'grad_norm': 8.304280281066895, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 109, 'max_steps': 7272}
  1%|▏         | 109/7272 [27:04<29:09:47, 14.66s/it]  2%|▏         | 110/7272 [27:18<29:03:33, 14.61s/it]                                                     {'loss': 2.2061, 'grad_norm': 8.76552677154541, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 110, 'max_steps': 7272}
  2%|▏         | 110/7272 [27:18<29:03:33, 14.61s/it]  2%|▏         | 111/7272 [27:33<28:59:04, 14.57s/it]                                                     {'loss': 0.4651, 'grad_norm': 4.360746383666992, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 111, 'max_steps': 7272}
  2%|▏         | 111/7272 [27:33<28:59:04, 14.57s/it]  2%|▏         | 112/7272 [27:47<28:54:10, 14.53s/it]                                                     {'loss': 1.04, 'grad_norm': 7.018102645874023, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 112, 'max_steps': 7272}
  2%|▏         | 112/7272 [27:47<28:54:10, 14.53s/it]  2%|▏         | 113/7272 [28:01<28:39:26, 14.41s/it]                                                     {'loss': 1.0773, 'grad_norm': 6.603164196014404, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 113, 'max_steps': 7272}
  2%|▏         | 113/7272 [28:01<28:39:26, 14.41s/it]  2%|▏         | 114/7272 [28:16<28:42:00, 14.43s/it]                                                     {'loss': 1.9047, 'grad_norm': 8.225218772888184, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 114, 'max_steps': 7272}
  2%|▏         | 114/7272 [28:16<28:42:00, 14.43s/it]  2%|▏         | 115/7272 [28:30<28:42:05, 14.44s/it]                                                     {'loss': 1.5735, 'grad_norm': 11.236699104309082, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 115, 'max_steps': 7272}
  2%|▏         | 115/7272 [28:30<28:42:05, 14.44s/it]  2%|▏         | 116/7272 [28:44<28:38:26, 14.41s/it]                                                     {'loss': 2.2615, 'grad_norm': 8.537403106689453, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 116, 'max_steps': 7272}
  2%|▏         | 116/7272 [28:44<28:38:26, 14.41s/it]  2%|▏         | 117/7272 [28:59<28:44:39, 14.46s/it]                                                     {'loss': 2.3073, 'grad_norm': 8.078463554382324, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 117, 'max_steps': 7272}
  2%|▏         | 117/7272 [28:59<28:44:39, 14.46s/it]  2%|▏         | 118/7272 [29:14<29:10:55, 14.68s/it]                                                     {'loss': 1.4407, 'grad_norm': 6.270085334777832, 'learning_rate': 5e-05, 'epoch': 0.06, 'step': 118, 'max_steps': 7272}
  2%|▏         | 118/7272 [29:14<29:10:55, 14.68s/it]  2%|▏         | 119/7272 [29:29<29:16:44, 14.74s/it]                                                     {'loss': 1.557, 'grad_norm': 8.310150146484375, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 119, 'max_steps': 7272}
  2%|▏         | 119/7272 [29:29<29:16:44, 14.74s/it]  2%|▏         | 120/7272 [29:44<29:17:58, 14.75s/it]                                                     {'loss': 2.0184, 'grad_norm': 7.724363327026367, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 120, 'max_steps': 7272}
  2%|▏         | 120/7272 [29:44<29:17:58, 14.75s/it]  2%|▏         | 121/7272 [29:59<29:42:04, 14.95s/it]                                                     {'loss': 0.7707, 'grad_norm': 5.460155487060547, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 121, 'max_steps': 7272}
  2%|▏         | 121/7272 [29:59<29:42:04, 14.95s/it]  2%|▏         | 122/7272 [30:14<29:47:11, 15.00s/it]                                                     {'loss': 1.7899, 'grad_norm': 9.89509391784668, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 122, 'max_steps': 7272}
  2%|▏         | 122/7272 [30:14<29:47:11, 15.00s/it]  2%|▏         | 123/7272 [30:29<29:26:08, 14.82s/it]                                                     {'loss': 2.1775, 'grad_norm': 17.094921112060547, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 123, 'max_steps': 7272}
  2%|▏         | 123/7272 [30:29<29:26:08, 14.82s/it]  2%|▏         | 124/7272 [30:44<29:35:01, 14.90s/it]                                                     {'loss': 2.7018, 'grad_norm': 14.818359375, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 124, 'max_steps': 7272}
  2%|▏         | 124/7272 [30:44<29:35:01, 14.90s/it]  2%|▏         | 125/7272 [30:58<29:19:39, 14.77s/it]                                                     {'loss': 1.4355, 'grad_norm': 8.742725372314453, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 125, 'max_steps': 7272}
  2%|▏         | 125/7272 [30:58<29:19:39, 14.77s/it]  2%|▏         | 126/7272 [31:13<29:23:30, 14.81s/it]                                                     {'loss': 3.0435, 'grad_norm': 15.487898826599121, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 126, 'max_steps': 7272}
  2%|▏         | 126/7272 [31:13<29:23:30, 14.81s/it]  2%|▏         | 127/7272 [31:28<29:14:18, 14.73s/it]                                                     {'loss': 1.0966, 'grad_norm': 9.168105125427246, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 127, 'max_steps': 7272}
  2%|▏         | 127/7272 [31:28<29:14:18, 14.73s/it]  2%|▏         | 128/7272 [31:43<29:35:17, 14.91s/it]                                                     {'loss': 1.0128, 'grad_norm': 4.730383396148682, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 128, 'max_steps': 7272}
  2%|▏         | 128/7272 [31:43<29:35:17, 14.91s/it]  2%|▏         | 129/7272 [31:58<29:19:32, 14.78s/it]                                                     {'loss': 2.0494, 'grad_norm': 7.038903713226318, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 129, 'max_steps': 7272}
  2%|▏         | 129/7272 [31:58<29:19:32, 14.78s/it]  2%|▏         | 130/7272 [32:13<29:44:33, 14.99s/it]                                                     {'loss': 1.593, 'grad_norm': 6.424543380737305, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 130, 'max_steps': 7272}
  2%|▏         | 130/7272 [32:13<29:44:33, 14.99s/it]  2%|▏         | 131/7272 [32:29<29:59:00, 15.12s/it]                                                     {'loss': 0.5507, 'grad_norm': 4.58970832824707, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 131, 'max_steps': 7272}
  2%|▏         | 131/7272 [32:29<29:59:00, 15.12s/it]  2%|▏         | 132/7272 [32:43<29:38:29, 14.95s/it]                                                     {'loss': 1.3679, 'grad_norm': 6.050034046173096, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 132, 'max_steps': 7272}
  2%|▏         | 132/7272 [32:43<29:38:29, 14.95s/it]  2%|▏         | 133/7272 [32:58<29:25:50, 14.84s/it]                                                     {'loss': 2.4414, 'grad_norm': 15.776723861694336, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 133, 'max_steps': 7272}
  2%|▏         | 133/7272 [32:58<29:25:50, 14.84s/it]  2%|▏         | 134/7272 [33:13<29:36:46, 14.94s/it]                                                     {'loss': 0.9456, 'grad_norm': 3.6423280239105225, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 134, 'max_steps': 7272}
  2%|▏         | 134/7272 [33:13<29:36:46, 14.94s/it]  2%|▏         | 135/7272 [33:28<29:39:25, 14.96s/it]                                                     {'loss': 1.1059, 'grad_norm': 4.231774806976318, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 135, 'max_steps': 7272}
  2%|▏         | 135/7272 [33:28<29:39:25, 14.96s/it]  2%|▏         | 136/7272 [33:42<29:23:34, 14.83s/it]                                                     {'loss': 1.8474, 'grad_norm': 13.285603523254395, 'learning_rate': 5e-05, 'epoch': 0.07, 'step': 136, 'max_steps': 7272}
  2%|▏         | 136/7272 [33:42<29:23:34, 14.83s/it]  2%|▏         | 137/7272 [33:57<29:29:10, 14.88s/it]                                                     {'loss': 2.0435, 'grad_norm': 11.637932777404785, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 137, 'max_steps': 7272}
  2%|▏         | 137/7272 [33:57<29:29:10, 14.88s/it]  2%|▏         | 138/7272 [34:14<30:16:14, 15.28s/it]                                                     {'loss': 2.6018, 'grad_norm': 10.661391258239746, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 138, 'max_steps': 7272}
  2%|▏         | 138/7272 [34:14<30:16:14, 15.28s/it]  2%|▏         | 139/7272 [34:29<30:09:17, 15.22s/it]                                                     {'loss': 1.1517, 'grad_norm': 4.151581287384033, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 139, 'max_steps': 7272}
  2%|▏         | 139/7272 [34:29<30:09:17, 15.22s/it]  2%|▏         | 140/7272 [34:44<30:22:37, 15.33s/it]                                                     {'loss': 1.0221, 'grad_norm': 3.730205535888672, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 140, 'max_steps': 7272}
  2%|▏         | 140/7272 [34:44<30:22:37, 15.33s/it]  2%|▏         | 141/7272 [34:59<30:01:36, 15.16s/it]                                                     {'loss': 1.232, 'grad_norm': 5.324657440185547, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 141, 'max_steps': 7272}
  2%|▏         | 141/7272 [34:59<30:01:36, 15.16s/it]  2%|▏         | 142/7272 [35:14<29:57:24, 15.13s/it]                                                     {'loss': 1.5156, 'grad_norm': 9.231927871704102, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 142, 'max_steps': 7272}
  2%|▏         | 142/7272 [35:14<29:57:24, 15.13s/it]  2%|▏         | 143/7272 [35:29<29:43:11, 15.01s/it]                                                     {'loss': 1.6843, 'grad_norm': 5.8824920654296875, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 143, 'max_steps': 7272}
  2%|▏         | 143/7272 [35:29<29:43:11, 15.01s/it]  2%|▏         | 144/7272 [35:43<29:27:33, 14.88s/it]                                                     {'loss': 1.3632, 'grad_norm': 4.174039363861084, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 144, 'max_steps': 7272}
  2%|▏         | 144/7272 [35:43<29:27:33, 14.88s/it]  2%|▏         | 145/7272 [35:58<29:31:32, 14.91s/it]                                                     {'loss': 1.1819, 'grad_norm': 5.277387619018555, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 145, 'max_steps': 7272}
  2%|▏         | 145/7272 [35:58<29:31:32, 14.91s/it]  2%|▏         | 146/7272 [36:13<29:34:11, 14.94s/it]                                                     {'loss': 1.6041, 'grad_norm': 10.384880065917969, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 146, 'max_steps': 7272}
  2%|▏         | 146/7272 [36:13<29:34:11, 14.94s/it]  2%|▏         | 147/7272 [36:29<29:45:42, 15.04s/it]                                                     {'loss': 1.728, 'grad_norm': 6.145702838897705, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 147, 'max_steps': 7272}
  2%|▏         | 147/7272 [36:29<29:45:42, 15.04s/it]  2%|▏         | 148/7272 [36:43<29:16:59, 14.80s/it]                                                     {'loss': 1.954, 'grad_norm': 5.948505878448486, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 148, 'max_steps': 7272}
  2%|▏         | 148/7272 [36:43<29:16:59, 14.80s/it]  2%|▏         | 149/7272 [36:57<28:52:32, 14.59s/it]                                                     {'loss': 1.0661, 'grad_norm': 5.893566131591797, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 149, 'max_steps': 7272}
  2%|▏         | 149/7272 [36:57<28:52:32, 14.59s/it]  2%|▏         | 150/7272 [37:11<28:36:47, 14.46s/it]                                                     {'loss': 1.4366, 'grad_norm': 4.436554908752441, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 150, 'max_steps': 7272}
  2%|▏         | 150/7272 [37:11<28:36:47, 14.46s/it]  2%|▏         | 151/7272 [37:25<28:32:26, 14.43s/it]                                                     {'loss': 1.2387, 'grad_norm': 5.388711452484131, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 151, 'max_steps': 7272}
  2%|▏         | 151/7272 [37:25<28:32:26, 14.43s/it]  2%|▏         | 152/7272 [37:40<28:40:53, 14.50s/it]                                                     {'loss': 1.9148, 'grad_norm': 7.019097328186035, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 152, 'max_steps': 7272}
  2%|▏         | 152/7272 [37:40<28:40:53, 14.50s/it]  2%|▏         | 153/7272 [37:55<29:03:01, 14.69s/it]                                                     {'loss': 0.964, 'grad_norm': 3.618434190750122, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 153, 'max_steps': 7272}
  2%|▏         | 153/7272 [37:55<29:03:01, 14.69s/it]  2%|▏         | 154/7272 [38:10<29:11:54, 14.77s/it]                                                     {'loss': 0.9439, 'grad_norm': 4.2830328941345215, 'learning_rate': 5e-05, 'epoch': 0.08, 'step': 154, 'max_steps': 7272}
  2%|▏         | 154/7272 [38:10<29:11:54, 14.77s/it]  2%|▏         | 155/7272 [38:25<28:56:58, 14.64s/it]                                                     {'loss': 2.5642, 'grad_norm': 7.475654602050781, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 155, 'max_steps': 7272}
  2%|▏         | 155/7272 [38:25<28:56:58, 14.64s/it]  2%|▏         | 156/7272 [38:39<28:53:32, 14.62s/it]                                                     {'loss': 1.5561, 'grad_norm': 6.366521835327148, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 156, 'max_steps': 7272}
  2%|▏         | 156/7272 [38:39<28:53:32, 14.62s/it]  2%|▏         | 157/7272 [38:53<28:42:10, 14.52s/it]                                                     {'loss': 0.7725, 'grad_norm': 2.8685953617095947, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 157, 'max_steps': 7272}
  2%|▏         | 157/7272 [38:53<28:42:10, 14.52s/it]  2%|▏         | 158/7272 [39:08<28:25:11, 14.38s/it]                                                     {'loss': 1.3731, 'grad_norm': 9.292486190795898, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 158, 'max_steps': 7272}
  2%|▏         | 158/7272 [39:08<28:25:11, 14.38s/it]  2%|▏         | 159/7272 [39:22<28:44:52, 14.55s/it]                                                     {'loss': 1.4546, 'grad_norm': 4.720722198486328, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 159, 'max_steps': 7272}
  2%|▏         | 159/7272 [39:22<28:44:52, 14.55s/it]  2%|▏         | 160/7272 [39:37<28:33:03, 14.45s/it]                                                     {'loss': 1.322, 'grad_norm': 5.712386608123779, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 160, 'max_steps': 7272}
  2%|▏         | 160/7272 [39:37<28:33:03, 14.45s/it]  2%|▏         | 161/7272 [39:51<28:30:23, 14.43s/it]                                                     {'loss': 1.2343, 'grad_norm': 4.101991653442383, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 161, 'max_steps': 7272}
  2%|▏         | 161/7272 [39:51<28:30:23, 14.43s/it]  2%|▏         | 162/7272 [40:06<28:35:03, 14.47s/it]                                                     {'loss': 1.0434, 'grad_norm': 3.2824296951293945, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 162, 'max_steps': 7272}
  2%|▏         | 162/7272 [40:06<28:35:03, 14.47s/it]  2%|▏         | 163/7272 [40:20<28:26:15, 14.40s/it]                                                     {'loss': 1.8258, 'grad_norm': 6.0933451652526855, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 163, 'max_steps': 7272}
  2%|▏         | 163/7272 [40:20<28:26:15, 14.40s/it]  2%|▏         | 164/7272 [40:34<28:16:30, 14.32s/it]                                                     {'loss': 2.0477, 'grad_norm': 6.041475772857666, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 164, 'max_steps': 7272}
  2%|▏         | 164/7272 [40:34<28:16:30, 14.32s/it]  2%|▏         | 165/7272 [40:48<28:03:04, 14.21s/it]                                                     {'loss': 1.7069, 'grad_norm': 7.9724249839782715, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 165, 'max_steps': 7272}
  2%|▏         | 165/7272 [40:48<28:03:04, 14.21s/it]  2%|▏         | 166/7272 [41:02<28:09:53, 14.27s/it]                                                     {'loss': 1.6293, 'grad_norm': 4.924060344696045, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 166, 'max_steps': 7272}
  2%|▏         | 166/7272 [41:02<28:09:53, 14.27s/it]  2%|▏         | 167/7272 [41:17<28:08:07, 14.26s/it]                                                     {'loss': 1.7542, 'grad_norm': 5.2672529220581055, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 167, 'max_steps': 7272}
  2%|▏         | 167/7272 [41:17<28:08:07, 14.26s/it]  2%|▏         | 168/7272 [41:31<28:13:45, 14.31s/it]                                                     {'loss': 0.8198, 'grad_norm': 3.7219550609588623, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 168, 'max_steps': 7272}
  2%|▏         | 168/7272 [41:31<28:13:45, 14.31s/it]  2%|▏         | 169/7272 [41:45<28:11:49, 14.29s/it]                                                     {'loss': 1.6064, 'grad_norm': 7.395267963409424, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 169, 'max_steps': 7272}
  2%|▏         | 169/7272 [41:45<28:11:49, 14.29s/it]  2%|▏         | 170/7272 [41:59<28:05:50, 14.24s/it]                                                     {'loss': 1.3991, 'grad_norm': 9.914052963256836, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 170, 'max_steps': 7272}
  2%|▏         | 170/7272 [41:59<28:05:50, 14.24s/it]  2%|▏         | 171/7272 [42:14<28:12:50, 14.30s/it]                                                     {'loss': 1.8674, 'grad_norm': 8.201295852661133, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 171, 'max_steps': 7272}
  2%|▏         | 171/7272 [42:14<28:12:50, 14.30s/it]  2%|▏         | 172/7272 [42:28<27:57:34, 14.18s/it]                                                     {'loss': 2.2393, 'grad_norm': 9.38188362121582, 'learning_rate': 5e-05, 'epoch': 0.09, 'step': 172, 'max_steps': 7272}
  2%|▏         | 172/7272 [42:28<27:57:34, 14.18s/it]  2%|▏         | 173/7272 [42:42<27:59:55, 14.20s/it]                                                     {'loss': 1.5044, 'grad_norm': 10.793437004089355, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 173, 'max_steps': 7272}
  2%|▏         | 173/7272 [42:42<27:59:55, 14.20s/it]  2%|▏         | 174/7272 [42:56<27:59:25, 14.20s/it]                                                     {'loss': 1.0274, 'grad_norm': 3.553328275680542, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 174, 'max_steps': 7272}
  2%|▏         | 174/7272 [42:56<27:59:25, 14.20s/it]  2%|▏         | 175/7272 [43:11<28:34:07, 14.49s/it]                                                     {'loss': 1.3118, 'grad_norm': 5.511435508728027, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 175, 'max_steps': 7272}
  2%|▏         | 175/7272 [43:11<28:34:07, 14.49s/it]  2%|▏         | 176/7272 [43:26<28:52:22, 14.65s/it]                                                     {'loss': 1.4327, 'grad_norm': 4.261745452880859, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 176, 'max_steps': 7272}
  2%|▏         | 176/7272 [43:26<28:52:22, 14.65s/it]  2%|▏         | 177/7272 [43:42<29:30:43, 14.97s/it]                                                     {'loss': 1.3943, 'grad_norm': 4.682779312133789, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 177, 'max_steps': 7272}
  2%|▏         | 177/7272 [43:42<29:30:43, 14.97s/it]  2%|▏         | 178/7272 [43:58<29:53:50, 15.17s/it]                                                     {'loss': 3.2713, 'grad_norm': 34.65723419189453, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 178, 'max_steps': 7272}
  2%|▏         | 178/7272 [43:58<29:53:50, 15.17s/it]  2%|▏         | 179/7272 [44:12<29:06:53, 14.78s/it]                                                     {'loss': 1.8595, 'grad_norm': 9.919469833374023, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 179, 'max_steps': 7272}
  2%|▏         | 179/7272 [44:12<29:06:53, 14.78s/it]  2%|▏         | 180/7272 [44:26<28:53:54, 14.67s/it]                                                     {'loss': 3.4844, 'grad_norm': 20.5427188873291, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 180, 'max_steps': 7272}
  2%|▏         | 180/7272 [44:26<28:53:54, 14.67s/it]  2%|▏         | 181/7272 [44:40<28:47:06, 14.61s/it]                                                     {'loss': 2.8417, 'grad_norm': 12.062582969665527, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 181, 'max_steps': 7272}
  2%|▏         | 181/7272 [44:40<28:47:06, 14.61s/it]  3%|▎         | 182/7272 [44:55<28:32:17, 14.49s/it]                                                     {'loss': 2.2441, 'grad_norm': 8.415760040283203, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 182, 'max_steps': 7272}
  3%|▎         | 182/7272 [44:55<28:32:17, 14.49s/it]  3%|▎         | 183/7272 [45:09<28:39:09, 14.55s/it]                                                     {'loss': 1.3258, 'grad_norm': 6.79232931137085, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 183, 'max_steps': 7272}
  3%|▎         | 183/7272 [45:09<28:39:09, 14.55s/it]  3%|▎         | 184/7272 [45:23<28:19:32, 14.39s/it]                                                     {'loss': 0.6645, 'grad_norm': 3.546086549758911, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 184, 'max_steps': 7272}
  3%|▎         | 184/7272 [45:23<28:19:32, 14.39s/it]  3%|▎         | 185/7272 [45:37<27:57:20, 14.20s/it]                                                     {'loss': 4.5116, 'grad_norm': 52.74398422241211, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 185, 'max_steps': 7272}
  3%|▎         | 185/7272 [45:37<27:57:20, 14.20s/it]  3%|▎         | 186/7272 [45:51<27:46:22, 14.11s/it]                                                     {'loss': 1.6734, 'grad_norm': 7.891808032989502, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 186, 'max_steps': 7272}
  3%|▎         | 186/7272 [45:51<27:46:22, 14.11s/it]  3%|▎         | 187/7272 [46:05<27:38:42, 14.05s/it]                                                     {'loss': 2.4427, 'grad_norm': 13.36418628692627, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 187, 'max_steps': 7272}
  3%|▎         | 187/7272 [46:05<27:38:42, 14.05s/it]  3%|▎         | 188/7272 [46:19<27:36:18, 14.03s/it]                                                     {'loss': 1.8279, 'grad_norm': 8.017396926879883, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 188, 'max_steps': 7272}
  3%|▎         | 188/7272 [46:19<27:36:18, 14.03s/it]  3%|▎         | 189/7272 [46:33<27:51:47, 14.16s/it]                                                     {'loss': 1.0657, 'grad_norm': 3.986440896987915, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 189, 'max_steps': 7272}
  3%|▎         | 189/7272 [46:33<27:51:47, 14.16s/it]  3%|▎         | 190/7272 [46:47<27:42:46, 14.09s/it]                                                     {'loss': 11.599, 'grad_norm': 113.44065856933594, 'learning_rate': 5e-05, 'epoch': 0.1, 'step': 190, 'max_steps': 7272}
  3%|▎         | 190/7272 [46:47<27:42:46, 14.09s/it]  3%|▎         | 191/7272 [47:02<28:01:13, 14.25s/it]                                                     {'loss': 2.1421, 'grad_norm': 7.37408971786499, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 191, 'max_steps': 7272}
  3%|▎         | 191/7272 [47:02<28:01:13, 14.25s/it]  3%|▎         | 192/7272 [47:17<28:35:47, 14.54s/it]                                                     {'loss': 1.4586, 'grad_norm': 11.452712059020996, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 192, 'max_steps': 7272}
  3%|▎         | 192/7272 [47:17<28:35:47, 14.54s/it]  3%|▎         | 193/7272 [47:32<28:42:12, 14.60s/it]                                                     {'loss': 0.7084, 'grad_norm': 3.41196346282959, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 193, 'max_steps': 7272}
  3%|▎         | 193/7272 [47:32<28:42:12, 14.60s/it]  3%|▎         | 194/7272 [47:46<28:17:49, 14.39s/it]                                                     {'loss': 1.556, 'grad_norm': 4.574460506439209, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 194, 'max_steps': 7272}
  3%|▎         | 194/7272 [47:46<28:17:49, 14.39s/it]  3%|▎         | 195/7272 [48:00<27:59:06, 14.24s/it]                                                     {'loss': 1.309, 'grad_norm': 4.859755039215088, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 195, 'max_steps': 7272}
  3%|▎         | 195/7272 [48:00<27:59:06, 14.24s/it]  3%|▎         | 196/7272 [48:13<27:39:37, 14.07s/it]                                                     {'loss': 1.3905, 'grad_norm': 4.402314186096191, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 196, 'max_steps': 7272}
  3%|▎         | 196/7272 [48:13<27:39:37, 14.07s/it]  3%|▎         | 197/7272 [48:27<27:35:31, 14.04s/it]                                                     {'loss': 1.1261, 'grad_norm': 3.661306381225586, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 197, 'max_steps': 7272}
  3%|▎         | 197/7272 [48:27<27:35:31, 14.04s/it]  3%|▎         | 198/7272 [48:41<27:15:15, 13.87s/it]                                                     {'loss': 0.54, 'grad_norm': 2.939650058746338, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 198, 'max_steps': 7272}
  3%|▎         | 198/7272 [48:41<27:15:15, 13.87s/it]  3%|▎         | 199/7272 [48:55<27:32:07, 14.01s/it]                                                     {'loss': 1.8407, 'grad_norm': 9.398811340332031, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 199, 'max_steps': 7272}
  3%|▎         | 199/7272 [48:55<27:32:07, 14.01s/it]  3%|▎         | 200/7272 [49:09<27:20:51, 13.92s/it]                                                     {'loss': 3.997, 'grad_norm': 129.88735961914062, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 200, 'max_steps': 7272}
  3%|▎         | 200/7272 [49:09<27:20:51, 13.92s/it]  3%|▎         | 201/7272 [49:23<27:26:48, 13.97s/it]                                                     {'loss': 1.4536, 'grad_norm': 3.838599920272827, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 201, 'max_steps': 7272}
  3%|▎         | 201/7272 [49:23<27:26:48, 13.97s/it]  3%|▎         | 202/7272 [49:38<28:00:08, 14.26s/it]                                                     {'loss': 3.0856, 'grad_norm': 13.87220573425293, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 202, 'max_steps': 7272}
  3%|▎         | 202/7272 [49:38<28:00:08, 14.26s/it]  3%|▎         | 203/7272 [49:52<27:45:45, 14.14s/it]                                                     {'loss': 5.2924, 'grad_norm': 49.892784118652344, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 203, 'max_steps': 7272}
  3%|▎         | 203/7272 [49:52<27:45:45, 14.14s/it]  3%|▎         | 204/7272 [50:06<27:40:27, 14.10s/it]                                                     {'loss': 4.814, 'grad_norm': 36.636104583740234, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 204, 'max_steps': 7272}
  3%|▎         | 204/7272 [50:06<27:40:27, 14.10s/it]  3%|▎         | 205/7272 [50:20<27:33:13, 14.04s/it]                                                     {'loss': 0.7971, 'grad_norm': 3.481398820877075, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 205, 'max_steps': 7272}
  3%|▎         | 205/7272 [50:20<27:33:13, 14.04s/it]  3%|▎         | 206/7272 [50:33<27:18:19, 13.91s/it]                                                     {'loss': 4.0563, 'grad_norm': 19.0614070892334, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 206, 'max_steps': 7272}
  3%|▎         | 206/7272 [50:33<27:18:19, 13.91s/it]  3%|▎         | 207/7272 [50:47<27:03:36, 13.79s/it]                                                     {'loss': 1.3966, 'grad_norm': 3.480039596557617, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 207, 'max_steps': 7272}
  3%|▎         | 207/7272 [50:47<27:03:36, 13.79s/it]  3%|▎         | 208/7272 [51:01<27:06:44, 13.82s/it]                                                     {'loss': 0.7174, 'grad_norm': 5.592469692230225, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 208, 'max_steps': 7272}
  3%|▎         | 208/7272 [51:01<27:06:44, 13.82s/it]  3%|▎         | 209/7272 [51:14<27:02:12, 13.78s/it]                                                     {'loss': 1.9616, 'grad_norm': 4.937421798706055, 'learning_rate': 5e-05, 'epoch': 0.11, 'step': 209, 'max_steps': 7272}
  3%|▎         | 209/7272 [51:14<27:02:12, 13.78s/it]  3%|▎         | 210/7272 [51:28<26:58:43, 13.75s/it]                                                     {'loss': 1.5652, 'grad_norm': 7.102169513702393, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 210, 'max_steps': 7272}
  3%|▎         | 210/7272 [51:28<26:58:43, 13.75s/it]  3%|▎         | 211/7272 [51:42<26:51:14, 13.69s/it]                                                     {'loss': 0.6329, 'grad_norm': 4.189650535583496, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 211, 'max_steps': 7272}
  3%|▎         | 211/7272 [51:42<26:51:14, 13.69s/it]  3%|▎         | 212/7272 [51:56<27:03:30, 13.80s/it]                                                     {'loss': 3.9644, 'grad_norm': 24.03689193725586, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 212, 'max_steps': 7272}
  3%|▎         | 212/7272 [51:56<27:03:30, 13.80s/it]  3%|▎         | 213/7272 [52:10<27:11:39, 13.87s/it]                                                     {'loss': 1.481, 'grad_norm': 5.50778341293335, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 213, 'max_steps': 7272}
  3%|▎         | 213/7272 [52:10<27:11:39, 13.87s/it]  3%|▎         | 214/7272 [52:24<27:17:32, 13.92s/it]                                                     {'loss': 3.7642, 'grad_norm': 17.771060943603516, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 214, 'max_steps': 7272}
  3%|▎         | 214/7272 [52:24<27:17:32, 13.92s/it]  3%|▎         | 215/7272 [52:38<27:19:29, 13.94s/it]                                                     {'loss': 1.6228, 'grad_norm': 5.68642520904541, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 215, 'max_steps': 7272}
  3%|▎         | 215/7272 [52:38<27:19:29, 13.94s/it]  3%|▎         | 216/7272 [52:52<27:32:23, 14.05s/it]                                                     {'loss': 4.407, 'grad_norm': 17.562362670898438, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 216, 'max_steps': 7272}
  3%|▎         | 216/7272 [52:52<27:32:23, 14.05s/it]  3%|▎         | 217/7272 [53:07<27:49:24, 14.20s/it]                                                     {'loss': 4.1464, 'grad_norm': 14.47620964050293, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 217, 'max_steps': 7272}
  3%|▎         | 217/7272 [53:07<27:49:24, 14.20s/it]  3%|▎         | 218/7272 [53:21<27:48:15, 14.19s/it]                                                     {'loss': 2.0423, 'grad_norm': 6.932353496551514, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 218, 'max_steps': 7272}
  3%|▎         | 218/7272 [53:21<27:48:15, 14.19s/it]  3%|▎         | 219/7272 [53:34<27:25:55, 14.00s/it]                                                     {'loss': 2.2826, 'grad_norm': 5.740944862365723, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 219, 'max_steps': 7272}
  3%|▎         | 219/7272 [53:34<27:25:55, 14.00s/it]  3%|▎         | 220/7272 [53:48<27:09:39, 13.87s/it]                                                     {'loss': 1.8103, 'grad_norm': 6.910403728485107, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 220, 'max_steps': 7272}
  3%|▎         | 220/7272 [53:48<27:09:39, 13.87s/it]  3%|▎         | 221/7272 [54:02<27:12:26, 13.89s/it]                                                     {'loss': 2.1238, 'grad_norm': 8.2460298538208, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 221, 'max_steps': 7272}
  3%|▎         | 221/7272 [54:02<27:12:26, 13.89s/it]  3%|▎         | 222/7272 [54:16<27:08:01, 13.86s/it]                                                     {'loss': 2.7897, 'grad_norm': 7.971696376800537, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 222, 'max_steps': 7272}
  3%|▎         | 222/7272 [54:16<27:08:01, 13.86s/it]  3%|▎         | 223/7272 [54:30<27:13:03, 13.90s/it]                                                     {'loss': 1.4045, 'grad_norm': 7.296838283538818, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 223, 'max_steps': 7272}
  3%|▎         | 223/7272 [54:30<27:13:03, 13.90s/it]  3%|▎         | 224/7272 [54:43<27:06:55, 13.85s/it]                                                     {'loss': 3.0813, 'grad_norm': 13.547369003295898, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 224, 'max_steps': 7272}
  3%|▎         | 224/7272 [54:43<27:06:55, 13.85s/it]  3%|▎         | 225/7272 [54:57<26:45:43, 13.67s/it]                                                     {'loss': 3.376, 'grad_norm': 15.201173782348633, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 225, 'max_steps': 7272}
  3%|▎         | 225/7272 [54:57<26:45:43, 13.67s/it]  3%|▎         | 226/7272 [55:10<26:35:29, 13.59s/it]                                                     {'loss': 1.0515, 'grad_norm': 7.970248222351074, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 226, 'max_steps': 7272}
  3%|▎         | 226/7272 [55:10<26:35:29, 13.59s/it]  3%|▎         | 227/7272 [55:23<26:30:37, 13.55s/it]                                                     {'loss': 2.2796, 'grad_norm': 9.792236328125, 'learning_rate': 5e-05, 'epoch': 0.12, 'step': 227, 'max_steps': 7272}
  3%|▎         | 227/7272 [55:23<26:30:37, 13.55s/it]  3%|▎         | 228/7272 [55:37<26:29:34, 13.54s/it]                                                     {'loss': 1.0249, 'grad_norm': 3.118478298187256, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 228, 'max_steps': 7272}
  3%|▎         | 228/7272 [55:37<26:29:34, 13.54s/it]  3%|▎         | 229/7272 [55:50<26:27:36, 13.53s/it]                                                     {'loss': 4.1871, 'grad_norm': 21.28046989440918, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 229, 'max_steps': 7272}
  3%|▎         | 229/7272 [55:50<26:27:36, 13.53s/it]  3%|▎         | 230/7272 [56:04<26:44:48, 13.67s/it]                                                     {'loss': 1.7232, 'grad_norm': 5.272274971008301, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 230, 'max_steps': 7272}
  3%|▎         | 230/7272 [56:04<26:44:48, 13.67s/it]  3%|▎         | 231/7272 [56:18<26:47:29, 13.70s/it]                                                     {'loss': 4.01, 'grad_norm': 18.2673397064209, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 231, 'max_steps': 7272}
  3%|▎         | 231/7272 [56:18<26:47:29, 13.70s/it]  3%|▎         | 232/7272 [56:31<26:33:14, 13.58s/it]                                                     {'loss': 1.1293, 'grad_norm': 5.12024450302124, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 232, 'max_steps': 7272}
  3%|▎         | 232/7272 [56:31<26:33:14, 13.58s/it]  3%|▎         | 233/7272 [56:45<26:35:35, 13.60s/it]                                                     {'loss': 2.5087, 'grad_norm': 16.342309951782227, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 233, 'max_steps': 7272}
  3%|▎         | 233/7272 [56:45<26:35:35, 13.60s/it]  3%|▎         | 234/7272 [56:59<26:50:49, 13.73s/it]                                                     {'loss': 2.0999, 'grad_norm': 6.6759033203125, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 234, 'max_steps': 7272}
  3%|▎         | 234/7272 [56:59<26:50:49, 13.73s/it]  3%|▎         | 235/7272 [57:13<27:10:54, 13.91s/it]                                                     {'loss': 1.7542, 'grad_norm': 9.916098594665527, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 235, 'max_steps': 7272}
  3%|▎         | 235/7272 [57:13<27:10:54, 13.91s/it]  3%|▎         | 236/7272 [57:27<27:01:23, 13.83s/it]                                                     {'loss': 4.1678, 'grad_norm': 16.966646194458008, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 236, 'max_steps': 7272}
  3%|▎         | 236/7272 [57:27<27:01:23, 13.83s/it]  3%|▎         | 237/7272 [57:41<27:06:26, 13.87s/it]                                                     {'loss': 2.6325, 'grad_norm': 11.825980186462402, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 237, 'max_steps': 7272}
  3%|▎         | 237/7272 [57:41<27:06:26, 13.87s/it]  3%|▎         | 238/7272 [57:55<27:21:39, 14.00s/it]                                                     {'loss': 2.2224, 'grad_norm': 7.294282913208008, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 238, 'max_steps': 7272}
  3%|▎         | 238/7272 [57:55<27:21:39, 14.00s/it]  3%|▎         | 239/7272 [58:09<27:22:16, 14.01s/it]                                                     {'loss': 2.1091, 'grad_norm': 5.000151634216309, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 239, 'max_steps': 7272}
  3%|▎         | 239/7272 [58:09<27:22:16, 14.01s/it]  3%|▎         | 240/7272 [58:23<27:07:16, 13.88s/it]                                                     {'loss': 1.4851, 'grad_norm': 4.904093265533447, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 240, 'max_steps': 7272}
  3%|▎         | 240/7272 [58:23<27:07:16, 13.88s/it]  3%|▎         | 241/7272 [58:37<27:09:17, 13.90s/it]                                                     {'loss': 1.3224, 'grad_norm': 7.85861873626709, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 241, 'max_steps': 7272}
  3%|▎         | 241/7272 [58:37<27:09:17, 13.90s/it]  3%|▎         | 242/7272 [58:51<27:11:49, 13.93s/it]                                                     {'loss': 1.7466, 'grad_norm': 6.092296123504639, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 242, 'max_steps': 7272}
  3%|▎         | 242/7272 [58:51<27:11:49, 13.93s/it]  3%|▎         | 243/7272 [59:05<27:14:29, 13.95s/it]                                                     {'loss': 4.0499, 'grad_norm': 14.334747314453125, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 243, 'max_steps': 7272}
  3%|▎         | 243/7272 [59:05<27:14:29, 13.95s/it]  3%|▎         | 244/7272 [59:19<27:08:07, 13.90s/it]                                                     {'loss': 6.0673, 'grad_norm': 16.0830135345459, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 244, 'max_steps': 7272}
  3%|▎         | 244/7272 [59:19<27:08:07, 13.90s/it]  3%|▎         | 245/7272 [59:33<27:21:11, 14.01s/it]                                                     {'loss': 1.1761, 'grad_norm': 6.274576663970947, 'learning_rate': 5e-05, 'epoch': 0.13, 'step': 245, 'max_steps': 7272}
  3%|▎         | 245/7272 [59:33<27:21:11, 14.01s/it]  3%|▎         | 246/7272 [59:47<27:15:09, 13.96s/it]                                                     {'loss': 3.8173, 'grad_norm': 11.706113815307617, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 246, 'max_steps': 7272}
  3%|▎         | 246/7272 [59:47<27:15:09, 13.96s/it]  3%|▎         | 247/7272 [1:00:01<27:05:39, 13.88s/it]                                                       {'loss': 4.2886, 'grad_norm': 16.36287498474121, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 247, 'max_steps': 7272}
  3%|▎         | 247/7272 [1:00:01<27:05:39, 13.88s/it]  3%|▎         | 248/7272 [1:00:15<27:18:14, 13.99s/it]                                                       {'loss': 0.6948, 'grad_norm': 2.8210368156433105, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 248, 'max_steps': 7272}
  3%|▎         | 248/7272 [1:00:15<27:18:14, 13.99s/it]  3%|▎         | 249/7272 [1:00:28<27:06:23, 13.89s/it]                                                       {'loss': 1.6617, 'grad_norm': 7.49921989440918, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 249, 'max_steps': 7272}
  3%|▎         | 249/7272 [1:00:28<27:06:23, 13.89s/it]  3%|▎         | 250/7272 [1:00:42<26:54:46, 13.80s/it]                                                       {'loss': 0.9354, 'grad_norm': 6.345138072967529, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 250, 'max_steps': 7272}
  3%|▎         | 250/7272 [1:00:42<26:54:46, 13.80s/it]  3%|▎         | 251/7272 [1:00:56<26:48:38, 13.75s/it]                                                       {'loss': 3.0147, 'grad_norm': 9.048276901245117, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 251, 'max_steps': 7272}
  3%|▎         | 251/7272 [1:00:56<26:48:38, 13.75s/it]  3%|▎         | 252/7272 [1:01:09<26:42:01, 13.69s/it]                                                       {'loss': 1.3637, 'grad_norm': 5.752386569976807, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 252, 'max_steps': 7272}
  3%|▎         | 252/7272 [1:01:09<26:42:01, 13.69s/it]  3%|▎         | 253/7272 [1:01:23<26:46:44, 13.73s/it]                                                       {'loss': 2.8693, 'grad_norm': 10.058611869812012, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 253, 'max_steps': 7272}
  3%|▎         | 253/7272 [1:01:23<26:46:44, 13.73s/it]  3%|▎         | 254/7272 [1:01:37<26:51:49, 13.78s/it]                                                       {'loss': 2.7603, 'grad_norm': 8.825026512145996, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 254, 'max_steps': 7272}
  3%|▎         | 254/7272 [1:01:37<26:51:49, 13.78s/it]  4%|▎         | 255/7272 [1:01:51<27:00:17, 13.85s/it]                                                       {'loss': 4.2729, 'grad_norm': 16.37775421142578, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 255, 'max_steps': 7272}
  4%|▎         | 255/7272 [1:01:51<27:00:17, 13.85s/it]  4%|▎         | 256/7272 [1:02:05<26:56:53, 13.83s/it]                                                       {'loss': 1.2222, 'grad_norm': 6.438465118408203, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 256, 'max_steps': 7272}
  4%|▎         | 256/7272 [1:02:05<26:56:53, 13.83s/it]  4%|▎         | 257/7272 [1:02:19<27:03:45, 13.89s/it]                                                       {'loss': 1.6171, 'grad_norm': 5.551499843597412, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 257, 'max_steps': 7272}
  4%|▎         | 257/7272 [1:02:19<27:03:45, 13.89s/it]  4%|▎         | 258/7272 [1:02:33<27:05:25, 13.90s/it]                                                       {'loss': 1.6514, 'grad_norm': 6.03608512878418, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 258, 'max_steps': 7272}
  4%|▎         | 258/7272 [1:02:33<27:05:25, 13.90s/it]  4%|▎         | 259/7272 [1:02:47<27:22:09, 14.05s/it]                                                       {'loss': 1.4528, 'grad_norm': 4.232077598571777, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 259, 'max_steps': 7272}
  4%|▎         | 259/7272 [1:02:47<27:22:09, 14.05s/it]  4%|▎         | 260/7272 [1:03:01<27:14:41, 13.99s/it]                                                       {'loss': 2.3996, 'grad_norm': 8.268945693969727, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 260, 'max_steps': 7272}
  4%|▎         | 260/7272 [1:03:01<27:14:41, 13.99s/it]  4%|▎         | 261/7272 [1:03:15<27:06:04, 13.92s/it]                                                       {'loss': 1.2417, 'grad_norm': 8.720701217651367, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 261, 'max_steps': 7272}
  4%|▎         | 261/7272 [1:03:15<27:06:04, 13.92s/it]  4%|▎         | 262/7272 [1:03:28<27:00:07, 13.87s/it]                                                       {'loss': 5.5203, 'grad_norm': 14.577574729919434, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 262, 'max_steps': 7272}
  4%|▎         | 262/7272 [1:03:28<27:00:07, 13.87s/it]  4%|▎         | 263/7272 [1:03:42<27:02:02, 13.89s/it]                                                       {'loss': 5.2282, 'grad_norm': 14.904088020324707, 'learning_rate': 5e-05, 'epoch': 0.14, 'step': 263, 'max_steps': 7272}
  4%|▎         | 263/7272 [1:03:42<27:02:02, 13.89s/it]  4%|▎         | 264/7272 [1:03:56<26:40:32, 13.70s/it]                                                       {'loss': 2.944, 'grad_norm': 8.02425765991211, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 264, 'max_steps': 7272}
  4%|▎         | 264/7272 [1:03:56<26:40:32, 13.70s/it]  4%|▎         | 265/7272 [1:04:09<26:41:04, 13.71s/it]                                                       {'loss': 1.9123, 'grad_norm': 4.738691806793213, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 265, 'max_steps': 7272}
  4%|▎         | 265/7272 [1:04:09<26:41:04, 13.71s/it]  4%|▎         | 266/7272 [1:04:23<26:48:08, 13.77s/it]                                                       {'loss': 1.7187, 'grad_norm': 3.7342898845672607, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 266, 'max_steps': 7272}
  4%|▎         | 266/7272 [1:04:23<26:48:08, 13.77s/it]  4%|▎         | 267/7272 [1:04:37<26:53:37, 13.82s/it]                                                       {'loss': 2.1832, 'grad_norm': 15.001655578613281, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 267, 'max_steps': 7272}
  4%|▎         | 267/7272 [1:04:37<26:53:37, 13.82s/it]  4%|▎         | 268/7272 [1:04:51<27:06:14, 13.93s/it]                                                       {'loss': 1.2092, 'grad_norm': 4.298085689544678, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 268, 'max_steps': 7272}
  4%|▎         | 268/7272 [1:04:51<27:06:14, 13.93s/it]  4%|▎         | 269/7272 [1:05:06<27:30:15, 14.14s/it]                                                       {'loss': 2.3622, 'grad_norm': 7.976037502288818, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 269, 'max_steps': 7272}
  4%|▎         | 269/7272 [1:05:06<27:30:15, 14.14s/it]  4%|▎         | 270/7272 [1:05:20<27:36:12, 14.19s/it]                                                       {'loss': 0.9943, 'grad_norm': 3.7844719886779785, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 270, 'max_steps': 7272}
  4%|▎         | 270/7272 [1:05:20<27:36:12, 14.19s/it]  4%|▎         | 271/7272 [1:05:34<27:28:03, 14.12s/it]                                                       {'loss': 2.3679, 'grad_norm': 6.953563213348389, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 271, 'max_steps': 7272}
  4%|▎         | 271/7272 [1:05:34<27:28:03, 14.12s/it]  4%|▎         | 272/7272 [1:05:49<27:41:43, 14.24s/it]                                                       {'loss': 4.3974, 'grad_norm': 13.795639038085938, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 272, 'max_steps': 7272}
  4%|▎         | 272/7272 [1:05:49<27:41:43, 14.24s/it]  4%|▍         | 273/7272 [1:06:04<28:01:05, 14.41s/it]                                                       {'loss': 2.2629, 'grad_norm': 11.721076965332031, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 273, 'max_steps': 7272}
  4%|▍         | 273/7272 [1:06:04<28:01:05, 14.41s/it]  4%|▍         | 274/7272 [1:06:18<27:53:43, 14.35s/it]                                                       {'loss': 1.3848, 'grad_norm': 13.765573501586914, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 274, 'max_steps': 7272}
  4%|▍         | 274/7272 [1:06:18<27:53:43, 14.35s/it]  4%|▍         | 275/7272 [1:06:32<27:55:48, 14.37s/it]                                                       {'loss': 1.463, 'grad_norm': 3.7037978172302246, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 275, 'max_steps': 7272}
  4%|▍         | 275/7272 [1:06:32<27:55:48, 14.37s/it]  4%|▍         | 276/7272 [1:06:46<27:46:12, 14.29s/it]                                                       {'loss': 1.9231, 'grad_norm': 5.1104512214660645, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 276, 'max_steps': 7272}
  4%|▍         | 276/7272 [1:06:46<27:46:12, 14.29s/it]  4%|▍         | 277/7272 [1:07:01<27:50:09, 14.33s/it]                                                       {'loss': 2.2316, 'grad_norm': 7.382981300354004, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 277, 'max_steps': 7272}
  4%|▍         | 277/7272 [1:07:01<27:50:09, 14.33s/it]  4%|▍         | 278/7272 [1:07:15<27:50:08, 14.33s/it]                                                       {'loss': 1.8539, 'grad_norm': 10.980304718017578, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 278, 'max_steps': 7272}
  4%|▍         | 278/7272 [1:07:15<27:50:08, 14.33s/it]  4%|▍         | 279/7272 [1:07:29<27:38:11, 14.23s/it]                                                       {'loss': 2.1663, 'grad_norm': 7.353618144989014, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 279, 'max_steps': 7272}
  4%|▍         | 279/7272 [1:07:29<27:38:11, 14.23s/it]  4%|▍         | 280/7272 [1:07:43<27:21:59, 14.09s/it]                                                       {'loss': 2.3102, 'grad_norm': 11.835865020751953, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 280, 'max_steps': 7272}
  4%|▍         | 280/7272 [1:07:43<27:21:59, 14.09s/it]  4%|▍         | 281/7272 [1:07:57<27:21:33, 14.09s/it]                                                       {'loss': 2.4296, 'grad_norm': 12.780913352966309, 'learning_rate': 5e-05, 'epoch': 0.15, 'step': 281, 'max_steps': 7272}
  4%|▍         | 281/7272 [1:07:57<27:21:33, 14.09s/it]  4%|▍         | 282/7272 [1:08:11<27:23:00, 14.10s/it]                                                       {'loss': 1.4406, 'grad_norm': 5.158437252044678, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 282, 'max_steps': 7272}
  4%|▍         | 282/7272 [1:08:11<27:23:00, 14.10s/it]  4%|▍         | 283/7272 [1:08:25<27:26:58, 14.14s/it]                                                       {'loss': 2.1795, 'grad_norm': 5.366135597229004, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 283, 'max_steps': 7272}
  4%|▍         | 283/7272 [1:08:25<27:26:58, 14.14s/it]  4%|▍         | 284/7272 [1:08:39<27:18:15, 14.07s/it]                                                       {'loss': 1.5031, 'grad_norm': 4.093980312347412, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 284, 'max_steps': 7272}
  4%|▍         | 284/7272 [1:08:39<27:18:15, 14.07s/it]  4%|▍         | 285/7272 [1:08:54<28:00:44, 14.43s/it]                                                       {'loss': 2.0583, 'grad_norm': 7.300534248352051, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 285, 'max_steps': 7272}
  4%|▍         | 285/7272 [1:08:54<28:00:44, 14.43s/it]  4%|▍         | 286/7272 [1:09:09<28:18:18, 14.59s/it]                                                       {'loss': 1.1945, 'grad_norm': 3.3962109088897705, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 286, 'max_steps': 7272}
  4%|▍         | 286/7272 [1:09:09<28:18:18, 14.59s/it]  4%|▍         | 287/7272 [1:09:24<28:33:52, 14.72s/it]                                                       {'loss': 4.2634, 'grad_norm': 17.650806427001953, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 287, 'max_steps': 7272}
  4%|▍         | 287/7272 [1:09:24<28:33:52, 14.72s/it]  4%|▍         | 288/7272 [1:09:40<29:17:57, 15.10s/it]                                                       {'loss': 1.2638, 'grad_norm': 2.877124786376953, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 288, 'max_steps': 7272}
  4%|▍         | 288/7272 [1:09:40<29:17:57, 15.10s/it]  4%|▍         | 289/7272 [1:09:56<29:43:52, 15.33s/it]                                                       {'loss': 2.0328, 'grad_norm': 8.924214363098145, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 289, 'max_steps': 7272}
  4%|▍         | 289/7272 [1:09:56<29:43:52, 15.33s/it]  4%|▍         | 290/7272 [1:10:11<29:27:17, 15.19s/it]                                                       {'loss': 2.2161, 'grad_norm': 3.877017021179199, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 290, 'max_steps': 7272}
  4%|▍         | 290/7272 [1:10:11<29:27:17, 15.19s/it]  4%|▍         | 291/7272 [1:10:26<29:22:29, 15.15s/it]                                                       {'loss': 1.1144, 'grad_norm': 4.031960964202881, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 291, 'max_steps': 7272}
  4%|▍         | 291/7272 [1:10:26<29:22:29, 15.15s/it]  4%|▍         | 292/7272 [1:10:41<29:23:31, 15.16s/it]                                                       {'loss': 2.5492, 'grad_norm': 8.945773124694824, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 292, 'max_steps': 7272}
  4%|▍         | 292/7272 [1:10:41<29:23:31, 15.16s/it]  4%|▍         | 293/7272 [1:10:56<29:05:24, 15.01s/it]                                                       {'loss': 1.4928, 'grad_norm': 6.07611083984375, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 293, 'max_steps': 7272}
  4%|▍         | 293/7272 [1:10:56<29:05:24, 15.01s/it]  4%|▍         | 294/7272 [1:11:12<29:28:06, 15.20s/it]                                                       {'loss': 2.8274, 'grad_norm': 4.976508617401123, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 294, 'max_steps': 7272}
  4%|▍         | 294/7272 [1:11:12<29:28:06, 15.20s/it]  4%|▍         | 295/7272 [1:11:26<28:58:54, 14.95s/it]                                                       {'loss': 0.8675, 'grad_norm': 6.958408832550049, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 295, 'max_steps': 7272}
  4%|▍         | 295/7272 [1:11:26<28:58:54, 14.95s/it]  4%|▍         | 296/7272 [1:11:40<28:33:39, 14.74s/it]                                                       {'loss': 2.2117, 'grad_norm': 14.917981147766113, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 296, 'max_steps': 7272}
  4%|▍         | 296/7272 [1:11:40<28:33:39, 14.74s/it]  4%|▍         | 297/7272 [1:11:54<28:06:09, 14.50s/it]                                                       {'loss': 0.6497, 'grad_norm': 4.585915565490723, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 297, 'max_steps': 7272}
  4%|▍         | 297/7272 [1:11:54<28:06:09, 14.50s/it]  4%|▍         | 298/7272 [1:12:08<27:44:26, 14.32s/it]                                                       {'loss': 1.2242, 'grad_norm': 5.501834392547607, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 298, 'max_steps': 7272}
  4%|▍         | 298/7272 [1:12:08<27:44:26, 14.32s/it]  4%|▍         | 299/7272 [1:12:22<27:36:19, 14.25s/it]                                                       {'loss': 4.2376, 'grad_norm': 7.853780746459961, 'learning_rate': 5e-05, 'epoch': 0.16, 'step': 299, 'max_steps': 7272}
  4%|▍         | 299/7272 [1:12:22<27:36:19, 14.25s/it]  4%|▍         | 300/7272 [1:12:37<27:40:06, 14.29s/it]                                                       {'loss': 1.2316, 'grad_norm': 4.5984086990356445, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 300, 'max_steps': 7272}
  4%|▍         | 300/7272 [1:12:37<27:40:06, 14.29s/it]  4%|▍         | 301/7272 [1:12:51<27:29:47, 14.20s/it]                                                       {'loss': 2.5043, 'grad_norm': 11.281768798828125, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 301, 'max_steps': 7272}
  4%|▍         | 301/7272 [1:12:51<27:29:47, 14.20s/it]  4%|▍         | 302/7272 [1:13:05<27:26:22, 14.17s/it]                                                       {'loss': 3.5171, 'grad_norm': 11.656645774841309, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 302, 'max_steps': 7272}
  4%|▍         | 302/7272 [1:13:05<27:26:22, 14.17s/it]  4%|▍         | 303/7272 [1:13:19<27:14:35, 14.07s/it]                                                       {'loss': 2.1795, 'grad_norm': 10.196487426757812, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 303, 'max_steps': 7272}
  4%|▍         | 303/7272 [1:13:19<27:14:35, 14.07s/it]  4%|▍         | 304/7272 [1:13:33<27:15:26, 14.08s/it]                                                       {'loss': 2.6573, 'grad_norm': 7.128594398498535, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 304, 'max_steps': 7272}
  4%|▍         | 304/7272 [1:13:33<27:15:26, 14.08s/it]  4%|▍         | 305/7272 [1:13:46<27:01:06, 13.96s/it]                                                       {'loss': 2.7283, 'grad_norm': 10.147492408752441, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 305, 'max_steps': 7272}
  4%|▍         | 305/7272 [1:13:46<27:01:06, 13.96s/it]  4%|▍         | 306/7272 [1:14:00<26:45:53, 13.83s/it]                                                       {'loss': 2.734, 'grad_norm': 9.962230682373047, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 306, 'max_steps': 7272}
  4%|▍         | 306/7272 [1:14:00<26:45:53, 13.83s/it]  4%|▍         | 307/7272 [1:14:13<26:36:37, 13.75s/it]                                                       {'loss': 2.7164, 'grad_norm': 8.865468978881836, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 307, 'max_steps': 7272}
  4%|▍         | 307/7272 [1:14:13<26:36:37, 13.75s/it]  4%|▍         | 308/7272 [1:14:28<26:52:22, 13.89s/it]                                                       {'loss': 1.895, 'grad_norm': 4.40006160736084, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 308, 'max_steps': 7272}
  4%|▍         | 308/7272 [1:14:28<26:52:22, 13.89s/it]  4%|▍         | 309/7272 [1:14:42<26:51:21, 13.89s/it]                                                       {'loss': 3.1674, 'grad_norm': 10.669328689575195, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 309, 'max_steps': 7272}
  4%|▍         | 309/7272 [1:14:42<26:51:21, 13.89s/it]  4%|▍         | 310/7272 [1:14:56<26:57:21, 13.94s/it]                                                       {'loss': 2.7567, 'grad_norm': 6.277400016784668, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 310, 'max_steps': 7272}
  4%|▍         | 310/7272 [1:14:56<26:57:21, 13.94s/it]  4%|▍         | 311/7272 [1:15:10<27:19:27, 14.13s/it]                                                       {'loss': 1.7685, 'grad_norm': 9.306041717529297, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 311, 'max_steps': 7272}
  4%|▍         | 311/7272 [1:15:10<27:19:27, 14.13s/it]  4%|▍         | 312/7272 [1:15:24<27:20:32, 14.14s/it]                                                       {'loss': 1.1032, 'grad_norm': 3.0886101722717285, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 312, 'max_steps': 7272}
  4%|▍         | 312/7272 [1:15:24<27:20:32, 14.14s/it]  4%|▍         | 313/7272 [1:15:38<27:10:38, 14.06s/it]                                                       {'loss': 1.5188, 'grad_norm': 4.822258949279785, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 313, 'max_steps': 7272}
  4%|▍         | 313/7272 [1:15:38<27:10:38, 14.06s/it]  4%|▍         | 314/7272 [1:15:52<27:09:19, 14.05s/it]                                                       {'loss': 1.2802, 'grad_norm': 10.669026374816895, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 314, 'max_steps': 7272}
  4%|▍         | 314/7272 [1:15:52<27:09:19, 14.05s/it]  4%|▍         | 315/7272 [1:16:06<27:11:55, 14.07s/it]                                                       {'loss': 0.9693, 'grad_norm': 4.536483287811279, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 315, 'max_steps': 7272}
  4%|▍         | 315/7272 [1:16:06<27:11:55, 14.07s/it]  4%|▍         | 316/7272 [1:16:20<26:59:55, 13.97s/it]                                                       {'loss': 4.1239, 'grad_norm': 15.917792320251465, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 316, 'max_steps': 7272}
  4%|▍         | 316/7272 [1:16:20<26:59:55, 13.97s/it]  4%|▍         | 317/7272 [1:16:35<27:27:01, 14.21s/it]                                                       {'loss': 2.5056, 'grad_norm': 11.89824390411377, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 317, 'max_steps': 7272}
  4%|▍         | 317/7272 [1:16:35<27:27:01, 14.21s/it]  4%|▍         | 318/7272 [1:16:49<27:22:50, 14.17s/it]                                                       {'loss': 1.291, 'grad_norm': 3.447781562805176, 'learning_rate': 5e-05, 'epoch': 0.17, 'step': 318, 'max_steps': 7272}
  4%|▍         | 318/7272 [1:16:49<27:22:50, 14.17s/it]  4%|▍         | 319/7272 [1:17:04<27:36:19, 14.29s/it]                                                       {'loss': 1.4059, 'grad_norm': 4.273403167724609, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 319, 'max_steps': 7272}
  4%|▍         | 319/7272 [1:17:04<27:36:19, 14.29s/it]  4%|▍         | 320/7272 [1:17:18<27:29:41, 14.24s/it]                                                       {'loss': 4.0961, 'grad_norm': 9.970919609069824, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 320, 'max_steps': 7272}
  4%|▍         | 320/7272 [1:17:18<27:29:41, 14.24s/it]  4%|▍         | 321/7272 [1:17:32<27:25:51, 14.21s/it]                                                       {'loss': 1.1693, 'grad_norm': 3.342283248901367, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 321, 'max_steps': 7272}
  4%|▍         | 321/7272 [1:17:32<27:25:51, 14.21s/it]  4%|▍         | 322/7272 [1:17:45<27:07:24, 14.05s/it]                                                       {'loss': 1.3104, 'grad_norm': 9.27507495880127, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 322, 'max_steps': 7272}
  4%|▍         | 322/7272 [1:17:45<27:07:24, 14.05s/it]  4%|▍         | 323/7272 [1:18:00<27:07:45, 14.05s/it]                                                       {'loss': 2.667, 'grad_norm': 7.308370590209961, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 323, 'max_steps': 7272}
  4%|▍         | 323/7272 [1:18:00<27:07:45, 14.05s/it]  4%|▍         | 324/7272 [1:18:14<27:21:38, 14.18s/it]                                                       {'loss': 1.1845, 'grad_norm': 6.112703800201416, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 324, 'max_steps': 7272}
  4%|▍         | 324/7272 [1:18:14<27:21:38, 14.18s/it]  4%|▍         | 325/7272 [1:18:29<27:33:54, 14.28s/it]                                                       {'loss': 2.7499, 'grad_norm': 13.55606460571289, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 325, 'max_steps': 7272}
  4%|▍         | 325/7272 [1:18:29<27:33:54, 14.28s/it]  4%|▍         | 326/7272 [1:18:43<27:22:09, 14.19s/it]                                                       {'loss': 2.9096, 'grad_norm': 7.953252792358398, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 326, 'max_steps': 7272}
  4%|▍         | 326/7272 [1:18:43<27:22:09, 14.19s/it]  4%|▍         | 327/7272 [1:18:57<27:41:21, 14.35s/it]                                                       {'loss': 2.3868, 'grad_norm': 8.954549789428711, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 327, 'max_steps': 7272}
  4%|▍         | 327/7272 [1:18:57<27:41:21, 14.35s/it]  5%|▍         | 328/7272 [1:19:11<27:37:00, 14.32s/it]                                                       {'loss': 2.5731, 'grad_norm': 11.293658256530762, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 328, 'max_steps': 7272}
  5%|▍         | 328/7272 [1:19:11<27:37:00, 14.32s/it]  5%|▍         | 329/7272 [1:19:26<27:28:30, 14.25s/it]                                                       {'loss': 2.0825, 'grad_norm': 11.071843147277832, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 329, 'max_steps': 7272}
  5%|▍         | 329/7272 [1:19:26<27:28:30, 14.25s/it]  5%|▍         | 330/7272 [1:19:40<27:41:23, 14.36s/it]                                                       {'loss': 0.8399, 'grad_norm': 9.860236167907715, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 330, 'max_steps': 7272}
  5%|▍         | 330/7272 [1:19:40<27:41:23, 14.36s/it]  5%|▍         | 331/7272 [1:19:55<27:49:21, 14.43s/it]                                                       {'loss': 1.9697, 'grad_norm': 37.319122314453125, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 331, 'max_steps': 7272}
  5%|▍         | 331/7272 [1:19:55<27:49:21, 14.43s/it]  5%|▍         | 332/7272 [1:20:09<27:54:55, 14.48s/it]                                                       {'loss': 1.8541, 'grad_norm': 9.342894554138184, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 332, 'max_steps': 7272}
  5%|▍         | 332/7272 [1:20:09<27:54:55, 14.48s/it]  5%|▍         | 333/7272 [1:20:24<27:54:35, 14.48s/it]                                                       {'loss': 3.2642, 'grad_norm': 59.09232711791992, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 333, 'max_steps': 7272}
  5%|▍         | 333/7272 [1:20:24<27:54:35, 14.48s/it]  5%|▍         | 334/7272 [1:20:38<27:54:49, 14.48s/it]                                                       {'loss': 1.84, 'grad_norm': 6.953193664550781, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 334, 'max_steps': 7272}
  5%|▍         | 334/7272 [1:20:38<27:54:49, 14.48s/it]  5%|▍         | 335/7272 [1:20:53<27:49:07, 14.44s/it]                                                       {'loss': 1.8142, 'grad_norm': 10.493277549743652, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 335, 'max_steps': 7272}
  5%|▍         | 335/7272 [1:20:53<27:49:07, 14.44s/it]  5%|▍         | 336/7272 [1:21:07<27:49:39, 14.44s/it]                                                       {'loss': 1.6798, 'grad_norm': 5.841590404510498, 'learning_rate': 5e-05, 'epoch': 0.18, 'step': 336, 'max_steps': 7272}
  5%|▍         | 336/7272 [1:21:07<27:49:39, 14.44s/it]  5%|▍         | 337/7272 [1:21:22<28:08:07, 14.61s/it]                                                       {'loss': 1.6197, 'grad_norm': 35.3611946105957, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 337, 'max_steps': 7272}
  5%|▍         | 337/7272 [1:21:22<28:08:07, 14.61s/it]  5%|▍         | 338/7272 [1:21:37<28:19:32, 14.71s/it]                                                       {'loss': 2.2245, 'grad_norm': 7.983638763427734, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 338, 'max_steps': 7272}
  5%|▍         | 338/7272 [1:21:37<28:19:32, 14.71s/it]  5%|▍         | 339/7272 [1:21:52<28:11:30, 14.64s/it]                                                       {'loss': 0.7947, 'grad_norm': 3.679177761077881, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 339, 'max_steps': 7272}
  5%|▍         | 339/7272 [1:21:52<28:11:30, 14.64s/it]  5%|▍         | 340/7272 [1:22:06<27:59:52, 14.54s/it]                                                       {'loss': 2.5444, 'grad_norm': 9.669377326965332, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 340, 'max_steps': 7272}
  5%|▍         | 340/7272 [1:22:06<27:59:52, 14.54s/it]  5%|▍         | 341/7272 [1:22:20<27:49:57, 14.46s/it]                                                       {'loss': 2.3059, 'grad_norm': 9.112629890441895, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 341, 'max_steps': 7272}
  5%|▍         | 341/7272 [1:22:20<27:49:57, 14.46s/it]  5%|▍         | 342/7272 [1:22:35<28:01:18, 14.56s/it]                                                       {'loss': 1.2536, 'grad_norm': 5.222654342651367, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 342, 'max_steps': 7272}
  5%|▍         | 342/7272 [1:22:35<28:01:18, 14.56s/it]  5%|▍         | 343/7272 [1:22:50<28:12:24, 14.65s/it]                                                       {'loss': 1.9687, 'grad_norm': 5.945489406585693, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 343, 'max_steps': 7272}
  5%|▍         | 343/7272 [1:22:50<28:12:24, 14.65s/it]  5%|▍         | 344/7272 [1:23:04<27:57:42, 14.53s/it]                                                       {'loss': 3.5608, 'grad_norm': 6.2698445320129395, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 344, 'max_steps': 7272}
  5%|▍         | 344/7272 [1:23:04<27:57:42, 14.53s/it]  5%|▍         | 345/7272 [1:23:19<28:03:00, 14.58s/it]                                                       {'loss': 4.0762, 'grad_norm': 10.759760856628418, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 345, 'max_steps': 7272}
  5%|▍         | 345/7272 [1:23:19<28:03:00, 14.58s/it]  5%|▍         | 346/7272 [1:23:33<28:06:12, 14.61s/it]                                                       {'loss': 1.7744, 'grad_norm': 5.205944538116455, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 346, 'max_steps': 7272}
  5%|▍         | 346/7272 [1:23:33<28:06:12, 14.61s/it]  5%|▍         | 347/7272 [1:23:48<28:18:27, 14.72s/it]                                                       {'loss': 1.1182, 'grad_norm': 3.762125015258789, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 347, 'max_steps': 7272}
  5%|▍         | 347/7272 [1:23:48<28:18:27, 14.72s/it]  5%|▍         | 348/7272 [1:24:03<28:16:04, 14.70s/it]                                                       {'loss': 2.1187, 'grad_norm': 30.701608657836914, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 348, 'max_steps': 7272}
  5%|▍         | 348/7272 [1:24:03<28:16:04, 14.70s/it]  5%|▍         | 349/7272 [1:24:19<28:46:21, 14.96s/it]                                                       {'loss': 2.2168, 'grad_norm': 5.4550395011901855, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 349, 'max_steps': 7272}
  5%|▍         | 349/7272 [1:24:19<28:46:21, 14.96s/it]  5%|▍         | 350/7272 [1:24:34<28:50:41, 15.00s/it]                                                       {'loss': 1.5434, 'grad_norm': 10.70139217376709, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 350, 'max_steps': 7272}
  5%|▍         | 350/7272 [1:24:34<28:50:41, 15.00s/it]  5%|▍         | 351/7272 [1:24:49<28:58:52, 15.07s/it]                                                       {'loss': 1.8804, 'grad_norm': 6.4870100021362305, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 351, 'max_steps': 7272}
  5%|▍         | 351/7272 [1:24:49<28:58:52, 15.07s/it]  5%|▍         | 352/7272 [1:25:04<28:55:10, 15.04s/it]                                                       {'loss': 2.0132, 'grad_norm': 9.667372703552246, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 352, 'max_steps': 7272}
  5%|▍         | 352/7272 [1:25:04<28:55:10, 15.04s/it]  5%|▍         | 353/7272 [1:25:18<28:21:54, 14.76s/it]                                                       {'loss': 3.163, 'grad_norm': 8.186952590942383, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 353, 'max_steps': 7272}
  5%|▍         | 353/7272 [1:25:18<28:21:54, 14.76s/it]  5%|▍         | 354/7272 [1:25:32<28:11:06, 14.67s/it]                                                       {'loss': 1.3457, 'grad_norm': 5.922789573669434, 'learning_rate': 5e-05, 'epoch': 0.19, 'step': 354, 'max_steps': 7272}
  5%|▍         | 354/7272 [1:25:32<28:11:06, 14.67s/it]  5%|▍         | 355/7272 [1:25:47<28:16:04, 14.71s/it]                                                       {'loss': 2.4137, 'grad_norm': 12.942760467529297, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 355, 'max_steps': 7272}
  5%|▍         | 355/7272 [1:25:47<28:16:04, 14.71s/it]  5%|▍         | 356/7272 [1:26:02<28:23:10, 14.78s/it]                                                       {'loss': 1.1309, 'grad_norm': 4.855690002441406, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 356, 'max_steps': 7272}
  5%|▍         | 356/7272 [1:26:02<28:23:10, 14.78s/it]  5%|▍         | 357/7272 [1:26:17<28:10:31, 14.67s/it]                                                       {'loss': 1.4361, 'grad_norm': 4.64033317565918, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 357, 'max_steps': 7272}
  5%|▍         | 357/7272 [1:26:17<28:10:31, 14.67s/it]  5%|▍         | 358/7272 [1:26:31<28:03:00, 14.61s/it]                                                       {'loss': 2.4344, 'grad_norm': 7.625976085662842, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 358, 'max_steps': 7272}
  5%|▍         | 358/7272 [1:26:31<28:03:00, 14.61s/it]  5%|▍         | 359/7272 [1:26:46<28:00:33, 14.59s/it]                                                       {'loss': 4.1477, 'grad_norm': 15.776861190795898, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 359, 'max_steps': 7272}
  5%|▍         | 359/7272 [1:26:46<28:00:33, 14.59s/it]  5%|▍         | 360/7272 [1:27:00<28:02:41, 14.61s/it]                                                       {'loss': 0.6994, 'grad_norm': 2.7812387943267822, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 360, 'max_steps': 7272}
  5%|▍         | 360/7272 [1:27:00<28:02:41, 14.61s/it]  5%|▍         | 361/7272 [1:27:15<27:50:30, 14.50s/it]                                                       {'loss': 1.6011, 'grad_norm': 6.889727592468262, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 361, 'max_steps': 7272}
  5%|▍         | 361/7272 [1:27:15<27:50:30, 14.50s/it]  5%|▍         | 362/7272 [1:27:29<27:47:39, 14.48s/it]                                                       {'loss': 3.6309, 'grad_norm': 13.054069519042969, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 362, 'max_steps': 7272}
  5%|▍         | 362/7272 [1:27:29<27:47:39, 14.48s/it]  5%|▍         | 363/7272 [1:27:43<27:20:02, 14.24s/it]                                                       {'loss': 3.1414, 'grad_norm': 12.60816764831543, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 363, 'max_steps': 7272}
  5%|▍         | 363/7272 [1:27:43<27:20:02, 14.24s/it]  5%|▌         | 364/7272 [1:27:57<27:15:06, 14.20s/it]                                                       {'loss': 0.9076, 'grad_norm': 4.695769786834717, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 364, 'max_steps': 7272}
  5%|▌         | 364/7272 [1:27:57<27:15:06, 14.20s/it]  5%|▌         | 365/7272 [1:28:10<26:56:23, 14.04s/it]                                                       {'loss': 2.6537, 'grad_norm': 10.337989807128906, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 365, 'max_steps': 7272}
  5%|▌         | 365/7272 [1:28:10<26:56:23, 14.04s/it]  5%|▌         | 366/7272 [1:28:24<26:53:16, 14.02s/it]                                                       {'loss': 2.8616, 'grad_norm': 9.783426284790039, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 366, 'max_steps': 7272}
  5%|▌         | 366/7272 [1:28:24<26:53:16, 14.02s/it]  5%|▌         | 367/7272 [1:28:38<26:32:51, 13.84s/it]                                                       {'loss': 3.0576, 'grad_norm': 19.719703674316406, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 367, 'max_steps': 7272}
  5%|▌         | 367/7272 [1:28:38<26:32:51, 13.84s/it]  5%|▌         | 368/7272 [1:28:52<26:34:39, 13.86s/it]                                                       {'loss': 3.2392, 'grad_norm': 11.013681411743164, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 368, 'max_steps': 7272}
  5%|▌         | 368/7272 [1:28:52<26:34:39, 13.86s/it]  5%|▌         | 369/7272 [1:29:06<26:53:09, 14.02s/it]                                                       {'loss': 1.9844, 'grad_norm': 11.001015663146973, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 369, 'max_steps': 7272}
  5%|▌         | 369/7272 [1:29:06<26:53:09, 14.02s/it]  5%|▌         | 370/7272 [1:29:20<26:50:51, 14.00s/it]                                                       {'loss': 3.9249, 'grad_norm': 9.329217910766602, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 370, 'max_steps': 7272}
  5%|▌         | 370/7272 [1:29:20<26:50:51, 14.00s/it]  5%|▌         | 371/7272 [1:29:34<26:49:40, 14.00s/it]                                                       {'loss': 3.1175, 'grad_norm': 8.202581405639648, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 371, 'max_steps': 7272}
  5%|▌         | 371/7272 [1:29:34<26:49:40, 14.00s/it]  5%|▌         | 372/7272 [1:29:48<26:41:39, 13.93s/it]                                                       {'loss': 1.8021, 'grad_norm': 5.968024730682373, 'learning_rate': 5e-05, 'epoch': 0.2, 'step': 372, 'max_steps': 7272}
  5%|▌         | 372/7272 [1:29:48<26:41:39, 13.93s/it]  5%|▌         | 373/7272 [1:30:03<27:13:52, 14.21s/it]                                                       {'loss': 2.0097, 'grad_norm': 5.2980875968933105, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 373, 'max_steps': 7272}
  5%|▌         | 373/7272 [1:30:03<27:13:52, 14.21s/it]  5%|▌         | 374/7272 [1:30:17<27:33:21, 14.38s/it]                                                       {'loss': 1.5317, 'grad_norm': 7.8692708015441895, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 374, 'max_steps': 7272}
  5%|▌         | 374/7272 [1:30:17<27:33:21, 14.38s/it]  5%|▌         | 375/7272 [1:30:32<27:31:26, 14.37s/it]                                                       {'loss': 1.8886, 'grad_norm': 10.86049747467041, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 375, 'max_steps': 7272}
  5%|▌         | 375/7272 [1:30:32<27:31:26, 14.37s/it]  5%|▌         | 376/7272 [1:30:47<28:00:24, 14.62s/it]                                                       {'loss': 2.6842, 'grad_norm': 8.18871021270752, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 376, 'max_steps': 7272}
  5%|▌         | 376/7272 [1:30:47<28:00:24, 14.62s/it]  5%|▌         | 377/7272 [1:31:02<28:16:53, 14.77s/it]                                                       {'loss': 0.8087, 'grad_norm': 5.159738540649414, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 377, 'max_steps': 7272}
  5%|▌         | 377/7272 [1:31:02<28:16:53, 14.77s/it]  5%|▌         | 378/7272 [1:31:17<28:33:32, 14.91s/it]                                                       {'loss': 2.1991, 'grad_norm': 8.427648544311523, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 378, 'max_steps': 7272}
  5%|▌         | 378/7272 [1:31:17<28:33:32, 14.91s/it]  5%|▌         | 379/7272 [1:31:32<28:31:38, 14.90s/it]                                                       {'loss': 1.2723, 'grad_norm': 6.04705810546875, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 379, 'max_steps': 7272}
  5%|▌         | 379/7272 [1:31:32<28:31:38, 14.90s/it]  5%|▌         | 380/7272 [1:31:48<28:54:17, 15.10s/it]                                                       {'loss': 1.3409, 'grad_norm': 3.7885754108428955, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 380, 'max_steps': 7272}
  5%|▌         | 380/7272 [1:31:48<28:54:17, 15.10s/it]  5%|▌         | 381/7272 [1:32:03<28:54:50, 15.11s/it]                                                       {'loss': 0.8265, 'grad_norm': 6.642829418182373, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 381, 'max_steps': 7272}
  5%|▌         | 381/7272 [1:32:03<28:54:50, 15.11s/it]  5%|▌         | 382/7272 [1:32:17<28:33:42, 14.92s/it]                                                       {'loss': 2.3573, 'grad_norm': 8.613615989685059, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 382, 'max_steps': 7272}
  5%|▌         | 382/7272 [1:32:17<28:33:42, 14.92s/it]  5%|▌         | 383/7272 [1:32:32<28:05:08, 14.68s/it]                                                       {'loss': 2.3022, 'grad_norm': 9.61804485321045, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 383, 'max_steps': 7272}
  5%|▌         | 383/7272 [1:32:32<28:05:08, 14.68s/it]  5%|▌         | 384/7272 [1:32:46<27:46:21, 14.52s/it]                                                       {'loss': 1.8578, 'grad_norm': 10.327369689941406, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 384, 'max_steps': 7272}
  5%|▌         | 384/7272 [1:32:46<27:46:21, 14.52s/it]  5%|▌         | 385/7272 [1:33:00<27:53:18, 14.58s/it]                                                       {'loss': 3.3548, 'grad_norm': 6.140810012817383, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 385, 'max_steps': 7272}
  5%|▌         | 385/7272 [1:33:00<27:53:18, 14.58s/it]  5%|▌         | 386/7272 [1:33:15<27:48:07, 14.53s/it]                                                       {'loss': 1.1351, 'grad_norm': 7.640758037567139, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 386, 'max_steps': 7272}
  5%|▌         | 386/7272 [1:33:15<27:48:07, 14.53s/it]  5%|▌         | 387/7272 [1:33:29<27:48:00, 14.54s/it]                                                       {'loss': 1.3293, 'grad_norm': 5.147012233734131, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 387, 'max_steps': 7272}
  5%|▌         | 387/7272 [1:33:29<27:48:00, 14.54s/it]  5%|▌         | 388/7272 [1:33:44<27:40:27, 14.47s/it]                                                       {'loss': 2.1386, 'grad_norm': 6.37098503112793, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 388, 'max_steps': 7272}
  5%|▌         | 388/7272 [1:33:44<27:40:27, 14.47s/it]  5%|▌         | 389/7272 [1:33:58<27:39:50, 14.47s/it]                                                       {'loss': 1.297, 'grad_norm': 4.069746017456055, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 389, 'max_steps': 7272}
  5%|▌         | 389/7272 [1:33:58<27:39:50, 14.47s/it]  5%|▌         | 390/7272 [1:34:13<27:49:50, 14.56s/it]                                                       {'loss': 1.8544, 'grad_norm': 5.864978790283203, 'learning_rate': 5e-05, 'epoch': 0.21, 'step': 390, 'max_steps': 7272}
  5%|▌         | 390/7272 [1:34:13<27:49:50, 14.56s/it]  5%|▌         | 391/7272 [1:34:29<28:28:03, 14.89s/it]                                                       {'loss': 2.3556, 'grad_norm': 9.674705505371094, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 391, 'max_steps': 7272}
  5%|▌         | 391/7272 [1:34:29<28:28:03, 14.89s/it]  5%|▌         | 392/7272 [1:34:44<28:46:51, 15.06s/it]                                                       {'loss': 3.0091, 'grad_norm': 9.127867698669434, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 392, 'max_steps': 7272}
  5%|▌         | 392/7272 [1:34:44<28:46:51, 15.06s/it]  5%|▌         | 393/7272 [1:34:59<28:43:24, 15.03s/it]                                                       {'loss': 2.6823, 'grad_norm': 14.122477531433105, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 393, 'max_steps': 7272}
  5%|▌         | 393/7272 [1:34:59<28:43:24, 15.03s/it]  5%|▌         | 394/7272 [1:35:14<28:47:47, 15.07s/it]                                                       {'loss': 3.935, 'grad_norm': 14.810002326965332, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 394, 'max_steps': 7272}
  5%|▌         | 394/7272 [1:35:14<28:47:47, 15.07s/it]  5%|▌         | 395/7272 [1:35:29<28:54:35, 15.13s/it]                                                       {'loss': 0.841, 'grad_norm': 4.7106242179870605, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 395, 'max_steps': 7272}
  5%|▌         | 395/7272 [1:35:29<28:54:35, 15.13s/it]  5%|▌         | 396/7272 [1:35:45<29:03:23, 15.21s/it]                                                       {'loss': 3.2584, 'grad_norm': 9.624184608459473, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 396, 'max_steps': 7272}
  5%|▌         | 396/7272 [1:35:45<29:03:23, 15.21s/it]  5%|▌         | 397/7272 [1:36:00<28:44:28, 15.05s/it]                                                       {'loss': 1.8167, 'grad_norm': 4.938673496246338, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 397, 'max_steps': 7272}
  5%|▌         | 397/7272 [1:36:00<28:44:28, 15.05s/it]  5%|▌         | 398/7272 [1:36:14<28:32:06, 14.94s/it]                                                       {'loss': 2.6667, 'grad_norm': 7.879093170166016, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 398, 'max_steps': 7272}
  5%|▌         | 398/7272 [1:36:14<28:32:06, 14.94s/it]  5%|▌         | 399/7272 [1:36:29<28:38:57, 15.01s/it]                                                       {'loss': 3.4962, 'grad_norm': 6.765812397003174, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 399, 'max_steps': 7272}
  5%|▌         | 399/7272 [1:36:29<28:38:57, 15.01s/it]  6%|▌         | 400/7272 [1:36:44<28:28:13, 14.91s/it]                                                       {'loss': 1.2861, 'grad_norm': 8.560807228088379, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 400, 'max_steps': 7272}
  6%|▌         | 400/7272 [1:36:44<28:28:13, 14.91s/it]  6%|▌         | 401/7272 [1:36:59<28:36:00, 14.98s/it]                                                       {'loss': 2.0874, 'grad_norm': 12.540216445922852, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 401, 'max_steps': 7272}
  6%|▌         | 401/7272 [1:36:59<28:36:00, 14.98s/it]  6%|▌         | 402/7272 [1:37:14<28:45:02, 15.07s/it]                                                       {'loss': 3.738, 'grad_norm': 8.94019889831543, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 402, 'max_steps': 7272}
  6%|▌         | 402/7272 [1:37:14<28:45:02, 15.07s/it]  6%|▌         | 403/7272 [1:37:30<29:16:06, 15.34s/it]                                                       {'loss': 3.2422, 'grad_norm': 10.40999698638916, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 403, 'max_steps': 7272}
  6%|▌         | 403/7272 [1:37:30<29:16:06, 15.34s/it]  6%|▌         | 404/7272 [1:37:46<29:38:39, 15.54s/it]                                                       {'loss': 1.2781, 'grad_norm': 5.1487040519714355, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 404, 'max_steps': 7272}
  6%|▌         | 404/7272 [1:37:46<29:38:39, 15.54s/it]  6%|▌         | 405/7272 [1:38:02<29:49:58, 15.64s/it]                                                       {'loss': 2.8597, 'grad_norm': 32.73809051513672, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 405, 'max_steps': 7272}
  6%|▌         | 405/7272 [1:38:02<29:49:58, 15.64s/it]  6%|▌         | 406/7272 [1:38:18<29:48:05, 15.63s/it]                                                       {'loss': 0.4924, 'grad_norm': 3.04417085647583, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 406, 'max_steps': 7272}
  6%|▌         | 406/7272 [1:38:18<29:48:05, 15.63s/it]  6%|▌         | 407/7272 [1:38:33<29:27:41, 15.45s/it]                                                       {'loss': 1.0515, 'grad_norm': 6.267602443695068, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 407, 'max_steps': 7272}
  6%|▌         | 407/7272 [1:38:33<29:27:41, 15.45s/it]  6%|▌         | 408/7272 [1:38:48<29:26:24, 15.44s/it]                                                       {'loss': 2.457, 'grad_norm': 5.495951175689697, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 408, 'max_steps': 7272}
  6%|▌         | 408/7272 [1:38:48<29:26:24, 15.44s/it]  6%|▌         | 409/7272 [1:39:04<29:20:13, 15.39s/it]                                                       {'loss': 4.6934, 'grad_norm': 7.401059150695801, 'learning_rate': 5e-05, 'epoch': 0.22, 'step': 409, 'max_steps': 7272}
  6%|▌         | 409/7272 [1:39:04<29:20:13, 15.39s/it]  6%|▌         | 410/7272 [1:39:20<29:45:51, 15.62s/it]                                                       {'loss': 5.703, 'grad_norm': 14.525230407714844, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 410, 'max_steps': 7272}
  6%|▌         | 410/7272 [1:39:20<29:45:51, 15.62s/it]  6%|▌         | 411/7272 [1:39:35<29:17:08, 15.37s/it]                                                       {'loss': 2.3087, 'grad_norm': 5.681232929229736, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 411, 'max_steps': 7272}
  6%|▌         | 411/7272 [1:39:35<29:17:08, 15.37s/it]  6%|▌         | 412/7272 [1:39:50<29:12:20, 15.33s/it]                                                       {'loss': 2.3905, 'grad_norm': 5.260189533233643, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 412, 'max_steps': 7272}
  6%|▌         | 412/7272 [1:39:50<29:12:20, 15.33s/it]  6%|▌         | 413/7272 [1:40:05<29:01:21, 15.23s/it]                                                       {'loss': 2.9651, 'grad_norm': 7.0780229568481445, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 413, 'max_steps': 7272}
  6%|▌         | 413/7272 [1:40:05<29:01:21, 15.23s/it]  6%|▌         | 414/7272 [1:40:20<29:07:19, 15.29s/it]                                                       {'loss': 1.8855, 'grad_norm': 5.880055904388428, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 414, 'max_steps': 7272}
  6%|▌         | 414/7272 [1:40:20<29:07:19, 15.29s/it]  6%|▌         | 415/7272 [1:40:35<28:37:39, 15.03s/it]                                                       {'loss': 1.8098, 'grad_norm': 10.698714256286621, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 415, 'max_steps': 7272}
  6%|▌         | 415/7272 [1:40:35<28:37:39, 15.03s/it]  6%|▌         | 416/7272 [1:40:49<28:13:53, 14.82s/it]                                                       {'loss': 2.6035, 'grad_norm': 5.83768367767334, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 416, 'max_steps': 7272}
  6%|▌         | 416/7272 [1:40:49<28:13:53, 14.82s/it]  6%|▌         | 417/7272 [1:41:04<28:04:00, 14.74s/it]                                                       {'loss': 1.2651, 'grad_norm': 4.646015167236328, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 417, 'max_steps': 7272}
  6%|▌         | 417/7272 [1:41:04<28:04:00, 14.74s/it]  6%|▌         | 418/7272 [1:41:19<28:17:01, 14.86s/it]                                                       {'loss': 3.3952, 'grad_norm': 11.090031623840332, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 418, 'max_steps': 7272}
  6%|▌         | 418/7272 [1:41:19<28:17:01, 14.86s/it]  6%|▌         | 419/7272 [1:41:34<28:24:23, 14.92s/it]                                                       {'loss': 3.4082, 'grad_norm': 12.179656028747559, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 419, 'max_steps': 7272}
  6%|▌         | 419/7272 [1:41:34<28:24:23, 14.92s/it]  6%|▌         | 420/7272 [1:41:48<28:13:05, 14.83s/it]                                                       {'loss': 1.73, 'grad_norm': 5.194935321807861, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 420, 'max_steps': 7272}
  6%|▌         | 420/7272 [1:41:48<28:13:05, 14.83s/it]  6%|▌         | 421/7272 [1:42:04<28:52:16, 15.17s/it]                                                       {'loss': 1.893, 'grad_norm': 8.407591819763184, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 421, 'max_steps': 7272}
  6%|▌         | 421/7272 [1:42:04<28:52:16, 15.17s/it]  6%|▌         | 422/7272 [1:42:20<29:07:24, 15.31s/it]                                                       {'loss': 3.7113, 'grad_norm': 10.168715476989746, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 422, 'max_steps': 7272}
  6%|▌         | 422/7272 [1:42:20<29:07:24, 15.31s/it]  6%|▌         | 423/7272 [1:42:35<28:52:59, 15.18s/it]                                                       {'loss': 2.1466, 'grad_norm': 8.219392776489258, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 423, 'max_steps': 7272}
  6%|▌         | 423/7272 [1:42:35<28:52:59, 15.18s/it]  6%|▌         | 424/7272 [1:42:49<28:34:34, 15.02s/it]                                                       {'loss': 1.8525, 'grad_norm': 7.679617881774902, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 424, 'max_steps': 7272}
  6%|▌         | 424/7272 [1:42:50<28:34:34, 15.02s/it]  6%|▌         | 425/7272 [1:43:05<28:48:40, 15.15s/it]                                                       {'loss': 3.1627, 'grad_norm': 11.913045883178711, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 425, 'max_steps': 7272}
  6%|▌         | 425/7272 [1:43:05<28:48:40, 15.15s/it]  6%|▌         | 426/7272 [1:43:19<28:26:45, 14.96s/it]                                                       {'loss': 3.4237, 'grad_norm': 8.451197624206543, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 426, 'max_steps': 7272}
  6%|▌         | 426/7272 [1:43:19<28:26:45, 14.96s/it]  6%|▌         | 427/7272 [1:43:34<28:29:06, 14.98s/it]                                                       {'loss': 1.245, 'grad_norm': 7.66385555267334, 'learning_rate': 5e-05, 'epoch': 0.23, 'step': 427, 'max_steps': 7272}
  6%|▌         | 427/7272 [1:43:34<28:29:06, 14.98s/it]  6%|▌         | 428/7272 [1:43:49<28:27:33, 14.97s/it]                                                       {'loss': 4.6038, 'grad_norm': 11.153885841369629, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 428, 'max_steps': 7272}
  6%|▌         | 428/7272 [1:43:49<28:27:33, 14.97s/it]  6%|▌         | 429/7272 [1:44:05<28:30:54, 15.00s/it]                                                       {'loss': 1.6644, 'grad_norm': 8.150559425354004, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 429, 'max_steps': 7272}
  6%|▌         | 429/7272 [1:44:05<28:30:54, 15.00s/it]  6%|▌         | 430/7272 [1:44:19<28:13:40, 14.85s/it]                                                       {'loss': 2.5982, 'grad_norm': 6.939259052276611, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 430, 'max_steps': 7272}
  6%|▌         | 430/7272 [1:44:19<28:13:40, 14.85s/it]  6%|▌         | 431/7272 [1:44:33<27:48:49, 14.64s/it]                                                       {'loss': 1.072, 'grad_norm': 8.222938537597656, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 431, 'max_steps': 7272}
  6%|▌         | 431/7272 [1:44:33<27:48:49, 14.64s/it]  6%|▌         | 432/7272 [1:44:48<28:09:17, 14.82s/it]                                                       {'loss': 1.4521, 'grad_norm': 6.326460361480713, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 432, 'max_steps': 7272}
  6%|▌         | 432/7272 [1:44:48<28:09:17, 14.82s/it]  6%|▌         | 433/7272 [1:45:04<28:21:01, 14.92s/it]                                                       {'loss': 1.1508, 'grad_norm': 5.008474826812744, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 433, 'max_steps': 7272}
  6%|▌         | 433/7272 [1:45:04<28:21:01, 14.92s/it]  6%|▌         | 434/7272 [1:45:18<28:20:20, 14.92s/it]                                                       {'loss': 1.0869, 'grad_norm': 3.001422882080078, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 434, 'max_steps': 7272}
  6%|▌         | 434/7272 [1:45:18<28:20:20, 14.92s/it]  6%|▌         | 435/7272 [1:45:33<28:16:10, 14.89s/it]                                                       {'loss': 0.4118, 'grad_norm': 2.07092547416687, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 435, 'max_steps': 7272}
  6%|▌         | 435/7272 [1:45:33<28:16:10, 14.89s/it]  6%|▌         | 436/7272 [1:45:48<28:23:44, 14.95s/it]                                                       {'loss': 1.7308, 'grad_norm': 6.043412685394287, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 436, 'max_steps': 7272}
  6%|▌         | 436/7272 [1:45:48<28:23:44, 14.95s/it]  6%|▌         | 437/7272 [1:46:03<28:24:40, 14.96s/it]                                                       {'loss': 1.1075, 'grad_norm': 4.7894673347473145, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 437, 'max_steps': 7272}
  6%|▌         | 437/7272 [1:46:03<28:24:40, 14.96s/it]  6%|▌         | 438/7272 [1:46:18<28:23:53, 14.96s/it]                                                       {'loss': 2.9055, 'grad_norm': 13.623449325561523, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 438, 'max_steps': 7272}
  6%|▌         | 438/7272 [1:46:18<28:23:53, 14.96s/it]  6%|▌         | 439/7272 [1:46:34<28:58:02, 15.26s/it]                                                       {'loss': 1.2393, 'grad_norm': 4.293355941772461, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 439, 'max_steps': 7272}
  6%|▌         | 439/7272 [1:46:34<28:58:02, 15.26s/it]  6%|▌         | 440/7272 [1:46:50<29:24:16, 15.49s/it]                                                       {'loss': 2.115, 'grad_norm': 6.199102878570557, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 440, 'max_steps': 7272}
  6%|▌         | 440/7272 [1:46:50<29:24:16, 15.49s/it]  6%|▌         | 441/7272 [1:47:05<29:06:31, 15.34s/it]                                                       {'loss': 3.1461, 'grad_norm': 9.24953842163086, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 441, 'max_steps': 7272}
  6%|▌         | 441/7272 [1:47:05<29:06:31, 15.34s/it]  6%|▌         | 442/7272 [1:47:20<28:58:07, 15.27s/it]                                                       {'loss': 1.375, 'grad_norm': 3.8937714099884033, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 442, 'max_steps': 7272}
  6%|▌         | 442/7272 [1:47:20<28:58:07, 15.27s/it]  6%|▌         | 443/7272 [1:47:35<28:24:46, 14.98s/it]                                                       {'loss': 1.6439, 'grad_norm': 5.734611988067627, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 443, 'max_steps': 7272}
  6%|▌         | 443/7272 [1:47:35<28:24:46, 14.98s/it]  6%|▌         | 444/7272 [1:47:49<27:47:40, 14.65s/it]                                                       {'loss': 2.0011, 'grad_norm': 8.845232009887695, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 444, 'max_steps': 7272}
  6%|▌         | 444/7272 [1:47:49<27:47:40, 14.65s/it]  6%|▌         | 445/7272 [1:48:03<27:34:46, 14.54s/it]                                                       {'loss': 1.746, 'grad_norm': 6.155505657196045, 'learning_rate': 5e-05, 'epoch': 0.24, 'step': 445, 'max_steps': 7272}
  6%|▌         | 445/7272 [1:48:03<27:34:46, 14.54s/it]  6%|▌         | 446/7272 [1:48:17<27:24:57, 14.46s/it]                                                       {'loss': 1.0852, 'grad_norm': 4.051814556121826, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 446, 'max_steps': 7272}
  6%|▌         | 446/7272 [1:48:17<27:24:57, 14.46s/it]  6%|▌         | 447/7272 [1:48:31<27:19:09, 14.41s/it]                                                       {'loss': 1.5699, 'grad_norm': 4.3857831954956055, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 447, 'max_steps': 7272}
  6%|▌         | 447/7272 [1:48:31<27:19:09, 14.41s/it]  6%|▌         | 448/7272 [1:48:46<27:14:17, 14.37s/it]                                                       {'loss': 2.3721, 'grad_norm': 6.135394096374512, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 448, 'max_steps': 7272}
  6%|▌         | 448/7272 [1:48:46<27:14:17, 14.37s/it]  6%|▌         | 449/7272 [1:48:59<26:52:39, 14.18s/it]                                                       {'loss': 1.3691, 'grad_norm': 8.20645809173584, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 449, 'max_steps': 7272}
  6%|▌         | 449/7272 [1:48:59<26:52:39, 14.18s/it]  6%|▌         | 450/7272 [1:49:14<26:52:45, 14.18s/it]                                                       {'loss': 1.6353, 'grad_norm': 4.435217380523682, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 450, 'max_steps': 7272}
  6%|▌         | 450/7272 [1:49:14<26:52:45, 14.18s/it]  6%|▌         | 451/7272 [1:49:28<26:46:32, 14.13s/it]                                                       {'loss': 2.8546, 'grad_norm': 6.8639678955078125, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 451, 'max_steps': 7272}
  6%|▌         | 451/7272 [1:49:28<26:46:32, 14.13s/it]  6%|▌         | 452/7272 [1:49:42<26:38:26, 14.06s/it]                                                       {'loss': 0.8011, 'grad_norm': 3.0785982608795166, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 452, 'max_steps': 7272}
  6%|▌         | 452/7272 [1:49:42<26:38:26, 14.06s/it]  6%|▌         | 453/7272 [1:49:56<26:49:19, 14.16s/it]                                                       {'loss': 1.3315, 'grad_norm': 3.9182615280151367, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 453, 'max_steps': 7272}
  6%|▌         | 453/7272 [1:49:56<26:49:19, 14.16s/it]  6%|▌         | 454/7272 [1:50:10<26:42:40, 14.10s/it]                                                       {'loss': 3.0149, 'grad_norm': 5.3103156089782715, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 454, 'max_steps': 7272}
  6%|▌         | 454/7272 [1:50:10<26:42:40, 14.10s/it]  6%|▋         | 455/7272 [1:50:24<26:47:54, 14.15s/it]                                                       {'loss': 2.3014, 'grad_norm': 9.139863014221191, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 455, 'max_steps': 7272}
  6%|▋         | 455/7272 [1:50:24<26:47:54, 14.15s/it]  6%|▋         | 456/7272 [1:50:38<26:52:36, 14.20s/it]                                                       {'loss': 2.3228, 'grad_norm': 10.692859649658203, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 456, 'max_steps': 7272}
  6%|▋         | 456/7272 [1:50:38<26:52:36, 14.20s/it]  6%|▋         | 457/7272 [1:50:53<26:49:41, 14.17s/it]                                                       {'loss': 2.343, 'grad_norm': 7.32450532913208, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 457, 'max_steps': 7272}
  6%|▋         | 457/7272 [1:50:53<26:49:41, 14.17s/it]  6%|▋         | 458/7272 [1:51:07<26:48:41, 14.17s/it]                                                       {'loss': 1.9758, 'grad_norm': 8.104090690612793, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 458, 'max_steps': 7272}
  6%|▋         | 458/7272 [1:51:07<26:48:41, 14.17s/it]  6%|▋         | 459/7272 [1:51:21<26:50:31, 14.18s/it]                                                       {'loss': 0.9251, 'grad_norm': 3.5508956909179688, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 459, 'max_steps': 7272}
  6%|▋         | 459/7272 [1:51:21<26:50:31, 14.18s/it]  6%|▋         | 460/7272 [1:51:35<26:41:30, 14.11s/it]                                                       {'loss': 0.5952, 'grad_norm': 4.114367485046387, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 460, 'max_steps': 7272}
  6%|▋         | 460/7272 [1:51:35<26:41:30, 14.11s/it]  6%|▋         | 461/7272 [1:51:50<27:07:26, 14.34s/it]                                                       {'loss': 1.1365, 'grad_norm': 3.044816732406616, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 461, 'max_steps': 7272}
  6%|▋         | 461/7272 [1:51:50<27:07:26, 14.34s/it]  6%|▋         | 462/7272 [1:52:04<27:13:45, 14.39s/it]                                                       {'loss': 1.4984, 'grad_norm': 4.821066856384277, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 462, 'max_steps': 7272}
  6%|▋         | 462/7272 [1:52:04<27:13:45, 14.39s/it]  6%|▋         | 463/7272 [1:52:19<27:12:44, 14.39s/it]                                                       {'loss': 1.3962, 'grad_norm': 5.461764812469482, 'learning_rate': 5e-05, 'epoch': 0.25, 'step': 463, 'max_steps': 7272}
  6%|▋         | 463/7272 [1:52:19<27:12:44, 14.39s/it]  6%|▋         | 464/7272 [1:52:33<27:18:00, 14.44s/it]                                                       {'loss': 2.1019, 'grad_norm': 8.648920059204102, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 464, 'max_steps': 7272}
  6%|▋         | 464/7272 [1:52:33<27:18:00, 14.44s/it]  6%|▋         | 465/7272 [1:52:48<27:12:44, 14.39s/it]                                                       {'loss': 1.8856, 'grad_norm': 8.898509979248047, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 465, 'max_steps': 7272}
  6%|▋         | 465/7272 [1:52:48<27:12:44, 14.39s/it]  6%|▋         | 466/7272 [1:53:02<27:09:05, 14.36s/it]                                                       {'loss': 0.924, 'grad_norm': 8.174403190612793, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 466, 'max_steps': 7272}
  6%|▋         | 466/7272 [1:53:02<27:09:05, 14.36s/it]  6%|▋         | 467/7272 [1:53:16<26:59:27, 14.28s/it]                                                       {'loss': 1.281, 'grad_norm': 5.348841190338135, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 467, 'max_steps': 7272}
  6%|▋         | 467/7272 [1:53:16<26:59:27, 14.28s/it]  6%|▋         | 468/7272 [1:53:30<26:45:35, 14.16s/it]                                                       {'loss': 1.509, 'grad_norm': 9.572348594665527, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 468, 'max_steps': 7272}
  6%|▋         | 468/7272 [1:53:30<26:45:35, 14.16s/it]  6%|▋         | 469/7272 [1:53:44<26:37:42, 14.09s/it]                                                       {'loss': 0.7283, 'grad_norm': 3.3642876148223877, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 469, 'max_steps': 7272}
  6%|▋         | 469/7272 [1:53:44<26:37:42, 14.09s/it]  6%|▋         | 470/7272 [1:53:58<26:34:28, 14.06s/it]                                                       {'loss': 1.3925, 'grad_norm': 8.099513053894043, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 470, 'max_steps': 7272}
  6%|▋         | 470/7272 [1:53:58<26:34:28, 14.06s/it]  6%|▋         | 471/7272 [1:54:12<26:34:41, 14.07s/it]                                                       {'loss': 1.7157, 'grad_norm': 8.993875503540039, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 471, 'max_steps': 7272}
  6%|▋         | 471/7272 [1:54:12<26:34:41, 14.07s/it]  6%|▋         | 472/7272 [1:54:26<26:32:26, 14.05s/it]                                                       {'loss': 2.2642, 'grad_norm': 9.481895446777344, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 472, 'max_steps': 7272}
  6%|▋         | 472/7272 [1:54:26<26:32:26, 14.05s/it]  7%|▋         | 473/7272 [1:54:39<26:11:28, 13.87s/it]                                                       {'loss': 3.1546, 'grad_norm': 9.934441566467285, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 473, 'max_steps': 7272}
  7%|▋         | 473/7272 [1:54:39<26:11:28, 13.87s/it]  7%|▋         | 474/7272 [1:54:53<26:01:56, 13.79s/it]                                                       {'loss': 1.1102, 'grad_norm': 6.721653461456299, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 474, 'max_steps': 7272}
  7%|▋         | 474/7272 [1:54:53<26:01:56, 13.79s/it]  7%|▋         | 475/7272 [1:55:07<26:04:58, 13.81s/it]                                                       {'loss': 4.6298, 'grad_norm': 12.469222068786621, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 475, 'max_steps': 7272}
  7%|▋         | 475/7272 [1:55:07<26:04:58, 13.81s/it]  7%|▋         | 476/7272 [1:55:21<26:11:20, 13.87s/it]                                                       {'loss': 0.7969, 'grad_norm': 6.539934158325195, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 476, 'max_steps': 7272}
  7%|▋         | 476/7272 [1:55:21<26:11:20, 13.87s/it]  7%|▋         | 477/7272 [1:55:34<26:06:59, 13.84s/it]                                                       {'loss': 2.6062, 'grad_norm': 9.71384048461914, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 477, 'max_steps': 7272}
  7%|▋         | 477/7272 [1:55:34<26:06:59, 13.84s/it]  7%|▋         | 478/7272 [1:55:48<26:02:14, 13.80s/it]                                                       {'loss': 2.4255, 'grad_norm': 5.8238396644592285, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 478, 'max_steps': 7272}
  7%|▋         | 478/7272 [1:55:48<26:02:14, 13.80s/it]  7%|▋         | 479/7272 [1:56:02<25:56:45, 13.75s/it]                                                       {'loss': 2.9754, 'grad_norm': 10.00660228729248, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 479, 'max_steps': 7272}
  7%|▋         | 479/7272 [1:56:02<25:56:45, 13.75s/it]  7%|▋         | 480/7272 [1:56:15<25:51:05, 13.70s/it]                                                       {'loss': 1.0978, 'grad_norm': 3.519361972808838, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 480, 'max_steps': 7272}
  7%|▋         | 480/7272 [1:56:15<25:51:05, 13.70s/it]  7%|▋         | 481/7272 [1:56:29<25:34:00, 13.55s/it]                                                       {'loss': 2.6293, 'grad_norm': 10.19328498840332, 'learning_rate': 5e-05, 'epoch': 0.26, 'step': 481, 'max_steps': 7272}
  7%|▋         | 481/7272 [1:56:29<25:34:00, 13.55s/it]  7%|▋         | 482/7272 [1:56:42<25:21:38, 13.45s/it]                                                       {'loss': 3.4109, 'grad_norm': 7.941347122192383, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 482, 'max_steps': 7272}
  7%|▋         | 482/7272 [1:56:42<25:21:38, 13.45s/it]  7%|▋         | 483/7272 [1:56:55<25:27:45, 13.50s/it]                                                       {'loss': 4.617, 'grad_norm': 14.836043357849121, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 483, 'max_steps': 7272}
  7%|▋         | 483/7272 [1:56:55<25:27:45, 13.50s/it]  7%|▋         | 484/7272 [1:57:09<25:35:08, 13.57s/it]                                                       {'loss': 2.0745, 'grad_norm': 9.349846839904785, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 484, 'max_steps': 7272}
  7%|▋         | 484/7272 [1:57:09<25:35:08, 13.57s/it]  7%|▋         | 485/7272 [1:57:23<25:51:03, 13.71s/it]                                                       {'loss': 2.7692, 'grad_norm': 8.236177444458008, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 485, 'max_steps': 7272}
  7%|▋         | 485/7272 [1:57:23<25:51:03, 13.71s/it]  7%|▋         | 486/7272 [1:57:37<25:45:55, 13.67s/it]                                                       {'loss': 3.4603, 'grad_norm': 13.062268257141113, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 486, 'max_steps': 7272}
  7%|▋         | 486/7272 [1:57:37<25:45:55, 13.67s/it]  7%|▋         | 487/7272 [1:57:50<25:40:03, 13.62s/it]                                                       {'loss': 3.7932, 'grad_norm': 10.204442024230957, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 487, 'max_steps': 7272}
  7%|▋         | 487/7272 [1:57:50<25:40:03, 13.62s/it]  7%|▋         | 488/7272 [1:58:04<25:39:29, 13.62s/it]                                                       {'loss': 1.9544, 'grad_norm': 9.312093734741211, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 488, 'max_steps': 7272}
  7%|▋         | 488/7272 [1:58:04<25:39:29, 13.62s/it]  7%|▋         | 489/7272 [1:58:18<25:45:14, 13.67s/it]                                                       {'loss': 0.9549, 'grad_norm': 6.293846130371094, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 489, 'max_steps': 7272}
  7%|▋         | 489/7272 [1:58:18<25:45:14, 13.67s/it]  7%|▋         | 490/7272 [1:58:31<25:30:08, 13.54s/it]                                                       {'loss': 0.7618, 'grad_norm': 4.2958760261535645, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 490, 'max_steps': 7272}
  7%|▋         | 490/7272 [1:58:31<25:30:08, 13.54s/it]  7%|▋         | 491/7272 [1:58:44<25:18:08, 13.43s/it]                                                       {'loss': 2.081, 'grad_norm': 12.090127944946289, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 491, 'max_steps': 7272}
  7%|▋         | 491/7272 [1:58:44<25:18:08, 13.43s/it]  7%|▋         | 492/7272 [1:58:58<25:39:36, 13.62s/it]                                                       {'loss': 1.786, 'grad_norm': 6.83087158203125, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 492, 'max_steps': 7272}
  7%|▋         | 492/7272 [1:58:58<25:39:36, 13.62s/it]  7%|▋         | 493/7272 [1:59:12<25:51:09, 13.73s/it]                                                       {'loss': 2.2136, 'grad_norm': 9.180254936218262, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 493, 'max_steps': 7272}
  7%|▋         | 493/7272 [1:59:12<25:51:09, 13.73s/it]  7%|▋         | 494/7272 [1:59:26<25:48:37, 13.71s/it]                                                       {'loss': 1.567, 'grad_norm': 5.651553153991699, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 494, 'max_steps': 7272}
  7%|▋         | 494/7272 [1:59:26<25:48:37, 13.71s/it]  7%|▋         | 495/7272 [1:59:39<25:43:47, 13.67s/it]                                                       {'loss': 2.3462, 'grad_norm': 5.720794677734375, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 495, 'max_steps': 7272}
  7%|▋         | 495/7272 [1:59:39<25:43:47, 13.67s/it]  7%|▋         | 496/7272 [1:59:53<25:38:42, 13.62s/it]                                                       {'loss': 0.9056, 'grad_norm': 3.4790163040161133, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 496, 'max_steps': 7272}
  7%|▋         | 496/7272 [1:59:53<25:38:42, 13.62s/it]  7%|▋         | 497/7272 [2:00:07<25:42:01, 13.66s/it]                                                       {'loss': 2.7484, 'grad_norm': 10.31212043762207, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 497, 'max_steps': 7272}
  7%|▋         | 497/7272 [2:00:07<25:42:01, 13.66s/it]  7%|▋         | 498/7272 [2:00:21<25:51:41, 13.74s/it]                                                       {'loss': 1.2748, 'grad_norm': 2.888502836227417, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 498, 'max_steps': 7272}
  7%|▋         | 498/7272 [2:00:21<25:51:41, 13.74s/it]  7%|▋         | 499/7272 [2:00:34<25:42:22, 13.66s/it]                                                       {'loss': 1.8785, 'grad_norm': 5.806176662445068, 'learning_rate': 5e-05, 'epoch': 0.27, 'step': 499, 'max_steps': 7272}
  7%|▋         | 499/7272 [2:00:34<25:42:22, 13.66s/it]  7%|▋         | 500/7272 [2:00:47<25:30:43, 13.56s/it]                                                       {'loss': 4.2113, 'grad_norm': 11.272068977355957, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 500, 'max_steps': 7272}
  7%|▋         | 500/7272 [2:00:47<25:30:43, 13.56s/it]
  0%|          | 0/455 [00:00<?, ?it/s][A
  0%|          | 2/455 [00:01<05:55,  1.27it/s][A
  1%|          | 3/455 [00:03<08:17,  1.10s/it][A
  1%|          | 4/455 [00:04<09:33,  1.27s/it][A
  1%|          | 5/455 [00:06<10:16,  1.37s/it][A
  1%|▏         | 6/455 [00:07<10:40,  1.43s/it][A
  2%|▏         | 7/455 [00:09<11:00,  1.47s/it][A
  2%|▏         | 8/455 [00:10<11:08,  1.49s/it][A
  2%|▏         | 9/455 [00:12<11:14,  1.51s/it][A
  2%|▏         | 10/455 [00:13<11:18,  1.52s/it][A
  2%|▏         | 11/455 [00:15<11:17,  1.53s/it][A
  3%|▎         | 12/455 [00:17<11:18,  1.53s/it][A
  3%|▎         | 13/455 [00:18<11:16,  1.53s/it][A
  3%|▎         | 14/455 [00:20<11:16,  1.54s/it][A
  3%|▎         | 15/455 [00:21<11:16,  1.54s/it][A
  4%|▎         | 16/455 [00:23<11:14,  1.54s/it][A
  4%|▎         | 17/455 [00:24<11:14,  1.54s/it][A
  4%|▍         | 18/455 [00:26<11:09,  1.53s/it][A
  4%|▍         | 19/455 [00:27<11:08,  1.53s/it][A
  4%|▍         | 20/455 [00:29<11:08,  1.54s/it][A
  5%|▍         | 21/455 [00:30<11:06,  1.54s/it][A
  5%|▍         | 22/455 [00:32<11:07,  1.54s/it][A
  5%|▌         | 23/455 [00:33<11:04,  1.54s/it][A
  5%|▌         | 24/455 [00:35<11:05,  1.54s/it][A
  5%|▌         | 25/455 [00:37<11:02,  1.54s/it][A
  6%|▌         | 26/455 [00:38<11:00,  1.54s/it][A
  6%|▌         | 27/455 [00:40<10:59,  1.54s/it][A
  6%|▌         | 28/455 [00:41<10:57,  1.54s/it][A
  6%|▋         | 29/455 [00:43<10:56,  1.54s/it][A
  7%|▋         | 30/455 [00:44<10:56,  1.54s/it][A
  7%|▋         | 31/455 [00:46<10:55,  1.55s/it][A
  7%|▋         | 32/455 [00:47<10:52,  1.54s/it][A
  7%|▋         | 33/455 [00:49<10:52,  1.55s/it][A
  7%|▋         | 34/455 [00:50<10:48,  1.54s/it][A
  8%|▊         | 35/455 [00:52<10:48,  1.54s/it][A
  8%|▊         | 36/455 [00:54<10:46,  1.54s/it][A
  8%|▊         | 37/455 [00:55<10:44,  1.54s/it][A
  8%|▊         | 38/455 [00:57<10:43,  1.54s/it][A
  9%|▊         | 39/455 [00:58<10:39,  1.54s/it][A
  9%|▉         | 40/455 [01:00<10:39,  1.54s/it][A
  9%|▉         | 41/455 [01:01<10:42,  1.55s/it][A
  9%|▉         | 42/455 [01:03<10:40,  1.55s/it][A
  9%|▉         | 43/455 [01:04<10:36,  1.54s/it][A
 10%|▉         | 44/455 [01:06<10:33,  1.54s/it][A
 10%|▉         | 45/455 [01:07<10:30,  1.54s/it][A
 10%|█         | 46/455 [01:09<10:28,  1.54s/it][A
 10%|█         | 47/455 [01:10<10:26,  1.54s/it][A
 11%|█         | 48/455 [01:12<10:25,  1.54s/it][A
 11%|█         | 49/455 [01:14<10:22,  1.53s/it][A
 11%|█         | 50/455 [01:15<10:25,  1.54s/it][A
 11%|█         | 51/455 [01:17<10:21,  1.54s/it][A
 11%|█▏        | 52/455 [01:18<10:21,  1.54s/it][A
 12%|█▏        | 53/455 [01:20<10:16,  1.53s/it][A
 12%|█▏        | 54/455 [01:21<10:15,  1.53s/it][A
 12%|█▏        | 55/455 [01:23<10:17,  1.54s/it][A
 12%|█▏        | 56/455 [01:24<10:14,  1.54s/it][A
 13%|█▎        | 57/455 [01:26<10:13,  1.54s/it][A
 13%|█▎        | 58/455 [01:27<10:10,  1.54s/it][A
 13%|█▎        | 59/455 [01:29<10:09,  1.54s/it][A
 13%|█▎        | 60/455 [01:30<10:07,  1.54s/it][A
 13%|█▎        | 61/455 [01:32<10:03,  1.53s/it][A
 14%|█▎        | 62/455 [01:34<10:02,  1.53s/it][A
 14%|█▍        | 63/455 [01:35<10:01,  1.53s/it][A
 14%|█▍        | 64/455 [01:37<10:01,  1.54s/it][A
 14%|█▍        | 65/455 [01:38<09:58,  1.53s/it][A
 15%|█▍        | 66/455 [01:40<09:57,  1.54s/it][A
 15%|█▍        | 67/455 [01:41<09:56,  1.54s/it][A
 15%|█▍        | 68/455 [01:43<09:55,  1.54s/it][A
 15%|█▌        | 69/455 [01:44<09:52,  1.53s/it][A
 15%|█▌        | 70/455 [01:46<09:50,  1.53s/it][A
 16%|█▌        | 71/455 [01:47<09:48,  1.53s/it][A
 16%|█▌        | 72/455 [01:49<09:47,  1.53s/it][A
 16%|█▌        | 73/455 [01:50<09:45,  1.53s/it][A
 16%|█▋        | 74/455 [01:52<09:45,  1.54s/it][A
 16%|█▋        | 75/455 [01:54<09:43,  1.54s/it][A
 17%|█▋        | 76/455 [01:55<09:41,  1.53s/it][A
 17%|█▋        | 77/455 [01:57<09:39,  1.53s/it][A
 17%|█▋        | 78/455 [01:58<09:36,  1.53s/it][A
 17%|█▋        | 79/455 [02:00<09:34,  1.53s/it][A
 18%|█▊        | 80/455 [02:01<09:34,  1.53s/it][A
 18%|█▊        | 81/455 [02:03<09:33,  1.53s/it][A
 18%|█▊        | 82/455 [02:04<09:30,  1.53s/it][A
 18%|█▊        | 83/455 [02:06<09:28,  1.53s/it][A
 18%|█▊        | 84/455 [02:07<09:28,  1.53s/it][A
 19%|█▊        | 85/455 [02:09<09:25,  1.53s/it][A
 19%|█▉        | 86/455 [02:10<09:25,  1.53s/it][A
 19%|█▉        | 87/455 [02:12<09:24,  1.53s/it][A
 19%|█▉        | 88/455 [02:13<09:22,  1.53s/it][A
 20%|█▉        | 89/455 [02:15<09:19,  1.53s/it][A
 20%|█▉        | 90/455 [02:16<09:18,  1.53s/it][A
 20%|██        | 91/455 [02:18<09:17,  1.53s/it][A
 20%|██        | 92/455 [02:20<09:17,  1.53s/it][A
 20%|██        | 93/455 [02:21<09:14,  1.53s/it][A
 21%|██        | 94/455 [02:23<09:13,  1.53s/it][A
 21%|██        | 95/455 [02:24<09:13,  1.54s/it][A
 21%|██        | 96/455 [02:26<09:09,  1.53s/it][A
 21%|██▏       | 97/455 [02:27<09:09,  1.53s/it][A
 22%|██▏       | 98/455 [02:29<09:09,  1.54s/it][A
 22%|██▏       | 99/455 [02:30<09:08,  1.54s/it][A
 22%|██▏       | 100/455 [02:32<09:06,  1.54s/it][A
 22%|██▏       | 101/455 [02:33<09:04,  1.54s/it][A
 22%|██▏       | 102/455 [02:35<09:01,  1.53s/it][A
 23%|██▎       | 103/455 [02:36<09:00,  1.54s/it][A
 23%|██▎       | 104/455 [02:38<08:59,  1.54s/it][A
 23%|██▎       | 105/455 [02:39<08:54,  1.53s/it][A
 23%|██▎       | 106/455 [02:41<08:53,  1.53s/it][A
 24%|██▎       | 107/455 [02:43<08:54,  1.53s/it][A
 24%|██▎       | 108/455 [02:44<08:52,  1.53s/it][A
 24%|██▍       | 109/455 [02:46<08:50,  1.53s/it][A
 24%|██▍       | 110/455 [02:47<08:48,  1.53s/it][A
 24%|██▍       | 111/455 [02:49<08:48,  1.54s/it][A
 25%|██▍       | 112/455 [02:50<08:46,  1.54s/it][A
 25%|██▍       | 113/455 [02:52<08:45,  1.54s/it][A
 25%|██▌       | 114/455 [02:53<08:45,  1.54s/it][A
 25%|██▌       | 115/455 [02:55<08:42,  1.54s/it][A
 25%|██▌       | 116/455 [02:56<08:41,  1.54s/it][A
 26%|██▌       | 117/455 [02:58<08:39,  1.54s/it][A
 26%|██▌       | 118/455 [02:59<08:37,  1.54s/it][A
 26%|██▌       | 119/455 [03:01<08:35,  1.53s/it][A
 26%|██▋       | 120/455 [03:03<08:32,  1.53s/it][A
 27%|██▋       | 121/455 [03:04<08:31,  1.53s/it][A
 27%|██▋       | 122/455 [03:06<08:30,  1.53s/it][A
 27%|██▋       | 123/455 [03:07<08:30,  1.54s/it][A
 27%|██▋       | 124/455 [03:09<08:30,  1.54s/it][A
 27%|██▋       | 125/455 [03:10<08:27,  1.54s/it][A
 28%|██▊       | 126/455 [03:12<08:24,  1.53s/it][A
 28%|██▊       | 127/455 [03:13<08:22,  1.53s/it][A
 28%|██▊       | 128/455 [03:15<08:20,  1.53s/it][A
 28%|██▊       | 129/455 [03:16<08:17,  1.52s/it][A
 29%|██▊       | 130/455 [03:18<08:16,  1.53s/it][A
 29%|██▉       | 131/455 [03:19<08:13,  1.52s/it][A
 29%|██▉       | 132/455 [03:21<08:18,  1.54s/it][A
 29%|██▉       | 133/455 [03:22<08:17,  1.54s/it][A
 29%|██▉       | 134/455 [03:24<08:15,  1.54s/it][A
 30%|██▉       | 135/455 [03:26<08:12,  1.54s/it][A
 30%|██▉       | 136/455 [03:27<08:11,  1.54s/it][A
 30%|███       | 137/455 [03:29<08:08,  1.54s/it][A
 30%|███       | 138/455 [03:30<08:07,  1.54s/it][A
 31%|███       | 139/455 [03:32<08:05,  1.53s/it][A
 31%|███       | 140/455 [03:33<08:03,  1.54s/it][A
 31%|███       | 141/455 [03:35<08:01,  1.53s/it][A
 31%|███       | 142/455 [03:36<07:59,  1.53s/it][A
 31%|███▏      | 143/455 [03:38<07:58,  1.53s/it][A
 32%|███▏      | 144/455 [03:39<07:59,  1.54s/it][A
 32%|███▏      | 145/455 [03:41<07:55,  1.53s/it][A
 32%|███▏      | 146/455 [03:42<07:53,  1.53s/it][A
 32%|███▏      | 147/455 [03:44<07:52,  1.53s/it][A
 33%|███▎      | 148/455 [03:45<07:50,  1.53s/it][A
 33%|███▎      | 149/455 [03:47<07:47,  1.53s/it][A
 33%|███▎      | 150/455 [03:49<07:45,  1.53s/it][A
 33%|███▎      | 151/455 [03:50<07:44,  1.53s/it][A
 33%|███▎      | 152/455 [03:52<07:44,  1.53s/it][A
 34%|███▎      | 153/455 [03:53<07:44,  1.54s/it][A
 34%|███▍      | 154/455 [03:55<07:39,  1.53s/it][A
 34%|███▍      | 155/455 [03:56<07:40,  1.53s/it][A
 34%|███▍      | 156/455 [03:58<07:39,  1.54s/it][A
 35%|███▍      | 157/455 [03:59<07:37,  1.53s/it][A
 35%|███▍      | 158/455 [04:01<07:36,  1.54s/it][A
 35%|███▍      | 159/455 [04:02<07:34,  1.53s/it][A
 35%|███▌      | 160/455 [04:04<07:32,  1.53s/it][A
 35%|███▌      | 161/455 [04:05<07:31,  1.53s/it][A
 36%|███▌      | 162/455 [04:07<07:27,  1.53s/it][A
 36%|███▌      | 163/455 [04:08<07:27,  1.53s/it][A
 36%|███▌      | 164/455 [04:10<07:25,  1.53s/it][A
 36%|███▋      | 165/455 [04:12<07:23,  1.53s/it][A
 36%|███▋      | 166/455 [04:13<07:23,  1.53s/it][A
 37%|███▋      | 167/455 [04:15<07:21,  1.53s/it][A
 37%|███▋      | 168/455 [04:16<07:22,  1.54s/it][A
 37%|███▋      | 169/455 [04:18<07:20,  1.54s/it][A
 37%|███▋      | 170/455 [04:19<07:18,  1.54s/it][A
 38%|███▊      | 171/455 [04:21<07:15,  1.54s/it][A
 38%|███▊      | 172/455 [04:22<07:12,  1.53s/it][A
 38%|███▊      | 173/455 [04:24<07:10,  1.52s/it][A
 38%|███▊      | 174/455 [04:25<07:10,  1.53s/it][A
 38%|███▊      | 175/455 [04:27<07:07,  1.53s/it][A
 39%|███▊      | 176/455 [04:28<07:07,  1.53s/it][A
 39%|███▉      | 177/455 [04:30<07:05,  1.53s/it][A
 39%|███▉      | 178/455 [04:31<07:03,  1.53s/it][A
 39%|███▉      | 179/455 [04:33<07:02,  1.53s/it][A
 40%|███▉      | 180/455 [04:35<07:01,  1.53s/it][A
 40%|███▉      | 181/455 [04:36<07:01,  1.54s/it][A
 40%|████      | 182/455 [04:38<06:59,  1.54s/it][A
 40%|████      | 183/455 [04:39<06:57,  1.53s/it][A
 40%|████      | 184/455 [04:41<06:54,  1.53s/it][A
 41%|████      | 185/455 [04:42<06:52,  1.53s/it][A
 41%|████      | 186/455 [04:44<06:51,  1.53s/it][A
 41%|████      | 187/455 [04:45<06:51,  1.53s/it][A
 41%|████▏     | 188/455 [04:47<06:49,  1.54s/it][A
 42%|████▏     | 189/455 [04:48<06:48,  1.53s/it][A
 42%|████▏     | 190/455 [04:50<06:46,  1.53s/it][A
 42%|████▏     | 191/455 [04:51<06:43,  1.53s/it][A
 42%|████▏     | 192/455 [04:53<06:45,  1.54s/it][A
 42%|████▏     | 193/455 [04:54<06:43,  1.54s/it][A
 43%|████▎     | 194/455 [04:56<06:41,  1.54s/it][A
 43%|████▎     | 195/455 [04:58<06:40,  1.54s/it][A
 43%|████▎     | 196/455 [04:59<06:39,  1.54s/it][A
 43%|████▎     | 197/455 [05:01<06:37,  1.54s/it][A
 44%|████▎     | 198/455 [05:02<06:34,  1.54s/it][A
 44%|████▎     | 199/455 [05:04<06:31,  1.53s/it][A
 44%|████▍     | 200/455 [05:05<06:27,  1.52s/it][A
 44%|████▍     | 201/455 [05:07<06:27,  1.52s/it][A
 44%|████▍     | 202/455 [05:08<06:27,  1.53s/it][A
 45%|████▍     | 203/455 [05:10<06:26,  1.53s/it][A
 45%|████▍     | 204/455 [05:11<06:23,  1.53s/it][A
 45%|████▌     | 205/455 [05:13<06:23,  1.53s/it][A
 45%|████▌     | 206/455 [05:14<06:21,  1.53s/it][A
 45%|████▌     | 207/455 [05:16<06:18,  1.53s/it][A
 46%|████▌     | 208/455 [05:17<06:16,  1.53s/it][A
 46%|████▌     | 209/455 [05:19<06:15,  1.53s/it][A
 46%|████▌     | 210/455 [05:20<06:14,  1.53s/it][A
 46%|████▋     | 211/455 [05:22<06:11,  1.52s/it][A
 47%|████▋     | 212/455 [05:24<06:10,  1.52s/it][A
 47%|████▋     | 213/455 [05:25<06:09,  1.53s/it][A
 47%|████▋     | 214/455 [05:27<06:08,  1.53s/it][A
 47%|████▋     | 215/455 [05:28<06:07,  1.53s/it][A
 47%|████▋     | 216/455 [05:30<06:05,  1.53s/it][A
 48%|████▊     | 217/455 [05:31<06:04,  1.53s/it][A
 48%|████▊     | 218/455 [05:33<06:02,  1.53s/it][A
 48%|████▊     | 219/455 [05:34<06:00,  1.53s/it][A
 48%|████▊     | 220/455 [05:36<05:59,  1.53s/it][A
 49%|████▊     | 221/455 [05:37<05:57,  1.53s/it][A
 49%|████▉     | 222/455 [05:39<05:56,  1.53s/it][A
 49%|████▉     | 223/455 [05:40<05:56,  1.54s/it][A
 49%|████▉     | 224/455 [05:42<05:55,  1.54s/it][A
 49%|████▉     | 225/455 [05:43<05:52,  1.53s/it][A
 50%|████▉     | 226/455 [05:45<05:50,  1.53s/it][A
 50%|████▉     | 227/455 [05:47<05:48,  1.53s/it][A
 50%|█████     | 228/455 [05:48<05:47,  1.53s/it][A
 50%|█████     | 229/455 [05:50<05:44,  1.52s/it][A
 51%|█████     | 230/455 [05:51<05:43,  1.53s/it][A
 51%|█████     | 231/455 [05:53<05:42,  1.53s/it][A
 51%|█████     | 232/455 [05:54<05:41,  1.53s/it][A
 51%|█████     | 233/455 [05:56<05:39,  1.53s/it][A
 51%|█████▏    | 234/455 [05:57<05:37,  1.53s/it][A
 52%|█████▏    | 235/455 [05:59<05:35,  1.53s/it][A
 52%|█████▏    | 236/455 [06:00<05:34,  1.53s/it][A
 52%|█████▏    | 237/455 [06:02<05:33,  1.53s/it][A
 52%|█████▏    | 238/455 [06:03<05:32,  1.53s/it][A
 53%|█████▎    | 239/455 [06:05<05:31,  1.54s/it][A
 53%|█████▎    | 240/455 [06:06<05:31,  1.54s/it][A
 53%|█████▎    | 241/455 [06:08<05:30,  1.55s/it][A
 53%|█████▎    | 242/455 [06:10<05:29,  1.55s/it][A
 53%|█████▎    | 243/455 [06:11<05:26,  1.54s/it][A
 54%|█████▎    | 244/455 [06:13<05:25,  1.54s/it][A
 54%|█████▍    | 245/455 [06:14<05:23,  1.54s/it][A
 54%|█████▍    | 246/455 [06:16<05:22,  1.54s/it][A
 54%|█████▍    | 247/455 [06:17<05:20,  1.54s/it][A
 55%|█████▍    | 248/455 [06:19<05:18,  1.54s/it][A
 55%|█████▍    | 249/455 [06:20<05:16,  1.54s/it][A
 55%|█████▍    | 250/455 [06:22<05:14,  1.53s/it][A
 55%|█████▌    | 251/455 [06:23<05:12,  1.53s/it][A
 55%|█████▌    | 252/455 [06:25<05:11,  1.53s/it][A
 56%|█████▌    | 253/455 [06:26<05:09,  1.53s/it][A
 56%|█████▌    | 254/455 [06:28<05:07,  1.53s/it][A
 56%|█████▌    | 255/455 [06:29<05:06,  1.53s/it][A
 56%|█████▋    | 256/455 [06:31<05:06,  1.54s/it][A
 56%|█████▋    | 257/455 [06:33<05:04,  1.54s/it][A
 57%|█████▋    | 258/455 [06:34<05:02,  1.53s/it][A
 57%|█████▋    | 259/455 [06:36<05:01,  1.54s/it][A
 57%|█████▋    | 260/455 [06:37<05:00,  1.54s/it][A
 57%|█████▋    | 261/455 [06:39<04:59,  1.54s/it][A
 58%|█████▊    | 262/455 [06:40<04:57,  1.54s/it][A
 58%|█████▊    | 263/455 [06:42<04:55,  1.54s/it][A
 58%|█████▊    | 264/455 [06:43<04:53,  1.54s/it][A
 58%|█████▊    | 265/455 [06:45<04:51,  1.53s/it][A
 58%|█████▊    | 266/455 [06:46<04:50,  1.54s/it][A
 59%|█████▊    | 267/455 [06:48<04:49,  1.54s/it][A
 59%|█████▉    | 268/455 [06:49<04:47,  1.54s/it][A
 59%|█████▉    | 269/455 [06:51<04:45,  1.54s/it][A
 59%|█████▉    | 270/455 [06:53<04:43,  1.53s/it][A
 60%|█████▉    | 271/455 [06:54<04:41,  1.53s/it][A
 60%|█████▉    | 272/455 [06:56<04:41,  1.54s/it][A
 60%|██████    | 273/455 [06:57<04:40,  1.54s/it][A
 60%|██████    | 274/455 [06:59<04:38,  1.54s/it][A
 60%|██████    | 275/455 [07:00<04:37,  1.54s/it][A
 61%|██████    | 276/455 [07:02<04:35,  1.54s/it][A
 61%|██████    | 277/455 [07:03<04:34,  1.54s/it][A
 61%|██████    | 278/455 [07:05<04:32,  1.54s/it][A
 61%|██████▏   | 279/455 [07:06<04:30,  1.54s/it][A
 62%|██████▏   | 280/455 [07:08<04:28,  1.53s/it][A
 62%|██████▏   | 281/455 [07:09<04:26,  1.53s/it][A
 62%|██████▏   | 282/455 [07:11<04:25,  1.54s/it][A
 62%|██████▏   | 283/455 [07:13<04:24,  1.54s/it][A
 62%|██████▏   | 284/455 [07:14<04:23,  1.54s/it][A
 63%|██████▎   | 285/455 [07:16<04:23,  1.55s/it][A
 63%|██████▎   | 286/455 [07:17<04:22,  1.55s/it][A
 63%|██████▎   | 287/455 [07:19<04:19,  1.55s/it][A
 63%|██████▎   | 288/455 [07:20<04:17,  1.54s/it][A
 64%|██████▎   | 289/455 [07:22<04:15,  1.54s/it][A
 64%|██████▎   | 290/455 [07:23<04:14,  1.54s/it][A
 64%|██████▍   | 291/455 [07:25<04:12,  1.54s/it][A
 64%|██████▍   | 292/455 [07:26<04:10,  1.54s/it][A
 64%|██████▍   | 293/455 [07:28<04:08,  1.54s/it][A
 65%|██████▍   | 294/455 [07:29<04:07,  1.54s/it][A
 65%|██████▍   | 295/455 [07:31<04:05,  1.53s/it][A
 65%|██████▌   | 296/455 [07:33<04:03,  1.53s/it][A
 65%|██████▌   | 297/455 [07:34<04:01,  1.53s/it][A
 65%|██████▌   | 298/455 [07:36<04:00,  1.53s/it][A
 66%|██████▌   | 299/455 [07:37<03:58,  1.53s/it][A
 66%|██████▌   | 300/455 [07:39<03:57,  1.53s/it][A
 66%|██████▌   | 301/455 [07:40<03:55,  1.53s/it][A
 66%|██████▋   | 302/455 [07:42<03:54,  1.54s/it][A
 67%|██████▋   | 303/455 [07:43<03:53,  1.54s/it][A
 67%|██████▋   | 304/455 [07:45<03:51,  1.54s/it][A
 67%|██████▋   | 305/455 [07:46<03:51,  1.54s/it][A
 67%|██████▋   | 306/455 [07:48<03:50,  1.55s/it][A
 67%|██████▋   | 307/455 [07:49<03:48,  1.54s/it][A
 68%|██████▊   | 308/455 [07:51<03:45,  1.53s/it][A
 68%|██████▊   | 309/455 [07:53<03:44,  1.54s/it][A
 68%|██████▊   | 310/455 [07:54<03:43,  1.54s/it][A
 68%|██████▊   | 311/455 [07:56<03:41,  1.54s/it][A
 69%|██████▊   | 312/455 [07:57<03:41,  1.55s/it][A
 69%|██████▉   | 313/455 [07:59<03:39,  1.55s/it][A
 69%|██████▉   | 314/455 [08:00<03:37,  1.54s/it][A
 69%|██████▉   | 315/455 [08:02<03:35,  1.54s/it][A
 69%|██████▉   | 316/455 [08:03<03:33,  1.54s/it][A
 70%|██████▉   | 317/455 [08:05<03:32,  1.54s/it][A
 70%|██████▉   | 318/455 [08:06<03:30,  1.54s/it][A
 70%|███████   | 319/455 [08:08<03:28,  1.53s/it][A
 70%|███████   | 320/455 [08:09<03:26,  1.53s/it][A
 71%|███████   | 321/455 [08:11<03:25,  1.53s/it][A
 71%|███████   | 322/455 [08:13<03:24,  1.54s/it][A
 71%|███████   | 323/455 [08:14<03:22,  1.53s/it][A
 71%|███████   | 324/455 [08:16<03:20,  1.53s/it][A
 71%|███████▏  | 325/455 [08:17<03:19,  1.53s/it][A
 72%|███████▏  | 326/455 [08:19<03:18,  1.54s/it][A
 72%|███████▏  | 327/455 [08:20<03:16,  1.53s/it][A
 72%|███████▏  | 328/455 [08:22<03:14,  1.53s/it][A
 72%|███████▏  | 329/455 [08:23<03:13,  1.53s/it][A
 73%|███████▎  | 330/455 [08:25<03:11,  1.53s/it][A
 73%|███████▎  | 331/455 [08:26<03:09,  1.53s/it][A
 73%|███████▎  | 332/455 [08:28<03:09,  1.54s/it][A
 73%|███████▎  | 333/455 [08:29<03:07,  1.54s/it][A
 73%|███████▎  | 334/455 [08:31<03:06,  1.54s/it][A
 74%|███████▎  | 335/455 [08:32<03:04,  1.54s/it][A
 74%|███████▍  | 336/455 [08:34<03:02,  1.54s/it][A
 74%|███████▍  | 337/455 [08:36<03:01,  1.54s/it][A
 74%|███████▍  | 338/455 [08:37<02:59,  1.54s/it][A
 75%|███████▍  | 339/455 [08:39<02:58,  1.54s/it][A
 75%|███████▍  | 340/455 [08:40<02:56,  1.54s/it][A
 75%|███████▍  | 341/455 [08:42<02:55,  1.54s/it][A
 75%|███████▌  | 342/455 [08:43<02:53,  1.54s/it][A
 75%|███████▌  | 343/455 [08:45<02:51,  1.53s/it][A
 76%|███████▌  | 344/455 [08:46<02:50,  1.53s/it][A
 76%|███████▌  | 345/455 [08:48<02:48,  1.53s/it][A
 76%|███████▌  | 346/455 [08:49<02:46,  1.53s/it][A
 76%|███████▋  | 347/455 [08:51<02:45,  1.53s/it][A
 76%|███████▋  | 348/455 [08:52<02:44,  1.54s/it][A
 77%|███████▋  | 349/455 [08:54<02:42,  1.53s/it][A
 77%|███████▋  | 350/455 [08:55<02:40,  1.53s/it][A
 77%|███████▋  | 351/455 [08:57<02:39,  1.53s/it][A
 77%|███████▋  | 352/455 [08:59<02:38,  1.53s/it][A
 78%|███████▊  | 353/455 [09:00<02:36,  1.53s/it][A
 78%|███████▊  | 354/455 [09:02<02:34,  1.53s/it][A
 78%|███████▊  | 355/455 [09:03<02:33,  1.54s/it][A
 78%|███████▊  | 356/455 [09:05<02:31,  1.53s/it][A
 78%|███████▊  | 357/455 [09:06<02:30,  1.53s/it][A
 79%|███████▊  | 358/455 [09:08<02:28,  1.54s/it][A
 79%|███████▉  | 359/455 [09:09<02:27,  1.53s/it][A
 79%|███████▉  | 360/455 [09:11<02:26,  1.54s/it][A
 79%|███████▉  | 361/455 [09:12<02:24,  1.54s/it][A
 80%|███████▉  | 362/455 [09:14<02:22,  1.53s/it][A
 80%|███████▉  | 363/455 [09:15<02:20,  1.53s/it][A
 80%|████████  | 364/455 [09:17<02:19,  1.53s/it][A
 80%|████████  | 365/455 [09:18<02:18,  1.53s/it][A
 80%|████████  | 366/455 [09:20<02:16,  1.53s/it][A
 81%|████████  | 367/455 [09:22<02:14,  1.53s/it][A
 81%|████████  | 368/455 [09:23<02:13,  1.53s/it][A
 81%|████████  | 369/455 [09:25<02:11,  1.53s/it][A
 81%|████████▏ | 370/455 [09:26<02:10,  1.53s/it][A
 82%|████████▏ | 371/455 [09:28<02:08,  1.53s/it][A
 82%|████████▏ | 372/455 [09:29<02:07,  1.54s/it][A
 82%|████████▏ | 373/455 [09:31<02:05,  1.54s/it][A
 82%|████████▏ | 374/455 [09:32<02:04,  1.54s/it][A
 82%|████████▏ | 375/455 [09:34<02:02,  1.54s/it][A
 83%|████████▎ | 376/455 [09:35<02:01,  1.54s/it][A
 83%|████████▎ | 377/455 [09:37<02:00,  1.54s/it][A
 83%|████████▎ | 378/455 [09:38<01:58,  1.54s/it][A
 83%|████████▎ | 379/455 [09:40<01:56,  1.54s/it][A
 84%|████████▎ | 380/455 [09:42<01:55,  1.54s/it][A
 84%|████████▎ | 381/455 [09:43<01:53,  1.54s/it][A
 84%|████████▍ | 382/455 [09:45<01:52,  1.53s/it][A
 84%|████████▍ | 383/455 [09:46<01:50,  1.54s/it][A
 84%|████████▍ | 384/455 [09:48<01:49,  1.54s/it][A
 85%|████████▍ | 385/455 [09:49<01:47,  1.53s/it][A
 85%|████████▍ | 386/455 [09:51<01:45,  1.53s/it][A
 85%|████████▌ | 387/455 [09:52<01:43,  1.52s/it][A
 85%|████████▌ | 388/455 [09:54<01:42,  1.53s/it][A
 85%|████████▌ | 389/455 [09:55<01:40,  1.53s/it][A
 86%|████████▌ | 390/455 [09:57<01:39,  1.53s/it][A
 86%|████████▌ | 391/455 [09:58<01:37,  1.53s/it][A
 86%|████████▌ | 392/455 [10:00<01:36,  1.53s/it][A
 86%|████████▋ | 393/455 [10:01<01:34,  1.53s/it][A
 87%|████████▋ | 394/455 [10:03<01:33,  1.53s/it][A
 87%|████████▋ | 395/455 [10:04<01:31,  1.53s/it][A
 87%|████████▋ | 396/455 [10:06<01:30,  1.53s/it][A
 87%|████████▋ | 397/455 [10:08<01:28,  1.53s/it][A
 87%|████████▋ | 398/455 [10:09<01:27,  1.53s/it][A
 88%|████████▊ | 399/455 [10:11<01:25,  1.53s/it][A
 88%|████████▊ | 400/455 [10:12<01:23,  1.52s/it][A
 88%|████████▊ | 401/455 [10:14<01:22,  1.53s/it][A
 88%|████████▊ | 402/455 [10:15<01:21,  1.54s/it][A
 89%|████████▊ | 403/455 [10:17<01:19,  1.54s/it][A
 89%|████████▉ | 404/455 [10:18<01:18,  1.53s/it][A
 89%|████████▉ | 405/455 [10:20<01:16,  1.54s/it][A
 89%|████████▉ | 406/455 [10:21<01:15,  1.54s/it][A
 89%|████████▉ | 407/455 [10:23<01:13,  1.54s/it][A
 90%|████████▉ | 408/455 [10:24<01:12,  1.54s/it][A
 90%|████████▉ | 409/455 [10:26<01:10,  1.54s/it][A
 90%|█████████ | 410/455 [10:28<01:09,  1.54s/it][A
 90%|█████████ | 411/455 [10:29<01:07,  1.54s/it][A
 91%|█████████ | 412/455 [10:31<01:06,  1.54s/it][A
 91%|█████████ | 413/455 [10:32<01:04,  1.53s/it][A
 91%|█████████ | 414/455 [10:34<01:02,  1.53s/it][A
 91%|█████████ | 415/455 [10:35<01:01,  1.54s/it][A
 91%|█████████▏| 416/455 [10:37<00:59,  1.53s/it][A
 92%|█████████▏| 417/455 [10:38<00:58,  1.53s/it][A
 92%|█████████▏| 418/455 [10:40<00:56,  1.53s/it][A
 92%|█████████▏| 419/455 [10:41<00:55,  1.53s/it][A
 92%|█████████▏| 420/455 [10:43<00:53,  1.53s/it][A
 93%|█████████▎| 421/455 [10:44<00:52,  1.54s/it][A
 93%|█████████▎| 422/455 [10:46<00:50,  1.54s/it][A
 93%|█████████▎| 423/455 [10:47<00:49,  1.54s/it][A
 93%|█████████▎| 424/455 [10:49<00:47,  1.53s/it][A
 93%|█████████▎| 425/455 [10:51<00:46,  1.54s/it][A
 94%|█████████▎| 426/455 [10:52<00:44,  1.55s/it][A
 94%|█████████▍| 427/455 [10:54<00:43,  1.54s/it][A
 94%|█████████▍| 428/455 [10:55<00:41,  1.54s/it][A
 94%|█████████▍| 429/455 [10:57<00:39,  1.54s/it][A
 95%|█████████▍| 430/455 [10:58<00:38,  1.53s/it][A
 95%|█████████▍| 431/455 [11:00<00:36,  1.53s/it][A
 95%|█████████▍| 432/455 [11:01<00:35,  1.53s/it][A
 95%|█████████▌| 433/455 [11:03<00:33,  1.53s/it][A
 95%|█████████▌| 434/455 [11:04<00:32,  1.53s/it][A
 96%|█████████▌| 435/455 [11:06<00:30,  1.53s/it][A
 96%|█████████▌| 436/455 [11:07<00:29,  1.53s/it][A
 96%|█████████▌| 437/455 [11:09<00:27,  1.53s/it][A
 96%|█████████▋| 438/455 [11:10<00:26,  1.54s/it][A
 96%|█████████▋| 439/455 [11:12<00:24,  1.54s/it][A
 97%|█████████▋| 440/455 [11:14<00:23,  1.54s/it][A
 97%|█████████▋| 441/455 [11:15<00:21,  1.54s/it][A
 97%|█████████▋| 442/455 [11:17<00:20,  1.54s/it][A
 97%|█████████▋| 443/455 [11:18<00:18,  1.53s/it][A
 98%|█████████▊| 444/455 [11:20<00:16,  1.54s/it][A
 98%|█████████▊| 445/455 [11:21<00:15,  1.54s/it][A
 98%|█████████▊| 446/455 [11:23<00:13,  1.54s/it][A
 98%|█████████▊| 447/455 [11:24<00:12,  1.54s/it][A
 98%|█████████▊| 448/455 [11:26<00:10,  1.54s/it][A
 99%|█████████▊| 449/455 [11:27<00:09,  1.54s/it][A
 99%|█████████▉| 450/455 [11:29<00:07,  1.54s/it][A
 99%|█████████▉| 451/455 [11:30<00:06,  1.53s/it][A
 99%|█████████▉| 452/455 [11:32<00:04,  1.53s/it][A
100%|█████████▉| 453/455 [11:34<00:03,  1.53s/it][A
100%|█████████▉| 454/455 [11:35<00:01,  1.54s/it][A
100%|██████████| 455/455 [11:37<00:00,  1.54s/it][A                                                       
                                                 [A{'eval_loss': 2.166121482849121, 'eval_runtime': 699.2065, 'eval_samples_per_second': 2.599, 'eval_steps_per_second': 0.651, 'epoch': 0.28, 'step': 500, 'max_steps': 7272}
  7%|▋         | 500/7272 [2:12:27<25:30:43, 13.56s/it]
100%|██████████| 455/455 [11:37<00:00,  1.54s/it][A
                                                 [A  7%|▋         | 501/7272 [2:12:42<420:49:08, 223.74s/it]                                                         {'loss': 2.5479, 'grad_norm': 7.909687042236328, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 501, 'max_steps': 7272}
  7%|▋         | 501/7272 [2:12:42<420:49:08, 223.74s/it]  7%|▋         | 502/7272 [2:12:56<302:29:02, 160.85s/it]                                                         {'loss': 1.6392, 'grad_norm': 6.0574421882629395, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 502, 'max_steps': 7272}
  7%|▋         | 502/7272 [2:12:56<302:29:02, 160.85s/it]  7%|▋         | 503/7272 [2:13:09<219:25:28, 116.70s/it]                                                         {'loss': 1.9485, 'grad_norm': 5.042792797088623, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 503, 'max_steps': 7272}
  7%|▋         | 503/7272 [2:13:09<219:25:28, 116.70s/it]  7%|▋         | 504/7272 [2:13:23<161:09:45, 85.72s/it]                                                         {'loss': 1.4315, 'grad_norm': 2.6362111568450928, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 504, 'max_steps': 7272}
  7%|▋         | 504/7272 [2:13:23<161:09:45, 85.72s/it]  7%|▋         | 505/7272 [2:13:37<120:35:10, 64.15s/it]                                                        {'loss': 1.975, 'grad_norm': 7.922378063201904, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 505, 'max_steps': 7272}
  7%|▋         | 505/7272 [2:13:37<120:35:10, 64.15s/it]  7%|▋         | 506/7272 [2:13:50<92:05:48, 49.00s/it]                                                        {'loss': 1.6278, 'grad_norm': 8.58303451538086, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 506, 'max_steps': 7272}
  7%|▋         | 506/7272 [2:13:50<92:05:48, 49.00s/it]  7%|▋         | 507/7272 [2:14:04<72:08:11, 38.39s/it]                                                       {'loss': 1.5206, 'grad_norm': 7.135199069976807, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 507, 'max_steps': 7272}
  7%|▋         | 507/7272 [2:14:04<72:08:11, 38.39s/it]  7%|▋         | 508/7272 [2:14:17<58:04:38, 30.91s/it]                                                       {'loss': 1.4921, 'grad_norm': 4.247961044311523, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 508, 'max_steps': 7272}
  7%|▋         | 508/7272 [2:14:17<58:04:38, 30.91s/it]  7%|▋         | 509/7272 [2:14:31<48:24:09, 25.77s/it]                                                       {'loss': 2.1593, 'grad_norm': 8.290870666503906, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 509, 'max_steps': 7272}
  7%|▋         | 509/7272 [2:14:31<48:24:09, 25.77s/it]  7%|▋         | 510/7272 [2:14:45<41:45:13, 22.23s/it]                                                       {'loss': 2.8515, 'grad_norm': 9.822681427001953, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 510, 'max_steps': 7272}
  7%|▋         | 510/7272 [2:14:45<41:45:13, 22.23s/it]  7%|▋         | 511/7272 [2:14:59<37:01:48, 19.72s/it]                                                       {'loss': 3.7323, 'grad_norm': 14.051166534423828, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 511, 'max_steps': 7272}
  7%|▋         | 511/7272 [2:14:59<37:01:48, 19.72s/it]  7%|▋         | 512/7272 [2:15:13<33:39:20, 17.92s/it]                                                       {'loss': 1.7231, 'grad_norm': 4.189675807952881, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 512, 'max_steps': 7272}
  7%|▋         | 512/7272 [2:15:13<33:39:20, 17.92s/it]  7%|▋         | 513/7272 [2:15:26<31:12:56, 16.63s/it]                                                       {'loss': 2.4178, 'grad_norm': 9.542101860046387, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 513, 'max_steps': 7272}
  7%|▋         | 513/7272 [2:15:26<31:12:56, 16.63s/it]  7%|▋         | 514/7272 [2:15:40<29:32:01, 15.73s/it]                                                       {'loss': 2.5503, 'grad_norm': 7.157042026519775, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 514, 'max_steps': 7272}
  7%|▋         | 514/7272 [2:15:40<29:32:01, 15.73s/it]  7%|▋         | 515/7272 [2:15:54<28:27:41, 15.16s/it]                                                       {'loss': 3.8433, 'grad_norm': 8.031651496887207, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 515, 'max_steps': 7272}
  7%|▋         | 515/7272 [2:15:54<28:27:41, 15.16s/it]  7%|▋         | 516/7272 [2:16:07<27:36:13, 14.71s/it]                                                       {'loss': 2.6935, 'grad_norm': 14.778306007385254, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 516, 'max_steps': 7272}
  7%|▋         | 516/7272 [2:16:07<27:36:13, 14.71s/it]  7%|▋         | 517/7272 [2:16:21<26:56:05, 14.35s/it]                                                       {'loss': 2.3027, 'grad_norm': 69.45034790039062, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 517, 'max_steps': 7272}
  7%|▋         | 517/7272 [2:16:21<26:56:05, 14.35s/it]  7%|▋         | 518/7272 [2:16:35<26:52:59, 14.33s/it]                                                       {'loss': 2.9987, 'grad_norm': 6.045632839202881, 'learning_rate': 5e-05, 'epoch': 0.28, 'step': 518, 'max_steps': 7272}
  7%|▋         | 518/7272 [2:16:35<26:52:59, 14.33s/it]  7%|▋         | 519/7272 [2:16:49<26:25:42, 14.09s/it]                                                       {'loss': 1.552, 'grad_norm': 7.84031867980957, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 519, 'max_steps': 7272}
  7%|▋         | 519/7272 [2:16:49<26:25:42, 14.09s/it]  7%|▋         | 520/7272 [2:17:02<26:03:44, 13.90s/it]                                                       {'loss': 1.8875, 'grad_norm': 9.074942588806152, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 520, 'max_steps': 7272}
  7%|▋         | 520/7272 [2:17:02<26:03:44, 13.90s/it]  7%|▋         | 521/7272 [2:17:16<26:01:30, 13.88s/it]                                                       {'loss': 2.4814, 'grad_norm': 5.422619819641113, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 521, 'max_steps': 7272}
  7%|▋         | 521/7272 [2:17:16<26:01:30, 13.88s/it]  7%|▋         | 522/7272 [2:17:30<26:07:19, 13.93s/it]                                                       {'loss': 1.2447, 'grad_norm': 10.06518268585205, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 522, 'max_steps': 7272}
  7%|▋         | 522/7272 [2:17:30<26:07:19, 13.93s/it]  7%|▋         | 523/7272 [2:17:44<26:01:10, 13.88s/it]                                                       {'loss': 2.0263, 'grad_norm': 7.5277838706970215, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 523, 'max_steps': 7272}
  7%|▋         | 523/7272 [2:17:44<26:01:10, 13.88s/it]  7%|▋         | 524/7272 [2:17:58<26:05:42, 13.92s/it]                                                       {'loss': 1.0818, 'grad_norm': 3.4033281803131104, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 524, 'max_steps': 7272}
  7%|▋         | 524/7272 [2:17:58<26:05:42, 13.92s/it]  7%|▋         | 525/7272 [2:18:12<26:11:07, 13.97s/it]                                                       {'loss': 1.3833, 'grad_norm': 6.962342262268066, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 525, 'max_steps': 7272}
  7%|▋         | 525/7272 [2:18:12<26:11:07, 13.97s/it]  7%|▋         | 526/7272 [2:18:26<26:11:45, 13.98s/it]                                                       {'loss': 2.5055, 'grad_norm': 8.702683448791504, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 526, 'max_steps': 7272}
  7%|▋         | 526/7272 [2:18:26<26:11:45, 13.98s/it]  7%|▋         | 527/7272 [2:18:40<26:10:14, 13.97s/it]                                                       {'loss': 1.6612, 'grad_norm': 10.260525703430176, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 527, 'max_steps': 7272}
  7%|▋         | 527/7272 [2:18:40<26:10:14, 13.97s/it]  7%|▋         | 528/7272 [2:18:54<26:04:52, 13.92s/it]                                                       {'loss': 1.8661, 'grad_norm': 7.661858558654785, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 528, 'max_steps': 7272}
  7%|▋         | 528/7272 [2:18:54<26:04:52, 13.92s/it]  7%|▋         | 529/7272 [2:19:08<26:20:51, 14.07s/it]                                                       {'loss': 2.265, 'grad_norm': 11.5501708984375, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 529, 'max_steps': 7272}
  7%|▋         | 529/7272 [2:19:08<26:20:51, 14.07s/it]  7%|▋         | 530/7272 [2:19:22<26:16:22, 14.03s/it]                                                       {'loss': 2.0375, 'grad_norm': 8.713232040405273, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 530, 'max_steps': 7272}
  7%|▋         | 530/7272 [2:19:22<26:16:22, 14.03s/it]  7%|▋         | 531/7272 [2:19:36<26:15:51, 14.03s/it]                                                       {'loss': 1.0633, 'grad_norm': 2.668853521347046, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 531, 'max_steps': 7272}
  7%|▋         | 531/7272 [2:19:36<26:15:51, 14.03s/it]  7%|▋         | 532/7272 [2:19:50<26:13:04, 14.00s/it]                                                       {'loss': 3.0965, 'grad_norm': 7.651266098022461, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 532, 'max_steps': 7272}
  7%|▋         | 532/7272 [2:19:50<26:13:04, 14.00s/it]  7%|▋         | 533/7272 [2:20:04<26:18:29, 14.05s/it]                                                       {'loss': 1.642, 'grad_norm': 3.4043965339660645, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 533, 'max_steps': 7272}
  7%|▋         | 533/7272 [2:20:04<26:18:29, 14.05s/it]  7%|▋         | 534/7272 [2:20:18<26:22:06, 14.09s/it]                                                       {'loss': 2.0345, 'grad_norm': 5.07564640045166, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 534, 'max_steps': 7272}
  7%|▋         | 534/7272 [2:20:18<26:22:06, 14.09s/it]  7%|▋         | 535/7272 [2:20:33<26:34:13, 14.20s/it]                                                       {'loss': 3.0397, 'grad_norm': 7.100339889526367, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 535, 'max_steps': 7272}
  7%|▋         | 535/7272 [2:20:33<26:34:13, 14.20s/it]  7%|▋         | 536/7272 [2:20:48<26:53:45, 14.37s/it]                                                       {'loss': 3.3403, 'grad_norm': 8.633710861206055, 'learning_rate': 5e-05, 'epoch': 0.29, 'step': 536, 'max_steps': 7272}
  7%|▋         | 536/7272 [2:20:48<26:53:45, 14.37s/it]  7%|▋         | 537/7272 [2:21:02<26:49:01, 14.33s/it]                                                       {'loss': 3.3539, 'grad_norm': 8.344795227050781, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 537, 'max_steps': 7272}
  7%|▋         | 537/7272 [2:21:02<26:49:01, 14.33s/it]  7%|▋         | 538/7272 [2:21:16<26:35:27, 14.22s/it]                                                       {'loss': 0.6006, 'grad_norm': 4.793068885803223, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 538, 'max_steps': 7272}
  7%|▋         | 538/7272 [2:21:16<26:35:27, 14.22s/it]  7%|▋         | 539/7272 [2:21:30<26:22:53, 14.11s/it]                                                       {'loss': 1.7897, 'grad_norm': 7.736500263214111, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 539, 'max_steps': 7272}
  7%|▋         | 539/7272 [2:21:30<26:22:53, 14.11s/it]  7%|▋         | 540/7272 [2:21:44<26:20:06, 14.08s/it]                                                       {'loss': 2.0231, 'grad_norm': 6.535076141357422, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 540, 'max_steps': 7272}
  7%|▋         | 540/7272 [2:21:44<26:20:06, 14.08s/it]  7%|▋         | 541/7272 [2:21:58<26:21:28, 14.10s/it]                                                       {'loss': 3.0514, 'grad_norm': 8.743138313293457, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 541, 'max_steps': 7272}
  7%|▋         | 541/7272 [2:21:58<26:21:28, 14.10s/it]  7%|▋         | 542/7272 [2:22:12<26:24:51, 14.13s/it]                                                       {'loss': 2.1581, 'grad_norm': 8.946627616882324, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 542, 'max_steps': 7272}
  7%|▋         | 542/7272 [2:22:12<26:24:51, 14.13s/it]  7%|▋         | 543/7272 [2:22:26<26:17:58, 14.07s/it]                                                       {'loss': 3.4228, 'grad_norm': 13.919393539428711, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 543, 'max_steps': 7272}
  7%|▋         | 543/7272 [2:22:26<26:17:58, 14.07s/it]  7%|▋         | 544/7272 [2:22:40<26:08:11, 13.99s/it]                                                       {'loss': 2.1888, 'grad_norm': 10.533482551574707, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 544, 'max_steps': 7272}
  7%|▋         | 544/7272 [2:22:40<26:08:11, 13.99s/it]  7%|▋         | 545/7272 [2:22:54<26:18:40, 14.08s/it]                                                       {'loss': 3.8466, 'grad_norm': 18.925676345825195, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 545, 'max_steps': 7272}
  7%|▋         | 545/7272 [2:22:54<26:18:40, 14.08s/it]  8%|▊         | 546/7272 [2:23:08<26:27:54, 14.17s/it]                                                       {'loss': 1.6449, 'grad_norm': 5.653659820556641, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 546, 'max_steps': 7272}
  8%|▊         | 546/7272 [2:23:08<26:27:54, 14.17s/it]  8%|▊         | 547/7272 [2:23:22<26:10:34, 14.01s/it]                                                       {'loss': 1.4356, 'grad_norm': 8.784714698791504, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 547, 'max_steps': 7272}
  8%|▊         | 547/7272 [2:23:22<26:10:34, 14.01s/it]  8%|▊         | 548/7272 [2:23:36<25:59:36, 13.92s/it]                                                       {'loss': 1.6452, 'grad_norm': 4.003195762634277, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 548, 'max_steps': 7272}
  8%|▊         | 548/7272 [2:23:36<25:59:36, 13.92s/it]  8%|▊         | 549/7272 [2:23:49<25:54:53, 13.88s/it]                                                       {'loss': 1.6722, 'grad_norm': 9.444401741027832, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 549, 'max_steps': 7272}
  8%|▊         | 549/7272 [2:23:49<25:54:53, 13.88s/it]  8%|▊         | 550/7272 [2:24:03<25:56:24, 13.89s/it]                                                       {'loss': 2.2218, 'grad_norm': 8.239792823791504, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 550, 'max_steps': 7272}
  8%|▊         | 550/7272 [2:24:03<25:56:24, 13.89s/it]  8%|▊         | 551/7272 [2:24:17<25:51:03, 13.85s/it]                                                       {'loss': 2.9477, 'grad_norm': 10.794591903686523, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 551, 'max_steps': 7272}
  8%|▊         | 551/7272 [2:24:17<25:51:03, 13.85s/it]  8%|▊         | 552/7272 [2:24:31<25:45:16, 13.80s/it]                                                       {'loss': 2.4814, 'grad_norm': 10.721467018127441, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 552, 'max_steps': 7272}
  8%|▊         | 552/7272 [2:24:31<25:45:16, 13.80s/it]  8%|▊         | 553/7272 [2:24:45<25:59:25, 13.93s/it]                                                       {'loss': 1.6715, 'grad_norm': 9.48706340789795, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 553, 'max_steps': 7272}
  8%|▊         | 553/7272 [2:24:45<25:59:25, 13.93s/it]  8%|▊         | 554/7272 [2:24:59<25:52:52, 13.87s/it]                                                       {'loss': 0.5891, 'grad_norm': 2.61154842376709, 'learning_rate': 5e-05, 'epoch': 0.3, 'step': 554, 'max_steps': 7272}
  8%|▊         | 554/7272 [2:24:59<25:52:52, 13.87s/it]  8%|▊         | 555/7272 [2:25:13<25:57:31, 13.91s/it]                                                       {'loss': 1.1007, 'grad_norm': 5.4235334396362305, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 555, 'max_steps': 7272}
  8%|▊         | 555/7272 [2:25:13<25:57:31, 13.91s/it]  8%|▊         | 556/7272 [2:25:27<25:53:45, 13.88s/it]                                                       {'loss': 1.0895, 'grad_norm': 6.963104248046875, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 556, 'max_steps': 7272}
  8%|▊         | 556/7272 [2:25:27<25:53:45, 13.88s/it]  8%|▊         | 557/7272 [2:25:41<25:56:26, 13.91s/it]                                                       {'loss': 1.6734, 'grad_norm': 7.105787754058838, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 557, 'max_steps': 7272}
  8%|▊         | 557/7272 [2:25:41<25:56:26, 13.91s/it]  8%|▊         | 558/7272 [2:25:54<25:52:40, 13.88s/it]                                                       {'loss': 2.3329, 'grad_norm': 4.825666427612305, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 558, 'max_steps': 7272}
  8%|▊         | 558/7272 [2:25:54<25:52:40, 13.88s/it]  8%|▊         | 559/7272 [2:26:08<25:59:40, 13.94s/it]                                                       {'loss': 1.8731, 'grad_norm': 5.345478534698486, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 559, 'max_steps': 7272}
  8%|▊         | 559/7272 [2:26:08<25:59:40, 13.94s/it]  8%|▊         | 560/7272 [2:26:23<26:05:20, 13.99s/it]                                                       {'loss': 1.0147, 'grad_norm': 4.392230033874512, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 560, 'max_steps': 7272}
  8%|▊         | 560/7272 [2:26:23<26:05:20, 13.99s/it]  8%|▊         | 561/7272 [2:26:37<26:14:44, 14.08s/it]                                                       {'loss': 0.8995, 'grad_norm': 4.941857814788818, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 561, 'max_steps': 7272}
  8%|▊         | 561/7272 [2:26:37<26:14:44, 14.08s/it]  8%|▊         | 562/7272 [2:26:51<26:10:29, 14.04s/it]                                                       {'loss': 2.4122, 'grad_norm': 8.188889503479004, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 562, 'max_steps': 7272}
  8%|▊         | 562/7272 [2:26:51<26:10:29, 14.04s/it]  8%|▊         | 563/7272 [2:27:05<26:22:54, 14.16s/it]                                                       {'loss': 1.5896, 'grad_norm': 5.94514799118042, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 563, 'max_steps': 7272}
  8%|▊         | 563/7272 [2:27:05<26:22:54, 14.16s/it]  8%|▊         | 564/7272 [2:27:20<26:32:08, 14.24s/it]                                                       {'loss': 1.2386, 'grad_norm': 6.222774505615234, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 564, 'max_steps': 7272}
  8%|▊         | 564/7272 [2:27:20<26:32:08, 14.24s/it]  8%|▊         | 565/7272 [2:27:34<26:26:34, 14.19s/it]                                                       {'loss': 2.3802, 'grad_norm': 8.464488983154297, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 565, 'max_steps': 7272}
  8%|▊         | 565/7272 [2:27:34<26:26:34, 14.19s/it]  8%|▊         | 566/7272 [2:27:48<26:29:50, 14.22s/it]                                                       {'loss': 1.9695, 'grad_norm': 15.532703399658203, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 566, 'max_steps': 7272}
  8%|▊         | 566/7272 [2:27:48<26:29:50, 14.22s/it]  8%|▊         | 567/7272 [2:28:02<26:32:14, 14.25s/it]                                                       {'loss': 1.6148, 'grad_norm': 4.881231784820557, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 567, 'max_steps': 7272}
  8%|▊         | 567/7272 [2:28:02<26:32:14, 14.25s/it]  8%|▊         | 568/7272 [2:28:16<26:23:58, 14.18s/it]                                                       {'loss': 1.202, 'grad_norm': 2.6099109649658203, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 568, 'max_steps': 7272}
  8%|▊         | 568/7272 [2:28:16<26:23:58, 14.18s/it]  8%|▊         | 569/7272 [2:28:31<26:27:15, 14.21s/it]                                                       {'loss': 3.0699, 'grad_norm': 7.429416179656982, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 569, 'max_steps': 7272}
  8%|▊         | 569/7272 [2:28:31<26:27:15, 14.21s/it]  8%|▊         | 570/7272 [2:28:45<26:23:33, 14.18s/it]                                                       {'loss': 3.077, 'grad_norm': 8.01209831237793, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 570, 'max_steps': 7272}
  8%|▊         | 570/7272 [2:28:45<26:23:33, 14.18s/it]  8%|▊         | 571/7272 [2:28:59<26:20:21, 14.15s/it]                                                       {'loss': 0.7786, 'grad_norm': 3.4087483882904053, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 571, 'max_steps': 7272}
  8%|▊         | 571/7272 [2:28:59<26:20:21, 14.15s/it]  8%|▊         | 572/7272 [2:29:13<26:14:34, 14.10s/it]                                                       {'loss': 2.1187, 'grad_norm': 13.194411277770996, 'learning_rate': 5e-05, 'epoch': 0.31, 'step': 572, 'max_steps': 7272}
  8%|▊         | 572/7272 [2:29:13<26:14:34, 14.10s/it]  8%|▊         | 573/7272 [2:29:27<26:15:55, 14.11s/it]                                                       {'loss': 1.8561, 'grad_norm': 5.631472587585449, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 573, 'max_steps': 7272}
  8%|▊         | 573/7272 [2:29:27<26:15:55, 14.11s/it]  8%|▊         | 574/7272 [2:29:41<26:10:30, 14.07s/it]                                                       {'loss': 1.5728, 'grad_norm': 4.246522903442383, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 574, 'max_steps': 7272}
  8%|▊         | 574/7272 [2:29:41<26:10:30, 14.07s/it]  8%|▊         | 575/7272 [2:29:55<26:07:00, 14.04s/it]                                                       {'loss': 2.0198, 'grad_norm': 3.9961555004119873, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 575, 'max_steps': 7272}
  8%|▊         | 575/7272 [2:29:55<26:07:00, 14.04s/it]  8%|▊         | 576/7272 [2:30:10<26:38:47, 14.33s/it]                                                       {'loss': 2.8479, 'grad_norm': 5.153149604797363, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 576, 'max_steps': 7272}
  8%|▊         | 576/7272 [2:30:10<26:38:47, 14.33s/it]  8%|▊         | 577/7272 [2:30:24<26:36:08, 14.30s/it]                                                       {'loss': 0.8735, 'grad_norm': 7.32094669342041, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 577, 'max_steps': 7272}
  8%|▊         | 577/7272 [2:30:24<26:36:08, 14.30s/it]  8%|▊         | 578/7272 [2:30:38<26:26:33, 14.22s/it]                                                       {'loss': 2.2115, 'grad_norm': 9.789030075073242, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 578, 'max_steps': 7272}
  8%|▊         | 578/7272 [2:30:38<26:26:33, 14.22s/it]  8%|▊         | 579/7272 [2:30:52<26:24:19, 14.20s/it]                                                       {'loss': 1.6094, 'grad_norm': 9.262935638427734, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 579, 'max_steps': 7272}
  8%|▊         | 579/7272 [2:30:52<26:24:19, 14.20s/it]  8%|▊         | 580/7272 [2:31:06<26:17:57, 14.15s/it]                                                       {'loss': 1.7172, 'grad_norm': 7.811600685119629, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 580, 'max_steps': 7272}
  8%|▊         | 580/7272 [2:31:06<26:17:57, 14.15s/it]  8%|▊         | 581/7272 [2:31:21<26:20:32, 14.17s/it]                                                       {'loss': 1.0993, 'grad_norm': 3.321640968322754, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 581, 'max_steps': 7272}
  8%|▊         | 581/7272 [2:31:21<26:20:32, 14.17s/it]  8%|▊         | 582/7272 [2:31:34<26:08:00, 14.06s/it]                                                       {'loss': 2.3677, 'grad_norm': 3.850379228591919, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 582, 'max_steps': 7272}
  8%|▊         | 582/7272 [2:31:34<26:08:00, 14.06s/it]  8%|▊         | 583/7272 [2:31:48<26:00:10, 13.99s/it]                                                       {'loss': 1.1881, 'grad_norm': 2.23822021484375, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 583, 'max_steps': 7272}
  8%|▊         | 583/7272 [2:31:48<26:00:10, 13.99s/it]  8%|▊         | 584/7272 [2:32:02<25:42:44, 13.84s/it]                                                       {'loss': 1.4815, 'grad_norm': 8.735486030578613, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 584, 'max_steps': 7272}
  8%|▊         | 584/7272 [2:32:02<25:42:44, 13.84s/it]  8%|▊         | 585/7272 [2:32:16<25:56:13, 13.96s/it]                                                       {'loss': 1.2616, 'grad_norm': 6.2956109046936035, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 585, 'max_steps': 7272}
  8%|▊         | 585/7272 [2:32:16<25:56:13, 13.96s/it]  8%|▊         | 586/7272 [2:32:30<26:01:18, 14.01s/it]                                                       {'loss': 1.0789, 'grad_norm': 3.923175811767578, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 586, 'max_steps': 7272}
  8%|▊         | 586/7272 [2:32:30<26:01:18, 14.01s/it]  8%|▊         | 587/7272 [2:32:45<26:24:33, 14.22s/it]                                                       {'loss': 3.2964, 'grad_norm': 9.697805404663086, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 587, 'max_steps': 7272}
  8%|▊         | 587/7272 [2:32:45<26:24:33, 14.22s/it]  8%|▊         | 588/7272 [2:32:59<26:38:28, 14.35s/it]                                                       {'loss': 1.0729, 'grad_norm': 7.150238990783691, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 588, 'max_steps': 7272}
  8%|▊         | 588/7272 [2:32:59<26:38:28, 14.35s/it]  8%|▊         | 589/7272 [2:33:14<26:27:39, 14.25s/it]                                                       {'loss': 0.6339, 'grad_norm': 2.8815970420837402, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 589, 'max_steps': 7272}
  8%|▊         | 589/7272 [2:33:14<26:27:39, 14.25s/it]  8%|▊         | 590/7272 [2:33:29<26:52:22, 14.48s/it]                                                       {'loss': 2.4762, 'grad_norm': 6.472107410430908, 'learning_rate': 5e-05, 'epoch': 0.32, 'step': 590, 'max_steps': 7272}
  8%|▊         | 590/7272 [2:33:29<26:52:22, 14.48s/it]  8%|▊         | 591/7272 [2:33:44<27:21:13, 14.74s/it]                                                       {'loss': 2.696, 'grad_norm': 9.82392692565918, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 591, 'max_steps': 7272}
  8%|▊         | 591/7272 [2:33:44<27:21:13, 14.74s/it]  8%|▊         | 592/7272 [2:33:59<27:38:29, 14.90s/it]                                                       {'loss': 3.514, 'grad_norm': 8.281618118286133, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 592, 'max_steps': 7272}
  8%|▊         | 592/7272 [2:33:59<27:38:29, 14.90s/it]  8%|▊         | 593/7272 [2:34:15<28:03:20, 15.12s/it]                                                       {'loss': 3.0354, 'grad_norm': 9.453296661376953, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 593, 'max_steps': 7272}
  8%|▊         | 593/7272 [2:34:15<28:03:20, 15.12s/it]  8%|▊         | 594/7272 [2:34:31<28:38:34, 15.44s/it]                                                       {'loss': 1.1877, 'grad_norm': 5.8500261306762695, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 594, 'max_steps': 7272}
  8%|▊         | 594/7272 [2:34:31<28:38:34, 15.44s/it]  8%|▊         | 595/7272 [2:34:47<29:10:19, 15.73s/it]                                                       {'loss': 1.3822, 'grad_norm': 5.390949249267578, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 595, 'max_steps': 7272}
  8%|▊         | 595/7272 [2:34:47<29:10:19, 15.73s/it]  8%|▊         | 596/7272 [2:35:03<29:22:42, 15.84s/it]                                                       {'loss': 1.8667, 'grad_norm': 5.944556713104248, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 596, 'max_steps': 7272}
  8%|▊         | 596/7272 [2:35:03<29:22:42, 15.84s/it]  8%|▊         | 597/7272 [2:35:20<29:48:19, 16.07s/it]                                                       {'loss': 2.7165, 'grad_norm': 9.274078369140625, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 597, 'max_steps': 7272}
  8%|▊         | 597/7272 [2:35:20<29:48:19, 16.07s/it]  8%|▊         | 598/7272 [2:35:37<30:00:06, 16.18s/it]                                                       {'loss': 1.9746, 'grad_norm': 19.116050720214844, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 598, 'max_steps': 7272}
  8%|▊         | 598/7272 [2:35:37<30:00:06, 16.18s/it]  8%|▊         | 599/7272 [2:35:53<29:56:44, 16.16s/it]                                                       {'loss': 1.5765, 'grad_norm': 4.6169753074646, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 599, 'max_steps': 7272}
  8%|▊         | 599/7272 [2:35:53<29:56:44, 16.16s/it]  8%|▊         | 600/7272 [2:36:08<29:41:00, 16.02s/it]                                                       {'loss': 1.459, 'grad_norm': 3.7249927520751953, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 600, 'max_steps': 7272}
  8%|▊         | 600/7272 [2:36:08<29:41:00, 16.02s/it]  8%|▊         | 601/7272 [2:36:24<29:41:54, 16.03s/it]                                                       {'loss': 1.4793, 'grad_norm': 6.244686603546143, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 601, 'max_steps': 7272}
  8%|▊         | 601/7272 [2:36:24<29:41:54, 16.03s/it]  8%|▊         | 602/7272 [2:36:40<29:29:15, 15.92s/it]                                                       {'loss': 1.1058, 'grad_norm': 3.686081886291504, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 602, 'max_steps': 7272}
  8%|▊         | 602/7272 [2:36:40<29:29:15, 15.92s/it]  8%|▊         | 603/7272 [2:36:56<29:28:08, 15.91s/it]                                                       {'loss': 2.6914, 'grad_norm': 6.969756603240967, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 603, 'max_steps': 7272}
  8%|▊         | 603/7272 [2:36:56<29:28:08, 15.91s/it]  8%|▊         | 604/7272 [2:37:12<29:38:06, 16.00s/it]                                                       {'loss': 1.5763, 'grad_norm': 5.238734245300293, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 604, 'max_steps': 7272}
  8%|▊         | 604/7272 [2:37:12<29:38:06, 16.00s/it]  8%|▊         | 605/7272 [2:37:28<29:34:17, 15.97s/it]                                                       {'loss': 1.6968, 'grad_norm': 8.963006019592285, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 605, 'max_steps': 7272}
  8%|▊         | 605/7272 [2:37:28<29:34:17, 15.97s/it]  8%|▊         | 606/7272 [2:37:44<29:36:05, 15.99s/it]                                                       {'loss': 1.4286, 'grad_norm': 7.460203170776367, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 606, 'max_steps': 7272}
  8%|▊         | 606/7272 [2:37:44<29:36:05, 15.99s/it]  8%|▊         | 607/7272 [2:38:00<29:29:45, 15.93s/it]                                                       {'loss': 1.6395, 'grad_norm': 5.507455348968506, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 607, 'max_steps': 7272}
  8%|▊         | 607/7272 [2:38:00<29:29:45, 15.93s/it]  8%|▊         | 608/7272 [2:38:16<29:29:28, 15.93s/it]                                                       {'loss': 2.5531, 'grad_norm': 5.3762993812561035, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 608, 'max_steps': 7272}
  8%|▊         | 608/7272 [2:38:16<29:29:28, 15.93s/it]  8%|▊         | 609/7272 [2:38:32<29:25:39, 15.90s/it]                                                       {'loss': 1.1461, 'grad_norm': 8.26728343963623, 'learning_rate': 5e-05, 'epoch': 0.33, 'step': 609, 'max_steps': 7272}
  8%|▊         | 609/7272 [2:38:32<29:25:39, 15.90s/it]  8%|▊         | 610/7272 [2:38:48<29:27:20, 15.92s/it]                                                       {'loss': 0.7314, 'grad_norm': 4.217452526092529, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 610, 'max_steps': 7272}
  8%|▊         | 610/7272 [2:38:48<29:27:20, 15.92s/it]  8%|▊         | 611/7272 [2:39:03<29:16:35, 15.82s/it]                                                       {'loss': 2.3886, 'grad_norm': 6.575057506561279, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 611, 'max_steps': 7272}
  8%|▊         | 611/7272 [2:39:03<29:16:35, 15.82s/it]  8%|▊         | 612/7272 [2:39:19<29:25:01, 15.90s/it]                                                       {'loss': 1.4367, 'grad_norm': 5.451298713684082, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 612, 'max_steps': 7272}
  8%|▊         | 612/7272 [2:39:19<29:25:01, 15.90s/it]  8%|▊         | 613/7272 [2:39:35<29:31:18, 15.96s/it]                                                       {'loss': 2.4882, 'grad_norm': 4.981016159057617, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 613, 'max_steps': 7272}
  8%|▊         | 613/7272 [2:39:35<29:31:18, 15.96s/it]  8%|▊         | 614/7272 [2:39:51<29:19:40, 15.86s/it]                                                       {'loss': 1.5737, 'grad_norm': 4.581114768981934, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 614, 'max_steps': 7272}
  8%|▊         | 614/7272 [2:39:51<29:19:40, 15.86s/it]  8%|▊         | 615/7272 [2:40:07<29:31:26, 15.97s/it]                                                       {'loss': 3.2454, 'grad_norm': 8.178083419799805, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 615, 'max_steps': 7272}
  8%|▊         | 615/7272 [2:40:07<29:31:26, 15.97s/it]  8%|▊         | 616/7272 [2:40:23<29:23:30, 15.90s/it]                                                       {'loss': 1.9212, 'grad_norm': 5.557485580444336, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 616, 'max_steps': 7272}
  8%|▊         | 616/7272 [2:40:23<29:23:30, 15.90s/it]  8%|▊         | 617/7272 [2:40:39<29:22:38, 15.89s/it]                                                       {'loss': 1.6599, 'grad_norm': 10.88653564453125, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 617, 'max_steps': 7272}
  8%|▊         | 617/7272 [2:40:39<29:22:38, 15.89s/it]  8%|▊         | 618/7272 [2:40:55<29:28:32, 15.95s/it]                                                       {'loss': 0.9153, 'grad_norm': 2.8563477993011475, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 618, 'max_steps': 7272}
  8%|▊         | 618/7272 [2:40:55<29:28:32, 15.95s/it]  9%|▊         | 619/7272 [2:41:11<29:27:43, 15.94s/it]                                                       {'loss': 1.1719, 'grad_norm': 4.483359336853027, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 619, 'max_steps': 7272}
  9%|▊         | 619/7272 [2:41:11<29:27:43, 15.94s/it]  9%|▊         | 620/7272 [2:41:26<29:11:13, 15.80s/it]                                                       {'loss': 2.927, 'grad_norm': 9.752852439880371, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 620, 'max_steps': 7272}
  9%|▊         | 620/7272 [2:41:26<29:11:13, 15.80s/it]  9%|▊         | 621/7272 [2:41:43<29:30:48, 15.97s/it]                                                       {'loss': 1.3327, 'grad_norm': 4.871433258056641, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 621, 'max_steps': 7272}
  9%|▊         | 621/7272 [2:41:43<29:30:48, 15.97s/it]  9%|▊         | 622/7272 [2:41:59<29:59:12, 16.23s/it]                                                       {'loss': 1.0505, 'grad_norm': 10.18072509765625, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 622, 'max_steps': 7272}
  9%|▊         | 622/7272 [2:41:59<29:59:12, 16.23s/it]  9%|▊         | 623/7272 [2:42:16<29:57:23, 16.22s/it]                                                       {'loss': 1.2506, 'grad_norm': 8.748601913452148, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 623, 'max_steps': 7272}
  9%|▊         | 623/7272 [2:42:16<29:57:23, 16.22s/it]  9%|▊         | 624/7272 [2:42:31<29:42:27, 16.09s/it]                                                       {'loss': 2.4612, 'grad_norm': 11.249496459960938, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 624, 'max_steps': 7272}
  9%|▊         | 624/7272 [2:42:31<29:42:27, 16.09s/it]  9%|▊         | 625/7272 [2:42:47<29:27:09, 15.95s/it]                                                       {'loss': 1.5273, 'grad_norm': 7.704329013824463, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 625, 'max_steps': 7272}
  9%|▊         | 625/7272 [2:42:47<29:27:09, 15.95s/it]  9%|▊         | 626/7272 [2:43:03<29:27:38, 15.96s/it]                                                       {'loss': 1.2841, 'grad_norm': 3.714564800262451, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 626, 'max_steps': 7272}
  9%|▊         | 626/7272 [2:43:03<29:27:38, 15.96s/it]  9%|▊         | 627/7272 [2:43:20<29:46:21, 16.13s/it]                                                       {'loss': 2.7073, 'grad_norm': 5.670436382293701, 'learning_rate': 5e-05, 'epoch': 0.34, 'step': 627, 'max_steps': 7272}
  9%|▊         | 627/7272 [2:43:20<29:46:21, 16.13s/it]  9%|▊         | 628/7272 [2:43:36<29:44:06, 16.11s/it]                                                       {'loss': 1.6148, 'grad_norm': 2.971195936203003, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 628, 'max_steps': 7272}
  9%|▊         | 628/7272 [2:43:36<29:44:06, 16.11s/it]  9%|▊         | 629/7272 [2:43:52<29:46:44, 16.14s/it]                                                       {'loss': 0.5614, 'grad_norm': 2.9170777797698975, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 629, 'max_steps': 7272}
  9%|▊         | 629/7272 [2:43:52<29:46:44, 16.14s/it]  9%|▊         | 630/7272 [2:44:08<29:40:12, 16.08s/it]                                                       {'loss': 1.4896, 'grad_norm': 5.1131978034973145, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 630, 'max_steps': 7272}
  9%|▊         | 630/7272 [2:44:08<29:40:12, 16.08s/it]  9%|▊         | 631/7272 [2:44:24<29:37:32, 16.06s/it]                                                       {'loss': 1.0987, 'grad_norm': 6.019542217254639, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 631, 'max_steps': 7272}
  9%|▊         | 631/7272 [2:44:24<29:37:32, 16.06s/it]  9%|▊         | 632/7272 [2:44:40<29:41:56, 16.10s/it]                                                       {'loss': 1.6712, 'grad_norm': 4.296299934387207, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 632, 'max_steps': 7272}
  9%|▊         | 632/7272 [2:44:40<29:41:56, 16.10s/it]  9%|▊         | 633/7272 [2:44:56<29:25:18, 15.95s/it]                                                       {'loss': 1.6674, 'grad_norm': 5.5482497215271, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 633, 'max_steps': 7272}
  9%|▊         | 633/7272 [2:44:56<29:25:18, 15.95s/it]  9%|▊         | 634/7272 [2:45:12<29:29:33, 15.99s/it]                                                       {'loss': 0.8722, 'grad_norm': 4.165440559387207, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 634, 'max_steps': 7272}
  9%|▊         | 634/7272 [2:45:12<29:29:33, 15.99s/it]  9%|▊         | 635/7272 [2:45:27<29:17:02, 15.88s/it]                                                       {'loss': 2.3459, 'grad_norm': 6.614755630493164, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 635, 'max_steps': 7272}
  9%|▊         | 635/7272 [2:45:27<29:17:02, 15.88s/it]  9%|▊         | 636/7272 [2:45:43<29:10:19, 15.83s/it]                                                       {'loss': 1.1262, 'grad_norm': 5.244664669036865, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 636, 'max_steps': 7272}
  9%|▊         | 636/7272 [2:45:43<29:10:19, 15.83s/it]  9%|▉         | 637/7272 [2:45:59<29:04:16, 15.77s/it]                                                       {'loss': 1.0618, 'grad_norm': 4.115008354187012, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 637, 'max_steps': 7272}
  9%|▉         | 637/7272 [2:45:59<29:04:16, 15.77s/it]  9%|▉         | 638/7272 [2:46:15<29:16:05, 15.88s/it]                                                       {'loss': 0.4985, 'grad_norm': 4.955351829528809, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 638, 'max_steps': 7272}
  9%|▉         | 638/7272 [2:46:15<29:16:05, 15.88s/it]  9%|▉         | 639/7272 [2:46:30<29:06:08, 15.80s/it]                                                       {'loss': 2.0734, 'grad_norm': 7.132530212402344, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 639, 'max_steps': 7272}
  9%|▉         | 639/7272 [2:46:30<29:06:08, 15.80s/it]  9%|▉         | 640/7272 [2:46:47<29:28:16, 16.00s/it]                                                       {'loss': 1.1552, 'grad_norm': 4.80277681350708, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 640, 'max_steps': 7272}
  9%|▉         | 640/7272 [2:46:47<29:28:16, 16.00s/it]  9%|▉         | 641/7272 [2:47:03<29:22:40, 15.95s/it]                                                       {'loss': 2.4127, 'grad_norm': 4.037903308868408, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 641, 'max_steps': 7272}
  9%|▉         | 641/7272 [2:47:03<29:22:40, 15.95s/it]  9%|▉         | 642/7272 [2:47:18<29:06:48, 15.81s/it]                                                       {'loss': 2.1951, 'grad_norm': 6.555778980255127, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 642, 'max_steps': 7272}
  9%|▉         | 642/7272 [2:47:18<29:06:48, 15.81s/it]  9%|▉         | 643/7272 [2:47:34<29:08:26, 15.83s/it]                                                       {'loss': 1.2023, 'grad_norm': 3.9655301570892334, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 643, 'max_steps': 7272}
  9%|▉         | 643/7272 [2:47:34<29:08:26, 15.83s/it]  9%|▉         | 644/7272 [2:47:50<29:04:23, 15.79s/it]                                                       {'loss': 1.247, 'grad_norm': 5.848409652709961, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 644, 'max_steps': 7272}
  9%|▉         | 644/7272 [2:47:50<29:04:23, 15.79s/it]  9%|▉         | 645/7272 [2:48:06<29:25:35, 15.99s/it]                                                       {'loss': 2.1857, 'grad_norm': 8.98799991607666, 'learning_rate': 5e-05, 'epoch': 0.35, 'step': 645, 'max_steps': 7272}
  9%|▉         | 645/7272 [2:48:06<29:25:35, 15.99s/it]  9%|▉         | 646/7272 [2:48:23<29:52:01, 16.23s/it]                                                       {'loss': 2.7829, 'grad_norm': 11.133014678955078, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 646, 'max_steps': 7272}
  9%|▉         | 646/7272 [2:48:23<29:52:01, 16.23s/it]  9%|▉         | 647/7272 [2:48:39<29:48:09, 16.19s/it]                                                       {'loss': 1.6054, 'grad_norm': 3.9684219360351562, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 647, 'max_steps': 7272}
  9%|▉         | 647/7272 [2:48:39<29:48:09, 16.19s/it]  9%|▉         | 648/7272 [2:48:56<29:56:51, 16.28s/it]                                                       {'loss': 1.3751, 'grad_norm': 3.9874823093414307, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 648, 'max_steps': 7272}
  9%|▉         | 648/7272 [2:48:56<29:56:51, 16.28s/it]  9%|▉         | 649/7272 [2:49:12<30:16:19, 16.45s/it]                                                       {'loss': 2.264, 'grad_norm': 6.511116027832031, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 649, 'max_steps': 7272}
  9%|▉         | 649/7272 [2:49:12<30:16:19, 16.45s/it]  9%|▉         | 650/7272 [2:49:29<30:24:12, 16.53s/it]                                                       {'loss': 1.6777, 'grad_norm': 6.33385705947876, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 650, 'max_steps': 7272}
  9%|▉         | 650/7272 [2:49:29<30:24:12, 16.53s/it]  9%|▉         | 651/7272 [2:49:45<30:06:19, 16.37s/it]                                                       {'loss': 2.115, 'grad_norm': 8.29776382446289, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 651, 'max_steps': 7272}
  9%|▉         | 651/7272 [2:49:45<30:06:19, 16.37s/it]  9%|▉         | 652/7272 [2:50:02<30:25:21, 16.54s/it]                                                       {'loss': 2.5392, 'grad_norm': 5.729690074920654, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 652, 'max_steps': 7272}
  9%|▉         | 652/7272 [2:50:02<30:25:21, 16.54s/it]  9%|▉         | 653/7272 [2:50:19<30:24:33, 16.54s/it]                                                       {'loss': 1.9468, 'grad_norm': 8.429801940917969, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 653, 'max_steps': 7272}
  9%|▉         | 653/7272 [2:50:19<30:24:33, 16.54s/it]  9%|▉         | 654/7272 [2:50:35<30:17:02, 16.47s/it]                                                       {'loss': 1.8312, 'grad_norm': 8.756145477294922, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 654, 'max_steps': 7272}
  9%|▉         | 654/7272 [2:50:35<30:17:02, 16.47s/it]  9%|▉         | 655/7272 [2:50:51<30:03:55, 16.36s/it]                                                       {'loss': 1.9535, 'grad_norm': 8.044795989990234, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 655, 'max_steps': 7272}
  9%|▉         | 655/7272 [2:50:51<30:03:55, 16.36s/it]  9%|▉         | 656/7272 [2:51:06<29:32:42, 16.08s/it]                                                       {'loss': 1.6154, 'grad_norm': 5.274593830108643, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 656, 'max_steps': 7272}
  9%|▉         | 656/7272 [2:51:06<29:32:42, 16.08s/it]  9%|▉         | 657/7272 [2:51:22<29:29:28, 16.05s/it]                                                       {'loss': 2.4779, 'grad_norm': 12.66342544555664, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 657, 'max_steps': 7272}
  9%|▉         | 657/7272 [2:51:22<29:29:28, 16.05s/it]  9%|▉         | 658/7272 [2:51:38<29:22:08, 15.99s/it]                                                       {'loss': 2.2721, 'grad_norm': 6.170673370361328, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 658, 'max_steps': 7272}
  9%|▉         | 658/7272 [2:51:38<29:22:08, 15.99s/it]  9%|▉         | 659/7272 [2:51:54<29:15:06, 15.92s/it]                                                       {'loss': 2.9431, 'grad_norm': 6.569957256317139, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 659, 'max_steps': 7272}
  9%|▉         | 659/7272 [2:51:54<29:15:06, 15.92s/it]  9%|▉         | 660/7272 [2:52:10<29:17:10, 15.95s/it]                                                       {'loss': 1.7506, 'grad_norm': 9.031511306762695, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 660, 'max_steps': 7272}
  9%|▉         | 660/7272 [2:52:10<29:17:10, 15.95s/it]  9%|▉         | 661/7272 [2:52:26<29:18:22, 15.96s/it]                                                       {'loss': 2.1077, 'grad_norm': 7.8314032554626465, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 661, 'max_steps': 7272}
  9%|▉         | 661/7272 [2:52:26<29:18:22, 15.96s/it]  9%|▉         | 662/7272 [2:52:42<29:16:05, 15.94s/it]                                                       {'loss': 2.5882, 'grad_norm': 8.650123596191406, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 662, 'max_steps': 7272}
  9%|▉         | 662/7272 [2:52:42<29:16:05, 15.94s/it]  9%|▉         | 663/7272 [2:52:58<29:14:57, 15.93s/it]                                                       {'loss': 1.7164, 'grad_norm': 9.255416870117188, 'learning_rate': 5e-05, 'epoch': 0.36, 'step': 663, 'max_steps': 7272}
  9%|▉         | 663/7272 [2:52:58<29:14:57, 15.93s/it]  9%|▉         | 664/7272 [2:53:14<29:12:41, 15.91s/it]                                                       {'loss': 1.055, 'grad_norm': 3.4472615718841553, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 664, 'max_steps': 7272}
  9%|▉         | 664/7272 [2:53:14<29:12:41, 15.91s/it]  9%|▉         | 665/7272 [2:53:30<29:11:00, 15.90s/it]                                                       {'loss': 2.4121, 'grad_norm': 11.805731773376465, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 665, 'max_steps': 7272}
  9%|▉         | 665/7272 [2:53:30<29:11:00, 15.90s/it]  9%|▉         | 666/7272 [2:53:45<29:02:37, 15.83s/it]                                                       {'loss': 2.9887, 'grad_norm': 6.351370811462402, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 666, 'max_steps': 7272}
  9%|▉         | 666/7272 [2:53:45<29:02:37, 15.83s/it]  9%|▉         | 667/7272 [2:54:01<28:54:06, 15.75s/it]                                                       {'loss': 2.8913, 'grad_norm': 9.302279472351074, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 667, 'max_steps': 7272}
  9%|▉         | 667/7272 [2:54:01<28:54:06, 15.75s/it]  9%|▉         | 668/7272 [2:54:17<28:52:35, 15.74s/it]                                                       {'loss': 1.4156, 'grad_norm': 5.194928169250488, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 668, 'max_steps': 7272}
  9%|▉         | 668/7272 [2:54:17<28:52:35, 15.74s/it]  9%|▉         | 669/7272 [2:54:33<29:11:52, 15.92s/it]                                                       {'loss': 1.0475, 'grad_norm': 4.318393707275391, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 669, 'max_steps': 7272}
  9%|▉         | 669/7272 [2:54:33<29:11:52, 15.92s/it]  9%|▉         | 670/7272 [2:54:49<29:17:28, 15.97s/it]                                                       {'loss': 1.5597, 'grad_norm': 6.843165397644043, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 670, 'max_steps': 7272}
  9%|▉         | 670/7272 [2:54:49<29:17:28, 15.97s/it]  9%|▉         | 671/7272 [2:55:05<29:30:41, 16.09s/it]                                                       {'loss': 1.3851, 'grad_norm': 2.3876736164093018, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 671, 'max_steps': 7272}
  9%|▉         | 671/7272 [2:55:05<29:30:41, 16.09s/it]  9%|▉         | 672/7272 [2:55:22<29:32:21, 16.11s/it]                                                       {'loss': 1.8965, 'grad_norm': 3.632260322570801, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 672, 'max_steps': 7272}
  9%|▉         | 672/7272 [2:55:22<29:32:21, 16.11s/it]  9%|▉         | 673/7272 [2:55:37<29:26:02, 16.06s/it]                                                       {'loss': 1.3665, 'grad_norm': 4.677384376525879, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 673, 'max_steps': 7272}
  9%|▉         | 673/7272 [2:55:37<29:26:02, 16.06s/it]  9%|▉         | 674/7272 [2:55:54<29:26:12, 16.06s/it]                                                       {'loss': 1.342, 'grad_norm': 2.87909197807312, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 674, 'max_steps': 7272}
  9%|▉         | 674/7272 [2:55:54<29:26:12, 16.06s/it]  9%|▉         | 675/7272 [2:56:09<29:15:57, 15.97s/it]                                                       {'loss': 1.7429, 'grad_norm': 5.088113307952881, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 675, 'max_steps': 7272}
  9%|▉         | 675/7272 [2:56:09<29:15:57, 15.97s/it]  9%|▉         | 676/7272 [2:56:25<28:58:33, 15.81s/it]                                                       {'loss': 1.553, 'grad_norm': 4.942822456359863, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 676, 'max_steps': 7272}
  9%|▉         | 676/7272 [2:56:25<28:58:33, 15.81s/it]  9%|▉         | 677/7272 [2:56:40<28:51:42, 15.75s/it]                                                       {'loss': 1.201, 'grad_norm': 2.3270232677459717, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 677, 'max_steps': 7272}
  9%|▉         | 677/7272 [2:56:40<28:51:42, 15.75s/it]  9%|▉         | 678/7272 [2:56:56<28:46:49, 15.71s/it]                                                       {'loss': 1.8997, 'grad_norm': 11.7307710647583, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 678, 'max_steps': 7272}
  9%|▉         | 678/7272 [2:56:56<28:46:49, 15.71s/it]  9%|▉         | 679/7272 [2:57:12<28:47:57, 15.73s/it]                                                       {'loss': 2.2909, 'grad_norm': 11.716340065002441, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 679, 'max_steps': 7272}
  9%|▉         | 679/7272 [2:57:12<28:47:57, 15.73s/it]  9%|▉         | 680/7272 [2:57:27<28:41:44, 15.67s/it]                                                       {'loss': 2.0551, 'grad_norm': 10.343496322631836, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 680, 'max_steps': 7272}
  9%|▉         | 680/7272 [2:57:27<28:41:44, 15.67s/it]  9%|▉         | 681/7272 [2:57:42<28:22:25, 15.50s/it]                                                       {'loss': 2.102, 'grad_norm': 9.554228782653809, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 681, 'max_steps': 7272}
  9%|▉         | 681/7272 [2:57:42<28:22:25, 15.50s/it]  9%|▉         | 682/7272 [2:57:59<28:46:28, 15.72s/it]                                                       {'loss': 2.0074, 'grad_norm': 5.138457298278809, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 682, 'max_steps': 7272}
  9%|▉         | 682/7272 [2:57:59<28:46:28, 15.72s/it]  9%|▉         | 683/7272 [2:58:15<29:09:30, 15.93s/it]                                                       {'loss': 2.3761, 'grad_norm': 8.862541198730469, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 683, 'max_steps': 7272}
  9%|▉         | 683/7272 [2:58:15<29:09:30, 15.93s/it]  9%|▉         | 684/7272 [2:58:31<29:18:59, 16.02s/it]                                                       {'loss': 2.6798, 'grad_norm': 6.003035545349121, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 684, 'max_steps': 7272}
  9%|▉         | 684/7272 [2:58:31<29:18:59, 16.02s/it]  9%|▉         | 685/7272 [2:58:48<29:33:40, 16.16s/it]                                                       {'loss': 2.9044, 'grad_norm': 6.050166130065918, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 685, 'max_steps': 7272}
  9%|▉         | 685/7272 [2:58:48<29:33:40, 16.16s/it]  9%|▉         | 686/7272 [2:59:04<29:43:49, 16.25s/it]                                                       {'loss': 1.2785, 'grad_norm': 4.823615074157715, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 686, 'max_steps': 7272}
  9%|▉         | 686/7272 [2:59:04<29:43:49, 16.25s/it]  9%|▉         | 687/7272 [2:59:20<29:42:38, 16.24s/it]                                                       {'loss': 1.9715, 'grad_norm': 7.507655620574951, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 687, 'max_steps': 7272}
  9%|▉         | 687/7272 [2:59:20<29:42:38, 16.24s/it]  9%|▉         | 688/7272 [2:59:36<29:20:24, 16.04s/it]                                                       {'loss': 2.0009, 'grad_norm': 5.956214904785156, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 688, 'max_steps': 7272}
  9%|▉         | 688/7272 [2:59:36<29:20:24, 16.04s/it]  9%|▉         | 689/7272 [2:59:52<29:18:13, 16.03s/it]                                                       {'loss': 2.1044, 'grad_norm': 7.636580467224121, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 689, 'max_steps': 7272}
  9%|▉         | 689/7272 [2:59:52<29:18:13, 16.03s/it]  9%|▉         | 690/7272 [3:00:08<29:20:49, 16.05s/it]                                                       {'loss': 1.9006, 'grad_norm': 10.481880187988281, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 690, 'max_steps': 7272}
  9%|▉         | 690/7272 [3:00:08<29:20:49, 16.05s/it] 10%|▉         | 691/7272 [3:00:24<29:25:40, 16.10s/it]                                                       {'loss': 2.208, 'grad_norm': 7.205620288848877, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 691, 'max_steps': 7272}
 10%|▉         | 691/7272 [3:00:24<29:25:40, 16.10s/it] 10%|▉         | 692/7272 [3:00:41<29:38:07, 16.21s/it]                                                       {'loss': 2.7635, 'grad_norm': 5.688187122344971, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 692, 'max_steps': 7272}
 10%|▉         | 692/7272 [3:00:41<29:38:07, 16.21s/it] 10%|▉         | 693/7272 [3:00:57<29:45:31, 16.28s/it]                                                       {'loss': 1.215, 'grad_norm': 4.927018165588379, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 693, 'max_steps': 7272}
 10%|▉         | 693/7272 [3:00:57<29:45:31, 16.28s/it] 10%|▉         | 694/7272 [3:01:14<29:46:46, 16.30s/it]                                                       {'loss': 1.0132, 'grad_norm': 3.7427592277526855, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 694, 'max_steps': 7272}
 10%|▉         | 694/7272 [3:01:14<29:46:46, 16.30s/it] 10%|▉         | 695/7272 [3:01:30<29:40:56, 16.25s/it]                                                       {'loss': 1.6502, 'grad_norm': 3.577436685562134, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 695, 'max_steps': 7272}
 10%|▉         | 695/7272 [3:01:30<29:40:56, 16.25s/it] 10%|▉         | 696/7272 [3:01:46<29:32:16, 16.17s/it]                                                       {'loss': 2.1047, 'grad_norm': 3.3481318950653076, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 696, 'max_steps': 7272}
 10%|▉         | 696/7272 [3:01:46<29:32:16, 16.17s/it] 10%|▉         | 697/7272 [3:02:01<29:08:30, 15.96s/it]                                                       {'loss': 2.6096, 'grad_norm': 4.70400333404541, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 697, 'max_steps': 7272}
 10%|▉         | 697/7272 [3:02:01<29:08:30, 15.96s/it] 10%|▉         | 698/7272 [3:02:17<29:09:01, 15.96s/it]                                                       {'loss': 1.0067, 'grad_norm': 2.6046290397644043, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 698, 'max_steps': 7272}
 10%|▉         | 698/7272 [3:02:17<29:09:01, 15.96s/it] 10%|▉         | 699/7272 [3:02:33<29:02:08, 15.90s/it]                                                       {'loss': 1.4633, 'grad_norm': 8.30162525177002, 'learning_rate': 5e-05, 'epoch': 0.38, 'step': 699, 'max_steps': 7272}
 10%|▉         | 699/7272 [3:02:33<29:02:08, 15.90s/it] 10%|▉         | 700/7272 [3:02:48<28:48:53, 15.78s/it]                                                       {'loss': 1.5984, 'grad_norm': 5.458126068115234, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 700, 'max_steps': 7272}
 10%|▉         | 700/7272 [3:02:48<28:48:53, 15.78s/it] 10%|▉         | 701/7272 [3:03:04<28:43:43, 15.74s/it]                                                       {'loss': 2.1103, 'grad_norm': 7.8894476890563965, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 701, 'max_steps': 7272}
 10%|▉         | 701/7272 [3:03:04<28:43:43, 15.74s/it] 10%|▉         | 702/7272 [3:03:20<28:44:02, 15.74s/it]                                                       {'loss': 1.382, 'grad_norm': 3.209580898284912, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 702, 'max_steps': 7272}
 10%|▉         | 702/7272 [3:03:20<28:44:02, 15.74s/it] 10%|▉         | 703/7272 [3:03:36<28:47:06, 15.78s/it]                                                       {'loss': 2.3167, 'grad_norm': 7.040421009063721, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 703, 'max_steps': 7272}
 10%|▉         | 703/7272 [3:03:36<28:47:06, 15.78s/it] 10%|▉         | 704/7272 [3:03:52<29:06:04, 15.95s/it]                                                       {'loss': 1.3443, 'grad_norm': 3.2299246788024902, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 704, 'max_steps': 7272}
 10%|▉         | 704/7272 [3:03:52<29:06:04, 15.95s/it] 10%|▉         | 705/7272 [3:04:09<29:32:55, 16.20s/it]                                                       {'loss': 0.736, 'grad_norm': 3.8621153831481934, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 705, 'max_steps': 7272}
 10%|▉         | 705/7272 [3:04:09<29:32:55, 16.20s/it] 10%|▉         | 706/7272 [3:04:25<29:24:15, 16.12s/it]                                                       {'loss': 1.043, 'grad_norm': 3.120189666748047, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 706, 'max_steps': 7272}
 10%|▉         | 706/7272 [3:04:25<29:24:15, 16.12s/it] 10%|▉         | 707/7272 [3:04:41<29:30:26, 16.18s/it]                                                       {'loss': 1.8825, 'grad_norm': 3.901676893234253, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 707, 'max_steps': 7272}
 10%|▉         | 707/7272 [3:04:41<29:30:26, 16.18s/it] 10%|▉         | 708/7272 [3:04:57<29:27:57, 16.16s/it]                                                       {'loss': 0.3965, 'grad_norm': 1.8740144968032837, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 708, 'max_steps': 7272}
 10%|▉         | 708/7272 [3:04:57<29:27:57, 16.16s/it] 10%|▉         | 709/7272 [3:05:13<29:16:36, 16.06s/it]                                                       {'loss': 2.7297, 'grad_norm': 5.9073286056518555, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 709, 'max_steps': 7272}
 10%|▉         | 709/7272 [3:05:13<29:16:36, 16.06s/it] 10%|▉         | 710/7272 [3:05:28<28:58:52, 15.90s/it]                                                       {'loss': 1.8313, 'grad_norm': 6.103991508483887, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 710, 'max_steps': 7272}
 10%|▉         | 710/7272 [3:05:28<28:58:52, 15.90s/it] 10%|▉         | 711/7272 [3:05:45<29:09:21, 16.00s/it]                                                       {'loss': 2.1019, 'grad_norm': 5.432352066040039, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 711, 'max_steps': 7272}
 10%|▉         | 711/7272 [3:05:45<29:09:21, 16.00s/it] 10%|▉         | 712/7272 [3:06:01<29:21:31, 16.11s/it]                                                       {'loss': 1.9985, 'grad_norm': 6.694005489349365, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 712, 'max_steps': 7272}
 10%|▉         | 712/7272 [3:06:01<29:21:31, 16.11s/it] 10%|▉         | 713/7272 [3:06:18<29:34:39, 16.23s/it]                                                       {'loss': 2.1958, 'grad_norm': 7.081164360046387, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 713, 'max_steps': 7272}
 10%|▉         | 713/7272 [3:06:18<29:34:39, 16.23s/it] 10%|▉         | 714/7272 [3:06:34<29:35:14, 16.24s/it]                                                       {'loss': 1.3837, 'grad_norm': 3.478468656539917, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 714, 'max_steps': 7272}
 10%|▉         | 714/7272 [3:06:34<29:35:14, 16.24s/it] 10%|▉         | 715/7272 [3:06:49<29:03:41, 15.96s/it]                                                       {'loss': 2.0866, 'grad_norm': 7.987171649932861, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 715, 'max_steps': 7272}
 10%|▉         | 715/7272 [3:06:49<29:03:41, 15.96s/it] 10%|▉         | 716/7272 [3:07:05<29:00:04, 15.93s/it]                                                       {'loss': 0.9169, 'grad_norm': 5.505786418914795, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 716, 'max_steps': 7272}
 10%|▉         | 716/7272 [3:07:05<29:00:04, 15.93s/it] 10%|▉         | 717/7272 [3:07:20<28:44:03, 15.78s/it]                                                       {'loss': 1.6137, 'grad_norm': 9.417972564697266, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 717, 'max_steps': 7272}
 10%|▉         | 717/7272 [3:07:20<28:44:03, 15.78s/it] 10%|▉         | 718/7272 [3:07:36<28:35:57, 15.71s/it]                                                       {'loss': 1.326, 'grad_norm': 4.334108829498291, 'learning_rate': 5e-05, 'epoch': 0.39, 'step': 718, 'max_steps': 7272}
 10%|▉         | 718/7272 [3:07:36<28:35:57, 15.71s/it] 10%|▉         | 719/7272 [3:07:52<28:56:21, 15.90s/it]                                                       {'loss': 2.1486, 'grad_norm': 9.932991981506348, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 719, 'max_steps': 7272}
 10%|▉         | 719/7272 [3:07:52<28:56:21, 15.90s/it] 10%|▉         | 720/7272 [3:08:09<29:09:42, 16.02s/it]                                                       {'loss': 2.1235, 'grad_norm': 5.6458892822265625, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 720, 'max_steps': 7272}
 10%|▉         | 720/7272 [3:08:09<29:09:42, 16.02s/it] 10%|▉         | 721/7272 [3:08:24<28:42:30, 15.78s/it]                                                       {'loss': 2.0005, 'grad_norm': 6.407139301300049, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 721, 'max_steps': 7272}
 10%|▉         | 721/7272 [3:08:24<28:42:30, 15.78s/it] 10%|▉         | 722/7272 [3:08:40<28:42:20, 15.78s/it]                                                       {'loss': 1.6173, 'grad_norm': 10.134515762329102, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 722, 'max_steps': 7272}
 10%|▉         | 722/7272 [3:08:40<28:42:20, 15.78s/it] 10%|▉         | 723/7272 [3:08:56<28:48:09, 15.83s/it]                                                       {'loss': 2.4852, 'grad_norm': 11.6697359085083, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 723, 'max_steps': 7272}
 10%|▉         | 723/7272 [3:08:56<28:48:09, 15.83s/it] 10%|▉         | 724/7272 [3:09:11<28:42:15, 15.78s/it]                                                       {'loss': 2.4294, 'grad_norm': 5.441494464874268, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 724, 'max_steps': 7272}
 10%|▉         | 724/7272 [3:09:11<28:42:15, 15.78s/it] 10%|▉         | 725/7272 [3:09:27<28:48:07, 15.84s/it]                                                       {'loss': 1.7202, 'grad_norm': 4.92190408706665, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 725, 'max_steps': 7272}
 10%|▉         | 725/7272 [3:09:27<28:48:07, 15.84s/it] 10%|▉         | 726/7272 [3:09:43<28:48:44, 15.85s/it]                                                       {'loss': 1.8528, 'grad_norm': 6.757220268249512, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 726, 'max_steps': 7272}
 10%|▉         | 726/7272 [3:09:43<28:48:44, 15.85s/it] 10%|▉         | 727/7272 [3:09:59<28:35:01, 15.72s/it]                                                       {'loss': 1.5449, 'grad_norm': 3.850263833999634, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 727, 'max_steps': 7272}
 10%|▉         | 727/7272 [3:09:59<28:35:01, 15.72s/it] 10%|█         | 728/7272 [3:10:14<28:31:52, 15.70s/it]                                                       {'loss': 1.9972, 'grad_norm': 5.877542018890381, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 728, 'max_steps': 7272}
 10%|█         | 728/7272 [3:10:14<28:31:52, 15.70s/it] 10%|█         | 729/7272 [3:10:30<28:35:11, 15.73s/it]                                                       {'loss': 1.282, 'grad_norm': 3.1729681491851807, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 729, 'max_steps': 7272}
 10%|█         | 729/7272 [3:10:30<28:35:11, 15.73s/it] 10%|█         | 730/7272 [3:10:46<28:35:06, 15.73s/it]                                                       {'loss': 1.1631, 'grad_norm': 6.830297946929932, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 730, 'max_steps': 7272}
 10%|█         | 730/7272 [3:10:46<28:35:06, 15.73s/it] 10%|█         | 731/7272 [3:11:01<28:35:15, 15.73s/it]                                                       {'loss': 0.9818, 'grad_norm': 5.513630390167236, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 731, 'max_steps': 7272}
 10%|█         | 731/7272 [3:11:01<28:35:15, 15.73s/it] 10%|█         | 732/7272 [3:11:17<28:27:02, 15.66s/it]                                                       {'loss': 1.9145, 'grad_norm': 6.490563869476318, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 732, 'max_steps': 7272}
 10%|█         | 732/7272 [3:11:17<28:27:02, 15.66s/it] 10%|█         | 733/7272 [3:11:32<28:15:02, 15.55s/it]                                                       {'loss': 1.425, 'grad_norm': 7.530026435852051, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 733, 'max_steps': 7272}
 10%|█         | 733/7272 [3:11:32<28:15:02, 15.55s/it] 10%|█         | 734/7272 [3:11:48<28:07:16, 15.48s/it]                                                       {'loss': 1.399, 'grad_norm': 8.943142890930176, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 734, 'max_steps': 7272}
 10%|█         | 734/7272 [3:11:48<28:07:16, 15.48s/it] 10%|█         | 735/7272 [3:12:03<28:19:13, 15.60s/it]                                                       {'loss': 1.6131, 'grad_norm': 14.660266876220703, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 735, 'max_steps': 7272}
 10%|█         | 735/7272 [3:12:03<28:19:13, 15.60s/it] 10%|█         | 736/7272 [3:12:19<28:30:47, 15.70s/it]                                                       {'loss': 2.1244, 'grad_norm': 4.8135833740234375, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 736, 'max_steps': 7272}
 10%|█         | 736/7272 [3:12:19<28:30:47, 15.70s/it] 10%|█         | 737/7272 [3:12:35<28:23:39, 15.64s/it]                                                       {'loss': 1.3555, 'grad_norm': 3.016437292098999, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 737, 'max_steps': 7272}
 10%|█         | 737/7272 [3:12:35<28:23:39, 15.64s/it] 10%|█         | 738/7272 [3:12:51<28:25:44, 15.66s/it]                                                       {'loss': 2.1905, 'grad_norm': 11.996186256408691, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 738, 'max_steps': 7272}
 10%|█         | 738/7272 [3:12:51<28:25:44, 15.66s/it] 10%|█         | 739/7272 [3:13:06<28:22:00, 15.63s/it]                                                       {'loss': 1.4352, 'grad_norm': 9.164226531982422, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 739, 'max_steps': 7272}
 10%|█         | 739/7272 [3:13:06<28:22:00, 15.63s/it] 10%|█         | 740/7272 [3:13:22<28:26:01, 15.67s/it]                                                       {'loss': 1.7308, 'grad_norm': 4.788702011108398, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 740, 'max_steps': 7272}
 10%|█         | 740/7272 [3:13:22<28:26:01, 15.67s/it] 10%|█         | 741/7272 [3:13:38<28:31:43, 15.73s/it]                                                       {'loss': 0.771, 'grad_norm': 12.409972190856934, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 741, 'max_steps': 7272}
 10%|█         | 741/7272 [3:13:38<28:31:43, 15.73s/it] 10%|█         | 742/7272 [3:13:54<28:36:14, 15.77s/it]                                                       {'loss': 1.4776, 'grad_norm': 8.110167503356934, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 742, 'max_steps': 7272}
 10%|█         | 742/7272 [3:13:54<28:36:14, 15.77s/it] 10%|█         | 743/7272 [3:14:10<28:47:59, 15.88s/it]                                                       {'loss': 1.5998, 'grad_norm': 6.907739162445068, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 743, 'max_steps': 7272}
 10%|█         | 743/7272 [3:14:10<28:47:59, 15.88s/it] 10%|█         | 744/7272 [3:14:25<28:31:06, 15.73s/it]                                                       {'loss': 1.2976, 'grad_norm': 3.5592453479766846, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 744, 'max_steps': 7272}
 10%|█         | 744/7272 [3:14:25<28:31:06, 15.73s/it] 10%|█         | 745/7272 [3:14:41<28:39:22, 15.81s/it]                                                       {'loss': 1.9333, 'grad_norm': 3.2972660064697266, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 745, 'max_steps': 7272}
 10%|█         | 745/7272 [3:14:41<28:39:22, 15.81s/it] 10%|█         | 746/7272 [3:14:57<28:45:29, 15.86s/it]                                                       {'loss': 1.4463, 'grad_norm': 4.516937255859375, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 746, 'max_steps': 7272}
 10%|█         | 746/7272 [3:14:57<28:45:29, 15.86s/it] 10%|█         | 747/7272 [3:15:13<28:54:25, 15.95s/it]                                                       {'loss': 1.1751, 'grad_norm': 3.25004243850708, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 747, 'max_steps': 7272}
 10%|█         | 747/7272 [3:15:13<28:54:25, 15.95s/it] 10%|█         | 748/7272 [3:15:29<28:57:54, 15.98s/it]                                                       {'loss': 1.5973, 'grad_norm': 4.730680465698242, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 748, 'max_steps': 7272}
 10%|█         | 748/7272 [3:15:29<28:57:54, 15.98s/it] 10%|█         | 749/7272 [3:15:45<28:58:35, 15.99s/it]                                                       {'loss': 1.3315, 'grad_norm': 3.3505754470825195, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 749, 'max_steps': 7272}
 10%|█         | 749/7272 [3:15:45<28:58:35, 15.99s/it] 10%|█         | 750/7272 [3:16:01<28:58:22, 15.99s/it]                                                       {'loss': 2.4021, 'grad_norm': 7.070284843444824, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 750, 'max_steps': 7272}
 10%|█         | 750/7272 [3:16:01<28:58:22, 15.99s/it] 10%|█         | 751/7272 [3:16:17<28:55:28, 15.97s/it]                                                       {'loss': 0.8532, 'grad_norm': 5.050030708312988, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 751, 'max_steps': 7272}
 10%|█         | 751/7272 [3:16:17<28:55:28, 15.97s/it] 10%|█         | 752/7272 [3:16:33<28:43:21, 15.86s/it]                                                       {'loss': 1.7747, 'grad_norm': 8.328248023986816, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 752, 'max_steps': 7272}
 10%|█         | 752/7272 [3:16:33<28:43:21, 15.86s/it] 10%|█         | 753/7272 [3:16:50<29:19:18, 16.19s/it]                                                       {'loss': 2.8139, 'grad_norm': 8.26784896850586, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 753, 'max_steps': 7272}
 10%|█         | 753/7272 [3:16:50<29:19:18, 16.19s/it] 10%|█         | 754/7272 [3:17:06<29:22:21, 16.22s/it]                                                       {'loss': 1.4852, 'grad_norm': 3.5796594619750977, 'learning_rate': 5e-05, 'epoch': 0.41, 'step': 754, 'max_steps': 7272}
 10%|█         | 754/7272 [3:17:06<29:22:21, 16.22s/it] 10%|█         | 755/7272 [3:17:22<29:16:25, 16.17s/it]                                                       {'loss': 1.2628, 'grad_norm': 13.184760093688965, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 755, 'max_steps': 7272}
 10%|█         | 755/7272 [3:17:22<29:16:25, 16.17s/it] 10%|█         | 756/7272 [3:17:38<29:20:53, 16.21s/it]                                                       {'loss': 1.1538, 'grad_norm': 2.669353723526001, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 756, 'max_steps': 7272}
 10%|█         | 756/7272 [3:17:38<29:20:53, 16.21s/it] 10%|█         | 757/7272 [3:17:55<29:37:33, 16.37s/it]                                                       {'loss': 1.6883, 'grad_norm': 8.75772476196289, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 757, 'max_steps': 7272}
 10%|█         | 757/7272 [3:17:55<29:37:33, 16.37s/it] 10%|█         | 758/7272 [3:18:11<29:25:01, 16.26s/it]                                                       {'loss': 1.1038, 'grad_norm': 4.4547014236450195, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 758, 'max_steps': 7272}
 10%|█         | 758/7272 [3:18:11<29:25:01, 16.26s/it] 10%|█         | 759/7272 [3:18:27<29:26:18, 16.27s/it]                                                       {'loss': 2.7816, 'grad_norm': 6.276885032653809, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 759, 'max_steps': 7272}
 10%|█         | 759/7272 [3:18:28<29:26:18, 16.27s/it] 10%|█         | 760/7272 [3:18:44<29:35:17, 16.36s/it]                                                       {'loss': 2.4049, 'grad_norm': 6.570184707641602, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 760, 'max_steps': 7272}
 10%|█         | 760/7272 [3:18:44<29:35:17, 16.36s/it] 10%|█         | 761/7272 [3:19:00<29:33:26, 16.34s/it]                                                       {'loss': 1.897, 'grad_norm': 8.967256546020508, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 761, 'max_steps': 7272}
 10%|█         | 761/7272 [3:19:00<29:33:26, 16.34s/it] 10%|█         | 762/7272 [3:19:16<29:26:05, 16.28s/it]                                                       {'loss': 1.5967, 'grad_norm': 5.015631198883057, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 762, 'max_steps': 7272}
 10%|█         | 762/7272 [3:19:16<29:26:05, 16.28s/it] 10%|█         | 763/7272 [3:19:32<29:06:43, 16.10s/it]                                                       {'loss': 2.1185, 'grad_norm': 6.960467338562012, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 763, 'max_steps': 7272}
 10%|█         | 763/7272 [3:19:32<29:06:43, 16.10s/it] 11%|█         | 764/7272 [3:19:48<28:59:19, 16.04s/it]                                                       {'loss': 2.4416, 'grad_norm': 13.35558795928955, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 764, 'max_steps': 7272}
 11%|█         | 764/7272 [3:19:48<28:59:19, 16.04s/it] 11%|█         | 765/7272 [3:20:04<28:44:53, 15.91s/it]                                                       {'loss': 1.4809, 'grad_norm': 7.086438179016113, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 765, 'max_steps': 7272}
 11%|█         | 765/7272 [3:20:04<28:44:53, 15.91s/it] 11%|█         | 766/7272 [3:20:20<28:46:36, 15.92s/it]                                                       {'loss': 1.7382, 'grad_norm': 4.760965824127197, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 766, 'max_steps': 7272}
 11%|█         | 766/7272 [3:20:20<28:46:36, 15.92s/it] 11%|█         | 767/7272 [3:20:36<29:04:03, 16.09s/it]                                                       {'loss': 1.7062, 'grad_norm': 4.23591947555542, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 767, 'max_steps': 7272}
 11%|█         | 767/7272 [3:20:36<29:04:03, 16.09s/it] 11%|█         | 768/7272 [3:20:52<29:04:30, 16.09s/it]                                                       {'loss': 2.3298, 'grad_norm': 6.562410831451416, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 768, 'max_steps': 7272}
 11%|█         | 768/7272 [3:20:52<29:04:30, 16.09s/it] 11%|█         | 769/7272 [3:21:08<29:05:56, 16.11s/it]                                                       {'loss': 1.5534, 'grad_norm': 4.747387409210205, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 769, 'max_steps': 7272}
 11%|█         | 769/7272 [3:21:08<29:05:56, 16.11s/it] 11%|█         | 770/7272 [3:21:24<29:06:54, 16.12s/it]                                                       {'loss': 0.9442, 'grad_norm': 2.473060131072998, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 770, 'max_steps': 7272}
 11%|█         | 770/7272 [3:21:24<29:06:54, 16.12s/it] 11%|█         | 771/7272 [3:21:41<29:10:20, 16.15s/it]                                                       {'loss': 1.9921, 'grad_norm': 3.6226041316986084, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 771, 'max_steps': 7272}
 11%|█         | 771/7272 [3:21:41<29:10:20, 16.15s/it] 11%|█         | 772/7272 [3:21:56<28:53:40, 16.00s/it]                                                       {'loss': 1.1191, 'grad_norm': 5.452737808227539, 'learning_rate': 5e-05, 'epoch': 0.42, 'step': 772, 'max_steps': 7272}
 11%|█         | 772/7272 [3:21:56<28:53:40, 16.00s/it] 11%|█         | 773/7272 [3:22:13<29:12:20, 16.18s/it]                                                       {'loss': 0.7271, 'grad_norm': 4.34171724319458, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 773, 'max_steps': 7272}
 11%|█         | 773/7272 [3:22:13<29:12:20, 16.18s/it] 11%|█         | 774/7272 [3:22:29<29:22:56, 16.28s/it]                                                       {'loss': 2.5068, 'grad_norm': 4.971360206604004, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 774, 'max_steps': 7272}
 11%|█         | 774/7272 [3:22:29<29:22:56, 16.28s/it] 11%|█         | 775/7272 [3:22:46<29:25:27, 16.30s/it]                                                       {'loss': 2.2994, 'grad_norm': 4.137233734130859, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 775, 'max_steps': 7272}
 11%|█         | 775/7272 [3:22:46<29:25:27, 16.30s/it] 11%|█         | 776/7272 [3:23:02<29:20:54, 16.26s/it]                                                       {'loss': 1.4693, 'grad_norm': 9.050033569335938, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 776, 'max_steps': 7272}
 11%|█         | 776/7272 [3:23:02<29:20:54, 16.26s/it] 11%|█         | 777/7272 [3:23:18<29:01:14, 16.09s/it]                                                       {'loss': 0.9078, 'grad_norm': 3.486098289489746, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 777, 'max_steps': 7272}
 11%|█         | 777/7272 [3:23:18<29:01:14, 16.09s/it] 11%|█         | 778/7272 [3:23:33<28:41:51, 15.91s/it]                                                       {'loss': 1.9151, 'grad_norm': 7.027923107147217, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 778, 'max_steps': 7272}
 11%|█         | 778/7272 [3:23:33<28:41:51, 15.91s/it] 11%|█         | 779/7272 [3:23:50<29:04:12, 16.12s/it]                                                       {'loss': 1.6694, 'grad_norm': 10.832243919372559, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 779, 'max_steps': 7272}
 11%|█         | 779/7272 [3:23:50<29:04:12, 16.12s/it] 11%|█         | 780/7272 [3:24:06<29:15:32, 16.22s/it]                                                       {'loss': 0.5194, 'grad_norm': 2.745926856994629, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 780, 'max_steps': 7272}
 11%|█         | 780/7272 [3:24:06<29:15:32, 16.22s/it] 11%|█         | 781/7272 [3:24:23<29:30:42, 16.37s/it]                                                       {'loss': 1.7015, 'grad_norm': 5.660198211669922, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 781, 'max_steps': 7272}
 11%|█         | 781/7272 [3:24:23<29:30:42, 16.37s/it] 11%|█         | 782/7272 [3:24:39<29:07:39, 16.16s/it]                                                       {'loss': 1.7213, 'grad_norm': 8.212188720703125, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 782, 'max_steps': 7272}
 11%|█         | 782/7272 [3:24:39<29:07:39, 16.16s/it] 11%|█         | 783/7272 [3:24:55<29:12:19, 16.20s/it]                                                       {'loss': 2.2527, 'grad_norm': 8.932136535644531, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 783, 'max_steps': 7272}
 11%|█         | 783/7272 [3:24:55<29:12:19, 16.20s/it] 11%|█         | 784/7272 [3:25:11<29:04:14, 16.13s/it]                                                       {'loss': 1.755, 'grad_norm': 4.847605228424072, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 784, 'max_steps': 7272}
 11%|█         | 784/7272 [3:25:11<29:04:14, 16.13s/it] 11%|█         | 785/7272 [3:25:27<28:56:28, 16.06s/it]                                                       {'loss': 2.4952, 'grad_norm': 5.604384899139404, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 785, 'max_steps': 7272}
 11%|█         | 785/7272 [3:25:27<28:56:28, 16.06s/it] 11%|█         | 786/7272 [3:25:43<29:00:49, 16.10s/it]                                                       {'loss': 2.854, 'grad_norm': 5.883768081665039, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 786, 'max_steps': 7272}
 11%|█         | 786/7272 [3:25:43<29:00:49, 16.10s/it] 11%|█         | 787/7272 [3:25:59<28:59:50, 16.10s/it]                                                       {'loss': 2.0236, 'grad_norm': 4.167405128479004, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 787, 'max_steps': 7272}
 11%|█         | 787/7272 [3:25:59<28:59:50, 16.10s/it] 11%|█         | 788/7272 [3:26:15<28:49:49, 16.01s/it]                                                       {'loss': 3.187, 'grad_norm': 6.729204177856445, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 788, 'max_steps': 7272}
 11%|█         | 788/7272 [3:26:15<28:49:49, 16.01s/it] 11%|█         | 789/7272 [3:26:31<28:42:10, 15.94s/it]                                                       {'loss': 1.0394, 'grad_norm': 4.817230701446533, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 789, 'max_steps': 7272}
 11%|█         | 789/7272 [3:26:31<28:42:10, 15.94s/it] 11%|█         | 790/7272 [3:26:47<29:02:40, 16.13s/it]                                                       {'loss': 2.4874, 'grad_norm': 6.245171070098877, 'learning_rate': 5e-05, 'epoch': 0.43, 'step': 790, 'max_steps': 7272}
 11%|█         | 790/7272 [3:26:47<29:02:40, 16.13s/it] 11%|█         | 791/7272 [3:27:03<29:04:16, 16.15s/it]                                                       {'loss': 2.6472, 'grad_norm': 11.280120849609375, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 791, 'max_steps': 7272}
 11%|█         | 791/7272 [3:27:03<29:04:16, 16.15s/it] 11%|█         | 792/7272 [3:27:19<28:55:05, 16.07s/it]                                                       {'loss': 1.8827, 'grad_norm': 4.3511552810668945, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 792, 'max_steps': 7272}
 11%|█         | 792/7272 [3:27:19<28:55:05, 16.07s/it] 11%|█         | 793/7272 [3:27:36<29:05:31, 16.16s/it]                                                       {'loss': 1.2085, 'grad_norm': 3.586979389190674, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 793, 'max_steps': 7272}
 11%|█         | 793/7272 [3:27:36<29:05:31, 16.16s/it] 11%|█         | 794/7272 [3:27:52<29:16:32, 16.27s/it]                                                       {'loss': 2.3943, 'grad_norm': 4.805233478546143, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 794, 'max_steps': 7272}
 11%|█         | 794/7272 [3:27:52<29:16:32, 16.27s/it] 11%|█         | 795/7272 [3:28:08<29:08:41, 16.20s/it]                                                       {'loss': 0.8776, 'grad_norm': 4.252687931060791, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 795, 'max_steps': 7272}
 11%|█         | 795/7272 [3:28:08<29:08:41, 16.20s/it] 11%|█         | 796/7272 [3:28:25<29:14:02, 16.25s/it]                                                       {'loss': 1.6201, 'grad_norm': 20.706645965576172, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 796, 'max_steps': 7272}
 11%|█         | 796/7272 [3:28:25<29:14:02, 16.25s/it] 11%|█         | 797/7272 [3:28:41<29:33:09, 16.43s/it]                                                       {'loss': 2.35, 'grad_norm': 5.489130020141602, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 797, 'max_steps': 7272}
 11%|█         | 797/7272 [3:28:41<29:33:09, 16.43s/it] 11%|█         | 798/7272 [3:28:58<29:38:07, 16.48s/it]                                                       {'loss': 1.396, 'grad_norm': 3.132582426071167, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 798, 'max_steps': 7272}
 11%|█         | 798/7272 [3:28:58<29:38:07, 16.48s/it] 11%|█         | 799/7272 [3:29:15<29:38:27, 16.48s/it]                                                       {'loss': 2.7453, 'grad_norm': 10.040214538574219, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 799, 'max_steps': 7272}
 11%|█         | 799/7272 [3:29:15<29:38:27, 16.48s/it] 11%|█         | 800/7272 [3:29:32<30:05:43, 16.74s/it]                                                       {'loss': 2.9576, 'grad_norm': 5.883822917938232, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 800, 'max_steps': 7272}
 11%|█         | 800/7272 [3:29:32<30:05:43, 16.74s/it] 11%|█         | 801/7272 [3:29:49<30:02:14, 16.71s/it]                                                       {'loss': 1.7697, 'grad_norm': 7.667413711547852, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 801, 'max_steps': 7272}
 11%|█         | 801/7272 [3:29:49<30:02:14, 16.71s/it] 11%|█         | 802/7272 [3:30:05<29:39:53, 16.51s/it]                                                       {'loss': 1.772, 'grad_norm': 5.614873886108398, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 802, 'max_steps': 7272}
 11%|█         | 802/7272 [3:30:05<29:39:53, 16.51s/it] 11%|█         | 803/7272 [3:30:20<29:17:53, 16.30s/it]                                                       {'loss': 1.4038, 'grad_norm': 7.801379680633545, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 803, 'max_steps': 7272}
 11%|█         | 803/7272 [3:30:20<29:17:53, 16.30s/it] 11%|█         | 804/7272 [3:30:36<29:02:03, 16.16s/it]                                                       {'loss': 1.2722, 'grad_norm': 7.1686906814575195, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 804, 'max_steps': 7272}
 11%|█         | 804/7272 [3:30:36<29:02:03, 16.16s/it] 11%|█         | 805/7272 [3:30:52<29:05:29, 16.19s/it]                                                       {'loss': 1.543, 'grad_norm': 5.435203552246094, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 805, 'max_steps': 7272}
 11%|█         | 805/7272 [3:30:52<29:05:29, 16.19s/it] 11%|█         | 806/7272 [3:31:08<28:47:23, 16.03s/it]                                                       {'loss': 1.5367, 'grad_norm': 4.226964473724365, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 806, 'max_steps': 7272}
 11%|█         | 806/7272 [3:31:08<28:47:23, 16.03s/it] 11%|█         | 807/7272 [3:31:24<28:47:28, 16.03s/it]                                                       {'loss': 1.5317, 'grad_norm': 3.486431360244751, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 807, 'max_steps': 7272}
 11%|█         | 807/7272 [3:31:24<28:47:28, 16.03s/it] 11%|█         | 808/7272 [3:31:41<29:02:57, 16.18s/it]                                                       {'loss': 2.8715, 'grad_norm': 8.948066711425781, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 808, 'max_steps': 7272}
 11%|█         | 808/7272 [3:31:41<29:02:57, 16.18s/it] 11%|█         | 809/7272 [3:31:57<29:21:17, 16.35s/it]                                                       {'loss': 2.3976, 'grad_norm': 8.892702102661133, 'learning_rate': 5e-05, 'epoch': 0.44, 'step': 809, 'max_steps': 7272}
 11%|█         | 809/7272 [3:31:57<29:21:17, 16.35s/it] 11%|█         | 810/7272 [3:32:14<29:15:46, 16.30s/it]                                                       {'loss': 2.5965, 'grad_norm': 8.414251327514648, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 810, 'max_steps': 7272}
 11%|█         | 810/7272 [3:32:14<29:15:46, 16.30s/it] 11%|█         | 811/7272 [3:32:30<29:07:44, 16.23s/it]                                                       {'loss': 2.9612, 'grad_norm': 9.932757377624512, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 811, 'max_steps': 7272}
 11%|█         | 811/7272 [3:32:30<29:07:44, 16.23s/it] 11%|█         | 812/7272 [3:32:45<28:36:02, 15.94s/it]                                                       {'loss': 0.7022, 'grad_norm': 2.2236716747283936, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 812, 'max_steps': 7272}
 11%|█         | 812/7272 [3:32:45<28:36:02, 15.94s/it] 11%|█         | 813/7272 [3:33:01<28:31:54, 15.90s/it]                                                       {'loss': 2.3578, 'grad_norm': 7.463172912597656, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 813, 'max_steps': 7272}
 11%|█         | 813/7272 [3:33:01<28:31:54, 15.90s/it] 11%|█         | 814/7272 [3:33:17<28:37:21, 15.96s/it]                                                       {'loss': 2.8373, 'grad_norm': 6.690968036651611, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 814, 'max_steps': 7272}
 11%|█         | 814/7272 [3:33:17<28:37:21, 15.96s/it] 11%|█         | 815/7272 [3:33:33<28:55:29, 16.13s/it]                                                       {'loss': 1.8782, 'grad_norm': 6.9943060874938965, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 815, 'max_steps': 7272}
 11%|█         | 815/7272 [3:33:33<28:55:29, 16.13s/it] 11%|█         | 816/7272 [3:33:49<28:52:24, 16.10s/it]                                                       {'loss': 1.2869, 'grad_norm': 3.55859112739563, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 816, 'max_steps': 7272}
 11%|█         | 816/7272 [3:33:49<28:52:24, 16.10s/it] 11%|█         | 817/7272 [3:34:06<29:10:55, 16.28s/it]                                                       {'loss': 1.535, 'grad_norm': 10.848583221435547, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 817, 'max_steps': 7272}
 11%|█         | 817/7272 [3:34:06<29:10:55, 16.28s/it] 11%|█         | 818/7272 [3:34:22<29:09:14, 16.26s/it]                                                       {'loss': 0.7887, 'grad_norm': 2.4360008239746094, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 818, 'max_steps': 7272}
 11%|█         | 818/7272 [3:34:22<29:09:14, 16.26s/it] 11%|█▏        | 819/7272 [3:34:38<28:58:18, 16.16s/it]                                                       {'loss': 2.7441, 'grad_norm': 10.113432884216309, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 819, 'max_steps': 7272}
 11%|█▏        | 819/7272 [3:34:38<28:58:18, 16.16s/it] 11%|█▏        | 820/7272 [3:34:54<28:48:37, 16.08s/it]                                                       {'loss': 1.8222, 'grad_norm': 6.283041000366211, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 820, 'max_steps': 7272}
 11%|█▏        | 820/7272 [3:34:54<28:48:37, 16.08s/it] 11%|█▏        | 821/7272 [3:35:11<29:06:35, 16.24s/it]                                                       {'loss': 1.6331, 'grad_norm': 3.4463107585906982, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 821, 'max_steps': 7272}
 11%|█▏        | 821/7272 [3:35:11<29:06:35, 16.24s/it] 11%|█▏        | 822/7272 [3:35:27<28:53:13, 16.12s/it]                                                       {'loss': 0.8635, 'grad_norm': 4.609435558319092, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 822, 'max_steps': 7272}
 11%|█▏        | 822/7272 [3:35:27<28:53:13, 16.12s/it] 11%|█▏        | 823/7272 [3:35:43<28:50:45, 16.10s/it]                                                       {'loss': 1.5069, 'grad_norm': 9.915742874145508, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 823, 'max_steps': 7272}
 11%|█▏        | 823/7272 [3:35:43<28:50:45, 16.10s/it] 11%|█▏        | 824/7272 [3:35:58<28:41:12, 16.02s/it]                                                       {'loss': 1.1765, 'grad_norm': 3.306274175643921, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 824, 'max_steps': 7272}
 11%|█▏        | 824/7272 [3:35:58<28:41:12, 16.02s/it] 11%|█▏        | 825/7272 [3:36:15<28:46:16, 16.07s/it]                                                       {'loss': 2.5423, 'grad_norm': 5.656948566436768, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 825, 'max_steps': 7272}
 11%|█▏        | 825/7272 [3:36:15<28:46:16, 16.07s/it] 11%|█▏        | 826/7272 [3:36:31<28:40:49, 16.02s/it]                                                       {'loss': 1.3779, 'grad_norm': 2.5552494525909424, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 826, 'max_steps': 7272}
 11%|█▏        | 826/7272 [3:36:31<28:40:49, 16.02s/it] 11%|█▏        | 827/7272 [3:36:46<28:29:52, 15.92s/it]                                                       {'loss': 1.7934, 'grad_norm': 3.8696868419647217, 'learning_rate': 5e-05, 'epoch': 0.45, 'step': 827, 'max_steps': 7272}
 11%|█▏        | 827/7272 [3:36:46<28:29:52, 15.92s/it] 11%|█▏        | 828/7272 [3:37:03<28:47:48, 16.09s/it]                                                       {'loss': 1.7326, 'grad_norm': 3.1341052055358887, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 828, 'max_steps': 7272}
 11%|█▏        | 828/7272 [3:37:03<28:47:48, 16.09s/it] 11%|█▏        | 829/7272 [3:37:19<28:39:34, 16.01s/it]                                                       {'loss': 2.5098, 'grad_norm': 7.264488697052002, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 829, 'max_steps': 7272}
 11%|█▏        | 829/7272 [3:37:19<28:39:34, 16.01s/it] 11%|█▏        | 830/7272 [3:37:35<28:38:04, 16.00s/it]                                                       {'loss': 2.9129, 'grad_norm': 6.014036178588867, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 830, 'max_steps': 7272}
 11%|█▏        | 830/7272 [3:37:35<28:38:04, 16.00s/it] 11%|█▏        | 831/7272 [3:37:50<28:34:05, 15.97s/it]                                                       {'loss': 1.8307, 'grad_norm': 4.756341457366943, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 831, 'max_steps': 7272}
 11%|█▏        | 831/7272 [3:37:50<28:34:05, 15.97s/it] 11%|█▏        | 832/7272 [3:38:06<28:24:59, 15.88s/it]                                                       {'loss': 1.5965, 'grad_norm': 3.2777976989746094, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 832, 'max_steps': 7272}
 11%|█▏        | 832/7272 [3:38:06<28:24:59, 15.88s/it] 11%|█▏        | 833/7272 [3:38:22<28:31:44, 15.95s/it]                                                       {'loss': 2.3528, 'grad_norm': 5.881180763244629, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 833, 'max_steps': 7272}
 11%|█▏        | 833/7272 [3:38:22<28:31:44, 15.95s/it] 11%|█▏        | 834/7272 [3:38:38<28:18:56, 15.83s/it]                                                       {'loss': 1.9244, 'grad_norm': 6.209719657897949, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 834, 'max_steps': 7272}
 11%|█▏        | 834/7272 [3:38:38<28:18:56, 15.83s/it] 11%|█▏        | 835/7272 [3:38:54<28:17:59, 15.83s/it]                                                       {'loss': 1.9536, 'grad_norm': 24.503671646118164, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 835, 'max_steps': 7272}
 11%|█▏        | 835/7272 [3:38:54<28:17:59, 15.83s/it] 11%|█▏        | 836/7272 [3:39:10<28:27:07, 15.91s/it]                                                       {'loss': 2.4408, 'grad_norm': 9.510457038879395, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 836, 'max_steps': 7272}
 11%|█▏        | 836/7272 [3:39:10<28:27:07, 15.91s/it] 12%|█▏        | 837/7272 [3:39:25<28:06:34, 15.73s/it]                                                       {'loss': 1.7031, 'grad_norm': 7.4003705978393555, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 837, 'max_steps': 7272}
 12%|█▏        | 837/7272 [3:39:25<28:06:34, 15.73s/it] 12%|█▏        | 838/7272 [3:39:41<28:10:49, 15.77s/it]                                                       {'loss': 2.453, 'grad_norm': 10.93809700012207, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 838, 'max_steps': 7272}
 12%|█▏        | 838/7272 [3:39:41<28:10:49, 15.77s/it] 12%|█▏        | 839/7272 [3:39:56<27:54:48, 15.62s/it]                                                       {'loss': 1.3002, 'grad_norm': 5.065814971923828, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 839, 'max_steps': 7272}
 12%|█▏        | 839/7272 [3:39:56<27:54:48, 15.62s/it] 12%|█▏        | 840/7272 [3:40:12<28:01:59, 15.69s/it]                                                       {'loss': 1.4957, 'grad_norm': 7.6126298904418945, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 840, 'max_steps': 7272}
 12%|█▏        | 840/7272 [3:40:12<28:01:59, 15.69s/it] 12%|█▏        | 841/7272 [3:40:28<28:27:12, 15.93s/it]                                                       {'loss': 1.5416, 'grad_norm': 7.364513874053955, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 841, 'max_steps': 7272}
 12%|█▏        | 841/7272 [3:40:28<28:27:12, 15.93s/it] 12%|█▏        | 842/7272 [3:40:44<28:26:48, 15.93s/it]                                                       {'loss': 3.98, 'grad_norm': 15.046492576599121, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 842, 'max_steps': 7272}
 12%|█▏        | 842/7272 [3:40:44<28:26:48, 15.93s/it] 12%|█▏        | 843/7272 [3:41:00<28:05:40, 15.73s/it]                                                       {'loss': 1.3018, 'grad_norm': 2.9893720149993896, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 843, 'max_steps': 7272}
 12%|█▏        | 843/7272 [3:41:00<28:05:40, 15.73s/it] 12%|█▏        | 844/7272 [3:41:15<27:57:24, 15.66s/it]                                                       {'loss': 1.8118, 'grad_norm': 5.230216026306152, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 844, 'max_steps': 7272}
 12%|█▏        | 844/7272 [3:41:15<27:57:24, 15.66s/it] 12%|█▏        | 845/7272 [3:41:31<28:00:36, 15.69s/it]                                                       {'loss': 1.3842, 'grad_norm': 3.8562519550323486, 'learning_rate': 5e-05, 'epoch': 0.46, 'step': 845, 'max_steps': 7272}
 12%|█▏        | 845/7272 [3:41:31<28:00:36, 15.69s/it] 12%|█▏        | 846/7272 [3:41:47<28:05:47, 15.74s/it]                                                       {'loss': 3.0557, 'grad_norm': 12.056236267089844, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 846, 'max_steps': 7272}
 12%|█▏        | 846/7272 [3:41:47<28:05:47, 15.74s/it] 12%|█▏        | 847/7272 [3:42:03<28:20:16, 15.88s/it]                                                       {'loss': 2.2109, 'grad_norm': 6.218081474304199, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 847, 'max_steps': 7272}
 12%|█▏        | 847/7272 [3:42:03<28:20:16, 15.88s/it] 12%|█▏        | 848/7272 [3:42:19<28:32:20, 15.99s/it]                                                       {'loss': 2.3762, 'grad_norm': 5.248447895050049, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 848, 'max_steps': 7272}
 12%|█▏        | 848/7272 [3:42:19<28:32:20, 15.99s/it] 12%|█▏        | 849/7272 [3:42:35<28:22:19, 15.90s/it]                                                       {'loss': 2.593, 'grad_norm': 5.299353122711182, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 849, 'max_steps': 7272}
 12%|█▏        | 849/7272 [3:42:35<28:22:19, 15.90s/it] 12%|█▏        | 850/7272 [3:42:51<28:18:48, 15.87s/it]                                                       {'loss': 1.6334, 'grad_norm': 7.398866653442383, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 850, 'max_steps': 7272}
 12%|█▏        | 850/7272 [3:42:51<28:18:48, 15.87s/it] 12%|█▏        | 851/7272 [3:43:06<28:06:04, 15.76s/it]                                                       {'loss': 1.492, 'grad_norm': 6.066798686981201, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 851, 'max_steps': 7272}
 12%|█▏        | 851/7272 [3:43:06<28:06:04, 15.76s/it] 12%|█▏        | 852/7272 [3:43:22<28:06:37, 15.76s/it]                                                       {'loss': 1.5842, 'grad_norm': 5.2870001792907715, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 852, 'max_steps': 7272}
 12%|█▏        | 852/7272 [3:43:22<28:06:37, 15.76s/it] 12%|█▏        | 853/7272 [3:43:38<28:15:16, 15.85s/it]                                                       {'loss': 2.7765, 'grad_norm': 7.793155670166016, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 853, 'max_steps': 7272}
 12%|█▏        | 853/7272 [3:43:38<28:15:16, 15.85s/it] 12%|█▏        | 854/7272 [3:43:54<28:08:59, 15.79s/it]                                                       {'loss': 1.2244, 'grad_norm': 4.206630229949951, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 854, 'max_steps': 7272}
 12%|█▏        | 854/7272 [3:43:54<28:08:59, 15.79s/it] 12%|█▏        | 855/7272 [3:44:09<27:54:55, 15.66s/it]                                                       {'loss': 2.942, 'grad_norm': 7.861561298370361, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 855, 'max_steps': 7272}
 12%|█▏        | 855/7272 [3:44:09<27:54:55, 15.66s/it] 12%|█▏        | 856/7272 [3:44:25<28:09:24, 15.80s/it]                                                       {'loss': 2.3282, 'grad_norm': 4.816200256347656, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 856, 'max_steps': 7272}
 12%|█▏        | 856/7272 [3:44:25<28:09:24, 15.80s/it] 12%|█▏        | 857/7272 [3:44:41<28:23:39, 15.93s/it]                                                       {'loss': 1.8704, 'grad_norm': 7.410791397094727, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 857, 'max_steps': 7272}
 12%|█▏        | 857/7272 [3:44:41<28:23:39, 15.93s/it] 12%|█▏        | 858/7272 [3:44:57<28:18:16, 15.89s/it]                                                       {'loss': 2.2198, 'grad_norm': 5.793135166168213, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 858, 'max_steps': 7272}
 12%|█▏        | 858/7272 [3:44:57<28:18:16, 15.89s/it] 12%|█▏        | 859/7272 [3:45:13<28:12:32, 15.84s/it]                                                       {'loss': 1.6266, 'grad_norm': 7.476958751678467, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 859, 'max_steps': 7272}
 12%|█▏        | 859/7272 [3:45:13<28:12:32, 15.84s/it] 12%|█▏        | 860/7272 [3:45:29<28:32:21, 16.02s/it]                                                       {'loss': 1.679, 'grad_norm': 3.5920825004577637, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 860, 'max_steps': 7272}
 12%|█▏        | 860/7272 [3:45:29<28:32:21, 16.02s/it] 12%|█▏        | 861/7272 [3:45:45<28:30:46, 16.01s/it]                                                       {'loss': 2.7341, 'grad_norm': 7.770477294921875, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 861, 'max_steps': 7272}
 12%|█▏        | 861/7272 [3:45:45<28:30:46, 16.01s/it] 12%|█▏        | 862/7272 [3:46:02<28:35:47, 16.06s/it]                                                       {'loss': 1.4611, 'grad_norm': 3.6138083934783936, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 862, 'max_steps': 7272}
 12%|█▏        | 862/7272 [3:46:02<28:35:47, 16.06s/it] 12%|█▏        | 863/7272 [3:46:18<28:38:03, 16.08s/it]                                                       {'loss': 1.9839, 'grad_norm': 7.746585845947266, 'learning_rate': 5e-05, 'epoch': 0.47, 'step': 863, 'max_steps': 7272}
 12%|█▏        | 863/7272 [3:46:18<28:38:03, 16.08s/it] 12%|█▏        | 864/7272 [3:46:33<28:13:58, 15.86s/it]                                                       {'loss': 3.0994, 'grad_norm': 6.95798921585083, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 864, 'max_steps': 7272}
 12%|█▏        | 864/7272 [3:46:33<28:13:58, 15.86s/it] 12%|█▏        | 865/7272 [3:46:48<27:59:58, 15.73s/it]                                                       {'loss': 0.9979, 'grad_norm': 7.833863735198975, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 865, 'max_steps': 7272}
 12%|█▏        | 865/7272 [3:46:48<27:59:58, 15.73s/it] 12%|█▏        | 866/7272 [3:47:04<27:48:45, 15.63s/it]                                                       {'loss': 1.2522, 'grad_norm': 7.337239742279053, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 866, 'max_steps': 7272}
 12%|█▏        | 866/7272 [3:47:04<27:48:45, 15.63s/it] 12%|█▏        | 867/7272 [3:47:20<27:48:43, 15.63s/it]                                                       {'loss': 2.0789, 'grad_norm': 5.878699779510498, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 867, 'max_steps': 7272}
 12%|█▏        | 867/7272 [3:47:20<27:48:43, 15.63s/it] 12%|█▏        | 868/7272 [3:47:36<28:25:44, 15.98s/it]                                                       {'loss': 1.734, 'grad_norm': 7.113655090332031, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 868, 'max_steps': 7272}
 12%|█▏        | 868/7272 [3:47:36<28:25:44, 15.98s/it] 12%|█▏        | 869/7272 [3:47:53<28:50:53, 16.22s/it]                                                       {'loss': 1.815, 'grad_norm': 5.502316951751709, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 869, 'max_steps': 7272}
 12%|█▏        | 869/7272 [3:47:53<28:50:53, 16.22s/it] 12%|█▏        | 870/7272 [3:48:09<28:38:27, 16.11s/it]                                                       {'loss': 1.6741, 'grad_norm': 4.806807041168213, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 870, 'max_steps': 7272}
 12%|█▏        | 870/7272 [3:48:09<28:38:27, 16.11s/it] 12%|█▏        | 871/7272 [3:48:24<28:15:19, 15.89s/it]                                                       {'loss': 1.8234, 'grad_norm': 9.782319068908691, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 871, 'max_steps': 7272}
 12%|█▏        | 871/7272 [3:48:24<28:15:19, 15.89s/it] 12%|█▏        | 872/7272 [3:48:40<28:05:44, 15.80s/it]                                                       {'loss': 1.6579, 'grad_norm': 10.5933256149292, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 872, 'max_steps': 7272}
 12%|█▏        | 872/7272 [3:48:40<28:05:44, 15.80s/it] 12%|█▏        | 873/7272 [3:48:56<28:05:15, 15.80s/it]                                                       {'loss': 1.7126, 'grad_norm': 4.194992542266846, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 873, 'max_steps': 7272}
 12%|█▏        | 873/7272 [3:48:56<28:05:15, 15.80s/it] 12%|█▏        | 874/7272 [3:49:11<28:02:18, 15.78s/it]                                                       {'loss': 1.7556, 'grad_norm': 7.622516632080078, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 874, 'max_steps': 7272}
 12%|█▏        | 874/7272 [3:49:11<28:02:18, 15.78s/it] 12%|█▏        | 875/7272 [3:49:27<28:05:25, 15.81s/it]                                                       {'loss': 1.6547, 'grad_norm': 5.133084297180176, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 875, 'max_steps': 7272}
 12%|█▏        | 875/7272 [3:49:27<28:05:25, 15.81s/it] 12%|█▏        | 876/7272 [3:49:43<27:59:13, 15.75s/it]                                                       {'loss': 1.555, 'grad_norm': 4.087919235229492, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 876, 'max_steps': 7272}
 12%|█▏        | 876/7272 [3:49:43<27:59:13, 15.75s/it] 12%|█▏        | 877/7272 [3:49:58<27:45:22, 15.63s/it]                                                       {'loss': 2.5321, 'grad_norm': 10.13386058807373, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 877, 'max_steps': 7272}
 12%|█▏        | 877/7272 [3:49:58<27:45:22, 15.63s/it] 12%|█▏        | 878/7272 [3:50:14<27:48:13, 15.65s/it]                                                       {'loss': 1.3077, 'grad_norm': 3.3858067989349365, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 878, 'max_steps': 7272}
 12%|█▏        | 878/7272 [3:50:14<27:48:13, 15.65s/it] 12%|█▏        | 879/7272 [3:50:29<27:42:51, 15.61s/it]                                                       {'loss': 1.898, 'grad_norm': 6.079196929931641, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 879, 'max_steps': 7272}
 12%|█▏        | 879/7272 [3:50:29<27:42:51, 15.61s/it] 12%|█▏        | 880/7272 [3:50:45<27:43:29, 15.61s/it]                                                       {'loss': 2.4689, 'grad_norm': 7.446654319763184, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 880, 'max_steps': 7272}
 12%|█▏        | 880/7272 [3:50:45<27:43:29, 15.61s/it] 12%|█▏        | 881/7272 [3:51:01<27:54:02, 15.72s/it]                                                       {'loss': 1.8629, 'grad_norm': 5.2677812576293945, 'learning_rate': 5e-05, 'epoch': 0.48, 'step': 881, 'max_steps': 7272}
 12%|█▏        | 881/7272 [3:51:01<27:54:02, 15.72s/it] 12%|█▏        | 882/7272 [3:51:17<28:13:20, 15.90s/it]                                                       {'loss': 0.802, 'grad_norm': 3.987886905670166, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 882, 'max_steps': 7272}
 12%|█▏        | 882/7272 [3:51:17<28:13:20, 15.90s/it] 12%|█▏        | 883/7272 [3:51:33<28:11:10, 15.88s/it]                                                       {'loss': 2.2135, 'grad_norm': 11.832303047180176, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 883, 'max_steps': 7272}
 12%|█▏        | 883/7272 [3:51:33<28:11:10, 15.88s/it] 12%|█▏        | 884/7272 [3:51:49<28:09:00, 15.86s/it]                                                       {'loss': 1.1983, 'grad_norm': 4.0347089767456055, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 884, 'max_steps': 7272}
 12%|█▏        | 884/7272 [3:51:49<28:09:00, 15.86s/it] 12%|█▏        | 885/7272 [3:52:05<28:20:40, 15.98s/it]                                                       {'loss': 2.11, 'grad_norm': 8.187718391418457, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 885, 'max_steps': 7272}
 12%|█▏        | 885/7272 [3:52:05<28:20:40, 15.98s/it] 12%|█▏        | 886/7272 [3:52:21<28:12:01, 15.90s/it]                                                       {'loss': 0.6797, 'grad_norm': 4.9842119216918945, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 886, 'max_steps': 7272}
 12%|█▏        | 886/7272 [3:52:21<28:12:01, 15.90s/it] 12%|█▏        | 887/7272 [3:52:37<28:01:39, 15.80s/it]                                                       {'loss': 3.721, 'grad_norm': 10.847078323364258, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 887, 'max_steps': 7272}
 12%|█▏        | 887/7272 [3:52:37<28:01:39, 15.80s/it] 12%|█▏        | 888/7272 [3:52:52<28:00:21, 15.79s/it]                                                       {'loss': 1.1141, 'grad_norm': 4.607292175292969, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 888, 'max_steps': 7272}
 12%|█▏        | 888/7272 [3:52:52<28:00:21, 15.79s/it] 12%|█▏        | 889/7272 [3:53:08<27:56:13, 15.76s/it]                                                       {'loss': 1.4712, 'grad_norm': 5.669570446014404, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 889, 'max_steps': 7272}
 12%|█▏        | 889/7272 [3:53:08<27:56:13, 15.76s/it] 12%|█▏        | 890/7272 [3:53:24<28:10:16, 15.89s/it]                                                       {'loss': 1.9767, 'grad_norm': 3.646970510482788, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 890, 'max_steps': 7272}
 12%|█▏        | 890/7272 [3:53:24<28:10:16, 15.89s/it] 12%|█▏        | 891/7272 [3:53:40<28:02:38, 15.82s/it]                                                       {'loss': 1.5189, 'grad_norm': 5.454109191894531, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 891, 'max_steps': 7272}
 12%|█▏        | 891/7272 [3:53:40<28:02:38, 15.82s/it] 12%|█▏        | 892/7272 [3:53:56<28:05:09, 15.85s/it]                                                       {'loss': 0.7842, 'grad_norm': 4.487667083740234, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 892, 'max_steps': 7272}
 12%|█▏        | 892/7272 [3:53:56<28:05:09, 15.85s/it] 12%|█▏        | 893/7272 [3:54:12<28:21:09, 16.00s/it]                                                       {'loss': 1.7461, 'grad_norm': 5.938094139099121, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 893, 'max_steps': 7272}
 12%|█▏        | 893/7272 [3:54:12<28:21:09, 16.00s/it] 12%|█▏        | 894/7272 [3:54:28<28:24:24, 16.03s/it]                                                       {'loss': 1.835, 'grad_norm': 5.116732597351074, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 894, 'max_steps': 7272}
 12%|█▏        | 894/7272 [3:54:28<28:24:24, 16.03s/it] 12%|█▏        | 895/7272 [3:54:44<28:19:30, 15.99s/it]                                                       {'loss': 1.1348, 'grad_norm': 2.6084959506988525, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 895, 'max_steps': 7272}
 12%|█▏        | 895/7272 [3:54:44<28:19:30, 15.99s/it] 12%|█▏        | 896/7272 [3:55:00<28:14:49, 15.95s/it]                                                       {'loss': 1.803, 'grad_norm': 3.234142541885376, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 896, 'max_steps': 7272}
 12%|█▏        | 896/7272 [3:55:00<28:14:49, 15.95s/it] 12%|█▏        | 897/7272 [3:55:16<28:02:26, 15.83s/it]                                                       {'loss': 2.1548, 'grad_norm': 7.401313781738281, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 897, 'max_steps': 7272}
 12%|█▏        | 897/7272 [3:55:16<28:02:26, 15.83s/it] 12%|█▏        | 898/7272 [3:55:31<27:58:19, 15.80s/it]                                                       {'loss': 1.4548, 'grad_norm': 3.134868860244751, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 898, 'max_steps': 7272}
 12%|█▏        | 898/7272 [3:55:31<27:58:19, 15.80s/it] 12%|█▏        | 899/7272 [3:55:48<28:14:20, 15.95s/it]                                                       {'loss': 1.3225, 'grad_norm': 5.780817031860352, 'learning_rate': 5e-05, 'epoch': 0.49, 'step': 899, 'max_steps': 7272}
 12%|█▏        | 899/7272 [3:55:48<28:14:20, 15.95s/it] 12%|█▏        | 900/7272 [3:56:04<28:19:06, 16.00s/it]                                                       {'loss': 1.9689, 'grad_norm': 17.962039947509766, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 900, 'max_steps': 7272}
 12%|█▏        | 900/7272 [3:56:04<28:19:06, 16.00s/it] 12%|█▏        | 901/7272 [3:56:19<28:06:58, 15.89s/it]                                                       {'loss': 1.3351, 'grad_norm': 2.9048912525177, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 901, 'max_steps': 7272}
 12%|█▏        | 901/7272 [3:56:19<28:06:58, 15.89s/it] 12%|█▏        | 902/7272 [3:56:36<28:18:37, 16.00s/it]                                                       {'loss': 0.6044, 'grad_norm': 2.1149306297302246, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 902, 'max_steps': 7272}
 12%|█▏        | 902/7272 [3:56:36<28:18:37, 16.00s/it] 12%|█▏        | 903/7272 [3:56:52<28:32:01, 16.13s/it]                                                       {'loss': 1.5861, 'grad_norm': 5.243878364562988, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 903, 'max_steps': 7272}
 12%|█▏        | 903/7272 [3:56:52<28:32:01, 16.13s/it] 12%|█▏        | 904/7272 [3:57:08<28:28:35, 16.10s/it]                                                       {'loss': 2.3698, 'grad_norm': 3.237077474594116, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 904, 'max_steps': 7272}
 12%|█▏        | 904/7272 [3:57:08<28:28:35, 16.10s/it] 12%|█▏        | 905/7272 [3:57:25<28:43:49, 16.24s/it]                                                       {'loss': 1.2672, 'grad_norm': 6.711974620819092, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 905, 'max_steps': 7272}
 12%|█▏        | 905/7272 [3:57:25<28:43:49, 16.24s/it] 12%|█▏        | 906/7272 [3:57:41<28:36:05, 16.17s/it]                                                       {'loss': 1.2717, 'grad_norm': 6.465494632720947, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 906, 'max_steps': 7272}
 12%|█▏        | 906/7272 [3:57:41<28:36:05, 16.17s/it] 12%|█▏        | 907/7272 [3:57:57<28:40:12, 16.22s/it]                                                       {'loss': 1.4698, 'grad_norm': 3.605494260787964, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 907, 'max_steps': 7272}
 12%|█▏        | 907/7272 [3:57:57<28:40:12, 16.22s/it] 12%|█▏        | 908/7272 [3:58:13<28:32:10, 16.14s/it]                                                       {'loss': 1.9966, 'grad_norm': 5.3757429122924805, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 908, 'max_steps': 7272}
 12%|█▏        | 908/7272 [3:58:13<28:32:10, 16.14s/it] 12%|█▎        | 909/7272 [3:58:29<28:22:50, 16.06s/it]                                                       {'loss': 2.9132, 'grad_norm': 7.595333099365234, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 909, 'max_steps': 7272}
 12%|█▎        | 909/7272 [3:58:29<28:22:50, 16.06s/it] 13%|█▎        | 910/7272 [3:58:44<28:11:18, 15.95s/it]                                                       {'loss': 1.8169, 'grad_norm': 7.237374782562256, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 910, 'max_steps': 7272}
 13%|█▎        | 910/7272 [3:58:44<28:11:18, 15.95s/it] 13%|█▎        | 911/7272 [3:59:00<28:00:29, 15.85s/it]                                                       {'loss': 3.2119, 'grad_norm': 5.2115325927734375, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 911, 'max_steps': 7272}
 13%|█▎        | 911/7272 [3:59:00<28:00:29, 15.85s/it] 13%|█▎        | 912/7272 [3:59:16<28:15:25, 15.99s/it]                                                       {'loss': 0.8485, 'grad_norm': 6.271892070770264, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 912, 'max_steps': 7272}
 13%|█▎        | 912/7272 [3:59:16<28:15:25, 15.99s/it] 13%|█▎        | 913/7272 [3:59:32<28:11:27, 15.96s/it]                                                       {'loss': 1.401, 'grad_norm': 5.388993740081787, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 913, 'max_steps': 7272}
 13%|█▎        | 913/7272 [3:59:32<28:11:27, 15.96s/it] 13%|█▎        | 914/7272 [3:59:48<28:03:27, 15.89s/it]                                                       {'loss': 1.2579, 'grad_norm': 4.616756916046143, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 914, 'max_steps': 7272}
 13%|█▎        | 914/7272 [3:59:48<28:03:27, 15.89s/it] 13%|█▎        | 915/7272 [4:00:03<27:46:54, 15.73s/it]                                                       {'loss': 1.5006, 'grad_norm': 3.208728551864624, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 915, 'max_steps': 7272}
 13%|█▎        | 915/7272 [4:00:03<27:46:54, 15.73s/it] 13%|█▎        | 916/7272 [4:00:19<27:50:21, 15.77s/it]                                                       {'loss': 1.533, 'grad_norm': 5.379720687866211, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 916, 'max_steps': 7272}
 13%|█▎        | 916/7272 [4:00:19<27:50:21, 15.77s/it] 13%|█▎        | 917/7272 [4:00:35<27:51:27, 15.78s/it]                                                       {'loss': 1.9382, 'grad_norm': 9.086098670959473, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 917, 'max_steps': 7272}
 13%|█▎        | 917/7272 [4:00:35<27:51:27, 15.78s/it] 13%|█▎        | 918/7272 [4:00:51<27:46:58, 15.74s/it]                                                       {'loss': 2.2356, 'grad_norm': 4.315348148345947, 'learning_rate': 5e-05, 'epoch': 0.5, 'step': 918, 'max_steps': 7272}
 13%|█▎        | 918/7272 [4:00:51<27:46:58, 15.74s/it] 13%|█▎        | 919/7272 [4:01:07<27:56:39, 15.84s/it]                                                       {'loss': 2.1644, 'grad_norm': 7.4610090255737305, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 919, 'max_steps': 7272}
 13%|█▎        | 919/7272 [4:01:07<27:56:39, 15.84s/it] 13%|█▎        | 920/7272 [4:01:23<28:02:59, 15.90s/it]                                                       {'loss': 1.7088, 'grad_norm': 4.412664413452148, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 920, 'max_steps': 7272}
 13%|█▎        | 920/7272 [4:01:23<28:02:59, 15.90s/it] 13%|█▎        | 921/7272 [4:01:40<28:32:19, 16.18s/it]                                                       {'loss': 1.4971, 'grad_norm': 3.9550070762634277, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 921, 'max_steps': 7272}
 13%|█▎        | 921/7272 [4:01:40<28:32:19, 16.18s/it] 13%|█▎        | 922/7272 [4:01:56<28:30:23, 16.16s/it]                                                       {'loss': 1.7904, 'grad_norm': 7.782991886138916, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 922, 'max_steps': 7272}
 13%|█▎        | 922/7272 [4:01:56<28:30:23, 16.16s/it] 13%|█▎        | 923/7272 [4:02:11<28:11:06, 15.98s/it]                                                       {'loss': 1.3197, 'grad_norm': 8.748431205749512, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 923, 'max_steps': 7272}
 13%|█▎        | 923/7272 [4:02:11<28:11:06, 15.98s/it] 13%|█▎        | 924/7272 [4:02:27<28:07:23, 15.95s/it]                                                       {'loss': 2.0351, 'grad_norm': 11.13318920135498, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 924, 'max_steps': 7272}
 13%|█▎        | 924/7272 [4:02:27<28:07:23, 15.95s/it] 13%|█▎        | 925/7272 [4:02:43<28:10:52, 15.98s/it]                                                       {'loss': 3.4828, 'grad_norm': 5.783898830413818, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 925, 'max_steps': 7272}
 13%|█▎        | 925/7272 [4:02:43<28:10:52, 15.98s/it] 13%|█▎        | 926/7272 [4:02:59<28:16:16, 16.04s/it]                                                       {'loss': 1.6046, 'grad_norm': 2.8838045597076416, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 926, 'max_steps': 7272}
 13%|█▎        | 926/7272 [4:02:59<28:16:16, 16.04s/it] 13%|█▎        | 927/7272 [4:03:16<28:29:16, 16.16s/it]                                                       {'loss': 2.7682, 'grad_norm': 6.827356338500977, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 927, 'max_steps': 7272}
 13%|█▎        | 927/7272 [4:03:16<28:29:16, 16.16s/it] 13%|█▎        | 928/7272 [4:03:32<28:29:08, 16.16s/it]                                                       {'loss': 2.6752, 'grad_norm': 12.32625961303711, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 928, 'max_steps': 7272}
 13%|█▎        | 928/7272 [4:03:32<28:29:08, 16.16s/it] 13%|█▎        | 929/7272 [4:03:48<28:17:00, 16.05s/it]                                                       {'loss': 1.9175, 'grad_norm': 4.808083534240723, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 929, 'max_steps': 7272}
 13%|█▎        | 929/7272 [4:03:48<28:17:00, 16.05s/it] 13%|█▎        | 930/7272 [4:04:04<28:05:58, 15.95s/it]                                                       {'loss': 1.5815, 'grad_norm': 7.764678955078125, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 930, 'max_steps': 7272}
 13%|█▎        | 930/7272 [4:04:04<28:05:58, 15.95s/it] 13%|█▎        | 931/7272 [4:04:20<28:06:34, 15.96s/it]                                                       {'loss': 1.5109, 'grad_norm': 9.039787292480469, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 931, 'max_steps': 7272}
 13%|█▎        | 931/7272 [4:04:20<28:06:34, 15.96s/it] 13%|█▎        | 932/7272 [4:04:35<27:58:23, 15.88s/it]                                                       {'loss': 2.3994, 'grad_norm': 6.8339104652404785, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 932, 'max_steps': 7272}
 13%|█▎        | 932/7272 [4:04:35<27:58:23, 15.88s/it] 13%|█▎        | 933/7272 [4:04:51<28:06:57, 15.97s/it]                                                       {'loss': 1.5637, 'grad_norm': 5.344025611877441, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 933, 'max_steps': 7272}
 13%|█▎        | 933/7272 [4:04:51<28:06:57, 15.97s/it] 13%|█▎        | 934/7272 [4:05:08<28:11:12, 16.01s/it]                                                       {'loss': 0.593, 'grad_norm': 5.35182523727417, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 934, 'max_steps': 7272}
 13%|█▎        | 934/7272 [4:05:08<28:11:12, 16.01s/it] 13%|█▎        | 935/7272 [4:05:24<28:11:37, 16.02s/it]                                                       {'loss': 2.2193, 'grad_norm': 6.653873920440674, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 935, 'max_steps': 7272}
 13%|█▎        | 935/7272 [4:05:24<28:11:37, 16.02s/it] 13%|█▎        | 936/7272 [4:05:39<28:02:41, 15.93s/it]                                                       {'loss': 0.9114, 'grad_norm': 4.217411994934082, 'learning_rate': 5e-05, 'epoch': 0.51, 'step': 936, 'max_steps': 7272}
 13%|█▎        | 936/7272 [4:05:39<28:02:41, 15.93s/it] 13%|█▎        | 937/7272 [4:05:55<27:47:17, 15.79s/it]                                                       {'loss': 0.9735, 'grad_norm': 7.470137119293213, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 937, 'max_steps': 7272}
 13%|█▎        | 937/7272 [4:05:55<27:47:17, 15.79s/it] 13%|█▎        | 938/7272 [4:06:10<27:36:31, 15.69s/it]                                                       {'loss': 1.9713, 'grad_norm': 5.656528472900391, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 938, 'max_steps': 7272}
 13%|█▎        | 938/7272 [4:06:10<27:36:31, 15.69s/it] 13%|█▎        | 939/7272 [4:06:27<28:04:44, 15.96s/it]                                                       {'loss': 0.8363, 'grad_norm': 3.327677011489868, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 939, 'max_steps': 7272}
 13%|█▎        | 939/7272 [4:06:27<28:04:44, 15.96s/it] 13%|█▎        | 940/7272 [4:06:43<28:08:54, 16.00s/it]                                                       {'loss': 2.5107, 'grad_norm': 6.681641578674316, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 940, 'max_steps': 7272}
 13%|█▎        | 940/7272 [4:06:43<28:08:54, 16.00s/it] 13%|█▎        | 941/7272 [4:06:58<27:48:57, 15.82s/it]                                                       {'loss': 0.7821, 'grad_norm': 2.8392746448516846, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 941, 'max_steps': 7272}
 13%|█▎        | 941/7272 [4:06:58<27:48:57, 15.82s/it] 13%|█▎        | 942/7272 [4:07:14<27:55:27, 15.88s/it]                                                       {'loss': 2.0684, 'grad_norm': 4.280527591705322, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 942, 'max_steps': 7272}
 13%|█▎        | 942/7272 [4:07:14<27:55:27, 15.88s/it] 13%|█▎        | 943/7272 [4:07:30<27:44:36, 15.78s/it]                                                       {'loss': 1.9655, 'grad_norm': 5.040355682373047, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 943, 'max_steps': 7272}
 13%|█▎        | 943/7272 [4:07:30<27:44:36, 15.78s/it] 13%|█▎        | 944/7272 [4:07:46<27:45:28, 15.79s/it]                                                       {'loss': 2.0409, 'grad_norm': 4.558042049407959, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 944, 'max_steps': 7272}
 13%|█▎        | 944/7272 [4:07:46<27:45:28, 15.79s/it] 13%|█▎        | 945/7272 [4:08:01<27:30:37, 15.65s/it]                                                       {'loss': 1.5931, 'grad_norm': 5.0034966468811035, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 945, 'max_steps': 7272}
 13%|█▎        | 945/7272 [4:08:01<27:30:37, 15.65s/it] 13%|█▎        | 946/7272 [4:08:17<27:33:46, 15.69s/it]                                                       {'loss': 2.2373, 'grad_norm': 14.502629280090332, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 946, 'max_steps': 7272}
 13%|█▎        | 946/7272 [4:08:17<27:33:46, 15.69s/it] 13%|█▎        | 947/7272 [4:08:33<27:45:41, 15.80s/it]                                                       {'loss': 1.3764, 'grad_norm': 4.508293151855469, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 947, 'max_steps': 7272}
 13%|█▎        | 947/7272 [4:08:33<27:45:41, 15.80s/it] 13%|█▎        | 948/7272 [4:08:49<28:00:57, 15.95s/it]                                                       {'loss': 1.2416, 'grad_norm': 4.717743396759033, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 948, 'max_steps': 7272}
 13%|█▎        | 948/7272 [4:08:49<28:00:57, 15.95s/it] 13%|█▎        | 949/7272 [4:09:05<28:02:55, 15.97s/it]                                                       {'loss': 2.653, 'grad_norm': 7.2360334396362305, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 949, 'max_steps': 7272}
 13%|█▎        | 949/7272 [4:09:05<28:02:55, 15.97s/it] 13%|█▎        | 950/7272 [4:09:21<28:13:46, 16.08s/it]                                                       {'loss': 2.2262, 'grad_norm': 7.713021278381348, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 950, 'max_steps': 7272}
 13%|█▎        | 950/7272 [4:09:21<28:13:46, 16.08s/it] 13%|█▎        | 951/7272 [4:09:37<28:06:33, 16.01s/it]                                                       {'loss': 1.6309, 'grad_norm': 6.955530166625977, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 951, 'max_steps': 7272}
 13%|█▎        | 951/7272 [4:09:37<28:06:33, 16.01s/it] 13%|█▎        | 952/7272 [4:09:53<28:08:40, 16.03s/it]                                                       {'loss': 1.0571, 'grad_norm': 3.1880996227264404, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 952, 'max_steps': 7272}
 13%|█▎        | 952/7272 [4:09:53<28:08:40, 16.03s/it] 13%|█▎        | 953/7272 [4:10:09<27:40:31, 15.77s/it]                                                       {'loss': 1.3502, 'grad_norm': 8.532608985900879, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 953, 'max_steps': 7272}
 13%|█▎        | 953/7272 [4:10:09<27:40:31, 15.77s/it] 13%|█▎        | 954/7272 [4:10:24<27:39:17, 15.76s/it]                                                       {'loss': 1.9439, 'grad_norm': 5.1758012771606445, 'learning_rate': 5e-05, 'epoch': 0.52, 'step': 954, 'max_steps': 7272}
 13%|█▎        | 954/7272 [4:10:24<27:39:17, 15.76s/it] 13%|█▎        | 955/7272 [4:10:40<27:39:25, 15.76s/it]                                                       {'loss': 1.5999, 'grad_norm': 3.1202850341796875, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 955, 'max_steps': 7272}
 13%|█▎        | 955/7272 [4:10:40<27:39:25, 15.76s/it] 13%|█▎        | 956/7272 [4:10:56<27:41:50, 15.79s/it]                                                       {'loss': 0.9257, 'grad_norm': 8.053431510925293, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 956, 'max_steps': 7272}
 13%|█▎        | 956/7272 [4:10:56<27:41:50, 15.79s/it] 13%|█▎        | 957/7272 [4:11:11<27:33:20, 15.71s/it]                                                       {'loss': 1.9884, 'grad_norm': 5.522767543792725, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 957, 'max_steps': 7272}
 13%|█▎        | 957/7272 [4:11:11<27:33:20, 15.71s/it] 13%|█▎        | 958/7272 [4:11:27<27:29:09, 15.67s/it]                                                       {'loss': 2.1603, 'grad_norm': 11.043805122375488, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 958, 'max_steps': 7272}
 13%|█▎        | 958/7272 [4:11:27<27:29:09, 15.67s/it] 13%|█▎        | 959/7272 [4:11:43<27:28:48, 15.67s/it]                                                       {'loss': 2.3629, 'grad_norm': 13.903074264526367, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 959, 'max_steps': 7272}
 13%|█▎        | 959/7272 [4:11:43<27:28:48, 15.67s/it] 13%|█▎        | 960/7272 [4:11:59<27:34:41, 15.73s/it]                                                       {'loss': 0.5241, 'grad_norm': 3.961615562438965, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 960, 'max_steps': 7272}
 13%|█▎        | 960/7272 [4:11:59<27:34:41, 15.73s/it] 13%|█▎        | 961/7272 [4:12:15<27:49:28, 15.87s/it]                                                       {'loss': 2.9205, 'grad_norm': 6.038032054901123, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 961, 'max_steps': 7272}
 13%|█▎        | 961/7272 [4:12:15<27:49:28, 15.87s/it] 13%|█▎        | 962/7272 [4:12:31<27:56:23, 15.94s/it]                                                       {'loss': 1.4855, 'grad_norm': 7.571230888366699, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 962, 'max_steps': 7272}
 13%|█▎        | 962/7272 [4:12:31<27:56:23, 15.94s/it] 13%|█▎        | 963/7272 [4:12:47<27:56:44, 15.95s/it]                                                       {'loss': 1.6247, 'grad_norm': 4.986806392669678, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 963, 'max_steps': 7272}
 13%|█▎        | 963/7272 [4:12:47<27:56:44, 15.95s/it] 13%|█▎        | 964/7272 [4:13:03<27:57:20, 15.95s/it]                                                       {'loss': 2.3275, 'grad_norm': 5.451908111572266, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 964, 'max_steps': 7272}
 13%|█▎        | 964/7272 [4:13:03<27:57:20, 15.95s/it] 13%|█▎        | 965/7272 [4:13:19<28:13:42, 16.11s/it]                                                       {'loss': 1.7799, 'grad_norm': 5.045837879180908, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 965, 'max_steps': 7272}
 13%|█▎        | 965/7272 [4:13:19<28:13:42, 16.11s/it] 13%|█▎        | 966/7272 [4:13:35<28:11:35, 16.10s/it]                                                       {'loss': 3.2045, 'grad_norm': 8.95272159576416, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 966, 'max_steps': 7272}
 13%|█▎        | 966/7272 [4:13:35<28:11:35, 16.10s/it] 13%|█▎        | 967/7272 [4:13:52<28:16:35, 16.15s/it]                                                       {'loss': 1.9341, 'grad_norm': 3.6948366165161133, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 967, 'max_steps': 7272}
 13%|█▎        | 967/7272 [4:13:52<28:16:35, 16.15s/it] 13%|█▎        | 968/7272 [4:14:08<28:24:11, 16.22s/it]                                                       {'loss': 1.3231, 'grad_norm': 4.258920192718506, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 968, 'max_steps': 7272}
 13%|█▎        | 968/7272 [4:14:08<28:24:11, 16.22s/it] 13%|█▎        | 969/7272 [4:14:24<28:24:09, 16.22s/it]                                                       {'loss': 1.8406, 'grad_norm': 6.021455764770508, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 969, 'max_steps': 7272}
 13%|█▎        | 969/7272 [4:14:24<28:24:09, 16.22s/it] 13%|█▎        | 970/7272 [4:14:40<28:10:44, 16.10s/it]                                                       {'loss': 2.4915, 'grad_norm': 6.636340618133545, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 970, 'max_steps': 7272}
 13%|█▎        | 970/7272 [4:14:40<28:10:44, 16.10s/it] 13%|█▎        | 971/7272 [4:14:56<28:09:48, 16.09s/it]                                                       {'loss': 2.4533, 'grad_norm': 4.8819169998168945, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 971, 'max_steps': 7272}
 13%|█▎        | 971/7272 [4:14:56<28:09:48, 16.09s/it] 13%|█▎        | 972/7272 [4:15:13<28:22:54, 16.22s/it]                                                       {'loss': 1.4093, 'grad_norm': 5.400210857391357, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 972, 'max_steps': 7272}
 13%|█▎        | 972/7272 [4:15:13<28:22:54, 16.22s/it] 13%|█▎        | 973/7272 [4:15:29<28:18:25, 16.18s/it]                                                       {'loss': 1.8417, 'grad_norm': 14.365104675292969, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 973, 'max_steps': 7272}
 13%|█▎        | 973/7272 [4:15:29<28:18:25, 16.18s/it] 13%|█▎        | 974/7272 [4:15:45<28:27:23, 16.27s/it]                                                       {'loss': 1.6648, 'grad_norm': 5.198080062866211, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 974, 'max_steps': 7272}
 13%|█▎        | 974/7272 [4:15:45<28:27:23, 16.27s/it] 13%|█▎        | 975/7272 [4:16:01<28:09:19, 16.10s/it]                                                       {'loss': 3.2089, 'grad_norm': 9.502908706665039, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 975, 'max_steps': 7272}
 13%|█▎        | 975/7272 [4:16:01<28:09:19, 16.10s/it] 13%|█▎        | 976/7272 [4:16:17<28:16:36, 16.17s/it]                                                       {'loss': 0.811, 'grad_norm': 2.7010393142700195, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 976, 'max_steps': 7272}
 13%|█▎        | 976/7272 [4:16:17<28:16:36, 16.17s/it] 13%|█▎        | 977/7272 [4:16:34<28:27:50, 16.28s/it]                                                       {'loss': 1.2828, 'grad_norm': 5.48090934753418, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 977, 'max_steps': 7272}
 13%|█▎        | 977/7272 [4:16:34<28:27:50, 16.28s/it] 13%|█▎        | 978/7272 [4:16:50<28:33:01, 16.33s/it]                                                       {'loss': 0.4706, 'grad_norm': 3.500513792037964, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 978, 'max_steps': 7272}
 13%|█▎        | 978/7272 [4:16:50<28:33:01, 16.33s/it] 13%|█▎        | 979/7272 [4:17:06<28:15:00, 16.16s/it]                                                       {'loss': 1.9227, 'grad_norm': 10.745662689208984, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 979, 'max_steps': 7272}
 13%|█▎        | 979/7272 [4:17:06<28:15:00, 16.16s/it] 13%|█▎        | 980/7272 [4:17:22<28:20:10, 16.21s/it]                                                       {'loss': 0.9019, 'grad_norm': 3.4416234493255615, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 980, 'max_steps': 7272}
 13%|█▎        | 980/7272 [4:17:22<28:20:10, 16.21s/it] 13%|█▎        | 981/7272 [4:17:38<28:19:35, 16.21s/it]                                                       {'loss': 2.1687, 'grad_norm': 9.274787902832031, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 981, 'max_steps': 7272}
 13%|█▎        | 981/7272 [4:17:39<28:19:35, 16.21s/it] 14%|█▎        | 982/7272 [4:17:54<27:59:44, 16.02s/it]                                                       {'loss': 3.2205, 'grad_norm': 7.315042018890381, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 982, 'max_steps': 7272}
 14%|█▎        | 982/7272 [4:17:54<27:59:44, 16.02s/it] 14%|█▎        | 983/7272 [4:18:10<27:58:48, 16.02s/it]                                                       {'loss': 1.5067, 'grad_norm': 4.308189868927002, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 983, 'max_steps': 7272}
 14%|█▎        | 983/7272 [4:18:10<27:58:48, 16.02s/it] 14%|█▎        | 984/7272 [4:18:26<28:05:07, 16.08s/it]                                                       {'loss': 1.8947, 'grad_norm': 6.455654144287109, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 984, 'max_steps': 7272}
 14%|█▎        | 984/7272 [4:18:26<28:05:07, 16.08s/it] 14%|█▎        | 985/7272 [4:18:42<28:00:48, 16.04s/it]                                                       {'loss': 1.3853, 'grad_norm': 7.176244735717773, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 985, 'max_steps': 7272}
 14%|█▎        | 985/7272 [4:18:42<28:00:48, 16.04s/it] 14%|█▎        | 986/7272 [4:18:58<27:43:50, 15.88s/it]                                                       {'loss': 1.5936, 'grad_norm': 5.824753284454346, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 986, 'max_steps': 7272}
 14%|█▎        | 986/7272 [4:18:58<27:43:50, 15.88s/it] 14%|█▎        | 987/7272 [4:19:13<27:32:30, 15.78s/it]                                                       {'loss': 0.7987, 'grad_norm': 4.188514232635498, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 987, 'max_steps': 7272}
 14%|█▎        | 987/7272 [4:19:13<27:32:30, 15.78s/it] 14%|█▎        | 988/7272 [4:19:29<27:29:52, 15.75s/it]                                                       {'loss': 1.4418, 'grad_norm': 3.072333812713623, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 988, 'max_steps': 7272}
 14%|█▎        | 988/7272 [4:19:29<27:29:52, 15.75s/it] 14%|█▎        | 989/7272 [4:19:45<27:26:55, 15.73s/it]                                                       {'loss': 2.2221, 'grad_norm': 11.277517318725586, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 989, 'max_steps': 7272}
 14%|█▎        | 989/7272 [4:19:45<27:26:55, 15.73s/it] 14%|█▎        | 990/7272 [4:20:01<27:33:43, 15.79s/it]                                                       {'loss': 0.8897, 'grad_norm': 3.8305342197418213, 'learning_rate': 5e-05, 'epoch': 0.54, 'step': 990, 'max_steps': 7272}
 14%|█▎        | 990/7272 [4:20:01<27:33:43, 15.79s/it] 14%|█▎        | 991/7272 [4:20:17<27:43:37, 15.89s/it]                                                       {'loss': 1.8581, 'grad_norm': 4.491631031036377, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 991, 'max_steps': 7272}
 14%|█▎        | 991/7272 [4:20:17<27:43:37, 15.89s/it] 14%|█▎        | 992/7272 [4:20:32<27:36:22, 15.83s/it]                                                       {'loss': 2.0869, 'grad_norm': 3.8467953205108643, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 992, 'max_steps': 7272}
 14%|█▎        | 992/7272 [4:20:32<27:36:22, 15.83s/it] 14%|█▎        | 993/7272 [4:20:48<27:36:38, 15.83s/it]                                                       {'loss': 1.2338, 'grad_norm': 6.286657810211182, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 993, 'max_steps': 7272}
 14%|█▎        | 993/7272 [4:20:48<27:36:38, 15.83s/it] 14%|█▎        | 994/7272 [4:21:04<27:31:54, 15.79s/it]                                                       {'loss': 0.8316, 'grad_norm': 2.7856647968292236, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 994, 'max_steps': 7272}
 14%|█▎        | 994/7272 [4:21:04<27:31:54, 15.79s/it] 14%|█▎        | 995/7272 [4:21:20<27:32:07, 15.79s/it]                                                       {'loss': 2.7249, 'grad_norm': 5.579033851623535, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 995, 'max_steps': 7272}
 14%|█▎        | 995/7272 [4:21:20<27:32:07, 15.79s/it] 14%|█▎        | 996/7272 [4:21:35<27:29:07, 15.77s/it]                                                       {'loss': 1.6579, 'grad_norm': 4.777840614318848, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 996, 'max_steps': 7272}
 14%|█▎        | 996/7272 [4:21:35<27:29:07, 15.77s/it] 14%|█▎        | 997/7272 [4:21:52<27:40:47, 15.88s/it]                                                       {'loss': 2.3208, 'grad_norm': 6.974809169769287, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 997, 'max_steps': 7272}
 14%|█▎        | 997/7272 [4:21:52<27:40:47, 15.88s/it] 14%|█▎        | 998/7272 [4:22:07<27:38:31, 15.86s/it]                                                       {'loss': 1.5576, 'grad_norm': 6.248838901519775, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 998, 'max_steps': 7272}
 14%|█▎        | 998/7272 [4:22:07<27:38:31, 15.86s/it] 14%|█▎        | 999/7272 [4:22:23<27:24:40, 15.73s/it]                                                       {'loss': 2.4888, 'grad_norm': 7.437638759613037, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 999, 'max_steps': 7272}
 14%|█▎        | 999/7272 [4:22:23<27:24:40, 15.73s/it] 14%|█▍        | 1000/7272 [4:22:39<27:36:30, 15.85s/it]                                                        {'loss': 1.828, 'grad_norm': 5.473948001861572, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 1000, 'max_steps': 7272}
 14%|█▍        | 1000/7272 [4:22:39<27:36:30, 15.85s/it]
  0%|          | 0/455 [00:00<?, ?it/s][A
  0%|          | 2/455 [00:01<05:59,  1.26it/s][A
  1%|          | 3/455 [00:03<08:19,  1.10s/it][A
  1%|          | 4/455 [00:04<09:39,  1.29s/it][A
  1%|          | 5/455 [00:06<10:20,  1.38s/it][A
  1%|▏         | 6/455 [00:07<10:44,  1.44s/it][A
  2%|▏         | 7/455 [00:09<11:08,  1.49s/it][A
  2%|▏         | 8/455 [00:10<11:16,  1.51s/it][A
  2%|▏         | 9/455 [00:12<11:19,  1.52s/it][A
  2%|▏         | 10/455 [00:14<11:22,  1.53s/it][A
  2%|▏         | 11/455 [00:15<11:20,  1.53s/it][A
  3%|▎         | 12/455 [00:17<11:20,  1.54s/it][A
  3%|▎         | 13/455 [00:18<11:19,  1.54s/it][A
  3%|▎         | 14/455 [00:20<11:19,  1.54s/it][A
  3%|▎         | 15/455 [00:21<11:18,  1.54s/it][A
  4%|▎         | 16/455 [00:23<11:16,  1.54s/it][A
  4%|▎         | 17/455 [00:24<11:15,  1.54s/it][A
  4%|▍         | 18/455 [00:26<11:11,  1.54s/it][A
  4%|▍         | 19/455 [00:27<11:11,  1.54s/it][A
  4%|▍         | 20/455 [00:29<11:10,  1.54s/it][A
  5%|▍         | 21/455 [00:31<11:09,  1.54s/it][A
  5%|▍         | 22/455 [00:32<11:09,  1.55s/it][A
  5%|▌         | 23/455 [00:34<11:05,  1.54s/it][A
  5%|▌         | 24/455 [00:35<11:05,  1.54s/it][A
  5%|▌         | 25/455 [00:37<11:00,  1.54s/it][A
  6%|▌         | 26/455 [00:38<10:59,  1.54s/it][A
  6%|▌         | 27/455 [00:40<10:59,  1.54s/it][A
  6%|▌         | 28/455 [00:41<10:57,  1.54s/it][A
  6%|▋         | 29/455 [00:43<10:55,  1.54s/it][A
  7%|▋         | 30/455 [00:44<10:54,  1.54s/it][A
  7%|▋         | 31/455 [00:46<10:54,  1.54s/it][A
  7%|▋         | 32/455 [00:47<10:50,  1.54s/it][A
  7%|▋         | 33/455 [00:49<10:51,  1.54s/it][A
  7%|▋         | 34/455 [00:51<10:47,  1.54s/it][A
  8%|▊         | 35/455 [00:52<10:47,  1.54s/it][A
  8%|▊         | 36/455 [00:54<10:44,  1.54s/it][A
  8%|▊         | 37/455 [00:55<10:42,  1.54s/it][A
  8%|▊         | 38/455 [00:57<10:40,  1.54s/it][A
  9%|▊         | 39/455 [00:58<10:37,  1.53s/it][A
  9%|▉         | 40/455 [01:00<10:37,  1.54s/it][A
  9%|▉         | 41/455 [01:01<10:36,  1.54s/it][A
  9%|▉         | 42/455 [01:03<10:35,  1.54s/it][A
  9%|▉         | 43/455 [01:04<10:32,  1.54s/it][A
 10%|▉         | 44/455 [01:06<10:29,  1.53s/it][A
 10%|▉         | 45/455 [01:07<10:28,  1.53s/it][A
 10%|█         | 46/455 [01:09<10:26,  1.53s/it][A
 10%|█         | 47/455 [01:11<10:26,  1.53s/it][A
 11%|█         | 48/455 [01:12<10:24,  1.54s/it][A
 11%|█         | 49/455 [01:14<10:23,  1.53s/it][A
 11%|█         | 50/455 [01:15<10:22,  1.54s/it][A
 11%|█         | 51/455 [01:17<10:20,  1.54s/it][A
 11%|█▏        | 52/455 [01:18<10:20,  1.54s/it][A
 12%|█▏        | 53/455 [01:20<10:15,  1.53s/it][A
 12%|█▏        | 54/455 [01:21<10:16,  1.54s/it][A
 12%|█▏        | 55/455 [01:23<10:14,  1.54s/it][A
 12%|█▏        | 56/455 [01:24<10:11,  1.53s/it][A
 13%|█▎        | 57/455 [01:26<10:10,  1.53s/it][A
 13%|█▎        | 58/455 [01:27<10:07,  1.53s/it][A
 13%|█▎        | 59/455 [01:29<10:07,  1.53s/it][A
 13%|█▎        | 60/455 [01:30<10:07,  1.54s/it][A
 13%|█▎        | 61/455 [01:32<10:04,  1.53s/it][A
 14%|█▎        | 62/455 [01:34<10:02,  1.53s/it][A
 14%|█▍        | 63/455 [01:35<10:02,  1.54s/it][A
 14%|█▍        | 64/455 [01:37<10:01,  1.54s/it][A
 14%|█▍        | 65/455 [01:38<09:59,  1.54s/it][A
 15%|█▍        | 66/455 [01:40<09:59,  1.54s/it][A
 15%|█▍        | 67/455 [01:41<09:58,  1.54s/it][A
 15%|█▍        | 68/455 [01:43<10:01,  1.55s/it][A
 15%|█▌        | 69/455 [01:44<09:57,  1.55s/it][A
 15%|█▌        | 70/455 [01:46<09:54,  1.54s/it][A
 16%|█▌        | 71/455 [01:47<09:51,  1.54s/it][A
 16%|█▌        | 72/455 [01:49<09:49,  1.54s/it][A
 16%|█▌        | 73/455 [01:51<09:50,  1.55s/it][A
 16%|█▋        | 74/455 [01:52<09:48,  1.55s/it][A
 16%|█▋        | 75/455 [01:54<09:46,  1.54s/it][A
 17%|█▋        | 76/455 [01:55<09:42,  1.54s/it][A
 17%|█▋        | 77/455 [01:57<09:40,  1.54s/it][A
 17%|█▋        | 78/455 [01:58<09:37,  1.53s/it][A
 17%|█▋        | 79/455 [02:00<09:34,  1.53s/it][A
 18%|█▊        | 80/455 [02:01<09:34,  1.53s/it][A
 18%|█▊        | 81/455 [02:03<09:33,  1.53s/it][A
 18%|█▊        | 82/455 [02:04<09:30,  1.53s/it][A
 18%|█▊        | 83/455 [02:06<09:29,  1.53s/it][A
 18%|█▊        | 84/455 [02:07<09:28,  1.53s/it][A
 19%|█▊        | 85/455 [02:09<09:26,  1.53s/it][A
 19%|█▉        | 86/455 [02:10<09:27,  1.54s/it][A
 19%|█▉        | 87/455 [02:12<09:25,  1.54s/it][A
 19%|█▉        | 88/455 [02:14<09:22,  1.53s/it][A
 20%|█▉        | 89/455 [02:15<09:19,  1.53s/it][A
 20%|█▉        | 90/455 [02:17<09:18,  1.53s/it][A
 20%|██        | 91/455 [02:18<09:18,  1.53s/it][A
 20%|██        | 92/455 [02:20<09:16,  1.53s/it][A
 20%|██        | 93/455 [02:21<09:15,  1.53s/it][A
 21%|██        | 94/455 [02:23<09:14,  1.54s/it][A
 21%|██        | 95/455 [02:24<09:13,  1.54s/it][A
 21%|██        | 96/455 [02:26<09:10,  1.53s/it][A
 21%|██▏       | 97/455 [02:27<09:09,  1.54s/it][A
 22%|██▏       | 98/455 [02:29<09:09,  1.54s/it][A
 22%|██▏       | 99/455 [02:30<09:09,  1.54s/it][A
 22%|██▏       | 100/455 [02:32<09:07,  1.54s/it][A
 22%|██▏       | 101/455 [02:34<09:06,  1.54s/it][A
 22%|██▏       | 102/455 [02:35<09:03,  1.54s/it][A
 23%|██▎       | 103/455 [02:37<09:05,  1.55s/it][A
 23%|██▎       | 104/455 [02:38<09:01,  1.54s/it][A
 23%|██▎       | 105/455 [02:40<08:55,  1.53s/it][A
 23%|██▎       | 106/455 [02:41<08:54,  1.53s/it][A
 24%|██▎       | 107/455 [02:43<08:53,  1.53s/it][A
 24%|██▎       | 108/455 [02:44<08:52,  1.53s/it][A
 24%|██▍       | 109/455 [02:46<08:54,  1.55s/it][A
 24%|██▍       | 110/455 [02:47<08:50,  1.54s/it][A
 24%|██▍       | 111/455 [02:49<08:48,  1.54s/it][A
 25%|██▍       | 112/455 [02:50<08:46,  1.53s/it][A
 25%|██▍       | 113/455 [02:52<08:45,  1.54s/it][A
 25%|██▌       | 114/455 [02:53<08:44,  1.54s/it][A
 25%|██▌       | 115/455 [02:55<08:41,  1.54s/it][A
 25%|██▌       | 116/455 [02:57<08:40,  1.53s/it][A
 26%|██▌       | 117/455 [02:58<08:37,  1.53s/it][A
 26%|██▌       | 118/455 [03:00<08:36,  1.53s/it][A
 26%|██▌       | 119/455 [03:01<08:37,  1.54s/it][A
 26%|██▋       | 120/455 [03:03<08:33,  1.53s/it][A
 27%|██▋       | 121/455 [03:04<08:32,  1.53s/it][A
 27%|██▋       | 122/455 [03:06<08:30,  1.53s/it][A
 27%|██▋       | 123/455 [03:07<08:29,  1.54s/it][A
 27%|██▋       | 124/455 [03:09<08:27,  1.53s/it][A
 27%|██▋       | 125/455 [03:10<08:28,  1.54s/it][A
 28%|██▊       | 126/455 [03:12<08:26,  1.54s/it][A
 28%|██▊       | 127/455 [03:13<08:24,  1.54s/it][A
 28%|██▊       | 128/455 [03:15<08:23,  1.54s/it][A
 28%|██▊       | 129/455 [03:17<08:18,  1.53s/it][A
 29%|██▊       | 130/455 [03:18<08:17,  1.53s/it][A
 29%|██▉       | 131/455 [03:20<08:14,  1.53s/it][A
 29%|██▉       | 132/455 [03:21<08:14,  1.53s/it][A
 29%|██▉       | 133/455 [03:23<08:14,  1.54s/it][A
 29%|██▉       | 134/455 [03:24<08:12,  1.53s/it][A
 30%|██▉       | 135/455 [03:26<08:10,  1.53s/it][A
 30%|██▉       | 136/455 [03:27<08:09,  1.54s/it][A
 30%|███       | 137/455 [03:29<08:07,  1.53s/it][A
 30%|███       | 138/455 [03:30<08:05,  1.53s/it][A
 31%|███       | 139/455 [03:32<08:04,  1.53s/it][A
 31%|███       | 140/455 [03:33<08:02,  1.53s/it][A
 31%|███       | 141/455 [03:35<08:01,  1.53s/it][A
 31%|███       | 142/455 [03:36<07:59,  1.53s/it][A
 31%|███▏      | 143/455 [03:38<07:58,  1.53s/it][A
 32%|███▏      | 144/455 [03:40<07:56,  1.53s/it][A
 32%|███▏      | 145/455 [03:41<07:52,  1.52s/it][A
 32%|███▏      | 146/455 [03:43<07:52,  1.53s/it][A
 32%|███▏      | 147/455 [03:44<07:51,  1.53s/it][A
 33%|███▎      | 148/455 [03:46<07:49,  1.53s/it][A
 33%|███▎      | 149/455 [03:47<07:47,  1.53s/it][A
 33%|███▎      | 150/455 [03:49<07:46,  1.53s/it][A
 33%|███▎      | 151/455 [03:50<07:44,  1.53s/it][A
 33%|███▎      | 152/455 [03:52<07:45,  1.54s/it][A
 34%|███▎      | 153/455 [03:53<07:44,  1.54s/it][A
 34%|███▍      | 154/455 [03:55<07:39,  1.53s/it][A
 34%|███▍      | 155/455 [03:56<07:38,  1.53s/it][A
 34%|███▍      | 156/455 [03:58<07:37,  1.53s/it][A
 35%|███▍      | 157/455 [03:59<07:36,  1.53s/it][A
 35%|███▍      | 158/455 [04:01<07:36,  1.54s/it][A
 35%|███▍      | 159/455 [04:02<07:33,  1.53s/it][A
 35%|███▌      | 160/455 [04:04<07:31,  1.53s/it][A
 35%|███▌      | 161/455 [04:06<07:29,  1.53s/it][A
 36%|███▌      | 162/455 [04:07<07:26,  1.52s/it][A
 36%|███▌      | 163/455 [04:09<07:26,  1.53s/it][A
 36%|███▌      | 164/455 [04:10<07:24,  1.53s/it][A
 36%|███▋      | 165/455 [04:12<07:23,  1.53s/it][A
 36%|███▋      | 166/455 [04:13<07:23,  1.53s/it][A
 37%|███▋      | 167/455 [04:15<07:21,  1.53s/it][A
 37%|███▋      | 168/455 [04:16<07:20,  1.54s/it][A
 37%|███▋      | 169/455 [04:18<07:18,  1.53s/it][A
 37%|███▋      | 170/455 [04:19<07:16,  1.53s/it][A
 38%|███▊      | 171/455 [04:21<07:14,  1.53s/it][A
 38%|███▊      | 172/455 [04:22<07:11,  1.52s/it][A
 38%|███▊      | 173/455 [04:24<07:08,  1.52s/it][A
 38%|███▊      | 174/455 [04:25<07:09,  1.53s/it][A
 38%|███▊      | 175/455 [04:27<07:07,  1.53s/it][A
 39%|███▊      | 176/455 [04:28<07:06,  1.53s/it][A
 39%|███▉      | 177/455 [04:30<07:05,  1.53s/it][A
 39%|███▉      | 178/455 [04:32<07:03,  1.53s/it][A
 39%|███▉      | 179/455 [04:33<07:01,  1.53s/it][A
 40%|███▉      | 180/455 [04:35<07:01,  1.53s/it][A
 40%|███▉      | 181/455 [04:36<07:00,  1.53s/it][A
 40%|████      | 182/455 [04:38<06:59,  1.53s/it][A
 40%|████      | 183/455 [04:39<06:56,  1.53s/it][A
 40%|████      | 184/455 [04:41<06:53,  1.53s/it][A
 41%|████      | 185/455 [04:42<06:51,  1.52s/it][A
 41%|████      | 186/455 [04:44<06:51,  1.53s/it][A
 41%|████      | 187/455 [04:45<06:51,  1.53s/it][A
 41%|████▏     | 188/455 [04:47<06:50,  1.54s/it][A
 42%|████▏     | 189/455 [04:48<06:47,  1.53s/it][A
 42%|████▏     | 190/455 [04:50<06:46,  1.53s/it][A
 42%|████▏     | 191/455 [04:51<06:44,  1.53s/it][A
 42%|████▏     | 192/455 [04:53<06:43,  1.54s/it][A
 42%|████▏     | 193/455 [04:54<06:41,  1.53s/it][A
 43%|████▎     | 194/455 [04:56<06:40,  1.54s/it][A
 43%|████▎     | 195/455 [04:58<06:39,  1.54s/it][A
 43%|████▎     | 196/455 [04:59<06:38,  1.54s/it][A
 43%|████▎     | 197/455 [05:01<06:36,  1.54s/it][A
 44%|████▎     | 198/455 [05:02<06:33,  1.53s/it][A
 44%|████▎     | 199/455 [05:04<06:30,  1.53s/it][A
 44%|████▍     | 200/455 [05:05<06:27,  1.52s/it][A
 44%|████▍     | 201/455 [05:07<06:26,  1.52s/it][A
 44%|████▍     | 202/455 [05:08<06:27,  1.53s/it][A
 45%|████▍     | 203/455 [05:10<06:25,  1.53s/it][A
 45%|████▍     | 204/455 [05:11<06:22,  1.53s/it][A
 45%|████▌     | 205/455 [05:13<06:22,  1.53s/it][A
 45%|████▌     | 206/455 [05:14<06:21,  1.53s/it][A
 45%|████▌     | 207/455 [05:16<06:18,  1.53s/it][A
 46%|████▌     | 208/455 [05:17<06:16,  1.52s/it][A
 46%|████▌     | 209/455 [05:19<06:15,  1.53s/it][A
 46%|████▌     | 210/455 [05:20<06:13,  1.53s/it][A
 46%|████▋     | 211/455 [05:22<06:11,  1.52s/it][A
 47%|████▋     | 212/455 [05:24<06:09,  1.52s/it][A
 47%|████▋     | 213/455 [05:25<06:09,  1.53s/it][A
 47%|████▋     | 214/455 [05:27<06:07,  1.53s/it][A
 47%|████▋     | 215/455 [05:28<06:06,  1.53s/it][A
 47%|████▋     | 216/455 [05:30<06:05,  1.53s/it][A
 48%|████▊     | 217/455 [05:31<06:04,  1.53s/it][A
 48%|████▊     | 218/455 [05:33<06:02,  1.53s/it][A
 48%|████▊     | 219/455 [05:34<06:00,  1.53s/it][A
 48%|████▊     | 220/455 [05:36<05:59,  1.53s/it][A
 49%|████▊     | 221/455 [05:37<05:57,  1.53s/it][A
 49%|████▉     | 222/455 [05:39<05:55,  1.53s/it][A
 49%|████▉     | 223/455 [05:40<05:54,  1.53s/it][A
 49%|████▉     | 224/455 [05:42<05:53,  1.53s/it][A
 49%|████▉     | 225/455 [05:43<05:50,  1.53s/it][A
 50%|████▉     | 226/455 [05:45<05:49,  1.53s/it][A
 50%|████▉     | 227/455 [05:46<05:48,  1.53s/it][A
 50%|█████     | 228/455 [05:48<05:47,  1.53s/it][A
 50%|█████     | 229/455 [05:49<05:44,  1.52s/it][A
 51%|█████     | 230/455 [05:51<05:43,  1.53s/it][A
 51%|█████     | 231/455 [05:53<05:42,  1.53s/it][A
 51%|█████     | 232/455 [05:54<05:40,  1.53s/it][A
 51%|█████     | 233/455 [05:56<05:39,  1.53s/it][A
 51%|█████▏    | 234/455 [05:57<05:36,  1.52s/it][A
 52%|█████▏    | 235/455 [05:59<05:35,  1.53s/it][A
 52%|█████▏    | 236/455 [06:00<05:33,  1.52s/it][A
 52%|█████▏    | 237/455 [06:02<05:32,  1.52s/it][A
 52%|█████▏    | 238/455 [06:03<05:31,  1.53s/it][A
 53%|█████▎    | 239/455 [06:05<05:31,  1.53s/it][A
 53%|█████▎    | 240/455 [06:06<05:28,  1.53s/it][A
 53%|█████▎    | 241/455 [06:08<05:26,  1.53s/it][A
 53%|█████▎    | 242/455 [06:09<05:25,  1.53s/it][A
 53%|█████▎    | 243/455 [06:11<05:24,  1.53s/it][A
 54%|█████▎    | 244/455 [06:12<05:23,  1.53s/it][A
 54%|█████▍    | 245/455 [06:14<05:22,  1.53s/it][A
 54%|█████▍    | 246/455 [06:16<05:21,  1.54s/it][A
 54%|█████▍    | 247/455 [06:17<05:19,  1.54s/it][A
 55%|█████▍    | 248/455 [06:19<05:17,  1.53s/it][A
 55%|█████▍    | 249/455 [06:20<05:16,  1.53s/it][A
 55%|█████▍    | 250/455 [06:22<05:13,  1.53s/it][A
 55%|█████▌    | 251/455 [06:23<05:12,  1.53s/it][A
 55%|█████▌    | 252/455 [06:25<05:10,  1.53s/it][A
 56%|█████▌    | 253/455 [06:26<05:08,  1.53s/it][A
 56%|█████▌    | 254/455 [06:28<05:07,  1.53s/it][A
 56%|█████▌    | 255/455 [06:29<05:06,  1.53s/it][A
 56%|█████▋    | 256/455 [06:31<05:05,  1.54s/it][A
 56%|█████▋    | 257/455 [06:32<05:04,  1.54s/it][A
 57%|█████▋    | 258/455 [06:34<05:02,  1.54s/it][A
 57%|█████▋    | 259/455 [06:35<05:01,  1.54s/it][A
 57%|█████▋    | 260/455 [06:37<04:59,  1.54s/it][A
 57%|█████▋    | 261/455 [06:39<04:58,  1.54s/it][A
 58%|█████▊    | 262/455 [06:40<04:57,  1.54s/it][A
 58%|█████▊    | 263/455 [06:42<04:55,  1.54s/it][A
 58%|█████▊    | 264/455 [06:43<04:53,  1.53s/it][A
 58%|█████▊    | 265/455 [06:45<04:51,  1.53s/it][A
 58%|█████▊    | 266/455 [06:46<04:50,  1.54s/it][A
 59%|█████▊    | 267/455 [06:48<04:49,  1.54s/it][A
 59%|█████▉    | 268/455 [06:49<04:47,  1.54s/it][A
 59%|█████▉    | 269/455 [06:51<04:45,  1.54s/it][A
 59%|█████▉    | 270/455 [06:52<04:43,  1.53s/it][A
 60%|█████▉    | 271/455 [06:54<04:41,  1.53s/it][A
 60%|█████▉    | 272/455 [06:55<04:40,  1.53s/it][A
 60%|██████    | 273/455 [06:57<04:39,  1.53s/it][A
 60%|██████    | 274/455 [06:58<04:37,  1.53s/it][A
 60%|██████    | 275/455 [07:00<04:36,  1.54s/it][A
 61%|██████    | 276/455 [07:02<04:34,  1.54s/it][A
 61%|██████    | 277/455 [07:03<04:33,  1.54s/it][A
 61%|██████    | 278/455 [07:05<04:31,  1.54s/it][A
 61%|██████▏   | 279/455 [07:06<04:30,  1.53s/it][A
 62%|██████▏   | 280/455 [07:08<04:28,  1.53s/it][A
 62%|██████▏   | 281/455 [07:09<04:26,  1.53s/it][A
 62%|██████▏   | 282/455 [07:11<04:24,  1.53s/it][A
 62%|██████▏   | 283/455 [07:12<04:25,  1.55s/it][A
 62%|██████▏   | 284/455 [07:14<04:24,  1.54s/it][A
 63%|██████▎   | 285/455 [07:15<04:22,  1.55s/it][A
 63%|██████▎   | 286/455 [07:17<04:20,  1.54s/it][A
 63%|██████▎   | 287/455 [07:18<04:18,  1.54s/it][A
 63%|██████▎   | 288/455 [07:20<04:16,  1.54s/it][A
 64%|██████▎   | 289/455 [07:22<04:14,  1.53s/it][A
 64%|██████▎   | 290/455 [07:23<04:13,  1.54s/it][A
 64%|██████▍   | 291/455 [07:25<04:11,  1.53s/it][A
 64%|██████▍   | 292/455 [07:26<04:10,  1.53s/it][A
 64%|██████▍   | 293/455 [07:28<04:08,  1.53s/it][A
 65%|██████▍   | 294/455 [07:29<04:06,  1.53s/it][A
 65%|██████▍   | 295/455 [07:31<04:04,  1.53s/it][A
 65%|██████▌   | 296/455 [07:32<04:03,  1.53s/it][A
 65%|██████▌   | 297/455 [07:34<04:01,  1.53s/it][A
 65%|██████▌   | 298/455 [07:35<04:00,  1.53s/it][A
 66%|██████▌   | 299/455 [07:37<03:58,  1.53s/it][A
 66%|██████▌   | 300/455 [07:38<03:57,  1.53s/it][A
 66%|██████▌   | 301/455 [07:40<03:55,  1.53s/it][A
 66%|██████▋   | 302/455 [07:41<03:53,  1.53s/it][A
 67%|██████▋   | 303/455 [07:43<03:52,  1.53s/it][A
 67%|██████▋   | 304/455 [07:44<03:50,  1.53s/it][A
 67%|██████▋   | 305/455 [07:46<03:50,  1.54s/it][A
 67%|██████▋   | 306/455 [07:48<03:49,  1.54s/it][A
 67%|██████▋   | 307/455 [07:49<03:48,  1.54s/it][A
 68%|██████▊   | 308/455 [07:51<03:45,  1.53s/it][A
 68%|██████▊   | 309/455 [07:52<03:44,  1.54s/it][A
 68%|██████▊   | 310/455 [07:54<03:42,  1.53s/it][A
 68%|██████▊   | 311/455 [07:55<03:40,  1.53s/it][A
 69%|██████▊   | 312/455 [07:57<03:39,  1.54s/it][A
 69%|██████▉   | 313/455 [07:58<03:38,  1.54s/it][A
 69%|██████▉   | 314/455 [08:00<03:36,  1.54s/it][A
 69%|██████▉   | 315/455 [08:01<03:34,  1.53s/it][A
 69%|██████▉   | 316/455 [08:03<03:32,  1.53s/it][A
 70%|██████▉   | 317/455 [08:04<03:31,  1.53s/it][A
 70%|██████▉   | 318/455 [08:06<03:29,  1.53s/it][A
 70%|███████   | 319/455 [08:08<03:27,  1.53s/it][A
 70%|███████   | 320/455 [08:09<03:26,  1.53s/it][A
 71%|███████   | 321/455 [08:11<03:25,  1.53s/it][A
 71%|███████   | 322/455 [08:12<03:23,  1.53s/it][A
 71%|███████   | 323/455 [08:14<03:21,  1.53s/it][A
 71%|███████   | 324/455 [08:15<03:20,  1.53s/it][A
 71%|███████▏  | 325/455 [08:17<03:18,  1.53s/it][A
 72%|███████▏  | 326/455 [08:18<03:18,  1.54s/it][A
 72%|███████▏  | 327/455 [08:20<03:16,  1.53s/it][A
 72%|███████▏  | 328/455 [08:21<03:14,  1.53s/it][A
 72%|███████▏  | 329/455 [08:23<03:13,  1.53s/it][A
 73%|███████▎  | 330/455 [08:24<03:11,  1.53s/it][A
 73%|███████▎  | 331/455 [08:26<03:09,  1.53s/it][A
 73%|███████▎  | 332/455 [08:27<03:08,  1.53s/it][A
 73%|███████▎  | 333/455 [08:29<03:07,  1.53s/it][A
 73%|███████▎  | 334/455 [08:31<03:06,  1.54s/it][A
 74%|███████▎  | 335/455 [08:32<03:04,  1.54s/it][A
 74%|███████▍  | 336/455 [08:34<03:02,  1.54s/it][A
 74%|███████▍  | 337/455 [08:35<03:00,  1.53s/it][A
 74%|███████▍  | 338/455 [08:37<02:59,  1.53s/it][A
 75%|███████▍  | 339/455 [08:38<02:57,  1.53s/it][A
 75%|███████▍  | 340/455 [08:40<02:55,  1.53s/it][A
 75%|███████▍  | 341/455 [08:41<02:54,  1.53s/it][A
 75%|███████▌  | 342/455 [08:43<02:52,  1.53s/it][A
 75%|███████▌  | 343/455 [08:44<02:50,  1.52s/it][A
 76%|███████▌  | 344/455 [08:46<02:49,  1.53s/it][A
 76%|███████▌  | 345/455 [08:47<02:49,  1.54s/it][A
 76%|███████▌  | 346/455 [08:49<02:47,  1.54s/it][A
 76%|███████▋  | 347/455 [08:50<02:45,  1.53s/it][A
 76%|███████▋  | 348/455 [08:52<02:44,  1.54s/it][A
 77%|███████▋  | 349/455 [08:54<02:42,  1.54s/it][A
 77%|███████▋  | 350/455 [08:55<02:41,  1.53s/it][A
 77%|███████▋  | 351/455 [08:57<02:39,  1.53s/it][A
 77%|███████▋  | 352/455 [08:58<02:39,  1.54s/it][A
 78%|███████▊  | 353/455 [09:00<02:37,  1.54s/it][A
 78%|███████▊  | 354/455 [09:01<02:35,  1.54s/it][A
 78%|███████▊  | 355/455 [09:03<02:34,  1.54s/it][A
 78%|███████▊  | 356/455 [09:04<02:31,  1.53s/it][A
 78%|███████▊  | 357/455 [09:06<02:30,  1.53s/it][A
 79%|███████▊  | 358/455 [09:07<02:30,  1.55s/it][A
 79%|███████▉  | 359/455 [09:09<02:28,  1.54s/it][A
 79%|███████▉  | 360/455 [09:10<02:26,  1.54s/it][A
 79%|███████▉  | 361/455 [09:12<02:24,  1.54s/it][A
 80%|███████▉  | 362/455 [09:14<02:23,  1.54s/it][A
 80%|███████▉  | 363/455 [09:15<02:21,  1.54s/it][A
 80%|████████  | 364/455 [09:17<02:20,  1.54s/it][A
 80%|████████  | 365/455 [09:18<02:18,  1.54s/it][A
 80%|████████  | 366/455 [09:20<02:16,  1.54s/it][A
 81%|████████  | 367/455 [09:21<02:15,  1.54s/it][A
 81%|████████  | 368/455 [09:23<02:14,  1.55s/it][A
 81%|████████  | 369/455 [09:24<02:12,  1.54s/it][A
 81%|████████▏ | 370/455 [09:26<02:10,  1.54s/it][A
 82%|████████▏ | 371/455 [09:27<02:09,  1.54s/it][A
 82%|████████▏ | 372/455 [09:29<02:07,  1.54s/it][A
 82%|████████▏ | 373/455 [09:30<02:06,  1.54s/it][A
 82%|████████▏ | 374/455 [09:32<02:04,  1.54s/it][A
 82%|████████▏ | 375/455 [09:34<02:02,  1.54s/it][A
 83%|████████▎ | 376/455 [09:35<02:01,  1.54s/it][A
 83%|████████▎ | 377/455 [09:37<02:00,  1.54s/it][A
 83%|████████▎ | 378/455 [09:38<01:58,  1.54s/it][A
 83%|████████▎ | 379/455 [09:40<01:56,  1.54s/it][A
 84%|████████▎ | 380/455 [09:41<01:55,  1.54s/it][A
 84%|████████▎ | 381/455 [09:43<01:53,  1.53s/it][A
 84%|████████▍ | 382/455 [09:44<01:51,  1.53s/it][A
 84%|████████▍ | 383/455 [09:46<01:50,  1.54s/it][A
 84%|████████▍ | 384/455 [09:47<01:49,  1.54s/it][A
 85%|████████▍ | 385/455 [09:49<01:47,  1.53s/it][A
 85%|████████▍ | 386/455 [09:50<01:45,  1.53s/it][A
 85%|████████▌ | 387/455 [09:52<01:43,  1.53s/it][A
 85%|████████▌ | 388/455 [09:53<01:42,  1.53s/it][A
 85%|████████▌ | 389/455 [09:55<01:41,  1.53s/it][A
 86%|████████▌ | 390/455 [09:57<01:39,  1.53s/it][A
 86%|████████▌ | 391/455 [09:58<01:37,  1.53s/it][A
 86%|████████▌ | 392/455 [10:00<01:36,  1.53s/it][A
 86%|████████▋ | 393/455 [10:01<01:34,  1.53s/it][A
 87%|████████▋ | 394/455 [10:03<01:33,  1.54s/it][A
 87%|████████▋ | 395/455 [10:04<01:32,  1.55s/it][A
 87%|████████▋ | 396/455 [10:06<01:30,  1.54s/it][A
 87%|████████▋ | 397/455 [10:07<01:28,  1.53s/it][A
 87%|████████▋ | 398/455 [10:09<01:27,  1.53s/it][A
 88%|████████▊ | 399/455 [10:10<01:26,  1.54s/it][A
 88%|████████▊ | 400/455 [10:12<01:24,  1.53s/it][A
 88%|████████▊ | 401/455 [10:13<01:22,  1.53s/it][A
 88%|████████▊ | 402/455 [10:15<01:22,  1.55s/it][A
 89%|████████▊ | 403/455 [10:17<01:20,  1.54s/it][A
 89%|████████▉ | 404/455 [10:18<01:18,  1.54s/it][A
 89%|████████▉ | 405/455 [10:20<01:16,  1.54s/it][A
 89%|████████▉ | 406/455 [10:21<01:15,  1.54s/it][A
 89%|████████▉ | 407/455 [10:23<01:13,  1.54s/it][A
 90%|████████▉ | 408/455 [10:24<01:12,  1.54s/it][A
 90%|████████▉ | 409/455 [10:26<01:10,  1.54s/it][A
 90%|█████████ | 410/455 [10:27<01:09,  1.54s/it][A
 90%|█████████ | 411/455 [10:29<01:07,  1.54s/it][A
 91%|█████████ | 412/455 [10:30<01:05,  1.53s/it][A
 91%|█████████ | 413/455 [10:32<01:04,  1.53s/it][A
 91%|█████████ | 414/455 [10:33<01:02,  1.53s/it][A
 91%|█████████ | 415/455 [10:35<01:01,  1.53s/it][A
 91%|█████████▏| 416/455 [10:37<00:59,  1.53s/it][A
 92%|█████████▏| 417/455 [10:38<00:58,  1.53s/it][A
 92%|█████████▏| 418/455 [10:40<00:56,  1.53s/it][A
 92%|█████████▏| 419/455 [10:41<00:55,  1.53s/it][A
 92%|█████████▏| 420/455 [10:43<00:53,  1.53s/it][A
 93%|█████████▎| 421/455 [10:44<00:52,  1.53s/it][A
 93%|█████████▎| 422/455 [10:46<00:50,  1.53s/it][A
 93%|█████████▎| 423/455 [10:47<00:49,  1.53s/it][A
 93%|█████████▎| 424/455 [10:49<00:47,  1.53s/it][A
 93%|█████████▎| 425/455 [10:50<00:46,  1.54s/it][A
 94%|█████████▎| 426/455 [10:52<00:44,  1.54s/it][A
 94%|█████████▍| 427/455 [10:53<00:43,  1.54s/it][A
 94%|█████████▍| 428/455 [10:55<00:41,  1.54s/it][A
 94%|█████████▍| 429/455 [10:56<00:39,  1.54s/it][A
 95%|█████████▍| 430/455 [10:58<00:38,  1.53s/it][A
 95%|█████████▍| 431/455 [11:00<00:36,  1.53s/it][A
 95%|█████████▍| 432/455 [11:01<00:35,  1.53s/it][A
 95%|█████████▌| 433/455 [11:03<00:33,  1.53s/it][A
 95%|█████████▌| 434/455 [11:04<00:32,  1.53s/it][A
 96%|█████████▌| 435/455 [11:06<00:30,  1.53s/it][A
 96%|█████████▌| 436/455 [11:07<00:29,  1.53s/it][A
 96%|█████████▌| 437/455 [11:09<00:27,  1.53s/it][A
 96%|█████████▋| 438/455 [11:10<00:26,  1.53s/it][A
 96%|█████████▋| 439/455 [11:12<00:24,  1.54s/it][A
 97%|█████████▋| 440/455 [11:13<00:23,  1.54s/it][A
 97%|█████████▋| 441/455 [11:15<00:21,  1.54s/it][A
 97%|█████████▋| 442/455 [11:16<00:20,  1.54s/it][A
 97%|█████████▋| 443/455 [11:18<00:18,  1.53s/it][A
 98%|█████████▊| 444/455 [11:19<00:16,  1.54s/it][A
 98%|█████████▊| 445/455 [11:21<00:15,  1.54s/it][A
 98%|█████████▊| 446/455 [11:23<00:13,  1.54s/it][A
 98%|█████████▊| 447/455 [11:24<00:12,  1.54s/it][A
 98%|█████████▊| 448/455 [11:26<00:10,  1.54s/it][A
 99%|█████████▊| 449/455 [11:27<00:09,  1.53s/it][A
 99%|█████████▉| 450/455 [11:29<00:07,  1.53s/it][A
 99%|█████████▉| 451/455 [11:30<00:06,  1.53s/it][A
 99%|█████████▉| 452/455 [11:32<00:04,  1.52s/it][A
100%|█████████▉| 453/455 [11:33<00:03,  1.53s/it][A
100%|█████████▉| 454/455 [11:35<00:01,  1.54s/it][A
100%|██████████| 455/455 [11:36<00:00,  1.54s/it][A                                                        
                                                 [A{'eval_loss': 1.7741918563842773, 'eval_runtime': 698.4463, 'eval_samples_per_second': 2.601, 'eval_steps_per_second': 0.651, 'epoch': 0.55, 'step': 1000, 'max_steps': 7272}
 14%|█▍        | 1000/7272 [4:34:17<27:36:30, 15.85s/it]
100%|██████████| 455/455 [11:36<00:00,  1.54s/it][A
                                                 [A 14%|█▍        | 1001/7272 [4:34:34<392:57:45, 225.59s/it]                                                          {'loss': 1.2625, 'grad_norm': 2.6948442459106445, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 1001, 'max_steps': 7272}
 14%|█▍        | 1001/7272 [4:34:34<392:57:45, 225.59s/it] 14%|█▍        | 1002/7272 [4:34:50<283:12:35, 162.61s/it]                                                          {'loss': 1.5383, 'grad_norm': 4.183420658111572, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 1002, 'max_steps': 7272}
 14%|█▍        | 1002/7272 [4:34:50<283:12:35, 162.61s/it] 14%|█▍        | 1003/7272 [4:35:05<206:11:47, 118.41s/it]                                                          {'loss': 1.1976, 'grad_norm': 3.921008825302124, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 1003, 'max_steps': 7272}
 14%|█▍        | 1003/7272 [4:35:05<206:11:47, 118.41s/it] 14%|█▍        | 1004/7272 [4:35:20<152:19:33, 87.49s/it]                                                          {'loss': 2.0577, 'grad_norm': 8.444367408752441, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 1004, 'max_steps': 7272}
 14%|█▍        | 1004/7272 [4:35:20<152:19:33, 87.49s/it] 14%|█▍        | 1005/7272 [4:35:36<114:59:04, 66.05s/it]                                                         {'loss': 1.0082, 'grad_norm': 4.841887474060059, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 1005, 'max_steps': 7272}
 14%|█▍        | 1005/7272 [4:35:36<114:59:04, 66.05s/it] 14%|█▍        | 1006/7272 [4:35:52<88:55:08, 51.09s/it]                                                         {'loss': 1.3897, 'grad_norm': 6.010071277618408, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 1006, 'max_steps': 7272}
 14%|█▍        | 1006/7272 [4:35:52<88:55:08, 51.09s/it] 14%|█▍        | 1007/7272 [4:36:09<70:38:23, 40.59s/it]                                                        {'loss': 1.857, 'grad_norm': 6.183515548706055, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 1007, 'max_steps': 7272}
 14%|█▍        | 1007/7272 [4:36:09<70:38:23, 40.59s/it] 14%|█▍        | 1008/7272 [4:36:24<57:38:25, 33.13s/it]                                                        {'loss': 0.9397, 'grad_norm': 2.393460750579834, 'learning_rate': 5e-05, 'epoch': 0.55, 'step': 1008, 'max_steps': 7272}
 14%|█▍        | 1008/7272 [4:36:24<57:38:25, 33.13s/it] 14%|█▍        | 1009/7272 [4:36:40<48:29:19, 27.87s/it]                                                        {'loss': 2.5214, 'grad_norm': 7.579437255859375, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1009, 'max_steps': 7272}
 14%|█▍        | 1009/7272 [4:36:40<48:29:19, 27.87s/it] 14%|█▍        | 1010/7272 [4:36:55<41:53:12, 24.08s/it]                                                        {'loss': 1.322, 'grad_norm': 2.939138650894165, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1010, 'max_steps': 7272}
 14%|█▍        | 1010/7272 [4:36:55<41:53:12, 24.08s/it] 14%|█▍        | 1011/7272 [4:37:11<37:32:33, 21.59s/it]                                                        {'loss': 1.1641, 'grad_norm': 3.187147617340088, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1011, 'max_steps': 7272}
 14%|█▍        | 1011/7272 [4:37:11<37:32:33, 21.59s/it] 14%|█▍        | 1012/7272 [4:37:26<34:24:00, 19.78s/it]                                                        {'loss': 1.5363, 'grad_norm': 6.321471214294434, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1012, 'max_steps': 7272}
 14%|█▍        | 1012/7272 [4:37:26<34:24:00, 19.78s/it] 14%|█▍        | 1013/7272 [4:37:42<32:15:31, 18.55s/it]                                                        {'loss': 2.5416, 'grad_norm': 4.013933181762695, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1013, 'max_steps': 7272}
 14%|█▍        | 1013/7272 [4:37:42<32:15:31, 18.55s/it] 14%|█▍        | 1014/7272 [4:37:59<31:16:41, 17.99s/it]                                                        {'loss': 1.1495, 'grad_norm': 5.9587812423706055, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1014, 'max_steps': 7272}
 14%|█▍        | 1014/7272 [4:37:59<31:16:41, 17.99s/it] 14%|█▍        | 1015/7272 [4:38:15<30:33:52, 17.59s/it]                                                        {'loss': 1.937, 'grad_norm': 4.071177959442139, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1015, 'max_steps': 7272}
 14%|█▍        | 1015/7272 [4:38:15<30:33:52, 17.59s/it] 14%|█▍        | 1016/7272 [4:38:32<30:10:40, 17.37s/it]                                                        {'loss': 2.5835, 'grad_norm': 7.549914836883545, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1016, 'max_steps': 7272}
 14%|█▍        | 1016/7272 [4:38:32<30:10:40, 17.37s/it] 14%|█▍        | 1017/7272 [4:38:48<29:32:24, 17.00s/it]                                                        {'loss': 2.2972, 'grad_norm': 5.947835922241211, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1017, 'max_steps': 7272}
 14%|█▍        | 1017/7272 [4:38:48<29:32:24, 17.00s/it] 14%|█▍        | 1018/7272 [4:39:05<29:12:04, 16.81s/it]                                                        {'loss': 2.0882, 'grad_norm': 5.346299648284912, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1018, 'max_steps': 7272}
 14%|█▍        | 1018/7272 [4:39:05<29:12:04, 16.81s/it] 14%|█▍        | 1019/7272 [4:39:21<28:37:43, 16.48s/it]                                                        {'loss': 2.3966, 'grad_norm': 8.336338996887207, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1019, 'max_steps': 7272}
 14%|█▍        | 1019/7272 [4:39:21<28:37:43, 16.48s/it] 14%|█▍        | 1020/7272 [4:39:36<28:07:03, 16.19s/it]                                                        {'loss': 3.3278, 'grad_norm': 10.391552925109863, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1020, 'max_steps': 7272}
 14%|█▍        | 1020/7272 [4:39:36<28:07:03, 16.19s/it] 14%|█▍        | 1021/7272 [4:39:52<27:59:20, 16.12s/it]                                                        {'loss': 2.4376, 'grad_norm': 8.002119064331055, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1021, 'max_steps': 7272}
 14%|█▍        | 1021/7272 [4:39:52<27:59:20, 16.12s/it] 14%|█▍        | 1022/7272 [4:40:08<28:00:54, 16.14s/it]                                                        {'loss': 2.5837, 'grad_norm': 7.333766937255859, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1022, 'max_steps': 7272}
 14%|█▍        | 1022/7272 [4:40:08<28:00:54, 16.14s/it] 14%|█▍        | 1023/7272 [4:40:24<27:50:29, 16.04s/it]                                                        {'loss': 1.8203, 'grad_norm': 6.598414421081543, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1023, 'max_steps': 7272}
 14%|█▍        | 1023/7272 [4:40:24<27:50:29, 16.04s/it] 14%|█▍        | 1024/7272 [4:40:40<27:50:03, 16.04s/it]                                                        {'loss': 2.0197, 'grad_norm': 2.697413682937622, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1024, 'max_steps': 7272}
 14%|█▍        | 1024/7272 [4:40:40<27:50:03, 16.04s/it] 14%|█▍        | 1025/7272 [4:40:55<27:31:10, 15.86s/it]                                                        {'loss': 1.6004, 'grad_norm': 4.187260627746582, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1025, 'max_steps': 7272}
 14%|█▍        | 1025/7272 [4:40:55<27:31:10, 15.86s/it] 14%|█▍        | 1026/7272 [4:41:11<27:25:59, 15.81s/it]                                                        {'loss': 1.8423, 'grad_norm': 5.712435722351074, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1026, 'max_steps': 7272}
 14%|█▍        | 1026/7272 [4:41:11<27:25:59, 15.81s/it] 14%|█▍        | 1027/7272 [4:41:27<27:24:59, 15.80s/it]                                                        {'loss': 0.9937, 'grad_norm': 3.3924670219421387, 'learning_rate': 5e-05, 'epoch': 0.56, 'step': 1027, 'max_steps': 7272}
 14%|█▍        | 1027/7272 [4:41:27<27:24:59, 15.80s/it] 14%|█▍        | 1028/7272 [4:41:43<27:23:59, 15.80s/it]                                                        {'loss': 1.6526, 'grad_norm': 7.045146942138672, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1028, 'max_steps': 7272}
 14%|█▍        | 1028/7272 [4:41:43<27:23:59, 15.80s/it] 14%|█▍        | 1029/7272 [4:41:58<27:05:01, 15.62s/it]                                                        {'loss': 1.0198, 'grad_norm': 3.1883761882781982, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1029, 'max_steps': 7272}
 14%|█▍        | 1029/7272 [4:41:58<27:05:01, 15.62s/it] 14%|█▍        | 1030/7272 [4:42:14<27:08:54, 15.66s/it]                                                        {'loss': 1.4856, 'grad_norm': 3.2699973583221436, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1030, 'max_steps': 7272}
 14%|█▍        | 1030/7272 [4:42:14<27:08:54, 15.66s/it] 14%|█▍        | 1031/7272 [4:42:30<27:27:30, 15.84s/it]                                                        {'loss': 1.622, 'grad_norm': 9.516496658325195, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1031, 'max_steps': 7272}
 14%|█▍        | 1031/7272 [4:42:30<27:27:30, 15.84s/it] 14%|█▍        | 1032/7272 [4:42:46<27:38:19, 15.95s/it]                                                        {'loss': 2.2743, 'grad_norm': 5.9305524826049805, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1032, 'max_steps': 7272}
 14%|█▍        | 1032/7272 [4:42:46<27:38:19, 15.95s/it] 14%|█▍        | 1033/7272 [4:43:03<27:58:18, 16.14s/it]                                                        {'loss': 0.4901, 'grad_norm': 2.1496098041534424, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1033, 'max_steps': 7272}
 14%|█▍        | 1033/7272 [4:43:03<27:58:18, 16.14s/it] 14%|█▍        | 1034/7272 [4:43:19<28:05:53, 16.22s/it]                                                        {'loss': 2.8453, 'grad_norm': 7.186400413513184, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1034, 'max_steps': 7272}
 14%|█▍        | 1034/7272 [4:43:19<28:05:53, 16.22s/it] 14%|█▍        | 1035/7272 [4:43:35<28:04:50, 16.21s/it]                                                        {'loss': 2.5174, 'grad_norm': 7.112401008605957, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1035, 'max_steps': 7272}
 14%|█▍        | 1035/7272 [4:43:35<28:04:50, 16.21s/it] 14%|█▍        | 1036/7272 [4:43:51<27:58:53, 16.15s/it]                                                        {'loss': 1.0677, 'grad_norm': 3.6864240169525146, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1036, 'max_steps': 7272}
 14%|█▍        | 1036/7272 [4:43:51<27:58:53, 16.15s/it] 14%|█▍        | 1037/7272 [4:44:08<28:01:01, 16.18s/it]                                                        {'loss': 2.8243, 'grad_norm': 10.198810577392578, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1037, 'max_steps': 7272}
 14%|█▍        | 1037/7272 [4:44:08<28:01:01, 16.18s/it] 14%|█▍        | 1038/7272 [4:44:24<28:10:10, 16.27s/it]                                                        {'loss': 2.2396, 'grad_norm': 5.290848255157471, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1038, 'max_steps': 7272}
 14%|█▍        | 1038/7272 [4:44:24<28:10:10, 16.27s/it] 14%|█▍        | 1039/7272 [4:44:40<28:00:10, 16.17s/it]                                                        {'loss': 2.9031, 'grad_norm': 10.553520202636719, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1039, 'max_steps': 7272}
 14%|█▍        | 1039/7272 [4:44:40<28:00:10, 16.17s/it] 14%|█▍        | 1040/7272 [4:44:57<28:15:27, 16.32s/it]                                                        {'loss': 1.823, 'grad_norm': 3.700942277908325, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1040, 'max_steps': 7272}
 14%|█▍        | 1040/7272 [4:44:57<28:15:27, 16.32s/it] 14%|█▍        | 1041/7272 [4:45:13<28:12:49, 16.30s/it]                                                        {'loss': 1.1881, 'grad_norm': 4.906702995300293, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1041, 'max_steps': 7272}
 14%|█▍        | 1041/7272 [4:45:13<28:12:49, 16.30s/it] 14%|█▍        | 1042/7272 [4:45:29<28:16:41, 16.34s/it]                                                        {'loss': 0.8196, 'grad_norm': 2.8084921836853027, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1042, 'max_steps': 7272}
 14%|█▍        | 1042/7272 [4:45:29<28:16:41, 16.34s/it] 14%|█▍        | 1043/7272 [4:45:45<28:05:32, 16.24s/it]                                                        {'loss': 2.8072, 'grad_norm': 8.23197078704834, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1043, 'max_steps': 7272}
 14%|█▍        | 1043/7272 [4:45:45<28:05:32, 16.24s/it] 14%|█▍        | 1044/7272 [4:46:02<28:10:30, 16.29s/it]                                                        {'loss': 0.9253, 'grad_norm': 2.4250049591064453, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1044, 'max_steps': 7272}
 14%|█▍        | 1044/7272 [4:46:02<28:10:30, 16.29s/it] 14%|█▍        | 1045/7272 [4:46:18<28:05:34, 16.24s/it]                                                        {'loss': 1.4001, 'grad_norm': 6.512406349182129, 'learning_rate': 5e-05, 'epoch': 0.57, 'step': 1045, 'max_steps': 7272}
 14%|█▍        | 1045/7272 [4:46:18<28:05:34, 16.24s/it] 14%|█▍        | 1046/7272 [4:46:34<27:51:15, 16.11s/it]                                                        {'loss': 0.9079, 'grad_norm': 3.5047717094421387, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1046, 'max_steps': 7272}
 14%|█▍        | 1046/7272 [4:46:34<27:51:15, 16.11s/it] 14%|█▍        | 1047/7272 [4:46:50<27:46:50, 16.07s/it]                                                        {'loss': 2.1346, 'grad_norm': 12.04965591430664, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1047, 'max_steps': 7272}
 14%|█▍        | 1047/7272 [4:46:50<27:46:50, 16.07s/it] 14%|█▍        | 1048/7272 [4:47:06<27:59:53, 16.19s/it]                                                        {'loss': 1.4988, 'grad_norm': 4.279242515563965, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1048, 'max_steps': 7272}
 14%|█▍        | 1048/7272 [4:47:06<27:59:53, 16.19s/it] 14%|█▍        | 1049/7272 [4:47:22<27:58:16, 16.18s/it]                                                        {'loss': 0.9094, 'grad_norm': 2.821743965148926, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1049, 'max_steps': 7272}
 14%|█▍        | 1049/7272 [4:47:22<27:58:16, 16.18s/it] 14%|█▍        | 1050/7272 [4:47:39<28:11:04, 16.31s/it]                                                        {'loss': 3.211, 'grad_norm': 6.88186502456665, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1050, 'max_steps': 7272}
 14%|█▍        | 1050/7272 [4:47:39<28:11:04, 16.31s/it] 14%|█▍        | 1051/7272 [4:47:55<28:01:34, 16.22s/it]                                                        {'loss': 2.9768, 'grad_norm': 6.817935466766357, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1051, 'max_steps': 7272}
 14%|█▍        | 1051/7272 [4:47:55<28:01:34, 16.22s/it] 14%|█▍        | 1052/7272 [4:48:11<27:55:31, 16.16s/it]                                                        {'loss': 1.7577, 'grad_norm': 6.2171311378479, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1052, 'max_steps': 7272}
 14%|█▍        | 1052/7272 [4:48:11<27:55:31, 16.16s/it] 14%|█▍        | 1053/7272 [4:48:28<28:18:43, 16.39s/it]                                                        {'loss': 1.5448, 'grad_norm': 4.29607629776001, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1053, 'max_steps': 7272}
 14%|█▍        | 1053/7272 [4:48:28<28:18:43, 16.39s/it] 14%|█▍        | 1054/7272 [4:48:45<28:33:31, 16.53s/it]                                                        {'loss': 2.0922, 'grad_norm': 8.581099510192871, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1054, 'max_steps': 7272}
 14%|█▍        | 1054/7272 [4:48:45<28:33:31, 16.53s/it] 15%|█▍        | 1055/7272 [4:49:01<28:19:48, 16.40s/it]                                                        {'loss': 3.0809, 'grad_norm': 4.994298458099365, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1055, 'max_steps': 7272}
 15%|█▍        | 1055/7272 [4:49:01<28:19:48, 16.40s/it] 15%|█▍        | 1056/7272 [4:49:17<28:28:03, 16.49s/it]                                                        {'loss': 1.5418, 'grad_norm': 6.190487384796143, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1056, 'max_steps': 7272}
 15%|█▍        | 1056/7272 [4:49:17<28:28:03, 16.49s/it] 15%|█▍        | 1057/7272 [4:49:34<28:26:27, 16.47s/it]                                                        {'loss': 2.7179, 'grad_norm': 8.96364974975586, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1057, 'max_steps': 7272}
 15%|█▍        | 1057/7272 [4:49:34<28:26:27, 16.47s/it] 15%|█▍        | 1058/7272 [4:49:51<28:29:35, 16.51s/it]                                                        {'loss': 2.2868, 'grad_norm': 4.917267799377441, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1058, 'max_steps': 7272}
 15%|█▍        | 1058/7272 [4:49:51<28:29:35, 16.51s/it] 15%|█▍        | 1059/7272 [4:50:07<28:38:38, 16.60s/it]                                                        {'loss': 2.1416, 'grad_norm': 5.460958480834961, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1059, 'max_steps': 7272}
 15%|█▍        | 1059/7272 [4:50:07<28:38:38, 16.60s/it] 15%|█▍        | 1060/7272 [4:50:23<28:21:17, 16.43s/it]                                                        {'loss': 2.2811, 'grad_norm': 5.28153657913208, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1060, 'max_steps': 7272}
 15%|█▍        | 1060/7272 [4:50:23<28:21:17, 16.43s/it] 15%|█▍        | 1061/7272 [4:50:40<28:29:30, 16.51s/it]                                                        {'loss': 1.7278, 'grad_norm': 5.2040114402771, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1061, 'max_steps': 7272}
 15%|█▍        | 1061/7272 [4:50:40<28:29:30, 16.51s/it] 15%|█▍        | 1062/7272 [4:50:56<28:11:26, 16.34s/it]                                                        {'loss': 2.6113, 'grad_norm': 3.6982622146606445, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1062, 'max_steps': 7272}
 15%|█▍        | 1062/7272 [4:50:56<28:11:26, 16.34s/it] 15%|█▍        | 1063/7272 [4:51:13<28:24:24, 16.47s/it]                                                        {'loss': 1.9483, 'grad_norm': 3.9393203258514404, 'learning_rate': 5e-05, 'epoch': 0.58, 'step': 1063, 'max_steps': 7272}
 15%|█▍        | 1063/7272 [4:51:13<28:24:24, 16.47s/it] 15%|█▍        | 1064/7272 [4:51:29<28:17:05, 16.40s/it]                                                        {'loss': 1.7858, 'grad_norm': 5.5190558433532715, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1064, 'max_steps': 7272}
 15%|█▍        | 1064/7272 [4:51:29<28:17:05, 16.40s/it] 15%|█▍        | 1065/7272 [4:51:45<28:14:24, 16.38s/it]                                                        {'loss': 2.5183, 'grad_norm': 6.190241813659668, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1065, 'max_steps': 7272}
 15%|█▍        | 1065/7272 [4:51:45<28:14:24, 16.38s/it] 15%|█▍        | 1066/7272 [4:52:01<27:53:21, 16.18s/it]                                                        {'loss': 0.7612, 'grad_norm': 3.998415231704712, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1066, 'max_steps': 7272}
 15%|█▍        | 1066/7272 [4:52:01<27:53:21, 16.18s/it] 15%|█▍        | 1067/7272 [4:52:17<27:47:27, 16.12s/it]                                                        {'loss': 2.5019, 'grad_norm': 6.356326580047607, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1067, 'max_steps': 7272}
 15%|█▍        | 1067/7272 [4:52:17<27:47:27, 16.12s/it] 15%|█▍        | 1068/7272 [4:52:33<27:55:19, 16.20s/it]                                                        {'loss': 2.0919, 'grad_norm': 4.616684436798096, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1068, 'max_steps': 7272}
 15%|█▍        | 1068/7272 [4:52:33<27:55:19, 16.20s/it] 15%|█▍        | 1069/7272 [4:52:50<27:57:03, 16.22s/it]                                                        {'loss': 1.0184, 'grad_norm': 4.825129508972168, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1069, 'max_steps': 7272}
 15%|█▍        | 1069/7272 [4:52:50<27:57:03, 16.22s/it] 15%|█▍        | 1070/7272 [4:53:06<28:01:15, 16.27s/it]                                                        {'loss': 2.95, 'grad_norm': 7.304885387420654, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1070, 'max_steps': 7272}
 15%|█▍        | 1070/7272 [4:53:06<28:01:15, 16.27s/it] 15%|█▍        | 1071/7272 [4:53:23<28:26:11, 16.51s/it]                                                        {'loss': 0.9311, 'grad_norm': 6.340344429016113, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1071, 'max_steps': 7272}
 15%|█▍        | 1071/7272 [4:53:23<28:26:11, 16.51s/it] 15%|█▍        | 1072/7272 [4:53:39<28:12:45, 16.38s/it]                                                        {'loss': 2.7073, 'grad_norm': 6.876276016235352, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1072, 'max_steps': 7272}
 15%|█▍        | 1072/7272 [4:53:39<28:12:45, 16.38s/it] 15%|█▍        | 1073/7272 [4:53:56<28:30:33, 16.56s/it]                                                        {'loss': 2.3688, 'grad_norm': 10.438045501708984, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1073, 'max_steps': 7272}
 15%|█▍        | 1073/7272 [4:53:56<28:30:33, 16.56s/it] 15%|█▍        | 1074/7272 [4:54:13<28:22:30, 16.48s/it]                                                        {'loss': 2.0583, 'grad_norm': 8.71143627166748, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1074, 'max_steps': 7272}
 15%|█▍        | 1074/7272 [4:54:13<28:22:30, 16.48s/it] 15%|█▍        | 1075/7272 [4:54:29<28:07:46, 16.34s/it]                                                        {'loss': 1.9073, 'grad_norm': 3.826308488845825, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1075, 'max_steps': 7272}
 15%|█▍        | 1075/7272 [4:54:29<28:07:46, 16.34s/it] 15%|█▍        | 1076/7272 [4:54:44<27:51:07, 16.18s/it]                                                        {'loss': 1.382, 'grad_norm': 7.080568790435791, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1076, 'max_steps': 7272}
 15%|█▍        | 1076/7272 [4:54:44<27:51:07, 16.18s/it] 15%|█▍        | 1077/7272 [4:55:01<27:52:14, 16.20s/it]                                                        {'loss': 1.3154, 'grad_norm': 4.175231456756592, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1077, 'max_steps': 7272}
 15%|█▍        | 1077/7272 [4:55:01<27:52:14, 16.20s/it] 15%|█▍        | 1078/7272 [4:55:16<27:39:21, 16.07s/it]                                                        {'loss': 2.2993, 'grad_norm': 10.666260719299316, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1078, 'max_steps': 7272}
 15%|█▍        | 1078/7272 [4:55:16<27:39:21, 16.07s/it] 15%|█▍        | 1079/7272 [4:55:32<27:28:07, 15.97s/it]                                                        {'loss': 1.2863, 'grad_norm': 7.016218662261963, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1079, 'max_steps': 7272}
 15%|█▍        | 1079/7272 [4:55:32<27:28:07, 15.97s/it] 15%|█▍        | 1080/7272 [4:55:48<27:15:06, 15.84s/it]                                                        {'loss': 2.6846, 'grad_norm': 8.656535148620605, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1080, 'max_steps': 7272}
 15%|█▍        | 1080/7272 [4:55:48<27:15:06, 15.84s/it] 15%|█▍        | 1081/7272 [4:56:04<27:18:59, 15.88s/it]                                                        {'loss': 0.8819, 'grad_norm': 4.5597825050354, 'learning_rate': 5e-05, 'epoch': 0.59, 'step': 1081, 'max_steps': 7272}
 15%|█▍        | 1081/7272 [4:56:04<27:18:59, 15.88s/it] 15%|█▍        | 1082/7272 [4:56:20<27:46:47, 16.16s/it]                                                        {'loss': 1.4007, 'grad_norm': 4.010076522827148, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1082, 'max_steps': 7272}
 15%|█▍        | 1082/7272 [4:56:20<27:46:47, 16.16s/it] 15%|█▍        | 1083/7272 [4:56:37<27:55:02, 16.24s/it]                                                        {'loss': 1.8554, 'grad_norm': 5.834510803222656, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1083, 'max_steps': 7272}
 15%|█▍        | 1083/7272 [4:56:37<27:55:02, 16.24s/it] 15%|█▍        | 1084/7272 [4:56:53<27:57:07, 16.26s/it]                                                        {'loss': 1.1307, 'grad_norm': 2.1032981872558594, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1084, 'max_steps': 7272}
 15%|█▍        | 1084/7272 [4:56:53<27:57:07, 16.26s/it] 15%|█▍        | 1085/7272 [4:57:10<28:02:54, 16.32s/it]                                                        {'loss': 2.288, 'grad_norm': 10.301658630371094, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1085, 'max_steps': 7272}
 15%|█▍        | 1085/7272 [4:57:10<28:02:54, 16.32s/it] 15%|█▍        | 1086/7272 [4:57:25<27:43:11, 16.13s/it]                                                        {'loss': 1.7153, 'grad_norm': 5.049103260040283, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1086, 'max_steps': 7272}
 15%|█▍        | 1086/7272 [4:57:25<27:43:11, 16.13s/it] 15%|█▍        | 1087/7272 [4:57:41<27:35:38, 16.06s/it]                                                        {'loss': 2.6112, 'grad_norm': 10.379755973815918, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1087, 'max_steps': 7272}
 15%|█▍        | 1087/7272 [4:57:41<27:35:38, 16.06s/it] 15%|█▍        | 1088/7272 [4:57:58<27:53:45, 16.24s/it]                                                        {'loss': 1.2633, 'grad_norm': 3.587317943572998, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1088, 'max_steps': 7272}
 15%|█▍        | 1088/7272 [4:57:58<27:53:45, 16.24s/it] 15%|█▍        | 1089/7272 [4:58:14<27:57:11, 16.28s/it]                                                        {'loss': 1.6397, 'grad_norm': 8.980263710021973, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1089, 'max_steps': 7272}
 15%|█▍        | 1089/7272 [4:58:14<27:57:11, 16.28s/it] 15%|█▍        | 1090/7272 [4:58:31<28:04:07, 16.35s/it]                                                        {'loss': 2.5975, 'grad_norm': 8.932652473449707, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1090, 'max_steps': 7272}
 15%|█▍        | 1090/7272 [4:58:31<28:04:07, 16.35s/it] 15%|█▌        | 1091/7272 [4:58:47<27:54:42, 16.26s/it]                                                        {'loss': 1.9724, 'grad_norm': 7.729613304138184, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1091, 'max_steps': 7272}
 15%|█▌        | 1091/7272 [4:58:47<27:54:42, 16.26s/it] 15%|█▌        | 1092/7272 [4:59:03<27:49:31, 16.21s/it]                                                        {'loss': 3.1378, 'grad_norm': 11.396637916564941, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1092, 'max_steps': 7272}
 15%|█▌        | 1092/7272 [4:59:03<27:49:31, 16.21s/it] 15%|█▌        | 1093/7272 [4:59:19<27:54:46, 16.26s/it]                                                        {'loss': 0.8299, 'grad_norm': 3.504669427871704, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1093, 'max_steps': 7272}
 15%|█▌        | 1093/7272 [4:59:19<27:54:46, 16.26s/it] 15%|█▌        | 1094/7272 [4:59:35<27:48:31, 16.20s/it]                                                        {'loss': 1.6884, 'grad_norm': 9.066145896911621, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1094, 'max_steps': 7272}
 15%|█▌        | 1094/7272 [4:59:35<27:48:31, 16.20s/it] 15%|█▌        | 1095/7272 [4:59:51<27:32:20, 16.05s/it]                                                        {'loss': 1.7852, 'grad_norm': 3.916987657546997, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1095, 'max_steps': 7272}
 15%|█▌        | 1095/7272 [4:59:51<27:32:20, 16.05s/it] 15%|█▌        | 1096/7272 [5:00:08<28:00:59, 16.33s/it]                                                        {'loss': 1.1346, 'grad_norm': 5.077004432678223, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1096, 'max_steps': 7272}
 15%|█▌        | 1096/7272 [5:00:08<28:00:59, 16.33s/it] 15%|█▌        | 1097/7272 [5:00:24<27:39:19, 16.12s/it]                                                        {'loss': 2.0143, 'grad_norm': 3.0237605571746826, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1097, 'max_steps': 7272}
 15%|█▌        | 1097/7272 [5:00:24<27:39:19, 16.12s/it] 15%|█▌        | 1098/7272 [5:00:40<27:32:59, 16.06s/it]                                                        {'loss': 1.2808, 'grad_norm': 4.252646446228027, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1098, 'max_steps': 7272}
 15%|█▌        | 1098/7272 [5:00:40<27:32:59, 16.06s/it] 15%|█▌        | 1099/7272 [5:00:55<27:20:40, 15.95s/it]                                                        {'loss': 1.3557, 'grad_norm': 2.774996757507324, 'learning_rate': 5e-05, 'epoch': 0.6, 'step': 1099, 'max_steps': 7272}
 15%|█▌        | 1099/7272 [5:00:55<27:20:40, 15.95s/it] 15%|█▌        | 1100/7272 [5:01:11<27:02:17, 15.77s/it]                                                        {'loss': 2.6288, 'grad_norm': 8.408677101135254, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1100, 'max_steps': 7272}
 15%|█▌        | 1100/7272 [5:01:11<27:02:17, 15.77s/it] 15%|█▌        | 1101/7272 [5:01:27<27:26:12, 16.01s/it]                                                        {'loss': 1.8324, 'grad_norm': 6.8486738204956055, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1101, 'max_steps': 7272}
 15%|█▌        | 1101/7272 [5:01:27<27:26:12, 16.01s/it] 15%|█▌        | 1102/7272 [5:01:43<27:35:31, 16.10s/it]                                                        {'loss': 0.8389, 'grad_norm': 5.831662654876709, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1102, 'max_steps': 7272}
 15%|█▌        | 1102/7272 [5:01:43<27:35:31, 16.10s/it] 15%|█▌        | 1103/7272 [5:01:59<27:31:59, 16.07s/it]                                                        {'loss': 1.8111, 'grad_norm': 6.411012172698975, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1103, 'max_steps': 7272}
 15%|█▌        | 1103/7272 [5:01:59<27:31:59, 16.07s/it] 15%|█▌        | 1104/7272 [5:02:16<27:37:44, 16.13s/it]                                                        {'loss': 1.1645, 'grad_norm': 2.8540570735931396, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1104, 'max_steps': 7272}
 15%|█▌        | 1104/7272 [5:02:16<27:37:44, 16.13s/it] 15%|█▌        | 1105/7272 [5:02:32<27:32:35, 16.08s/it]                                                        {'loss': 1.7527, 'grad_norm': 9.017939567565918, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1105, 'max_steps': 7272}
 15%|█▌        | 1105/7272 [5:02:32<27:32:35, 16.08s/it] 15%|█▌        | 1106/7272 [5:02:48<27:31:56, 16.07s/it]                                                        {'loss': 2.5205, 'grad_norm': 7.303220748901367, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1106, 'max_steps': 7272}
 15%|█▌        | 1106/7272 [5:02:48<27:31:56, 16.07s/it] 15%|█▌        | 1107/7272 [5:03:04<27:44:09, 16.20s/it]                                                        {'loss': 3.9471, 'grad_norm': 9.03829574584961, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1107, 'max_steps': 7272}
 15%|█▌        | 1107/7272 [5:03:04<27:44:09, 16.20s/it] 15%|█▌        | 1108/7272 [5:03:20<27:44:53, 16.21s/it]                                                        {'loss': 1.4106, 'grad_norm': 5.024086952209473, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1108, 'max_steps': 7272}
 15%|█▌        | 1108/7272 [5:03:20<27:44:53, 16.21s/it] 15%|█▌        | 1109/7272 [5:03:37<27:46:19, 16.22s/it]                                                        {'loss': 1.0112, 'grad_norm': 5.873809814453125, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1109, 'max_steps': 7272}
 15%|█▌        | 1109/7272 [5:03:37<27:46:19, 16.22s/it] 15%|█▌        | 1110/7272 [5:03:53<27:46:35, 16.23s/it]                                                        {'loss': 2.3022, 'grad_norm': 6.007704734802246, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1110, 'max_steps': 7272}
 15%|█▌        | 1110/7272 [5:03:53<27:46:35, 16.23s/it] 15%|█▌        | 1111/7272 [5:04:09<27:51:49, 16.28s/it]                                                        {'loss': 1.8469, 'grad_norm': 10.85108757019043, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1111, 'max_steps': 7272}
 15%|█▌        | 1111/7272 [5:04:09<27:51:49, 16.28s/it] 15%|█▌        | 1112/7272 [5:04:26<28:03:17, 16.40s/it]                                                        {'loss': 2.8731, 'grad_norm': 7.12703275680542, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1112, 'max_steps': 7272}
 15%|█▌        | 1112/7272 [5:04:26<28:03:17, 16.40s/it] 15%|█▌        | 1113/7272 [5:04:43<28:08:09, 16.45s/it]                                                        {'loss': 0.9825, 'grad_norm': 2.8573131561279297, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1113, 'max_steps': 7272}
 15%|█▌        | 1113/7272 [5:04:43<28:08:09, 16.45s/it] 15%|█▌        | 1114/7272 [5:04:59<28:05:50, 16.43s/it]                                                        {'loss': 2.1015, 'grad_norm': 5.5085062980651855, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1114, 'max_steps': 7272}
 15%|█▌        | 1114/7272 [5:04:59<28:05:50, 16.43s/it] 15%|█▌        | 1115/7272 [5:05:15<27:53:08, 16.30s/it]                                                        {'loss': 2.5801, 'grad_norm': 5.361128807067871, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1115, 'max_steps': 7272}
 15%|█▌        | 1115/7272 [5:05:15<27:53:08, 16.30s/it] 15%|█▌        | 1116/7272 [5:05:31<27:35:47, 16.14s/it]                                                        {'loss': 2.6841, 'grad_norm': 6.939632415771484, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1116, 'max_steps': 7272}
 15%|█▌        | 1116/7272 [5:05:31<27:35:47, 16.14s/it] 15%|█▌        | 1117/7272 [5:05:47<27:37:22, 16.16s/it]                                                        {'loss': 0.9833, 'grad_norm': 5.393898963928223, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1117, 'max_steps': 7272}
 15%|█▌        | 1117/7272 [5:05:47<27:37:22, 16.16s/it] 15%|█▌        | 1118/7272 [5:06:03<27:40:48, 16.19s/it]                                                        {'loss': 1.6613, 'grad_norm': 8.291047096252441, 'learning_rate': 5e-05, 'epoch': 0.61, 'step': 1118, 'max_steps': 7272}
 15%|█▌        | 1118/7272 [5:06:03<27:40:48, 16.19s/it] 15%|█▌        | 1119/7272 [5:06:20<27:53:13, 16.32s/it]                                                        {'loss': 2.6094, 'grad_norm': 9.278919219970703, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1119, 'max_steps': 7272}
 15%|█▌        | 1119/7272 [5:06:20<27:53:13, 16.32s/it] 15%|█▌        | 1120/7272 [5:06:37<28:20:15, 16.58s/it]                                                        {'loss': 2.1219, 'grad_norm': 4.536896705627441, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1120, 'max_steps': 7272}
 15%|█▌        | 1120/7272 [5:06:37<28:20:15, 16.58s/it] 15%|█▌        | 1121/7272 [5:06:53<28:11:42, 16.50s/it]                                                        {'loss': 2.3103, 'grad_norm': 5.359114170074463, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1121, 'max_steps': 7272}
 15%|█▌        | 1121/7272 [5:06:53<28:11:42, 16.50s/it] 15%|█▌        | 1122/7272 [5:07:10<28:08:15, 16.47s/it]                                                        {'loss': 1.133, 'grad_norm': 2.818268299102783, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1122, 'max_steps': 7272}
 15%|█▌        | 1122/7272 [5:07:10<28:08:15, 16.47s/it] 15%|█▌        | 1123/7272 [5:07:26<28:00:31, 16.40s/it]                                                        {'loss': 1.3943, 'grad_norm': 5.420548915863037, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1123, 'max_steps': 7272}
 15%|█▌        | 1123/7272 [5:07:26<28:00:31, 16.40s/it] 15%|█▌        | 1124/7272 [5:07:42<27:59:10, 16.39s/it]                                                        {'loss': 1.5763, 'grad_norm': 3.027298927307129, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1124, 'max_steps': 7272}
 15%|█▌        | 1124/7272 [5:07:42<27:59:10, 16.39s/it] 15%|█▌        | 1125/7272 [5:07:58<27:41:45, 16.22s/it]                                                        {'loss': 1.0023, 'grad_norm': 6.0916547775268555, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1125, 'max_steps': 7272}
 15%|█▌        | 1125/7272 [5:07:58<27:41:45, 16.22s/it] 15%|█▌        | 1126/7272 [5:08:14<27:32:59, 16.14s/it]                                                        {'loss': 1.2317, 'grad_norm': 4.781739234924316, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1126, 'max_steps': 7272}
 15%|█▌        | 1126/7272 [5:08:14<27:32:59, 16.14s/it] 15%|█▌        | 1127/7272 [5:08:31<27:46:51, 16.28s/it]                                                        {'loss': 2.5138, 'grad_norm': 3.8089399337768555, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1127, 'max_steps': 7272}
 15%|█▌        | 1127/7272 [5:08:31<27:46:51, 16.28s/it] 16%|█▌        | 1128/7272 [5:08:47<27:38:44, 16.20s/it]                                                        {'loss': 3.0941, 'grad_norm': 4.907066822052002, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1128, 'max_steps': 7272}
 16%|█▌        | 1128/7272 [5:08:47<27:38:44, 16.20s/it] 16%|█▌        | 1129/7272 [5:09:03<27:30:36, 16.12s/it]                                                        {'loss': 1.0444, 'grad_norm': 2.696662425994873, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1129, 'max_steps': 7272}
 16%|█▌        | 1129/7272 [5:09:03<27:30:36, 16.12s/it] 16%|█▌        | 1130/7272 [5:09:19<27:33:05, 16.15s/it]                                                        {'loss': 2.5364, 'grad_norm': 4.351089000701904, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1130, 'max_steps': 7272}
 16%|█▌        | 1130/7272 [5:09:19<27:33:05, 16.15s/it] 16%|█▌        | 1131/7272 [5:09:35<27:22:25, 16.05s/it]                                                        {'loss': 0.7512, 'grad_norm': 5.119579315185547, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1131, 'max_steps': 7272}
 16%|█▌        | 1131/7272 [5:09:35<27:22:25, 16.05s/it] 16%|█▌        | 1132/7272 [5:09:51<27:21:41, 16.04s/it]                                                        {'loss': 2.1976, 'grad_norm': 6.552030086517334, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1132, 'max_steps': 7272}
 16%|█▌        | 1132/7272 [5:09:51<27:21:41, 16.04s/it] 16%|█▌        | 1133/7272 [5:10:07<27:13:50, 15.97s/it]                                                        {'loss': 1.5267, 'grad_norm': 4.970228672027588, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1133, 'max_steps': 7272}
 16%|█▌        | 1133/7272 [5:10:07<27:13:50, 15.97s/it] 16%|█▌        | 1134/7272 [5:10:23<27:21:53, 16.05s/it]                                                        {'loss': 1.389, 'grad_norm': 2.5723140239715576, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1134, 'max_steps': 7272}
 16%|█▌        | 1134/7272 [5:10:23<27:21:53, 16.05s/it] 16%|█▌        | 1135/7272 [5:10:39<27:32:43, 16.16s/it]                                                        {'loss': 2.0274, 'grad_norm': 8.891142845153809, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1135, 'max_steps': 7272}
 16%|█▌        | 1135/7272 [5:10:39<27:32:43, 16.16s/it] 16%|█▌        | 1136/7272 [5:10:55<27:09:46, 15.94s/it]                                                        {'loss': 1.6477, 'grad_norm': 3.651827573776245, 'learning_rate': 5e-05, 'epoch': 0.62, 'step': 1136, 'max_steps': 7272}
 16%|█▌        | 1136/7272 [5:10:55<27:09:46, 15.94s/it] 16%|█▌        | 1137/7272 [5:11:11<27:10:26, 15.95s/it]                                                        {'loss': 2.2855, 'grad_norm': 4.945617198944092, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1137, 'max_steps': 7272}
 16%|█▌        | 1137/7272 [5:11:11<27:10:26, 15.95s/it] 16%|█▌        | 1138/7272 [5:11:27<27:10:53, 15.95s/it]                                                        {'loss': 1.7062, 'grad_norm': 4.092621803283691, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1138, 'max_steps': 7272}
 16%|█▌        | 1138/7272 [5:11:27<27:10:53, 15.95s/it] 16%|█▌        | 1139/7272 [5:11:42<27:01:03, 15.86s/it]                                                        {'loss': 1.5781, 'grad_norm': 4.008862018585205, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1139, 'max_steps': 7272}
 16%|█▌        | 1139/7272 [5:11:42<27:01:03, 15.86s/it] 16%|█▌        | 1140/7272 [5:11:58<27:01:40, 15.87s/it]                                                        {'loss': 2.2097, 'grad_norm': 3.738422393798828, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1140, 'max_steps': 7272}
 16%|█▌        | 1140/7272 [5:11:58<27:01:40, 15.87s/it] 16%|█▌        | 1141/7272 [5:12:14<27:06:37, 15.92s/it]                                                        {'loss': 0.8875, 'grad_norm': 2.3565611839294434, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1141, 'max_steps': 7272}
 16%|█▌        | 1141/7272 [5:12:14<27:06:37, 15.92s/it] 16%|█▌        | 1142/7272 [5:12:30<27:03:10, 15.89s/it]                                                        {'loss': 1.3348, 'grad_norm': 6.701408386230469, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1142, 'max_steps': 7272}
 16%|█▌        | 1142/7272 [5:12:30<27:03:10, 15.89s/it] 16%|█▌        | 1143/7272 [5:12:46<26:55:54, 15.82s/it]                                                        {'loss': 1.8777, 'grad_norm': 7.632966995239258, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1143, 'max_steps': 7272}
 16%|█▌        | 1143/7272 [5:12:46<26:55:54, 15.82s/it] 16%|█▌        | 1144/7272 [5:13:01<26:58:46, 15.85s/it]                                                        {'loss': 1.2193, 'grad_norm': 3.8137850761413574, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1144, 'max_steps': 7272}
 16%|█▌        | 1144/7272 [5:13:01<26:58:46, 15.85s/it] 16%|█▌        | 1145/7272 [5:13:18<27:10:42, 15.97s/it]                                                        {'loss': 1.262, 'grad_norm': 4.489396095275879, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1145, 'max_steps': 7272}
 16%|█▌        | 1145/7272 [5:13:18<27:10:42, 15.97s/it] 16%|█▌        | 1146/7272 [5:13:33<27:03:38, 15.90s/it]                                                        {'loss': 1.4616, 'grad_norm': 3.3621232509613037, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1146, 'max_steps': 7272}
 16%|█▌        | 1146/7272 [5:13:33<27:03:38, 15.90s/it] 16%|█▌        | 1147/7272 [5:13:49<26:58:23, 15.85s/it]                                                        {'loss': 0.6638, 'grad_norm': 3.4136593341827393, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1147, 'max_steps': 7272}
 16%|█▌        | 1147/7272 [5:13:49<26:58:23, 15.85s/it] 16%|█▌        | 1148/7272 [5:14:05<27:05:54, 15.93s/it]                                                        {'loss': 1.621, 'grad_norm': 6.63184118270874, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1148, 'max_steps': 7272}
 16%|█▌        | 1148/7272 [5:14:05<27:05:54, 15.93s/it] 16%|█▌        | 1149/7272 [5:14:22<27:20:18, 16.07s/it]                                                        {'loss': 1.3666, 'grad_norm': 3.702535629272461, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1149, 'max_steps': 7272}
 16%|█▌        | 1149/7272 [5:14:22<27:20:18, 16.07s/it] 16%|█▌        | 1150/7272 [5:14:38<27:18:19, 16.06s/it]                                                        {'loss': 1.6878, 'grad_norm': 4.182545185089111, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1150, 'max_steps': 7272}
 16%|█▌        | 1150/7272 [5:14:38<27:18:19, 16.06s/it] 16%|█▌        | 1151/7272 [5:14:54<27:37:40, 16.25s/it]                                                        {'loss': 0.849, 'grad_norm': 2.794138193130493, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1151, 'max_steps': 7272}
 16%|█▌        | 1151/7272 [5:14:54<27:37:40, 16.25s/it] 16%|█▌        | 1152/7272 [5:15:10<27:13:10, 16.01s/it]                                                        {'loss': 1.7294, 'grad_norm': 4.70086669921875, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1152, 'max_steps': 7272}
 16%|█▌        | 1152/7272 [5:15:10<27:13:10, 16.01s/it] 16%|█▌        | 1153/7272 [5:15:26<27:08:20, 15.97s/it]                                                        {'loss': 2.0838, 'grad_norm': 5.030328750610352, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1153, 'max_steps': 7272}
 16%|█▌        | 1153/7272 [5:15:26<27:08:20, 15.97s/it] 16%|█▌        | 1154/7272 [5:15:42<27:15:07, 16.04s/it]                                                        {'loss': 2.6247, 'grad_norm': 5.978875160217285, 'learning_rate': 5e-05, 'epoch': 0.63, 'step': 1154, 'max_steps': 7272}
 16%|█▌        | 1154/7272 [5:15:42<27:15:07, 16.04s/it] 16%|█▌        | 1155/7272 [5:15:59<27:34:56, 16.23s/it]                                                        {'loss': 1.053, 'grad_norm': 2.3870391845703125, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1155, 'max_steps': 7272}
 16%|█▌        | 1155/7272 [5:15:59<27:34:56, 16.23s/it] 16%|█▌        | 1156/7272 [5:16:15<27:40:46, 16.29s/it]                                                        {'loss': 2.4717, 'grad_norm': 6.6354217529296875, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1156, 'max_steps': 7272}
 16%|█▌        | 1156/7272 [5:16:15<27:40:46, 16.29s/it] 16%|█▌        | 1157/7272 [5:16:31<27:28:18, 16.17s/it]                                                        {'loss': 0.6854, 'grad_norm': 1.89737868309021, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1157, 'max_steps': 7272}
 16%|█▌        | 1157/7272 [5:16:31<27:28:18, 16.17s/it] 16%|█▌        | 1158/7272 [5:16:46<27:00:58, 15.91s/it]                                                        {'loss': 1.611, 'grad_norm': 8.393370628356934, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1158, 'max_steps': 7272}
 16%|█▌        | 1158/7272 [5:16:46<27:00:58, 15.91s/it] 16%|█▌        | 1159/7272 [5:17:02<27:02:09, 15.92s/it]                                                        {'loss': 1.2476, 'grad_norm': 8.23337173461914, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1159, 'max_steps': 7272}
 16%|█▌        | 1159/7272 [5:17:02<27:02:09, 15.92s/it] 16%|█▌        | 1160/7272 [5:17:18<27:02:40, 15.93s/it]                                                        {'loss': 1.1028, 'grad_norm': 5.2578277587890625, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1160, 'max_steps': 7272}
 16%|█▌        | 1160/7272 [5:17:18<27:02:40, 15.93s/it] 16%|█▌        | 1161/7272 [5:17:34<27:08:51, 15.99s/it]                                                        {'loss': 2.0821, 'grad_norm': 6.434453964233398, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1161, 'max_steps': 7272}
 16%|█▌        | 1161/7272 [5:17:34<27:08:51, 15.99s/it] 16%|█▌        | 1162/7272 [5:17:50<27:04:56, 15.96s/it]                                                        {'loss': 2.3557, 'grad_norm': 5.909185886383057, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1162, 'max_steps': 7272}
 16%|█▌        | 1162/7272 [5:17:50<27:04:56, 15.96s/it] 16%|█▌        | 1163/7272 [5:18:06<27:06:37, 15.98s/it]                                                        {'loss': 1.6787, 'grad_norm': 5.775538444519043, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1163, 'max_steps': 7272}
 16%|█▌        | 1163/7272 [5:18:06<27:06:37, 15.98s/it] 16%|█▌        | 1164/7272 [5:18:21<26:44:04, 15.76s/it]                                                        {'loss': 1.1841, 'grad_norm': 5.169580459594727, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1164, 'max_steps': 7272}
 16%|█▌        | 1164/7272 [5:18:21<26:44:04, 15.76s/it] 16%|█▌        | 1165/7272 [5:18:37<26:37:15, 15.69s/it]                                                        {'loss': 2.897, 'grad_norm': 7.039238929748535, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1165, 'max_steps': 7272}
 16%|█▌        | 1165/7272 [5:18:37<26:37:15, 15.69s/it] 16%|█▌        | 1166/7272 [5:18:53<26:36:50, 15.69s/it]                                                        {'loss': 1.8964, 'grad_norm': 5.180410385131836, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1166, 'max_steps': 7272}
 16%|█▌        | 1166/7272 [5:18:53<26:36:50, 15.69s/it] 16%|█▌        | 1167/7272 [5:19:09<26:48:59, 15.81s/it]                                                        {'loss': 1.3601, 'grad_norm': 4.127712726593018, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1167, 'max_steps': 7272}
 16%|█▌        | 1167/7272 [5:19:09<26:48:59, 15.81s/it] 16%|█▌        | 1168/7272 [5:19:25<27:04:09, 15.96s/it]                                                        {'loss': 2.4246, 'grad_norm': 6.5349531173706055, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1168, 'max_steps': 7272}
 16%|█▌        | 1168/7272 [5:19:25<27:04:09, 15.96s/it] 16%|█▌        | 1169/7272 [5:19:41<26:59:40, 15.92s/it]                                                        {'loss': 2.2041, 'grad_norm': 12.568761825561523, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1169, 'max_steps': 7272}
 16%|█▌        | 1169/7272 [5:19:41<26:59:40, 15.92s/it] 16%|█▌        | 1170/7272 [5:19:57<27:04:17, 15.97s/it]                                                        {'loss': 2.6217, 'grad_norm': 4.823453426361084, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1170, 'max_steps': 7272}
 16%|█▌        | 1170/7272 [5:19:57<27:04:17, 15.97s/it] 16%|█▌        | 1171/7272 [5:20:13<27:01:00, 15.94s/it]                                                        {'loss': 1.8303, 'grad_norm': 7.268389701843262, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1171, 'max_steps': 7272}
 16%|█▌        | 1171/7272 [5:20:13<27:01:00, 15.94s/it] 16%|█▌        | 1172/7272 [5:20:29<27:19:52, 16.13s/it]                                                        {'loss': 1.9508, 'grad_norm': 5.085331439971924, 'learning_rate': 5e-05, 'epoch': 0.64, 'step': 1172, 'max_steps': 7272}
 16%|█▌        | 1172/7272 [5:20:29<27:19:52, 16.13s/it] 16%|█▌        | 1173/7272 [5:20:45<27:11:25, 16.05s/it]                                                        {'loss': 2.0593, 'grad_norm': 7.566982269287109, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1173, 'max_steps': 7272}
 16%|█▌        | 1173/7272 [5:20:45<27:11:25, 16.05s/it] 16%|█▌        | 1174/7272 [5:21:01<26:58:34, 15.93s/it]                                                        {'loss': 1.6447, 'grad_norm': 4.235445976257324, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1174, 'max_steps': 7272}
 16%|█▌        | 1174/7272 [5:21:01<26:58:34, 15.93s/it] 16%|█▌        | 1175/7272 [5:21:17<27:11:02, 16.05s/it]                                                        {'loss': 2.6495, 'grad_norm': 8.35340690612793, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1175, 'max_steps': 7272}
 16%|█▌        | 1175/7272 [5:21:17<27:11:02, 16.05s/it] 16%|█▌        | 1176/7272 [5:21:33<27:05:58, 16.00s/it]                                                        {'loss': 1.13, 'grad_norm': 3.216259002685547, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1176, 'max_steps': 7272}
 16%|█▌        | 1176/7272 [5:21:33<27:05:58, 16.00s/it] 16%|█▌        | 1177/7272 [5:21:49<26:51:36, 15.86s/it]                                                        {'loss': 3.1132, 'grad_norm': 10.424805641174316, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1177, 'max_steps': 7272}
 16%|█▌        | 1177/7272 [5:21:49<26:51:36, 15.86s/it] 16%|█▌        | 1178/7272 [5:22:05<26:49:16, 15.84s/it]                                                        {'loss': 2.0217, 'grad_norm': 8.537501335144043, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1178, 'max_steps': 7272}
 16%|█▌        | 1178/7272 [5:22:05<26:49:16, 15.84s/it] 16%|█▌        | 1179/7272 [5:22:21<26:57:05, 15.92s/it]                                                        {'loss': 2.1177, 'grad_norm': 5.780046463012695, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1179, 'max_steps': 7272}
 16%|█▌        | 1179/7272 [5:22:21<26:57:05, 15.92s/it] 16%|█▌        | 1180/7272 [5:22:37<26:56:07, 15.92s/it]                                                        {'loss': 2.4926, 'grad_norm': 4.129311561584473, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1180, 'max_steps': 7272}
 16%|█▌        | 1180/7272 [5:22:37<26:56:07, 15.92s/it] 16%|█▌        | 1181/7272 [5:22:53<27:06:35, 16.02s/it]                                                        {'loss': 1.2195, 'grad_norm': 5.182407379150391, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1181, 'max_steps': 7272}
 16%|█▌        | 1181/7272 [5:22:53<27:06:35, 16.02s/it] 16%|█▋        | 1182/7272 [5:23:09<27:03:37, 16.00s/it]                                                        {'loss': 1.9733, 'grad_norm': 6.355860233306885, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1182, 'max_steps': 7272}
 16%|█▋        | 1182/7272 [5:23:09<27:03:37, 16.00s/it] 16%|█▋        | 1183/7272 [5:23:24<26:55:03, 15.91s/it]                                                        {'loss': 0.8355, 'grad_norm': 2.2031140327453613, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1183, 'max_steps': 7272}
 16%|█▋        | 1183/7272 [5:23:24<26:55:03, 15.91s/it] 16%|█▋        | 1184/7272 [5:23:41<27:11:19, 16.08s/it]                                                        {'loss': 2.2842, 'grad_norm': 5.094285011291504, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1184, 'max_steps': 7272}
 16%|█▋        | 1184/7272 [5:23:41<27:11:19, 16.08s/it] 16%|█▋        | 1185/7272 [5:23:57<27:17:41, 16.14s/it]                                                        {'loss': 2.7675, 'grad_norm': 6.965408802032471, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1185, 'max_steps': 7272}
 16%|█▋        | 1185/7272 [5:23:57<27:17:41, 16.14s/it] 16%|█▋        | 1186/7272 [5:24:13<27:19:58, 16.17s/it]                                                        {'loss': 1.5556, 'grad_norm': 4.514819622039795, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1186, 'max_steps': 7272}
 16%|█▋        | 1186/7272 [5:24:13<27:19:58, 16.17s/it] 16%|█▋        | 1187/7272 [5:24:30<27:27:35, 16.25s/it]                                                        {'loss': 1.1441, 'grad_norm': 6.812510967254639, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1187, 'max_steps': 7272}
 16%|█▋        | 1187/7272 [5:24:30<27:27:35, 16.25s/it] 16%|█▋        | 1188/7272 [5:24:46<27:23:15, 16.21s/it]                                                        {'loss': 1.0829, 'grad_norm': 2.14497709274292, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1188, 'max_steps': 7272}
 16%|█▋        | 1188/7272 [5:24:46<27:23:15, 16.21s/it] 16%|█▋        | 1189/7272 [5:25:02<27:27:45, 16.25s/it]                                                        {'loss': 1.7046, 'grad_norm': 2.4806740283966064, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1189, 'max_steps': 7272}
 16%|█▋        | 1189/7272 [5:25:02<27:27:45, 16.25s/it] 16%|█▋        | 1190/7272 [5:25:19<27:35:15, 16.33s/it]                                                        {'loss': 2.3215, 'grad_norm': 9.922632217407227, 'learning_rate': 5e-05, 'epoch': 0.65, 'step': 1190, 'max_steps': 7272}
 16%|█▋        | 1190/7272 [5:25:19<27:35:15, 16.33s/it] 16%|█▋        | 1191/7272 [5:25:35<27:42:49, 16.41s/it]                                                        {'loss': 1.8953, 'grad_norm': 5.493519306182861, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1191, 'max_steps': 7272}
 16%|█▋        | 1191/7272 [5:25:35<27:42:49, 16.41s/it] 16%|█▋        | 1192/7272 [5:25:52<27:47:14, 16.45s/it]                                                        {'loss': 1.8538, 'grad_norm': 3.840970039367676, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1192, 'max_steps': 7272}
 16%|█▋        | 1192/7272 [5:25:52<27:47:14, 16.45s/it] 16%|█▋        | 1193/7272 [5:26:08<27:36:52, 16.35s/it]                                                        {'loss': 1.4959, 'grad_norm': 14.30516242980957, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1193, 'max_steps': 7272}
 16%|█▋        | 1193/7272 [5:26:08<27:36:52, 16.35s/it] 16%|█▋        | 1194/7272 [5:26:24<27:16:48, 16.16s/it]                                                        {'loss': 0.5028, 'grad_norm': 1.5389646291732788, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1194, 'max_steps': 7272}
 16%|█▋        | 1194/7272 [5:26:24<27:16:48, 16.16s/it] 16%|█▋        | 1195/7272 [5:26:40<27:03:32, 16.03s/it]                                                        {'loss': 2.8113, 'grad_norm': 6.787450313568115, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1195, 'max_steps': 7272}
 16%|█▋        | 1195/7272 [5:26:40<27:03:32, 16.03s/it] 16%|█▋        | 1196/7272 [5:26:55<26:53:21, 15.93s/it]                                                        {'loss': 1.813, 'grad_norm': 4.154305458068848, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1196, 'max_steps': 7272}
 16%|█▋        | 1196/7272 [5:26:55<26:53:21, 15.93s/it] 16%|█▋        | 1197/7272 [5:27:11<27:00:05, 16.00s/it]                                                        {'loss': 1.903, 'grad_norm': 3.9389548301696777, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1197, 'max_steps': 7272}
 16%|█▋        | 1197/7272 [5:27:11<27:00:05, 16.00s/it] 16%|█▋        | 1198/7272 [5:27:27<26:53:50, 15.94s/it]                                                        {'loss': 1.033, 'grad_norm': 7.022778511047363, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1198, 'max_steps': 7272}
 16%|█▋        | 1198/7272 [5:27:27<26:53:50, 15.94s/it] 16%|█▋        | 1199/7272 [5:27:43<26:59:22, 16.00s/it]                                                        {'loss': 1.2416, 'grad_norm': 2.9590349197387695, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1199, 'max_steps': 7272}
 16%|█▋        | 1199/7272 [5:27:43<26:59:22, 16.00s/it] 17%|█▋        | 1200/7272 [5:28:00<27:06:04, 16.07s/it]                                                        {'loss': 1.4707, 'grad_norm': 8.7941312789917, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1200, 'max_steps': 7272}
 17%|█▋        | 1200/7272 [5:28:00<27:06:04, 16.07s/it] 17%|█▋        | 1201/7272 [5:28:15<26:56:47, 15.98s/it]                                                        {'loss': 0.7049, 'grad_norm': 1.8580703735351562, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1201, 'max_steps': 7272}
 17%|█▋        | 1201/7272 [5:28:15<26:56:47, 15.98s/it] 17%|█▋        | 1202/7272 [5:28:31<26:54:32, 15.96s/it]                                                        {'loss': 1.7605, 'grad_norm': 5.52209997177124, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1202, 'max_steps': 7272}
 17%|█▋        | 1202/7272 [5:28:31<26:54:32, 15.96s/it] 17%|█▋        | 1203/7272 [5:28:47<26:48:58, 15.91s/it]                                                        {'loss': 2.0053, 'grad_norm': 4.150754451751709, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1203, 'max_steps': 7272}
 17%|█▋        | 1203/7272 [5:28:47<26:48:58, 15.91s/it] 17%|█▋        | 1204/7272 [5:29:03<26:40:26, 15.83s/it]                                                        {'loss': 1.874, 'grad_norm': 5.710946083068848, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1204, 'max_steps': 7272}
 17%|█▋        | 1204/7272 [5:29:03<26:40:26, 15.83s/it] 17%|█▋        | 1205/7272 [5:29:19<26:43:34, 15.86s/it]                                                        {'loss': 1.3825, 'grad_norm': 8.499991416931152, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1205, 'max_steps': 7272}
 17%|█▋        | 1205/7272 [5:29:19<26:43:34, 15.86s/it] 17%|█▋        | 1206/7272 [5:29:34<26:35:23, 15.78s/it]                                                        {'loss': 2.2706, 'grad_norm': 8.365108489990234, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1206, 'max_steps': 7272}
 17%|█▋        | 1206/7272 [5:29:34<26:35:23, 15.78s/it] 17%|█▋        | 1207/7272 [5:29:50<26:32:57, 15.76s/it]                                                        {'loss': 4.0019, 'grad_norm': 8.471277236938477, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1207, 'max_steps': 7272}
 17%|█▋        | 1207/7272 [5:29:50<26:32:57, 15.76s/it] 17%|█▋        | 1208/7272 [5:30:06<26:27:33, 15.71s/it]                                                        {'loss': 1.6905, 'grad_norm': 10.139520645141602, 'learning_rate': 5e-05, 'epoch': 0.66, 'step': 1208, 'max_steps': 7272}
 17%|█▋        | 1208/7272 [5:30:06<26:27:33, 15.71s/it] 17%|█▋        | 1209/7272 [5:30:22<26:36:38, 15.80s/it]                                                        {'loss': 1.2896, 'grad_norm': 2.689279079437256, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1209, 'max_steps': 7272}
 17%|█▋        | 1209/7272 [5:30:22<26:36:38, 15.80s/it] 17%|█▋        | 1210/7272 [5:30:38<26:50:03, 15.94s/it]                                                        {'loss': 2.3277, 'grad_norm': 11.219708442687988, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1210, 'max_steps': 7272}
 17%|█▋        | 1210/7272 [5:30:38<26:50:03, 15.94s/it] 17%|█▋        | 1211/7272 [5:30:54<26:51:50, 15.96s/it]                                                        {'loss': 2.3861, 'grad_norm': 5.679190635681152, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1211, 'max_steps': 7272}
 17%|█▋        | 1211/7272 [5:30:54<26:51:50, 15.96s/it] 17%|█▋        | 1212/7272 [5:31:10<26:59:49, 16.04s/it]                                                        {'loss': 1.522, 'grad_norm': 7.960616588592529, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1212, 'max_steps': 7272}
 17%|█▋        | 1212/7272 [5:31:10<26:59:49, 16.04s/it] 17%|█▋        | 1213/7272 [5:31:26<26:42:54, 15.87s/it]                                                        {'loss': 1.7396, 'grad_norm': 2.8508732318878174, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1213, 'max_steps': 7272}
 17%|█▋        | 1213/7272 [5:31:26<26:42:54, 15.87s/it] 17%|█▋        | 1214/7272 [5:31:41<26:40:10, 15.85s/it]                                                        {'loss': 1.0021, 'grad_norm': 3.5625522136688232, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1214, 'max_steps': 7272}
 17%|█▋        | 1214/7272 [5:31:41<26:40:10, 15.85s/it] 17%|█▋        | 1215/7272 [5:31:57<26:26:05, 15.71s/it]                                                        {'loss': 2.4327, 'grad_norm': 8.89954662322998, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1215, 'max_steps': 7272}
 17%|█▋        | 1215/7272 [5:31:57<26:26:05, 15.71s/it] 17%|█▋        | 1216/7272 [5:32:12<26:27:11, 15.73s/it]                                                        {'loss': 1.4405, 'grad_norm': 4.43978214263916, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1216, 'max_steps': 7272}
 17%|█▋        | 1216/7272 [5:32:12<26:27:11, 15.73s/it] 17%|█▋        | 1217/7272 [5:32:28<26:20:58, 15.67s/it]                                                        {'loss': 0.9216, 'grad_norm': 2.6612377166748047, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1217, 'max_steps': 7272}
 17%|█▋        | 1217/7272 [5:32:28<26:20:58, 15.67s/it] 17%|█▋        | 1218/7272 [5:32:43<26:13:47, 15.60s/it]                                                        {'loss': 0.7688, 'grad_norm': 2.5488617420196533, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1218, 'max_steps': 7272}
 17%|█▋        | 1218/7272 [5:32:43<26:13:47, 15.60s/it] 17%|█▋        | 1219/7272 [5:32:59<26:13:20, 15.60s/it]                                                        {'loss': 0.722, 'grad_norm': 6.189554691314697, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1219, 'max_steps': 7272}
 17%|█▋        | 1219/7272 [5:32:59<26:13:20, 15.60s/it] 17%|█▋        | 1220/7272 [5:33:15<26:30:23, 15.77s/it]                                                        {'loss': 2.9291, 'grad_norm': 8.648653030395508, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1220, 'max_steps': 7272}
 17%|█▋        | 1220/7272 [5:33:15<26:30:23, 15.77s/it] 17%|█▋        | 1221/7272 [5:33:31<26:31:57, 15.79s/it]                                                        {'loss': 2.4549, 'grad_norm': 4.989230155944824, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1221, 'max_steps': 7272}
 17%|█▋        | 1221/7272 [5:33:31<26:31:57, 15.79s/it] 17%|█▋        | 1222/7272 [5:33:47<26:34:34, 15.81s/it]                                                        {'loss': 3.6035, 'grad_norm': 7.077192783355713, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1222, 'max_steps': 7272}
 17%|█▋        | 1222/7272 [5:33:47<26:34:34, 15.81s/it] 17%|█▋        | 1223/7272 [5:34:03<26:39:23, 15.86s/it]                                                        {'loss': 2.0373, 'grad_norm': 7.432501792907715, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1223, 'max_steps': 7272}
 17%|█▋        | 1223/7272 [5:34:03<26:39:23, 15.86s/it] 17%|█▋        | 1224/7272 [5:34:19<26:42:21, 15.90s/it]                                                        {'loss': 2.0987, 'grad_norm': 4.094770908355713, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1224, 'max_steps': 7272}
 17%|█▋        | 1224/7272 [5:34:19<26:42:21, 15.90s/it] 17%|█▋        | 1225/7272 [5:34:35<26:47:45, 15.95s/it]                                                        {'loss': 2.7027, 'grad_norm': 3.573866367340088, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1225, 'max_steps': 7272}
 17%|█▋        | 1225/7272 [5:34:35<26:47:45, 15.95s/it] 17%|█▋        | 1226/7272 [5:34:51<26:37:58, 15.86s/it]                                                        {'loss': 0.5467, 'grad_norm': 1.6556496620178223, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1226, 'max_steps': 7272}
 17%|█▋        | 1226/7272 [5:34:51<26:37:58, 15.86s/it] 17%|█▋        | 1227/7272 [5:35:07<26:48:56, 15.97s/it]                                                        {'loss': 2.9702, 'grad_norm': 25.116865158081055, 'learning_rate': 5e-05, 'epoch': 0.67, 'step': 1227, 'max_steps': 7272}
 17%|█▋        | 1227/7272 [5:35:07<26:48:56, 15.97s/it] 17%|█▋        | 1228/7272 [5:35:23<26:48:24, 15.97s/it]                                                        {'loss': 1.9312, 'grad_norm': 5.890522480010986, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1228, 'max_steps': 7272}
 17%|█▋        | 1228/7272 [5:35:23<26:48:24, 15.97s/it] 17%|█▋        | 1229/7272 [5:35:39<26:54:40, 16.03s/it]                                                        {'loss': 0.5967, 'grad_norm': 4.324824333190918, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1229, 'max_steps': 7272}
 17%|█▋        | 1229/7272 [5:35:39<26:54:40, 16.03s/it] 17%|█▋        | 1230/7272 [5:35:54<26:40:16, 15.89s/it]                                                        {'loss': 1.2587, 'grad_norm': 7.886427402496338, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1230, 'max_steps': 7272}
 17%|█▋        | 1230/7272 [5:35:54<26:40:16, 15.89s/it] 17%|█▋        | 1231/7272 [5:36:10<26:43:24, 15.93s/it]                                                        {'loss': 2.4103, 'grad_norm': 6.20022439956665, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1231, 'max_steps': 7272}
 17%|█▋        | 1231/7272 [5:36:11<26:43:24, 15.93s/it] 17%|█▋        | 1232/7272 [5:36:26<26:21:24, 15.71s/it]                                                        {'loss': 2.2593, 'grad_norm': 4.573753356933594, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1232, 'max_steps': 7272}
 17%|█▋        | 1232/7272 [5:36:26<26:21:24, 15.71s/it] 17%|█▋        | 1233/7272 [5:36:42<26:25:23, 15.75s/it]                                                        {'loss': 2.0555, 'grad_norm': 3.5777738094329834, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1233, 'max_steps': 7272}
 17%|█▋        | 1233/7272 [5:36:42<26:25:23, 15.75s/it] 17%|█▋        | 1234/7272 [5:36:57<26:26:59, 15.77s/it]                                                        {'loss': 1.5152, 'grad_norm': 2.562692880630493, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1234, 'max_steps': 7272}
 17%|█▋        | 1234/7272 [5:36:57<26:26:59, 15.77s/it] 17%|█▋        | 1235/7272 [5:37:13<26:15:03, 15.65s/it]                                                        {'loss': 2.0283, 'grad_norm': 7.159463405609131, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1235, 'max_steps': 7272}
 17%|█▋        | 1235/7272 [5:37:13<26:15:03, 15.65s/it] 17%|█▋        | 1236/7272 [5:37:29<26:24:49, 15.75s/it]                                                        {'loss': 1.4372, 'grad_norm': 5.615795612335205, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1236, 'max_steps': 7272}
 17%|█▋        | 1236/7272 [5:37:29<26:24:49, 15.75s/it] 17%|█▋        | 1237/7272 [5:37:45<26:32:38, 15.83s/it]                                                        {'loss': 1.6492, 'grad_norm': 4.028434753417969, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1237, 'max_steps': 7272}
 17%|█▋        | 1237/7272 [5:37:45<26:32:38, 15.83s/it] 17%|█▋        | 1238/7272 [5:38:01<26:31:02, 15.82s/it]                                                        {'loss': 2.7988, 'grad_norm': 12.099749565124512, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1238, 'max_steps': 7272}
 17%|█▋        | 1238/7272 [5:38:01<26:31:02, 15.82s/it] 17%|█▋        | 1239/7272 [5:38:16<26:32:17, 15.84s/it]                                                        {'loss': 2.5288, 'grad_norm': 14.344263076782227, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1239, 'max_steps': 7272}
 17%|█▋        | 1239/7272 [5:38:16<26:32:17, 15.84s/it] 17%|█▋        | 1240/7272 [5:38:32<26:33:40, 15.85s/it]                                                        {'loss': 1.9795, 'grad_norm': 4.964755058288574, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1240, 'max_steps': 7272}
 17%|█▋        | 1240/7272 [5:38:32<26:33:40, 15.85s/it] 17%|█▋        | 1241/7272 [5:38:49<26:47:02, 15.99s/it]                                                        {'loss': 3.6543, 'grad_norm': 7.628239154815674, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1241, 'max_steps': 7272}
 17%|█▋        | 1241/7272 [5:38:49<26:47:02, 15.99s/it] 17%|█▋        | 1242/7272 [5:39:05<26:47:09, 15.99s/it]                                                        {'loss': 1.5201, 'grad_norm': 5.956948280334473, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1242, 'max_steps': 7272}
 17%|█▋        | 1242/7272 [5:39:05<26:47:09, 15.99s/it] 17%|█▋        | 1243/7272 [5:39:21<26:44:07, 15.96s/it]                                                        {'loss': 1.6435, 'grad_norm': 5.868146896362305, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1243, 'max_steps': 7272}
 17%|█▋        | 1243/7272 [5:39:21<26:44:07, 15.96s/it] 17%|█▋        | 1244/7272 [5:39:36<26:38:43, 15.91s/it]                                                        {'loss': 1.6079, 'grad_norm': 3.8858559131622314, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1244, 'max_steps': 7272}
 17%|█▋        | 1244/7272 [5:39:36<26:38:43, 15.91s/it] 17%|█▋        | 1245/7272 [5:39:52<26:44:12, 15.97s/it]                                                        {'loss': 2.4077, 'grad_norm': 8.064536094665527, 'learning_rate': 5e-05, 'epoch': 0.68, 'step': 1245, 'max_steps': 7272}
 17%|█▋        | 1245/7272 [5:39:52<26:44:12, 15.97s/it] 17%|█▋        | 1246/7272 [5:40:08<26:43:56, 15.97s/it]                                                        {'loss': 1.5558, 'grad_norm': 3.332441568374634, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1246, 'max_steps': 7272}
 17%|█▋        | 1246/7272 [5:40:08<26:43:56, 15.97s/it] 17%|█▋        | 1247/7272 [5:40:24<26:47:06, 16.00s/it]                                                        {'loss': 0.8804, 'grad_norm': 3.264704465866089, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1247, 'max_steps': 7272}
 17%|█▋        | 1247/7272 [5:40:24<26:47:06, 16.00s/it] 17%|█▋        | 1248/7272 [5:40:40<26:38:07, 15.92s/it]                                                        {'loss': 1.9843, 'grad_norm': 6.932947635650635, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1248, 'max_steps': 7272}
 17%|█▋        | 1248/7272 [5:40:40<26:38:07, 15.92s/it] 17%|█▋        | 1249/7272 [5:40:56<26:40:05, 15.94s/it]                                                        {'loss': 1.8538, 'grad_norm': 9.020630836486816, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1249, 'max_steps': 7272}
 17%|█▋        | 1249/7272 [5:40:56<26:40:05, 15.94s/it] 17%|█▋        | 1250/7272 [5:41:11<26:18:41, 15.73s/it]                                                        {'loss': 1.373, 'grad_norm': 3.5311598777770996, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1250, 'max_steps': 7272}
 17%|█▋        | 1250/7272 [5:41:11<26:18:41, 15.73s/it] 17%|█▋        | 1251/7272 [5:41:27<26:04:59, 15.60s/it]                                                        {'loss': 0.8991, 'grad_norm': 8.520214080810547, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1251, 'max_steps': 7272}
 17%|█▋        | 1251/7272 [5:41:27<26:04:59, 15.60s/it] 17%|█▋        | 1252/7272 [5:41:42<26:04:24, 15.59s/it]                                                        {'loss': 1.4466, 'grad_norm': 4.034725189208984, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1252, 'max_steps': 7272}
 17%|█▋        | 1252/7272 [5:41:42<26:04:24, 15.59s/it] 17%|█▋        | 1253/7272 [5:41:59<26:23:39, 15.79s/it]                                                        {'loss': 1.195, 'grad_norm': 11.762304306030273, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1253, 'max_steps': 7272}
 17%|█▋        | 1253/7272 [5:41:59<26:23:39, 15.79s/it] 17%|█▋        | 1254/7272 [5:42:15<26:33:18, 15.89s/it]                                                        {'loss': 2.1297, 'grad_norm': 4.339003086090088, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1254, 'max_steps': 7272}
 17%|█▋        | 1254/7272 [5:42:15<26:33:18, 15.89s/it] 17%|█▋        | 1255/7272 [5:42:30<26:22:47, 15.78s/it]                                                        {'loss': 1.3006, 'grad_norm': 6.963410377502441, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1255, 'max_steps': 7272}
 17%|█▋        | 1255/7272 [5:42:30<26:22:47, 15.78s/it] 17%|█▋        | 1256/7272 [5:42:46<26:16:06, 15.72s/it]                                                        {'loss': 2.1458, 'grad_norm': 13.088898658752441, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1256, 'max_steps': 7272}
 17%|█▋        | 1256/7272 [5:42:46<26:16:06, 15.72s/it] 17%|█▋        | 1257/7272 [5:43:01<26:06:44, 15.63s/it]                                                        {'loss': 2.3825, 'grad_norm': 9.975068092346191, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1257, 'max_steps': 7272}
 17%|█▋        | 1257/7272 [5:43:01<26:06:44, 15.63s/it] 17%|█▋        | 1258/7272 [5:43:17<26:02:39, 15.59s/it]                                                        {'loss': 2.5897, 'grad_norm': 4.897916316986084, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1258, 'max_steps': 7272}
 17%|█▋        | 1258/7272 [5:43:17<26:02:39, 15.59s/it] 17%|█▋        | 1259/7272 [5:43:33<26:24:19, 15.81s/it]                                                        {'loss': 1.261, 'grad_norm': 5.410141468048096, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1259, 'max_steps': 7272}
 17%|█▋        | 1259/7272 [5:43:33<26:24:19, 15.81s/it] 17%|█▋        | 1260/7272 [5:43:49<26:30:42, 15.88s/it]                                                        {'loss': 1.641, 'grad_norm': 4.532044887542725, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1260, 'max_steps': 7272}
 17%|█▋        | 1260/7272 [5:43:49<26:30:42, 15.88s/it] 17%|█▋        | 1261/7272 [5:44:05<26:32:56, 15.90s/it]                                                        {'loss': 1.0592, 'grad_norm': 3.3287265300750732, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1261, 'max_steps': 7272}
 17%|█▋        | 1261/7272 [5:44:05<26:32:56, 15.90s/it] 17%|█▋        | 1262/7272 [5:44:21<26:36:07, 15.93s/it]                                                        {'loss': 0.9714, 'grad_norm': 4.099239826202393, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1262, 'max_steps': 7272}
 17%|█▋        | 1262/7272 [5:44:21<26:36:07, 15.93s/it] 17%|█▋        | 1263/7272 [5:44:38<27:01:45, 16.19s/it]                                                        {'loss': 1.5432, 'grad_norm': 4.360426902770996, 'learning_rate': 5e-05, 'epoch': 0.69, 'step': 1263, 'max_steps': 7272}
 17%|█▋        | 1263/7272 [5:44:38<27:01:45, 16.19s/it] 17%|█▋        | 1264/7272 [5:44:54<26:58:26, 16.16s/it]                                                        {'loss': 1.1099, 'grad_norm': 7.079498291015625, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1264, 'max_steps': 7272}
 17%|█▋        | 1264/7272 [5:44:54<26:58:26, 16.16s/it] 17%|█▋        | 1265/7272 [5:45:10<26:47:48, 16.06s/it]                                                        {'loss': 2.4396, 'grad_norm': 8.874897956848145, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1265, 'max_steps': 7272}
 17%|█▋        | 1265/7272 [5:45:10<26:47:48, 16.06s/it] 17%|█▋        | 1266/7272 [5:45:26<26:47:12, 16.06s/it]                                                        {'loss': 2.4164, 'grad_norm': 6.668642520904541, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1266, 'max_steps': 7272}
 17%|█▋        | 1266/7272 [5:45:26<26:47:12, 16.06s/it] 17%|█▋        | 1267/7272 [5:45:42<26:57:39, 16.16s/it]                                                        {'loss': 1.0705, 'grad_norm': 4.592625141143799, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1267, 'max_steps': 7272}
 17%|█▋        | 1267/7272 [5:45:42<26:57:39, 16.16s/it] 17%|█▋        | 1268/7272 [5:45:58<26:43:51, 16.03s/it]                                                        {'loss': 2.0534, 'grad_norm': 10.6613187789917, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1268, 'max_steps': 7272}
 17%|█▋        | 1268/7272 [5:45:58<26:43:51, 16.03s/it] 17%|█▋        | 1269/7272 [5:46:14<26:46:28, 16.06s/it]                                                        {'loss': 1.5534, 'grad_norm': 6.830377101898193, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1269, 'max_steps': 7272}
 17%|█▋        | 1269/7272 [5:46:14<26:46:28, 16.06s/it] 17%|█▋        | 1270/7272 [5:46:30<26:50:09, 16.10s/it]                                                        {'loss': 1.8602, 'grad_norm': 4.161931991577148, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1270, 'max_steps': 7272}
 17%|█▋        | 1270/7272 [5:46:30<26:50:09, 16.10s/it] 17%|█▋        | 1271/7272 [5:46:46<26:40:23, 16.00s/it]                                                        {'loss': 2.637, 'grad_norm': 8.032846450805664, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1271, 'max_steps': 7272}
 17%|█▋        | 1271/7272 [5:46:46<26:40:23, 16.00s/it] 17%|█▋        | 1272/7272 [5:47:02<26:35:21, 15.95s/it]                                                        {'loss': 1.8736, 'grad_norm': 8.561102867126465, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1272, 'max_steps': 7272}
 17%|█▋        | 1272/7272 [5:47:02<26:35:21, 15.95s/it] 18%|█▊        | 1273/7272 [5:47:18<26:43:29, 16.04s/it]                                                        {'loss': 2.1923, 'grad_norm': 5.478533744812012, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1273, 'max_steps': 7272}
 18%|█▊        | 1273/7272 [5:47:18<26:43:29, 16.04s/it] 18%|█▊        | 1274/7272 [5:47:33<26:23:44, 15.84s/it]                                                        {'loss': 1.0815, 'grad_norm': 4.19325590133667, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1274, 'max_steps': 7272}
 18%|█▊        | 1274/7272 [5:47:33<26:23:44, 15.84s/it] 18%|█▊        | 1275/7272 [5:47:49<26:23:09, 15.84s/it]                                                        {'loss': 2.6668, 'grad_norm': 4.6316752433776855, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1275, 'max_steps': 7272}
 18%|█▊        | 1275/7272 [5:47:49<26:23:09, 15.84s/it] 18%|█▊        | 1276/7272 [5:48:06<26:37:45, 15.99s/it]                                                        {'loss': 1.4378, 'grad_norm': 4.4098286628723145, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1276, 'max_steps': 7272}
 18%|█▊        | 1276/7272 [5:48:06<26:37:45, 15.99s/it] 18%|█▊        | 1277/7272 [5:48:23<27:16:36, 16.38s/it]                                                        {'loss': 1.8682, 'grad_norm': 3.947098970413208, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1277, 'max_steps': 7272}
 18%|█▊        | 1277/7272 [5:48:23<27:16:36, 16.38s/it] 18%|█▊        | 1278/7272 [5:48:39<27:02:48, 16.24s/it]                                                        {'loss': 1.979, 'grad_norm': 10.007920265197754, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1278, 'max_steps': 7272}
 18%|█▊        | 1278/7272 [5:48:39<27:02:48, 16.24s/it] 18%|█▊        | 1279/7272 [5:48:55<27:07:17, 16.29s/it]                                                        {'loss': 1.5144, 'grad_norm': 3.6951136589050293, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1279, 'max_steps': 7272}
 18%|█▊        | 1279/7272 [5:48:55<27:07:17, 16.29s/it] 18%|█▊        | 1280/7272 [5:49:11<26:51:46, 16.14s/it]                                                        {'loss': 0.8721, 'grad_norm': 2.388345956802368, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1280, 'max_steps': 7272}
 18%|█▊        | 1280/7272 [5:49:11<26:51:46, 16.14s/it] 18%|█▊        | 1281/7272 [5:49:27<26:49:40, 16.12s/it]                                                        {'loss': 1.9383, 'grad_norm': 8.426959037780762, 'learning_rate': 5e-05, 'epoch': 0.7, 'step': 1281, 'max_steps': 7272}
 18%|█▊        | 1281/7272 [5:49:27<26:49:40, 16.12s/it] 18%|█▊        | 1282/7272 [5:49:43<26:45:53, 16.09s/it]                                                        {'loss': 2.1854, 'grad_norm': 5.49202823638916, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1282, 'max_steps': 7272}
 18%|█▊        | 1282/7272 [5:49:43<26:45:53, 16.09s/it] 18%|█▊        | 1283/7272 [5:49:59<26:43:21, 16.06s/it]                                                        {'loss': 1.9923, 'grad_norm': 7.101489067077637, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1283, 'max_steps': 7272}
 18%|█▊        | 1283/7272 [5:49:59<26:43:21, 16.06s/it] 18%|█▊        | 1284/7272 [5:50:15<26:51:29, 16.15s/it]                                                        {'loss': 1.639, 'grad_norm': 5.156407356262207, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1284, 'max_steps': 7272}
 18%|█▊        | 1284/7272 [5:50:15<26:51:29, 16.15s/it] 18%|█▊        | 1285/7272 [5:50:31<26:44:03, 16.08s/it]                                                        {'loss': 2.0643, 'grad_norm': 3.774393081665039, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1285, 'max_steps': 7272}
 18%|█▊        | 1285/7272 [5:50:31<26:44:03, 16.08s/it] 18%|█▊        | 1286/7272 [5:50:47<26:30:07, 15.94s/it]                                                        {'loss': 0.9524, 'grad_norm': 2.0835134983062744, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1286, 'max_steps': 7272}
 18%|█▊        | 1286/7272 [5:50:47<26:30:07, 15.94s/it] 18%|█▊        | 1287/7272 [5:51:03<26:23:28, 15.87s/it]                                                        {'loss': 3.1308, 'grad_norm': 9.407381057739258, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1287, 'max_steps': 7272}
 18%|█▊        | 1287/7272 [5:51:03<26:23:28, 15.87s/it] 18%|█▊        | 1288/7272 [5:51:18<26:09:50, 15.74s/it]                                                        {'loss': 0.7718, 'grad_norm': 1.774608850479126, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1288, 'max_steps': 7272}
 18%|█▊        | 1288/7272 [5:51:18<26:09:50, 15.74s/it] 18%|█▊        | 1289/7272 [5:51:34<25:58:58, 15.63s/it]                                                        {'loss': 1.4328, 'grad_norm': 7.436120510101318, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1289, 'max_steps': 7272}
 18%|█▊        | 1289/7272 [5:51:34<25:58:58, 15.63s/it] 18%|█▊        | 1290/7272 [5:51:49<26:04:01, 15.69s/it]                                                        {'loss': 0.7365, 'grad_norm': 4.034664154052734, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1290, 'max_steps': 7272}
 18%|█▊        | 1290/7272 [5:51:49<26:04:01, 15.69s/it] 18%|█▊        | 1291/7272 [5:52:06<26:23:23, 15.88s/it]                                                        {'loss': 1.5602, 'grad_norm': 6.0354228019714355, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1291, 'max_steps': 7272}
 18%|█▊        | 1291/7272 [5:52:06<26:23:23, 15.88s/it] 18%|█▊        | 1292/7272 [5:52:23<26:52:52, 16.18s/it]                                                        {'loss': 1.6693, 'grad_norm': 3.923330068588257, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1292, 'max_steps': 7272}
 18%|█▊        | 1292/7272 [5:52:23<26:52:52, 16.18s/it] 18%|█▊        | 1293/7272 [5:52:39<26:47:38, 16.13s/it]                                                        {'loss': 1.7384, 'grad_norm': 5.8577470779418945, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1293, 'max_steps': 7272}
 18%|█▊        | 1293/7272 [5:52:39<26:47:38, 16.13s/it] 18%|█▊        | 1294/7272 [5:52:55<26:42:13, 16.08s/it]                                                        {'loss': 2.0679, 'grad_norm': 3.4486539363861084, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1294, 'max_steps': 7272}
 18%|█▊        | 1294/7272 [5:52:55<26:42:13, 16.08s/it] 18%|█▊        | 1295/7272 [5:53:10<26:31:08, 15.97s/it]                                                        {'loss': 1.2342, 'grad_norm': 2.927504301071167, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1295, 'max_steps': 7272}
 18%|█▊        | 1295/7272 [5:53:10<26:31:08, 15.97s/it] 18%|█▊        | 1296/7272 [5:53:26<26:28:12, 15.95s/it]                                                        {'loss': 2.2155, 'grad_norm': 10.02432632446289, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1296, 'max_steps': 7272}
 18%|█▊        | 1296/7272 [5:53:26<26:28:12, 15.95s/it] 18%|█▊        | 1297/7272 [5:53:42<26:22:10, 15.89s/it]                                                        {'loss': 0.7926, 'grad_norm': 2.5596821308135986, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1297, 'max_steps': 7272}
 18%|█▊        | 1297/7272 [5:53:42<26:22:10, 15.89s/it] 18%|█▊        | 1298/7272 [5:53:58<26:39:41, 16.07s/it]                                                        {'loss': 1.0069, 'grad_norm': 11.736279487609863, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1298, 'max_steps': 7272}
 18%|█▊        | 1298/7272 [5:53:58<26:39:41, 16.07s/it] 18%|█▊        | 1299/7272 [5:54:14<26:41:36, 16.09s/it]                                                        {'loss': 2.3884, 'grad_norm': 5.2062225341796875, 'learning_rate': 5e-05, 'epoch': 0.71, 'step': 1299, 'max_steps': 7272}
 18%|█▊        | 1299/7272 [5:54:14<26:41:36, 16.09s/it] 18%|█▊        | 1300/7272 [5:54:31<26:47:11, 16.15s/it]                                                        {'loss': 1.3748, 'grad_norm': 5.113093376159668, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1300, 'max_steps': 7272}
 18%|█▊        | 1300/7272 [5:54:31<26:47:11, 16.15s/it] 18%|█▊        | 1301/7272 [5:54:47<26:48:30, 16.16s/it]                                                        {'loss': 2.1007, 'grad_norm': 3.8909692764282227, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1301, 'max_steps': 7272}
 18%|█▊        | 1301/7272 [5:54:47<26:48:30, 16.16s/it] 18%|█▊        | 1302/7272 [5:55:03<26:42:45, 16.11s/it]                                                        {'loss': 1.6842, 'grad_norm': 7.499963283538818, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1302, 'max_steps': 7272}
 18%|█▊        | 1302/7272 [5:55:03<26:42:45, 16.11s/it] 18%|█▊        | 1303/7272 [5:55:19<26:39:11, 16.07s/it]                                                        {'loss': 1.4116, 'grad_norm': 5.665261268615723, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1303, 'max_steps': 7272}
 18%|█▊        | 1303/7272 [5:55:19<26:39:11, 16.07s/it] 18%|█▊        | 1304/7272 [5:55:35<26:44:46, 16.13s/it]                                                        {'loss': 1.2622, 'grad_norm': 4.697883129119873, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1304, 'max_steps': 7272}
 18%|█▊        | 1304/7272 [5:55:35<26:44:46, 16.13s/it] 18%|█▊        | 1305/7272 [5:55:51<26:25:14, 15.94s/it]                                                        {'loss': 2.8871, 'grad_norm': 6.179064750671387, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1305, 'max_steps': 7272}
 18%|█▊        | 1305/7272 [5:55:51<26:25:14, 15.94s/it] 18%|█▊        | 1306/7272 [5:56:06<26:05:23, 15.74s/it]                                                        {'loss': 1.819, 'grad_norm': 8.207645416259766, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1306, 'max_steps': 7272}
 18%|█▊        | 1306/7272 [5:56:06<26:05:23, 15.74s/it] 18%|█▊        | 1307/7272 [5:56:22<26:12:00, 15.81s/it]                                                        {'loss': 0.9722, 'grad_norm': 5.548501968383789, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1307, 'max_steps': 7272}
 18%|█▊        | 1307/7272 [5:56:22<26:12:00, 15.81s/it] 18%|█▊        | 1308/7272 [5:56:37<25:52:56, 15.62s/it]                                                        {'loss': 4.1087, 'grad_norm': 15.583568572998047, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1308, 'max_steps': 7272}
 18%|█▊        | 1308/7272 [5:56:37<25:52:56, 15.62s/it] 18%|█▊        | 1309/7272 [5:56:52<25:40:56, 15.50s/it]                                                        {'loss': 0.6665, 'grad_norm': 1.849096417427063, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1309, 'max_steps': 7272}
 18%|█▊        | 1309/7272 [5:56:52<25:40:56, 15.50s/it] 18%|█▊        | 1310/7272 [5:57:08<25:38:05, 15.48s/it]                                                        {'loss': 0.8298, 'grad_norm': 2.0963335037231445, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1310, 'max_steps': 7272}
 18%|█▊        | 1310/7272 [5:57:08<25:38:05, 15.48s/it] 18%|█▊        | 1311/7272 [5:57:24<25:55:45, 15.66s/it]                                                        {'loss': 1.3617, 'grad_norm': 4.281570911407471, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1311, 'max_steps': 7272}
 18%|█▊        | 1311/7272 [5:57:24<25:55:45, 15.66s/it] 18%|█▊        | 1312/7272 [5:57:40<26:03:38, 15.74s/it]                                                        {'loss': 1.459, 'grad_norm': 4.0640668869018555, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1312, 'max_steps': 7272}
 18%|█▊        | 1312/7272 [5:57:40<26:03:38, 15.74s/it] 18%|█▊        | 1313/7272 [5:57:56<26:10:09, 15.81s/it]                                                        {'loss': 1.7487, 'grad_norm': 7.4120659828186035, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1313, 'max_steps': 7272}
 18%|█▊        | 1313/7272 [5:57:56<26:10:09, 15.81s/it] 18%|█▊        | 1314/7272 [5:58:12<26:14:35, 15.86s/it]                                                        {'loss': 2.5141, 'grad_norm': 4.6870436668396, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1314, 'max_steps': 7272}
 18%|█▊        | 1314/7272 [5:58:12<26:14:35, 15.86s/it] 18%|█▊        | 1315/7272 [5:58:28<26:12:39, 15.84s/it]                                                        {'loss': 0.7627, 'grad_norm': 1.9762916564941406, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1315, 'max_steps': 7272}
 18%|█▊        | 1315/7272 [5:58:28<26:12:39, 15.84s/it] 18%|█▊        | 1316/7272 [5:58:43<26:10:58, 15.83s/it]                                                        {'loss': 3.0726, 'grad_norm': 6.543599605560303, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1316, 'max_steps': 7272}
 18%|█▊        | 1316/7272 [5:58:43<26:10:58, 15.83s/it] 18%|█▊        | 1317/7272 [5:58:59<26:08:11, 15.80s/it]                                                        {'loss': 2.4858, 'grad_norm': 4.1785807609558105, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1317, 'max_steps': 7272}
 18%|█▊        | 1317/7272 [5:58:59<26:08:11, 15.80s/it] 18%|█▊        | 1318/7272 [5:59:15<26:16:51, 15.89s/it]                                                        {'loss': 2.135, 'grad_norm': 11.086891174316406, 'learning_rate': 5e-05, 'epoch': 0.72, 'step': 1318, 'max_steps': 7272}
 18%|█▊        | 1318/7272 [5:59:15<26:16:51, 15.89s/it] 18%|█▊        | 1319/7272 [5:59:31<26:12:23, 15.85s/it]                                                        {'loss': 2.3178, 'grad_norm': 3.985738754272461, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1319, 'max_steps': 7272}
 18%|█▊        | 1319/7272 [5:59:31<26:12:23, 15.85s/it] 18%|█▊        | 1320/7272 [5:59:47<26:10:48, 15.83s/it]                                                        {'loss': 3.2648, 'grad_norm': 10.35181999206543, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1320, 'max_steps': 7272}
 18%|█▊        | 1320/7272 [5:59:47<26:10:48, 15.83s/it] 18%|█▊        | 1321/7272 [6:00:02<25:59:56, 15.73s/it]                                                        {'loss': 2.4113, 'grad_norm': 6.049120903015137, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1321, 'max_steps': 7272}
 18%|█▊        | 1321/7272 [6:00:02<25:59:56, 15.73s/it] 18%|█▊        | 1322/7272 [6:00:18<25:57:56, 15.71s/it]                                                        {'loss': 1.9788, 'grad_norm': 3.9437029361724854, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1322, 'max_steps': 7272}
 18%|█▊        | 1322/7272 [6:00:18<25:57:56, 15.71s/it] 18%|█▊        | 1323/7272 [6:00:33<25:44:05, 15.57s/it]                                                        {'loss': 2.4056, 'grad_norm': 8.076560020446777, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1323, 'max_steps': 7272}
 18%|█▊        | 1323/7272 [6:00:33<25:44:05, 15.57s/it] 18%|█▊        | 1324/7272 [6:00:49<25:57:28, 15.71s/it]                                                        {'loss': 3.0408, 'grad_norm': 6.7798662185668945, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1324, 'max_steps': 7272}
 18%|█▊        | 1324/7272 [6:00:49<25:57:28, 15.71s/it] 18%|█▊        | 1325/7272 [6:01:05<26:01:29, 15.75s/it]                                                        {'loss': 1.3012, 'grad_norm': 4.163507461547852, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1325, 'max_steps': 7272}
 18%|█▊        | 1325/7272 [6:01:05<26:01:29, 15.75s/it] 18%|█▊        | 1326/7272 [6:01:21<25:58:55, 15.73s/it]                                                        {'loss': 1.1681, 'grad_norm': 3.4968371391296387, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1326, 'max_steps': 7272}
 18%|█▊        | 1326/7272 [6:01:21<25:58:55, 15.73s/it] 18%|█▊        | 1327/7272 [6:01:37<26:04:52, 15.79s/it]                                                        {'loss': 3.2728, 'grad_norm': 7.341248512268066, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1327, 'max_steps': 7272}
 18%|█▊        | 1327/7272 [6:01:37<26:04:52, 15.79s/it] 18%|█▊        | 1328/7272 [6:01:53<26:16:09, 15.91s/it]                                                        {'loss': 1.9641, 'grad_norm': 5.070734977722168, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1328, 'max_steps': 7272}
 18%|█▊        | 1328/7272 [6:01:53<26:16:09, 15.91s/it] 18%|█▊        | 1329/7272 [6:02:09<26:35:29, 16.11s/it]                                                        {'loss': 2.3126, 'grad_norm': 7.159862995147705, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1329, 'max_steps': 7272}
 18%|█▊        | 1329/7272 [6:02:09<26:35:29, 16.11s/it] 18%|█▊        | 1330/7272 [6:02:26<26:43:09, 16.19s/it]                                                        {'loss': 1.4401, 'grad_norm': 7.007406711578369, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1330, 'max_steps': 7272}
 18%|█▊        | 1330/7272 [6:02:26<26:43:09, 16.19s/it] 18%|█▊        | 1331/7272 [6:02:41<26:23:46, 15.99s/it]                                                        {'loss': 3.0304, 'grad_norm': 5.144885540008545, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1331, 'max_steps': 7272}
 18%|█▊        | 1331/7272 [6:02:41<26:23:46, 15.99s/it] 18%|█▊        | 1332/7272 [6:02:57<26:21:00, 15.97s/it]                                                        {'loss': 2.0367, 'grad_norm': 8.424918174743652, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1332, 'max_steps': 7272}
 18%|█▊        | 1332/7272 [6:02:57<26:21:00, 15.97s/it] 18%|█▊        | 1333/7272 [6:03:13<26:28:47, 16.05s/it]                                                        {'loss': 2.886, 'grad_norm': 5.103816032409668, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1333, 'max_steps': 7272}
 18%|█▊        | 1333/7272 [6:03:13<26:28:47, 16.05s/it] 18%|█▊        | 1334/7272 [6:03:30<26:50:17, 16.27s/it]                                                        {'loss': 2.0724, 'grad_norm': 3.0445473194122314, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1334, 'max_steps': 7272}
 18%|█▊        | 1334/7272 [6:03:30<26:50:17, 16.27s/it] 18%|█▊        | 1335/7272 [6:03:47<26:55:46, 16.33s/it]                                                        {'loss': 1.8957, 'grad_norm': 6.542503356933594, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1335, 'max_steps': 7272}
 18%|█▊        | 1335/7272 [6:03:47<26:55:46, 16.33s/it] 18%|█▊        | 1336/7272 [6:04:03<26:50:54, 16.28s/it]                                                        {'loss': 1.1379, 'grad_norm': 2.553255081176758, 'learning_rate': 5e-05, 'epoch': 0.73, 'step': 1336, 'max_steps': 7272}
 18%|█▊        | 1336/7272 [6:04:03<26:50:54, 16.28s/it] 18%|█▊        | 1337/7272 [6:04:20<27:04:07, 16.42s/it]                                                        {'loss': 2.7755, 'grad_norm': 3.961414098739624, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1337, 'max_steps': 7272}
 18%|█▊        | 1337/7272 [6:04:20<27:04:07, 16.42s/it] 18%|█▊        | 1338/7272 [6:04:36<26:59:20, 16.37s/it]                                                        {'loss': 1.0049, 'grad_norm': 4.324037551879883, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1338, 'max_steps': 7272}
 18%|█▊        | 1338/7272 [6:04:36<26:59:20, 16.37s/it] 18%|█▊        | 1339/7272 [6:04:52<26:52:46, 16.31s/it]                                                        {'loss': 0.9868, 'grad_norm': 3.4390456676483154, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1339, 'max_steps': 7272}
 18%|█▊        | 1339/7272 [6:04:52<26:52:46, 16.31s/it] 18%|█▊        | 1340/7272 [6:05:08<26:49:23, 16.28s/it]                                                        {'loss': 2.9754, 'grad_norm': 9.311193466186523, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1340, 'max_steps': 7272}
 18%|█▊        | 1340/7272 [6:05:08<26:49:23, 16.28s/it] 18%|█▊        | 1341/7272 [6:05:24<26:33:23, 16.12s/it]                                                        {'loss': 0.6324, 'grad_norm': 2.7848544120788574, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1341, 'max_steps': 7272}
 18%|█▊        | 1341/7272 [6:05:24<26:33:23, 16.12s/it] 18%|█▊        | 1342/7272 [6:05:40<26:26:41, 16.05s/it]                                                        {'loss': 1.9873, 'grad_norm': 5.385580062866211, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1342, 'max_steps': 7272}
 18%|█▊        | 1342/7272 [6:05:40<26:26:41, 16.05s/it] 18%|█▊        | 1343/7272 [6:05:56<26:23:43, 16.03s/it]                                                        {'loss': 1.6977, 'grad_norm': 8.59349250793457, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1343, 'max_steps': 7272}
 18%|█▊        | 1343/7272 [6:05:56<26:23:43, 16.03s/it] 18%|█▊        | 1344/7272 [6:06:12<26:16:01, 15.95s/it]                                                        {'loss': 2.2308, 'grad_norm': 5.882961750030518, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1344, 'max_steps': 7272}
 18%|█▊        | 1344/7272 [6:06:12<26:16:01, 15.95s/it] 18%|█▊        | 1345/7272 [6:06:27<25:51:18, 15.70s/it]                                                        {'loss': 3.2854, 'grad_norm': 7.866985321044922, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1345, 'max_steps': 7272}
 18%|█▊        | 1345/7272 [6:06:27<25:51:18, 15.70s/it] 19%|█▊        | 1346/7272 [6:06:43<26:16:45, 15.96s/it]                                                        {'loss': 1.7179, 'grad_norm': 9.492974281311035, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1346, 'max_steps': 7272}
 19%|█▊        | 1346/7272 [6:06:43<26:16:45, 15.96s/it] 19%|█▊        | 1347/7272 [6:06:59<26:06:02, 15.86s/it]                                                        {'loss': 1.0235, 'grad_norm': 7.319666385650635, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1347, 'max_steps': 7272}
 19%|█▊        | 1347/7272 [6:06:59<26:06:02, 15.86s/it] 19%|█▊        | 1348/7272 [6:07:14<25:51:46, 15.72s/it]                                                        {'loss': 1.4707, 'grad_norm': 8.243017196655273, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1348, 'max_steps': 7272}
 19%|█▊        | 1348/7272 [6:07:14<25:51:46, 15.72s/it] 19%|█▊        | 1349/7272 [6:07:30<25:50:25, 15.71s/it]                                                        {'loss': 0.8944, 'grad_norm': 6.406596660614014, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1349, 'max_steps': 7272}
 19%|█▊        | 1349/7272 [6:07:30<25:50:25, 15.71s/it] 19%|█▊        | 1350/7272 [6:07:45<25:33:20, 15.54s/it]                                                        {'loss': 2.6894, 'grad_norm': 6.416994094848633, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1350, 'max_steps': 7272}
 19%|█▊        | 1350/7272 [6:07:45<25:33:20, 15.54s/it] 19%|█▊        | 1351/7272 [6:08:01<25:40:24, 15.61s/it]                                                        {'loss': 2.235, 'grad_norm': 5.764199256896973, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1351, 'max_steps': 7272}
 19%|█▊        | 1351/7272 [6:08:01<25:40:24, 15.61s/it] 19%|█▊        | 1352/7272 [6:08:16<25:35:48, 15.57s/it]                                                        {'loss': 1.2358, 'grad_norm': 4.45029354095459, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1352, 'max_steps': 7272}
 19%|█▊        | 1352/7272 [6:08:16<25:35:48, 15.57s/it] 19%|█▊        | 1353/7272 [6:08:33<26:04:06, 15.86s/it]                                                        {'loss': 3.16, 'grad_norm': 6.261659145355225, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1353, 'max_steps': 7272}
 19%|█▊        | 1353/7272 [6:08:33<26:04:06, 15.86s/it] 19%|█▊        | 1354/7272 [6:08:49<26:06:00, 15.88s/it]                                                        {'loss': 0.948, 'grad_norm': 1.9046846628189087, 'learning_rate': 5e-05, 'epoch': 0.74, 'step': 1354, 'max_steps': 7272}
 19%|█▊        | 1354/7272 [6:08:49<26:06:00, 15.88s/it] 19%|█▊        | 1355/7272 [6:09:05<26:03:56, 15.86s/it]                                                        {'loss': 1.4662, 'grad_norm': 3.187105894088745, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1355, 'max_steps': 7272}
 19%|█▊        | 1355/7272 [6:09:05<26:03:56, 15.86s/it] 19%|█▊        | 1356/7272 [6:09:20<25:52:50, 15.75s/it]                                                        {'loss': 0.5967, 'grad_norm': 5.359979629516602, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1356, 'max_steps': 7272}
 19%|█▊        | 1356/7272 [6:09:20<25:52:50, 15.75s/it] 19%|█▊        | 1357/7272 [6:09:36<25:41:49, 15.64s/it]                                                        {'loss': 2.6049, 'grad_norm': 7.129875659942627, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1357, 'max_steps': 7272}
 19%|█▊        | 1357/7272 [6:09:36<25:41:49, 15.64s/it] 19%|█▊        | 1358/7272 [6:09:52<25:57:44, 15.80s/it]                                                        {'loss': 1.8434, 'grad_norm': 5.668824672698975, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1358, 'max_steps': 7272}
 19%|█▊        | 1358/7272 [6:09:52<25:57:44, 15.80s/it] 19%|█▊        | 1359/7272 [6:10:08<26:04:52, 15.88s/it]                                                        {'loss': 1.1925, 'grad_norm': 2.719217538833618, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1359, 'max_steps': 7272}
 19%|█▊        | 1359/7272 [6:10:08<26:04:52, 15.88s/it] 19%|█▊        | 1360/7272 [6:10:24<26:16:02, 15.99s/it]                                                        {'loss': 0.8091, 'grad_norm': 5.84881067276001, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1360, 'max_steps': 7272}
 19%|█▊        | 1360/7272 [6:10:24<26:16:02, 15.99s/it] 19%|█▊        | 1361/7272 [6:10:41<26:32:33, 16.17s/it]                                                        {'loss': 1.0258, 'grad_norm': 10.023526191711426, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1361, 'max_steps': 7272}
 19%|█▊        | 1361/7272 [6:10:41<26:32:33, 16.17s/it] 19%|█▊        | 1362/7272 [6:10:57<26:33:28, 16.18s/it]                                                        {'loss': 1.0773, 'grad_norm': 3.7979090213775635, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1362, 'max_steps': 7272}
 19%|█▊        | 1362/7272 [6:10:57<26:33:28, 16.18s/it] 19%|█▊        | 1363/7272 [6:11:12<26:09:42, 15.94s/it]                                                        {'loss': 1.6705, 'grad_norm': 13.204360008239746, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1363, 'max_steps': 7272}
 19%|█▊        | 1363/7272 [6:11:12<26:09:42, 15.94s/it] 19%|█▉        | 1364/7272 [6:11:28<26:07:00, 15.91s/it]                                                        {'loss': 1.5508, 'grad_norm': 6.208970069885254, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1364, 'max_steps': 7272}
 19%|█▉        | 1364/7272 [6:11:28<26:07:00, 15.91s/it] 19%|█▉        | 1365/7272 [6:11:44<26:12:43, 15.97s/it]                                                        {'loss': 0.9953, 'grad_norm': 3.5841026306152344, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1365, 'max_steps': 7272}
 19%|█▉        | 1365/7272 [6:11:44<26:12:43, 15.97s/it] 19%|█▉        | 1366/7272 [6:12:00<25:55:41, 15.80s/it]                                                        {'loss': 0.9034, 'grad_norm': 3.3333163261413574, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1366, 'max_steps': 7272}
 19%|█▉        | 1366/7272 [6:12:00<25:55:41, 15.80s/it] 19%|█▉        | 1367/7272 [6:12:15<25:54:29, 15.80s/it]                                                        {'loss': 1.9267, 'grad_norm': 5.198583126068115, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1367, 'max_steps': 7272}
 19%|█▉        | 1367/7272 [6:12:15<25:54:29, 15.80s/it] 19%|█▉        | 1368/7272 [6:12:31<25:52:36, 15.78s/it]                                                        {'loss': 1.9726, 'grad_norm': 6.3141560554504395, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1368, 'max_steps': 7272}
 19%|█▉        | 1368/7272 [6:12:31<25:52:36, 15.78s/it] 19%|█▉        | 1369/7272 [6:12:47<25:57:11, 15.83s/it]                                                        {'loss': 3.2785, 'grad_norm': 8.703219413757324, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1369, 'max_steps': 7272}
 19%|█▉        | 1369/7272 [6:12:47<25:57:11, 15.83s/it] 19%|█▉        | 1370/7272 [6:13:03<26:05:31, 15.92s/it]                                                        {'loss': 2.4273, 'grad_norm': 3.7984461784362793, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1370, 'max_steps': 7272}
 19%|█▉        | 1370/7272 [6:13:03<26:05:31, 15.92s/it] 19%|█▉        | 1371/7272 [6:13:19<25:48:42, 15.75s/it]                                                        {'loss': 1.1181, 'grad_norm': 7.728609561920166, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1371, 'max_steps': 7272}
 19%|█▉        | 1371/7272 [6:13:19<25:48:42, 15.75s/it] 19%|█▉        | 1372/7272 [6:13:34<25:36:35, 15.63s/it]                                                        {'loss': 1.4092, 'grad_norm': 4.391140937805176, 'learning_rate': 5e-05, 'epoch': 0.75, 'step': 1372, 'max_steps': 7272}
 19%|█▉        | 1372/7272 [6:13:34<25:36:35, 15.63s/it] 19%|█▉        | 1373/7272 [6:13:49<25:35:09, 15.61s/it]                                                        {'loss': 1.8076, 'grad_norm': 5.986813545227051, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1373, 'max_steps': 7272}
 19%|█▉        | 1373/7272 [6:13:49<25:35:09, 15.61s/it] 19%|█▉        | 1374/7272 [6:14:05<25:36:23, 15.63s/it]                                                        {'loss': 1.666, 'grad_norm': 18.463199615478516, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1374, 'max_steps': 7272}
 19%|█▉        | 1374/7272 [6:14:05<25:36:23, 15.63s/it] 19%|█▉        | 1375/7272 [6:14:21<25:48:35, 15.76s/it]                                                        {'loss': 1.4256, 'grad_norm': 13.779491424560547, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1375, 'max_steps': 7272}
 19%|█▉        | 1375/7272 [6:14:21<25:48:35, 15.76s/it] 19%|█▉        | 1376/7272 [6:14:37<25:48:50, 15.76s/it]                                                        {'loss': 0.6844, 'grad_norm': 2.134772777557373, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1376, 'max_steps': 7272}
 19%|█▉        | 1376/7272 [6:14:37<25:48:50, 15.76s/it] 19%|█▉        | 1377/7272 [6:14:54<26:20:01, 16.08s/it]                                                        {'loss': 1.6989, 'grad_norm': 4.429727077484131, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1377, 'max_steps': 7272}
 19%|█▉        | 1377/7272 [6:14:54<26:20:01, 16.08s/it] 19%|█▉        | 1378/7272 [6:15:09<25:55:33, 15.84s/it]                                                        {'loss': 3.3258, 'grad_norm': 6.213925361633301, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1378, 'max_steps': 7272}
 19%|█▉        | 1378/7272 [6:15:09<25:55:33, 15.84s/it] 19%|█▉        | 1379/7272 [6:15:24<25:35:14, 15.63s/it]                                                        {'loss': 1.9368, 'grad_norm': 2.889714479446411, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1379, 'max_steps': 7272}
 19%|█▉        | 1379/7272 [6:15:24<25:35:14, 15.63s/it] 19%|█▉        | 1380/7272 [6:15:40<25:35:12, 15.63s/it]                                                        {'loss': 0.7306, 'grad_norm': 1.7523142099380493, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1380, 'max_steps': 7272}
 19%|█▉        | 1380/7272 [6:15:40<25:35:12, 15.63s/it] 19%|█▉        | 1381/7272 [6:15:56<25:43:58, 15.73s/it]                                                        {'loss': 3.4525, 'grad_norm': 8.081905364990234, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1381, 'max_steps': 7272}
 19%|█▉        | 1381/7272 [6:15:56<25:43:58, 15.73s/it] 19%|█▉        | 1382/7272 [6:16:11<25:26:57, 15.55s/it]                                                        {'loss': 2.2571, 'grad_norm': 8.455611228942871, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1382, 'max_steps': 7272}
 19%|█▉        | 1382/7272 [6:16:11<25:26:57, 15.55s/it] 19%|█▉        | 1383/7272 [6:16:26<25:24:28, 15.53s/it]                                                        {'loss': 1.8721, 'grad_norm': 7.626218795776367, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1383, 'max_steps': 7272}
 19%|█▉        | 1383/7272 [6:16:26<25:24:28, 15.53s/it] 19%|█▉        | 1384/7272 [6:16:42<25:34:51, 15.64s/it]                                                        {'loss': 1.2607, 'grad_norm': 4.211886882781982, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1384, 'max_steps': 7272}
 19%|█▉        | 1384/7272 [6:16:42<25:34:51, 15.64s/it] 19%|█▉        | 1385/7272 [6:16:58<25:25:51, 15.55s/it]                                                        {'loss': 1.9048, 'grad_norm': 5.656683444976807, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1385, 'max_steps': 7272}
 19%|█▉        | 1385/7272 [6:16:58<25:25:51, 15.55s/it] 19%|█▉        | 1386/7272 [6:17:13<25:33:26, 15.63s/it]                                                        {'loss': 0.6161, 'grad_norm': 2.9316132068634033, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1386, 'max_steps': 7272}
 19%|█▉        | 1386/7272 [6:17:13<25:33:26, 15.63s/it] 19%|█▉        | 1387/7272 [6:17:29<25:38:58, 15.69s/it]                                                        {'loss': 2.1154, 'grad_norm': 4.239867210388184, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1387, 'max_steps': 7272}
 19%|█▉        | 1387/7272 [6:17:29<25:38:58, 15.69s/it] 19%|█▉        | 1388/7272 [6:17:45<25:44:48, 15.75s/it]                                                        {'loss': 1.6962, 'grad_norm': 7.489970684051514, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1388, 'max_steps': 7272}
 19%|█▉        | 1388/7272 [6:17:45<25:44:48, 15.75s/it] 19%|█▉        | 1389/7272 [6:18:01<25:42:20, 15.73s/it]                                                        {'loss': 1.121, 'grad_norm': 5.765007019042969, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1389, 'max_steps': 7272}
 19%|█▉        | 1389/7272 [6:18:01<25:42:20, 15.73s/it] 19%|█▉        | 1390/7272 [6:18:18<26:11:21, 16.03s/it]                                                        {'loss': 2.6318, 'grad_norm': 3.5245578289031982, 'learning_rate': 5e-05, 'epoch': 0.76, 'step': 1390, 'max_steps': 7272}
 19%|█▉        | 1390/7272 [6:18:18<26:11:21, 16.03s/it] 19%|█▉        | 1391/7272 [6:18:33<25:58:22, 15.90s/it]                                                        {'loss': 0.8076, 'grad_norm': 2.3718838691711426, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1391, 'max_steps': 7272}
 19%|█▉        | 1391/7272 [6:18:33<25:58:22, 15.90s/it] 19%|█▉        | 1392/7272 [6:18:49<25:53:06, 15.85s/it]                                                        {'loss': 2.1757, 'grad_norm': 5.80844783782959, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1392, 'max_steps': 7272}
 19%|█▉        | 1392/7272 [6:18:49<25:53:06, 15.85s/it] 19%|█▉        | 1393/7272 [6:19:06<26:24:58, 16.18s/it]                                                        {'loss': 1.802, 'grad_norm': 4.30517578125, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1393, 'max_steps': 7272}
 19%|█▉        | 1393/7272 [6:19:06<26:24:58, 16.18s/it] 19%|█▉        | 1394/7272 [6:19:22<26:18:36, 16.11s/it]                                                        {'loss': 1.7595, 'grad_norm': 5.192337512969971, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1394, 'max_steps': 7272}
 19%|█▉        | 1394/7272 [6:19:22<26:18:36, 16.11s/it] 19%|█▉        | 1395/7272 [6:19:38<26:28:57, 16.22s/it]                                                        {'loss': 2.3133, 'grad_norm': 12.094326972961426, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1395, 'max_steps': 7272}
 19%|█▉        | 1395/7272 [6:19:38<26:28:57, 16.22s/it] 19%|█▉        | 1396/7272 [6:19:54<26:14:00, 16.07s/it]                                                        {'loss': 1.3633, 'grad_norm': 4.604868412017822, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1396, 'max_steps': 7272}
 19%|█▉        | 1396/7272 [6:19:54<26:14:00, 16.07s/it] 19%|█▉        | 1397/7272 [6:20:09<25:55:10, 15.88s/it]                                                        {'loss': 2.4287, 'grad_norm': 4.434527397155762, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1397, 'max_steps': 7272}
 19%|█▉        | 1397/7272 [6:20:09<25:55:10, 15.88s/it] 19%|█▉        | 1398/7272 [6:20:25<25:52:52, 15.86s/it]                                                        {'loss': 1.7168, 'grad_norm': 6.501522064208984, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1398, 'max_steps': 7272}
 19%|█▉        | 1398/7272 [6:20:25<25:52:52, 15.86s/it] 19%|█▉        | 1399/7272 [6:20:41<25:58:54, 15.93s/it]                                                        {'loss': 0.5068, 'grad_norm': 8.12059211730957, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1399, 'max_steps': 7272}
 19%|█▉        | 1399/7272 [6:20:41<25:58:54, 15.93s/it] 19%|█▉        | 1400/7272 [6:20:57<25:47:10, 15.81s/it]                                                        {'loss': 1.9979, 'grad_norm': 4.731304168701172, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1400, 'max_steps': 7272}
 19%|█▉        | 1400/7272 [6:20:57<25:47:10, 15.81s/it] 19%|█▉        | 1401/7272 [6:21:13<25:45:54, 15.80s/it]                                                        {'loss': 2.0424, 'grad_norm': 3.9835023880004883, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1401, 'max_steps': 7272}
 19%|█▉        | 1401/7272 [6:21:13<25:45:54, 15.80s/it] 19%|█▉        | 1402/7272 [6:21:28<25:33:39, 15.68s/it]                                                        {'loss': 1.5343, 'grad_norm': 2.527683734893799, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1402, 'max_steps': 7272}
 19%|█▉        | 1402/7272 [6:21:28<25:33:39, 15.68s/it] 19%|█▉        | 1403/7272 [6:21:44<25:37:01, 15.71s/it]                                                        {'loss': 1.6246, 'grad_norm': 8.68333625793457, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1403, 'max_steps': 7272}
 19%|█▉        | 1403/7272 [6:21:44<25:37:01, 15.71s/it] 19%|█▉        | 1404/7272 [6:22:00<25:43:42, 15.78s/it]                                                        {'loss': 1.3429, 'grad_norm': 3.64574933052063, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1404, 'max_steps': 7272}
 19%|█▉        | 1404/7272 [6:22:00<25:43:42, 15.78s/it] 19%|█▉        | 1405/7272 [6:22:15<25:23:33, 15.58s/it]                                                        {'loss': 2.6216, 'grad_norm': 9.638184547424316, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1405, 'max_steps': 7272}
 19%|█▉        | 1405/7272 [6:22:15<25:23:33, 15.58s/it] 19%|█▉        | 1406/7272 [6:22:30<25:11:17, 15.46s/it]                                                        {'loss': 2.003, 'grad_norm': 3.446753740310669, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1406, 'max_steps': 7272}
 19%|█▉        | 1406/7272 [6:22:30<25:11:17, 15.46s/it] 19%|█▉        | 1407/7272 [6:22:46<25:10:53, 15.46s/it]                                                        {'loss': 1.22, 'grad_norm': 3.5062124729156494, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1407, 'max_steps': 7272}
 19%|█▉        | 1407/7272 [6:22:46<25:10:53, 15.46s/it] 19%|█▉        | 1408/7272 [6:23:01<25:12:52, 15.48s/it]                                                        {'loss': 0.9989, 'grad_norm': 2.9544615745544434, 'learning_rate': 5e-05, 'epoch': 0.77, 'step': 1408, 'max_steps': 7272}
 19%|█▉        | 1408/7272 [6:23:01<25:12:52, 15.48s/it] 19%|█▉        | 1409/7272 [6:23:16<25:06:54, 15.42s/it]                                                        {'loss': 2.8552, 'grad_norm': 8.701937675476074, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1409, 'max_steps': 7272}
 19%|█▉        | 1409/7272 [6:23:16<25:06:54, 15.42s/it] 19%|█▉        | 1410/7272 [6:23:33<25:35:47, 15.72s/it]                                                        {'loss': 2.0136, 'grad_norm': 13.448925971984863, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1410, 'max_steps': 7272}
 19%|█▉        | 1410/7272 [6:23:33<25:35:47, 15.72s/it] 19%|█▉        | 1411/7272 [6:23:48<25:25:27, 15.62s/it]                                                        {'loss': 1.8668, 'grad_norm': 2.9039382934570312, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1411, 'max_steps': 7272}
 19%|█▉        | 1411/7272 [6:23:48<25:25:27, 15.62s/it] 19%|█▉        | 1412/7272 [6:24:05<25:48:14, 15.85s/it]                                                        {'loss': 0.6963, 'grad_norm': 3.3458170890808105, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1412, 'max_steps': 7272}
 19%|█▉        | 1412/7272 [6:24:05<25:48:14, 15.85s/it] 19%|█▉        | 1413/7272 [6:24:20<25:35:16, 15.72s/it]                                                        {'loss': 2.4137, 'grad_norm': 4.604680061340332, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1413, 'max_steps': 7272}
 19%|█▉        | 1413/7272 [6:24:20<25:35:16, 15.72s/it] 19%|█▉        | 1414/7272 [6:24:36<25:52:03, 15.90s/it]                                                        {'loss': 0.8615, 'grad_norm': 5.729237079620361, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1414, 'max_steps': 7272}
 19%|█▉        | 1414/7272 [6:24:36<25:52:03, 15.90s/it] 19%|█▉        | 1415/7272 [6:24:53<26:07:27, 16.06s/it]                                                        {'loss': 3.7859, 'grad_norm': 10.424928665161133, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1415, 'max_steps': 7272}
 19%|█▉        | 1415/7272 [6:24:53<26:07:27, 16.06s/it] 19%|█▉        | 1416/7272 [6:25:10<26:43:18, 16.43s/it]                                                        {'loss': 1.2077, 'grad_norm': 4.554746627807617, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1416, 'max_steps': 7272}
 19%|█▉        | 1416/7272 [6:25:10<26:43:18, 16.43s/it] 19%|█▉        | 1417/7272 [6:25:26<26:29:07, 16.28s/it]                                                        {'loss': 1.2761, 'grad_norm': 4.691642761230469, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1417, 'max_steps': 7272}
 19%|█▉        | 1417/7272 [6:25:26<26:29:07, 16.28s/it] 19%|█▉        | 1418/7272 [6:25:42<26:25:04, 16.25s/it]                                                        {'loss': 0.8875, 'grad_norm': 4.7902703285217285, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1418, 'max_steps': 7272}
 19%|█▉        | 1418/7272 [6:25:42<26:25:04, 16.25s/it] 20%|█▉        | 1419/7272 [6:25:58<26:01:57, 16.01s/it]                                                        {'loss': 1.8579, 'grad_norm': 4.881147384643555, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1419, 'max_steps': 7272}
 20%|█▉        | 1419/7272 [6:25:58<26:01:57, 16.01s/it] 20%|█▉        | 1420/7272 [6:26:14<26:13:18, 16.13s/it]                                                        {'loss': 2.3252, 'grad_norm': 12.101653099060059, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1420, 'max_steps': 7272}
 20%|█▉        | 1420/7272 [6:26:14<26:13:18, 16.13s/it] 20%|█▉        | 1421/7272 [6:26:29<25:53:03, 15.93s/it]                                                        {'loss': 0.9475, 'grad_norm': 4.930365085601807, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1421, 'max_steps': 7272}
 20%|█▉        | 1421/7272 [6:26:29<25:53:03, 15.93s/it] 20%|█▉        | 1422/7272 [6:26:45<25:47:41, 15.87s/it]                                                        {'loss': 1.873, 'grad_norm': 7.976917743682861, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1422, 'max_steps': 7272}
 20%|█▉        | 1422/7272 [6:26:45<25:47:41, 15.87s/it] 20%|█▉        | 1423/7272 [6:27:01<25:33:22, 15.73s/it]                                                        {'loss': 0.6147, 'grad_norm': 2.998649835586548, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1423, 'max_steps': 7272}
 20%|█▉        | 1423/7272 [6:27:01<25:33:22, 15.73s/it] 20%|█▉        | 1424/7272 [6:27:16<25:20:53, 15.60s/it]                                                        {'loss': 1.7361, 'grad_norm': 4.972982883453369, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1424, 'max_steps': 7272}
 20%|█▉        | 1424/7272 [6:27:16<25:20:53, 15.60s/it] 20%|█▉        | 1425/7272 [6:27:31<25:11:16, 15.51s/it]                                                        {'loss': 1.9671, 'grad_norm': 4.563164710998535, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1425, 'max_steps': 7272}
 20%|█▉        | 1425/7272 [6:27:31<25:11:16, 15.51s/it] 20%|█▉        | 1426/7272 [6:27:47<25:20:17, 15.60s/it]                                                        {'loss': 1.2322, 'grad_norm': 2.826883316040039, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1426, 'max_steps': 7272}
 20%|█▉        | 1426/7272 [6:27:47<25:20:17, 15.60s/it] 20%|█▉        | 1427/7272 [6:28:03<25:21:16, 15.62s/it]                                                        {'loss': 1.8255, 'grad_norm': 4.2329792976379395, 'learning_rate': 5e-05, 'epoch': 0.78, 'step': 1427, 'max_steps': 7272}
 20%|█▉        | 1427/7272 [6:28:03<25:21:16, 15.62s/it] 20%|█▉        | 1428/7272 [6:28:18<25:16:11, 15.57s/it]                                                        {'loss': 2.0397, 'grad_norm': 5.467686653137207, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1428, 'max_steps': 7272}
 20%|█▉        | 1428/7272 [6:28:18<25:16:11, 15.57s/it] 20%|█▉        | 1429/7272 [6:28:34<25:15:53, 15.57s/it]                                                        {'loss': 1.2323, 'grad_norm': 6.5022873878479, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1429, 'max_steps': 7272}
 20%|█▉        | 1429/7272 [6:28:34<25:15:53, 15.57s/it] 20%|█▉        | 1430/7272 [6:28:49<25:12:50, 15.54s/it]                                                        {'loss': 0.7764, 'grad_norm': 4.18083381652832, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1430, 'max_steps': 7272}
 20%|█▉        | 1430/7272 [6:28:49<25:12:50, 15.54s/it] 20%|█▉        | 1431/7272 [6:29:05<25:09:05, 15.50s/it]                                                        {'loss': 1.9791, 'grad_norm': 4.587647438049316, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1431, 'max_steps': 7272}
 20%|█▉        | 1431/7272 [6:29:05<25:09:05, 15.50s/it] 20%|█▉        | 1432/7272 [6:29:21<25:25:45, 15.68s/it]                                                        {'loss': 0.8893, 'grad_norm': 4.629881381988525, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1432, 'max_steps': 7272}
 20%|█▉        | 1432/7272 [6:29:21<25:25:45, 15.68s/it] 20%|█▉        | 1433/7272 [6:29:36<25:30:51, 15.73s/it]                                                        {'loss': 1.5186, 'grad_norm': 5.629336357116699, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1433, 'max_steps': 7272}
 20%|█▉        | 1433/7272 [6:29:36<25:30:51, 15.73s/it] 20%|█▉        | 1434/7272 [6:29:53<25:39:15, 15.82s/it]                                                        {'loss': 2.4997, 'grad_norm': 5.443831443786621, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1434, 'max_steps': 7272}
 20%|█▉        | 1434/7272 [6:29:53<25:39:15, 15.82s/it] 20%|█▉        | 1435/7272 [6:30:08<25:32:27, 15.75s/it]                                                        {'loss': 1.587, 'grad_norm': 5.52021598815918, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1435, 'max_steps': 7272}
 20%|█▉        | 1435/7272 [6:30:08<25:32:27, 15.75s/it] 20%|█▉        | 1436/7272 [6:30:25<25:51:51, 15.95s/it]                                                        {'loss': 1.4074, 'grad_norm': 3.200611114501953, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1436, 'max_steps': 7272}
 20%|█▉        | 1436/7272 [6:30:25<25:51:51, 15.95s/it] 20%|█▉        | 1437/7272 [6:30:41<26:00:57, 16.05s/it]                                                        {'loss': 1.011, 'grad_norm': 3.7020673751831055, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1437, 'max_steps': 7272}
 20%|█▉        | 1437/7272 [6:30:41<26:00:57, 16.05s/it] 20%|█▉        | 1438/7272 [6:30:57<26:05:34, 16.10s/it]                                                        {'loss': 1.8526, 'grad_norm': 4.215757846832275, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1438, 'max_steps': 7272}
 20%|█▉        | 1438/7272 [6:30:57<26:05:34, 16.10s/it] 20%|█▉        | 1439/7272 [6:31:13<25:54:19, 15.99s/it]                                                        {'loss': 1.858, 'grad_norm': 6.177966117858887, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1439, 'max_steps': 7272}
 20%|█▉        | 1439/7272 [6:31:13<25:54:19, 15.99s/it] 20%|█▉        | 1440/7272 [6:31:28<25:32:52, 15.77s/it]                                                        {'loss': 1.7792, 'grad_norm': 5.602818489074707, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1440, 'max_steps': 7272}
 20%|█▉        | 1440/7272 [6:31:28<25:32:52, 15.77s/it] 20%|█▉        | 1441/7272 [6:31:43<25:24:12, 15.68s/it]                                                        {'loss': 1.8796, 'grad_norm': 10.074124336242676, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1441, 'max_steps': 7272}
 20%|█▉        | 1441/7272 [6:31:44<25:24:12, 15.68s/it] 20%|█▉        | 1442/7272 [6:31:59<25:30:56, 15.76s/it]                                                        {'loss': 1.2891, 'grad_norm': 5.553322792053223, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1442, 'max_steps': 7272}
 20%|█▉        | 1442/7272 [6:31:59<25:30:56, 15.76s/it] 20%|█▉        | 1443/7272 [6:32:16<25:48:14, 15.94s/it]                                                        {'loss': 1.0438, 'grad_norm': 2.5771570205688477, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1443, 'max_steps': 7272}
 20%|█▉        | 1443/7272 [6:32:16<25:48:14, 15.94s/it] 20%|█▉        | 1444/7272 [6:32:32<26:05:37, 16.12s/it]                                                        {'loss': 1.3451, 'grad_norm': 4.48258113861084, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1444, 'max_steps': 7272}
 20%|█▉        | 1444/7272 [6:32:32<26:05:37, 16.12s/it] 20%|█▉        | 1445/7272 [6:32:49<26:08:02, 16.15s/it]                                                        {'loss': 1.5805, 'grad_norm': 4.151443958282471, 'learning_rate': 5e-05, 'epoch': 0.79, 'step': 1445, 'max_steps': 7272}
 20%|█▉        | 1445/7272 [6:32:49<26:08:02, 16.15s/it] 20%|█▉        | 1446/7272 [6:33:04<26:02:30, 16.09s/it]                                                        {'loss': 2.4231, 'grad_norm': 5.0775980949401855, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1446, 'max_steps': 7272}
 20%|█▉        | 1446/7272 [6:33:05<26:02:30, 16.09s/it] 20%|█▉        | 1447/7272 [6:33:20<25:50:55, 15.98s/it]                                                        {'loss': 1.489, 'grad_norm': 3.824084758758545, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1447, 'max_steps': 7272}
 20%|█▉        | 1447/7272 [6:33:20<25:50:55, 15.98s/it] 20%|█▉        | 1448/7272 [6:33:36<25:44:56, 15.92s/it]                                                        {'loss': 1.2487, 'grad_norm': 3.2287938594818115, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1448, 'max_steps': 7272}
 20%|█▉        | 1448/7272 [6:33:36<25:44:56, 15.92s/it] 20%|█▉        | 1449/7272 [6:33:52<25:33:23, 15.80s/it]                                                        {'loss': 2.7453, 'grad_norm': 8.766036987304688, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1449, 'max_steps': 7272}
 20%|█▉        | 1449/7272 [6:33:52<25:33:23, 15.80s/it] 20%|█▉        | 1450/7272 [6:34:07<25:11:02, 15.57s/it]                                                        {'loss': 1.197, 'grad_norm': 4.31435489654541, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1450, 'max_steps': 7272}
 20%|█▉        | 1450/7272 [6:34:07<25:11:02, 15.57s/it] 20%|█▉        | 1451/7272 [6:34:22<25:05:38, 15.52s/it]                                                        {'loss': 1.5538, 'grad_norm': 9.450261116027832, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1451, 'max_steps': 7272}
 20%|█▉        | 1451/7272 [6:34:22<25:05:38, 15.52s/it] 20%|█▉        | 1452/7272 [6:34:38<25:11:10, 15.58s/it]                                                        {'loss': 2.8288, 'grad_norm': 6.122738361358643, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1452, 'max_steps': 7272}
 20%|█▉        | 1452/7272 [6:34:38<25:11:10, 15.58s/it] 20%|█▉        | 1453/7272 [6:34:53<25:13:55, 15.61s/it]                                                        {'loss': 3.5055, 'grad_norm': 10.0657377243042, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1453, 'max_steps': 7272}
 20%|█▉        | 1453/7272 [6:34:53<25:13:55, 15.61s/it] 20%|█▉        | 1454/7272 [6:35:09<25:27:40, 15.75s/it]                                                        {'loss': 2.621, 'grad_norm': 4.027596950531006, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1454, 'max_steps': 7272}
 20%|█▉        | 1454/7272 [6:35:09<25:27:40, 15.75s/it] 20%|██        | 1455/7272 [6:35:25<25:36:20, 15.85s/it]                                                        {'loss': 1.0463, 'grad_norm': 4.427602767944336, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1455, 'max_steps': 7272}
 20%|██        | 1455/7272 [6:35:26<25:36:20, 15.85s/it] 20%|██        | 1456/7272 [6:35:41<25:35:58, 15.85s/it]                                                        {'loss': 2.0739, 'grad_norm': 5.9007439613342285, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1456, 'max_steps': 7272}
 20%|██        | 1456/7272 [6:35:41<25:35:58, 15.85s/it] 20%|██        | 1457/7272 [6:35:57<25:24:39, 15.73s/it]                                                        {'loss': 1.5835, 'grad_norm': 4.390822887420654, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1457, 'max_steps': 7272}
 20%|██        | 1457/7272 [6:35:57<25:24:39, 15.73s/it] 20%|██        | 1458/7272 [6:36:12<25:15:02, 15.64s/it]                                                        {'loss': 1.2406, 'grad_norm': 3.0343503952026367, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1458, 'max_steps': 7272}
 20%|██        | 1458/7272 [6:36:12<25:15:02, 15.64s/it] 20%|██        | 1459/7272 [6:36:28<25:12:16, 15.61s/it]                                                        {'loss': 2.4544, 'grad_norm': 5.483957290649414, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1459, 'max_steps': 7272}
 20%|██        | 1459/7272 [6:36:28<25:12:16, 15.61s/it] 20%|██        | 1460/7272 [6:36:43<25:02:43, 15.51s/it]                                                        {'loss': 1.5868, 'grad_norm': 9.372179985046387, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1460, 'max_steps': 7272}
 20%|██        | 1460/7272 [6:36:43<25:02:43, 15.51s/it] 20%|██        | 1461/7272 [6:36:59<25:16:00, 15.65s/it]                                                        {'loss': 3.2933, 'grad_norm': 7.114949703216553, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1461, 'max_steps': 7272}
 20%|██        | 1461/7272 [6:36:59<25:16:00, 15.65s/it] 20%|██        | 1462/7272 [6:37:15<25:31:43, 15.82s/it]                                                        {'loss': 0.9146, 'grad_norm': 3.533416509628296, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1462, 'max_steps': 7272}
 20%|██        | 1462/7272 [6:37:15<25:31:43, 15.82s/it] 20%|██        | 1463/7272 [6:37:31<25:43:47, 15.95s/it]                                                        {'loss': 2.4891, 'grad_norm': 7.543966770172119, 'learning_rate': 5e-05, 'epoch': 0.8, 'step': 1463, 'max_steps': 7272}
 20%|██        | 1463/7272 [6:37:31<25:43:47, 15.95s/it] 20%|██        | 1464/7272 [6:37:47<25:44:09, 15.95s/it]                                                        {'loss': 2.141, 'grad_norm': 5.701582908630371, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1464, 'max_steps': 7272}
 20%|██        | 1464/7272 [6:37:47<25:44:09, 15.95s/it] 20%|██        | 1465/7272 [6:38:03<25:42:54, 15.94s/it]                                                        {'loss': 2.4594, 'grad_norm': 13.395950317382812, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1465, 'max_steps': 7272}
 20%|██        | 1465/7272 [6:38:03<25:42:54, 15.94s/it] 20%|██        | 1466/7272 [6:38:19<25:36:38, 15.88s/it]                                                        {'loss': 2.6883, 'grad_norm': 6.9657464027404785, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1466, 'max_steps': 7272}
 20%|██        | 1466/7272 [6:38:19<25:36:38, 15.88s/it] 20%|██        | 1467/7272 [6:38:34<25:14:41, 15.66s/it]                                                        {'loss': 1.2259, 'grad_norm': 2.9746997356414795, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1467, 'max_steps': 7272}
 20%|██        | 1467/7272 [6:38:34<25:14:41, 15.66s/it] 20%|██        | 1468/7272 [6:38:50<25:09:06, 15.60s/it]                                                        {'loss': 2.8861, 'grad_norm': 6.13142728805542, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1468, 'max_steps': 7272}
 20%|██        | 1468/7272 [6:38:50<25:09:06, 15.60s/it] 20%|██        | 1469/7272 [6:39:06<25:18:17, 15.70s/it]                                                        {'loss': 1.6057, 'grad_norm': 3.251574993133545, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1469, 'max_steps': 7272}
 20%|██        | 1469/7272 [6:39:06<25:18:17, 15.70s/it] 20%|██        | 1470/7272 [6:39:21<25:09:16, 15.61s/it]                                                        {'loss': 3.2794, 'grad_norm': 13.346559524536133, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1470, 'max_steps': 7272}
 20%|██        | 1470/7272 [6:39:21<25:09:16, 15.61s/it] 20%|██        | 1471/7272 [6:39:36<25:00:30, 15.52s/it]                                                        {'loss': 3.2961, 'grad_norm': 6.14785623550415, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1471, 'max_steps': 7272}
 20%|██        | 1471/7272 [6:39:36<25:00:30, 15.52s/it] 20%|██        | 1472/7272 [6:39:51<24:48:19, 15.40s/it]                                                        {'loss': 1.6954, 'grad_norm': 3.515846014022827, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1472, 'max_steps': 7272}
 20%|██        | 1472/7272 [6:39:51<24:48:19, 15.40s/it] 20%|██        | 1473/7272 [6:40:06<24:33:59, 15.25s/it]                                                        {'loss': 0.6085, 'grad_norm': 1.9628456830978394, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1473, 'max_steps': 7272}
 20%|██        | 1473/7272 [6:40:06<24:33:59, 15.25s/it] 20%|██        | 1474/7272 [6:40:22<24:44:00, 15.36s/it]                                                        {'loss': 1.3116, 'grad_norm': 3.100464344024658, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1474, 'max_steps': 7272}
 20%|██        | 1474/7272 [6:40:22<24:44:00, 15.36s/it] 20%|██        | 1475/7272 [6:40:37<24:39:08, 15.31s/it]                                                        {'loss': 1.2404, 'grad_norm': 4.728996276855469, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1475, 'max_steps': 7272}
 20%|██        | 1475/7272 [6:40:37<24:39:08, 15.31s/it] 20%|██        | 1476/7272 [6:40:53<24:39:57, 15.32s/it]                                                        {'loss': 2.1945, 'grad_norm': 6.054244041442871, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1476, 'max_steps': 7272}
 20%|██        | 1476/7272 [6:40:53<24:39:57, 15.32s/it] 20%|██        | 1477/7272 [6:41:08<24:55:21, 15.48s/it]                                                        {'loss': 1.8703, 'grad_norm': 3.023310899734497, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1477, 'max_steps': 7272}
 20%|██        | 1477/7272 [6:41:08<24:55:21, 15.48s/it] 20%|██        | 1478/7272 [6:41:24<24:51:08, 15.44s/it]                                                        {'loss': 2.8656, 'grad_norm': 11.53372859954834, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1478, 'max_steps': 7272}
 20%|██        | 1478/7272 [6:41:24<24:51:08, 15.44s/it] 20%|██        | 1479/7272 [6:41:40<25:09:36, 15.64s/it]                                                        {'loss': 2.4058, 'grad_norm': 7.473140239715576, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1479, 'max_steps': 7272}
 20%|██        | 1479/7272 [6:41:40<25:09:36, 15.64s/it] 20%|██        | 1480/7272 [6:41:56<25:32:58, 15.88s/it]                                                        {'loss': 1.9069, 'grad_norm': 4.226909160614014, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1480, 'max_steps': 7272}
 20%|██        | 1480/7272 [6:41:56<25:32:58, 15.88s/it] 20%|██        | 1481/7272 [6:42:12<25:33:17, 15.89s/it]                                                        {'loss': 1.9333, 'grad_norm': 7.639896869659424, 'learning_rate': 5e-05, 'epoch': 0.81, 'step': 1481, 'max_steps': 7272}
 20%|██        | 1481/7272 [6:42:12<25:33:17, 15.89s/it] 20%|██        | 1482/7272 [6:42:28<25:44:08, 16.00s/it]                                                        {'loss': 1.43, 'grad_norm': 7.558971881866455, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1482, 'max_steps': 7272}
 20%|██        | 1482/7272 [6:42:28<25:44:08, 16.00s/it] 20%|██        | 1483/7272 [6:42:44<25:34:25, 15.90s/it]                                                        {'loss': 2.4777, 'grad_norm': 5.369720935821533, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1483, 'max_steps': 7272}
 20%|██        | 1483/7272 [6:42:44<25:34:25, 15.90s/it] 20%|██        | 1484/7272 [6:43:00<25:47:54, 16.05s/it]                                                        {'loss': 2.8495, 'grad_norm': 6.104276657104492, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1484, 'max_steps': 7272}
 20%|██        | 1484/7272 [6:43:00<25:47:54, 16.05s/it] 20%|██        | 1485/7272 [6:43:16<25:32:25, 15.89s/it]                                                        {'loss': 1.8981, 'grad_norm': 5.3224263191223145, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1485, 'max_steps': 7272}
 20%|██        | 1485/7272 [6:43:16<25:32:25, 15.89s/it] 20%|██        | 1486/7272 [6:43:32<25:29:41, 15.86s/it]                                                        {'loss': 1.2363, 'grad_norm': 5.108946323394775, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1486, 'max_steps': 7272}
 20%|██        | 1486/7272 [6:43:32<25:29:41, 15.86s/it] 20%|██        | 1487/7272 [6:43:47<25:21:15, 15.78s/it]                                                        {'loss': 1.0457, 'grad_norm': 5.163856506347656, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1487, 'max_steps': 7272}
 20%|██        | 1487/7272 [6:43:47<25:21:15, 15.78s/it] 20%|██        | 1488/7272 [6:44:03<25:11:59, 15.68s/it]                                                        {'loss': 1.326, 'grad_norm': 7.9503936767578125, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1488, 'max_steps': 7272}
 20%|██        | 1488/7272 [6:44:03<25:11:59, 15.68s/it] 20%|██        | 1489/7272 [6:44:19<25:15:12, 15.72s/it]                                                        {'loss': 1.1851, 'grad_norm': 7.139463901519775, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1489, 'max_steps': 7272}
 20%|██        | 1489/7272 [6:44:19<25:15:12, 15.72s/it] 20%|██        | 1490/7272 [6:44:34<25:10:36, 15.68s/it]                                                        {'loss': 0.9237, 'grad_norm': 5.666721820831299, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1490, 'max_steps': 7272}
 20%|██        | 1490/7272 [6:44:34<25:10:36, 15.68s/it] 21%|██        | 1491/7272 [6:44:50<25:17:10, 15.75s/it]                                                        {'loss': 2.2573, 'grad_norm': 5.152645111083984, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1491, 'max_steps': 7272}
 21%|██        | 1491/7272 [6:44:50<25:17:10, 15.75s/it] 21%|██        | 1492/7272 [6:45:06<25:32:03, 15.90s/it]                                                        {'loss': 0.9256, 'grad_norm': 4.438914775848389, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1492, 'max_steps': 7272}
 21%|██        | 1492/7272 [6:45:06<25:32:03, 15.90s/it] 21%|██        | 1493/7272 [6:45:22<25:18:34, 15.77s/it]                                                        {'loss': 1.7671, 'grad_norm': 4.335712432861328, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1493, 'max_steps': 7272}
 21%|██        | 1493/7272 [6:45:22<25:18:34, 15.77s/it] 21%|██        | 1494/7272 [6:45:38<25:24:53, 15.83s/it]                                                        {'loss': 2.4692, 'grad_norm': 6.40896463394165, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1494, 'max_steps': 7272}
 21%|██        | 1494/7272 [6:45:38<25:24:53, 15.83s/it] 21%|██        | 1495/7272 [6:45:53<25:15:20, 15.74s/it]                                                        {'loss': 3.7937, 'grad_norm': 13.296487808227539, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1495, 'max_steps': 7272}
 21%|██        | 1495/7272 [6:45:53<25:15:20, 15.74s/it] 21%|██        | 1496/7272 [6:46:09<25:06:42, 15.65s/it]                                                        {'loss': 1.7562, 'grad_norm': 4.75523042678833, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1496, 'max_steps': 7272}
 21%|██        | 1496/7272 [6:46:09<25:06:42, 15.65s/it] 21%|██        | 1497/7272 [6:46:25<25:20:09, 15.79s/it]                                                        {'loss': 1.635, 'grad_norm': 5.837905406951904, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1497, 'max_steps': 7272}
 21%|██        | 1497/7272 [6:46:25<25:20:09, 15.79s/it] 21%|██        | 1498/7272 [6:46:41<25:16:55, 15.76s/it]                                                        {'loss': 1.6858, 'grad_norm': 6.8564453125, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1498, 'max_steps': 7272}
 21%|██        | 1498/7272 [6:46:41<25:16:55, 15.76s/it] 21%|██        | 1499/7272 [6:46:56<25:12:47, 15.72s/it]                                                        {'loss': 1.6082, 'grad_norm': 4.614325523376465, 'learning_rate': 5e-05, 'epoch': 0.82, 'step': 1499, 'max_steps': 7272}
 21%|██        | 1499/7272 [6:46:56<25:12:47, 15.72s/it] 21%|██        | 1500/7272 [6:47:12<25:05:38, 15.65s/it]                                                        {'loss': 1.8695, 'grad_norm': 4.309868335723877, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1500, 'max_steps': 7272}
 21%|██        | 1500/7272 [6:47:12<25:05:38, 15.65s/it]
  0%|          | 0/455 [00:00<?, ?it/s][A
  0%|          | 2/455 [00:01<06:01,  1.25it/s][A
  1%|          | 3/455 [00:03<08:21,  1.11s/it][A
  1%|          | 4/455 [00:04<09:35,  1.28s/it][A
  1%|          | 5/455 [00:06<10:14,  1.37s/it][A
  1%|▏         | 6/455 [00:07<10:42,  1.43s/it][A
  2%|▏         | 7/455 [00:09<10:59,  1.47s/it][A
  2%|▏         | 8/455 [00:10<11:10,  1.50s/it][A
  2%|▏         | 9/455 [00:12<11:16,  1.52s/it][A
  2%|▏         | 10/455 [00:14<11:19,  1.53s/it][A
  2%|▏         | 11/455 [00:15<11:17,  1.53s/it][A
  3%|▎         | 12/455 [00:17<11:17,  1.53s/it][A
  3%|▎         | 13/455 [00:18<11:16,  1.53s/it][A
  3%|▎         | 14/455 [00:20<11:17,  1.54s/it][A
  3%|▎         | 15/455 [00:21<11:15,  1.54s/it][A
  4%|▎         | 16/455 [00:23<11:13,  1.53s/it][A
  4%|▎         | 17/455 [00:24<11:12,  1.54s/it][A
  4%|▍         | 18/455 [00:26<11:09,  1.53s/it][A
  4%|▍         | 19/455 [00:27<11:09,  1.54s/it][A
  4%|▍         | 20/455 [00:29<11:08,  1.54s/it][A
  5%|▍         | 21/455 [00:30<11:06,  1.54s/it][A
  5%|▍         | 22/455 [00:32<11:06,  1.54s/it][A
  5%|▌         | 23/455 [00:33<11:03,  1.53s/it][A
  5%|▌         | 24/455 [00:35<11:03,  1.54s/it][A
  5%|▌         | 25/455 [00:37<10:58,  1.53s/it][A
  6%|▌         | 26/455 [00:38<10:56,  1.53s/it][A
  6%|▌         | 27/455 [00:40<10:56,  1.53s/it][A
  6%|▌         | 28/455 [00:41<10:54,  1.53s/it][A
  6%|▋         | 29/455 [00:43<10:53,  1.53s/it][A
  7%|▋         | 30/455 [00:44<10:54,  1.54s/it][A
  7%|▋         | 31/455 [00:46<10:53,  1.54s/it][A
  7%|▋         | 32/455 [00:47<10:50,  1.54s/it][A
  7%|▋         | 33/455 [00:49<10:50,  1.54s/it][A
  7%|▋         | 34/455 [00:50<10:47,  1.54s/it][A
  8%|▊         | 35/455 [00:52<10:45,  1.54s/it][A
  8%|▊         | 36/455 [00:53<10:43,  1.54s/it][A
  8%|▊         | 37/455 [00:55<10:41,  1.53s/it][A
  8%|▊         | 38/455 [00:57<10:39,  1.53s/it][A
  9%|▊         | 39/455 [00:58<10:37,  1.53s/it][A
  9%|▉         | 40/455 [01:00<10:36,  1.53s/it][A
  9%|▉         | 41/455 [01:01<10:35,  1.53s/it][A
  9%|▉         | 42/455 [01:03<10:35,  1.54s/it][A
  9%|▉         | 43/455 [01:04<10:32,  1.53s/it][A
 10%|▉         | 44/455 [01:06<10:28,  1.53s/it][A
 10%|▉         | 45/455 [01:07<10:27,  1.53s/it][A
 10%|█         | 46/455 [01:09<10:25,  1.53s/it][A
 10%|█         | 47/455 [01:10<10:24,  1.53s/it][A
 11%|█         | 48/455 [01:12<10:24,  1.54s/it][A
 11%|█         | 49/455 [01:13<10:22,  1.53s/it][A
 11%|█         | 50/455 [01:15<10:22,  1.54s/it][A
 11%|█         | 51/455 [01:16<10:19,  1.53s/it][A
 11%|█▏        | 52/455 [01:18<10:18,  1.54s/it][A
 12%|█▏        | 53/455 [01:20<10:15,  1.53s/it][A
 12%|█▏        | 54/455 [01:21<10:15,  1.53s/it][A
 12%|█▏        | 55/455 [01:23<10:13,  1.53s/it][A
 12%|█▏        | 56/455 [01:24<10:11,  1.53s/it][A
 13%|█▎        | 57/455 [01:26<10:09,  1.53s/it][A
 13%|█▎        | 58/455 [01:27<10:06,  1.53s/it][A
 13%|█▎        | 59/455 [01:29<10:06,  1.53s/it][A
 13%|█▎        | 60/455 [01:30<10:06,  1.53s/it][A
 13%|█▎        | 61/455 [01:32<10:03,  1.53s/it][A
 14%|█▎        | 62/455 [01:33<10:02,  1.53s/it][A
 14%|█▍        | 63/455 [01:35<10:01,  1.53s/it][A
 14%|█▍        | 64/455 [01:36<09:59,  1.53s/it][A
 14%|█▍        | 65/455 [01:38<09:57,  1.53s/it][A
 15%|█▍        | 66/455 [01:39<09:56,  1.53s/it][A
 15%|█▍        | 67/455 [01:41<09:56,  1.54s/it][A
 15%|█▍        | 68/455 [01:43<09:55,  1.54s/it][A
 15%|█▌        | 69/455 [01:44<09:52,  1.53s/it][A
 15%|█▌        | 70/455 [01:46<09:50,  1.53s/it][A
 16%|█▌        | 71/455 [01:47<09:48,  1.53s/it][A
 16%|█▌        | 72/455 [01:49<09:47,  1.53s/it][A
 16%|█▌        | 73/455 [01:50<09:45,  1.53s/it][A
 16%|█▋        | 74/455 [01:52<09:44,  1.53s/it][A
 16%|█▋        | 75/455 [01:53<09:43,  1.53s/it][A
 17%|█▋        | 76/455 [01:55<09:40,  1.53s/it][A
 17%|█▋        | 77/455 [01:56<09:38,  1.53s/it][A
 17%|█▋        | 78/455 [01:58<09:36,  1.53s/it][A
 17%|█▋        | 79/455 [01:59<09:35,  1.53s/it][A
 18%|█▊        | 80/455 [02:01<09:34,  1.53s/it][A
 18%|█▊        | 81/455 [02:02<09:32,  1.53s/it][A
 18%|█▊        | 82/455 [02:04<09:29,  1.53s/it][A
 18%|█▊        | 83/455 [02:05<09:27,  1.53s/it][A
 18%|█▊        | 84/455 [02:07<09:26,  1.53s/it][A
 19%|█▊        | 85/455 [02:09<09:25,  1.53s/it][A
 19%|█▉        | 86/455 [02:10<09:25,  1.53s/it][A
 19%|█▉        | 87/455 [02:12<09:25,  1.54s/it][A
 19%|█▉        | 88/455 [02:13<09:30,  1.56s/it][A
 20%|█▉        | 89/455 [02:15<09:32,  1.57s/it][A
 20%|█▉        | 90/455 [02:16<09:28,  1.56s/it][A
 20%|██        | 91/455 [02:18<09:25,  1.55s/it][A
 20%|██        | 92/455 [02:19<09:22,  1.55s/it][A
 20%|██        | 93/455 [02:21<09:17,  1.54s/it][A
 21%|██        | 94/455 [02:22<09:16,  1.54s/it][A
 21%|██        | 95/455 [02:24<09:14,  1.54s/it][A
 21%|██        | 96/455 [02:26<09:10,  1.53s/it][A
 21%|██▏       | 97/455 [02:27<09:10,  1.54s/it][A
 22%|██▏       | 98/455 [02:29<09:09,  1.54s/it][A
 22%|██▏       | 99/455 [02:30<09:08,  1.54s/it][A
 22%|██▏       | 100/455 [02:32<09:06,  1.54s/it][A
 22%|██▏       | 101/455 [02:33<09:05,  1.54s/it][A
 22%|██▏       | 102/455 [02:35<09:02,  1.54s/it][A
 23%|██▎       | 103/455 [02:36<09:01,  1.54s/it][A
 23%|██▎       | 104/455 [02:38<08:58,  1.53s/it][A
 23%|██▎       | 105/455 [02:39<08:57,  1.54s/it][A
 23%|██▎       | 106/455 [02:41<08:55,  1.54s/it][A
 24%|██▎       | 107/455 [02:42<08:57,  1.54s/it][A
 24%|██▎       | 108/455 [02:44<08:54,  1.54s/it][A
 24%|██▍       | 109/455 [02:46<08:53,  1.54s/it][A
 24%|██▍       | 110/455 [02:47<08:50,  1.54s/it][A
 24%|██▍       | 111/455 [02:49<08:49,  1.54s/it][A
 25%|██▍       | 112/455 [02:50<08:47,  1.54s/it][A
 25%|██▍       | 113/455 [02:52<08:46,  1.54s/it][A
 25%|██▌       | 114/455 [02:53<08:45,  1.54s/it][A
 25%|██▌       | 115/455 [02:55<08:42,  1.54s/it][A
 25%|██▌       | 116/455 [02:56<08:41,  1.54s/it][A
 26%|██▌       | 117/455 [02:58<08:38,  1.53s/it][A
 26%|██▌       | 118/455 [02:59<08:37,  1.54s/it][A
 26%|██▌       | 119/455 [03:01<08:35,  1.53s/it][A
 26%|██▋       | 120/455 [03:02<08:33,  1.53s/it][A
 27%|██▋       | 121/455 [03:04<08:32,  1.53s/it][A
 27%|██▋       | 122/455 [03:06<08:31,  1.54s/it][A
 27%|██▋       | 123/455 [03:07<08:30,  1.54s/it][A
 27%|██▋       | 124/455 [03:09<08:28,  1.54s/it][A
 27%|██▋       | 125/455 [03:10<08:26,  1.54s/it][A
 28%|██▊       | 126/455 [03:12<08:24,  1.53s/it][A
 28%|██▊       | 127/455 [03:13<08:23,  1.54s/it][A
 28%|██▊       | 128/455 [03:15<08:22,  1.54s/it][A
 28%|██▊       | 129/455 [03:16<08:18,  1.53s/it][A
 29%|██▊       | 130/455 [03:18<08:17,  1.53s/it][A
 29%|██▉       | 131/455 [03:19<08:13,  1.52s/it][A
 29%|██▉       | 132/455 [03:21<08:14,  1.53s/it][A
 29%|██▉       | 133/455 [03:22<08:13,  1.53s/it][A
 29%|██▉       | 134/455 [03:24<08:12,  1.54s/it][A
 30%|██▉       | 135/455 [03:25<08:11,  1.53s/it][A
 30%|██▉       | 136/455 [03:27<08:10,  1.54s/it][A
 30%|███       | 137/455 [03:29<08:08,  1.53s/it][A
 30%|███       | 138/455 [03:30<08:05,  1.53s/it][A
 31%|███       | 139/455 [03:32<08:04,  1.53s/it][A
 31%|███       | 140/455 [03:33<08:03,  1.53s/it][A
 31%|███       | 141/455 [03:35<08:02,  1.54s/it][A
 31%|███       | 142/455 [03:36<08:01,  1.54s/it][A
 31%|███▏      | 143/455 [03:38<07:59,  1.54s/it][A
 32%|███▏      | 144/455 [03:39<07:57,  1.54s/it][A
 32%|███▏      | 145/455 [03:41<07:53,  1.53s/it][A
 32%|███▏      | 146/455 [03:42<07:52,  1.53s/it][A
 32%|███▏      | 147/455 [03:44<07:52,  1.53s/it][A
 33%|███▎      | 148/455 [03:45<07:49,  1.53s/it][A
 33%|███▎      | 149/455 [03:47<07:48,  1.53s/it][A
 33%|███▎      | 150/455 [03:48<07:46,  1.53s/it][A
 33%|███▎      | 151/455 [03:50<07:45,  1.53s/it][A
 33%|███▎      | 152/455 [03:52<07:45,  1.54s/it][A
 34%|███▎      | 153/455 [03:53<07:44,  1.54s/it][A
 34%|███▍      | 154/455 [03:55<07:42,  1.54s/it][A
 34%|███▍      | 155/455 [03:56<07:40,  1.53s/it][A
 34%|███▍      | 156/455 [03:58<07:39,  1.54s/it][A
 35%|███▍      | 157/455 [03:59<07:38,  1.54s/it][A
 35%|███▍      | 158/455 [04:01<07:37,  1.54s/it][A
 35%|███▍      | 159/455 [04:02<07:35,  1.54s/it][A
 35%|███▌      | 160/455 [04:04<07:33,  1.54s/it][A
 35%|███▌      | 161/455 [04:05<07:31,  1.54s/it][A
 36%|███▌      | 162/455 [04:07<07:28,  1.53s/it][A
 36%|███▌      | 163/455 [04:08<07:27,  1.53s/it][A
 36%|███▌      | 164/455 [04:10<07:25,  1.53s/it][A
 36%|███▋      | 165/455 [04:11<07:24,  1.53s/it][A
 36%|███▋      | 166/455 [04:13<07:24,  1.54s/it][A
 37%|███▋      | 167/455 [04:15<07:23,  1.54s/it][A
 37%|███▋      | 168/455 [04:16<07:22,  1.54s/it][A
 37%|███▋      | 169/455 [04:18<07:20,  1.54s/it][A
 37%|███▋      | 170/455 [04:19<07:18,  1.54s/it][A
 38%|███▊      | 171/455 [04:21<07:16,  1.54s/it][A
 38%|███▊      | 172/455 [04:22<07:12,  1.53s/it][A
 38%|███▊      | 173/455 [04:24<07:09,  1.52s/it][A
 38%|███▊      | 174/455 [04:25<07:09,  1.53s/it][A
 38%|███▊      | 175/455 [04:27<07:08,  1.53s/it][A
 39%|███▊      | 176/455 [04:28<07:08,  1.54s/it][A
 39%|███▉      | 177/455 [04:30<07:08,  1.54s/it][A
 39%|███▉      | 178/455 [04:31<07:06,  1.54s/it][A
 39%|███▉      | 179/455 [04:33<07:03,  1.53s/it][A
 40%|███▉      | 180/455 [04:35<07:02,  1.54s/it][A
 40%|███▉      | 181/455 [04:36<07:01,  1.54s/it][A
 40%|████      | 182/455 [04:38<06:59,  1.54s/it][A
 40%|████      | 183/455 [04:39<06:56,  1.53s/it][A
 40%|████      | 184/455 [04:41<06:53,  1.53s/it][A
 41%|████      | 185/455 [04:42<06:51,  1.52s/it][A
 41%|████      | 186/455 [04:44<06:51,  1.53s/it][A
 41%|████      | 187/455 [04:45<06:50,  1.53s/it][A
 41%|████▏     | 188/455 [04:47<06:50,  1.54s/it][A
 42%|████▏     | 189/455 [04:48<06:49,  1.54s/it][A
 42%|████▏     | 190/455 [04:50<06:47,  1.54s/it][A
 42%|████▏     | 191/455 [04:51<06:44,  1.53s/it][A
 42%|████▏     | 192/455 [04:53<06:44,  1.54s/it][A
 42%|████▏     | 193/455 [04:54<06:42,  1.54s/it][A
 43%|████▎     | 194/455 [04:56<06:41,  1.54s/it][A
 43%|████▎     | 195/455 [04:58<06:40,  1.54s/it][A
 43%|████▎     | 196/455 [04:59<06:39,  1.54s/it][A
 43%|████▎     | 197/455 [05:01<06:37,  1.54s/it][A
 44%|████▎     | 198/455 [05:02<06:35,  1.54s/it][A
 44%|████▎     | 199/455 [05:04<06:31,  1.53s/it][A
 44%|████▍     | 200/455 [05:05<06:28,  1.52s/it][A
 44%|████▍     | 201/455 [05:07<06:27,  1.53s/it][A
 44%|████▍     | 202/455 [05:08<06:27,  1.53s/it][A
 45%|████▍     | 203/455 [05:10<06:26,  1.53s/it][A
 45%|████▍     | 204/455 [05:11<06:23,  1.53s/it][A
 45%|████▌     | 205/455 [05:13<06:23,  1.53s/it][A
 45%|████▌     | 206/455 [05:14<06:21,  1.53s/it][A
 45%|████▌     | 207/455 [05:16<06:18,  1.53s/it][A
 46%|████▌     | 208/455 [05:17<06:16,  1.52s/it][A
 46%|████▌     | 209/455 [05:19<06:15,  1.53s/it][A
 46%|████▌     | 210/455 [05:20<06:14,  1.53s/it][A
 46%|████▋     | 211/455 [05:22<06:11,  1.52s/it][A
 47%|████▋     | 212/455 [05:24<06:10,  1.52s/it][A
 47%|████▋     | 213/455 [05:25<06:10,  1.53s/it][A
 47%|████▋     | 214/455 [05:27<06:08,  1.53s/it][A
 47%|████▋     | 215/455 [05:28<06:07,  1.53s/it][A
 47%|████▋     | 216/455 [05:30<06:05,  1.53s/it][A
 48%|████▊     | 217/455 [05:31<06:05,  1.54s/it][A
 48%|████▊     | 218/455 [05:33<06:02,  1.53s/it][A
 48%|████▊     | 219/455 [05:34<06:00,  1.53s/it][A
 48%|████▊     | 220/455 [05:36<05:59,  1.53s/it][A
 49%|████▊     | 221/455 [05:37<05:58,  1.53s/it][A
 49%|████▉     | 222/455 [05:39<05:56,  1.53s/it][A
 49%|████▉     | 223/455 [05:40<05:55,  1.53s/it][A
 49%|████▉     | 224/455 [05:42<05:54,  1.53s/it][A
 49%|████▉     | 225/455 [05:43<05:51,  1.53s/it][A
 50%|████▉     | 226/455 [05:45<05:49,  1.53s/it][A
 50%|████▉     | 227/455 [05:46<05:48,  1.53s/it][A
 50%|█████     | 228/455 [05:48<05:47,  1.53s/it][A
 50%|█████     | 229/455 [05:50<05:44,  1.53s/it][A
 51%|█████     | 230/455 [05:51<05:44,  1.53s/it][A
 51%|█████     | 231/455 [05:53<05:42,  1.53s/it][A
 51%|█████     | 232/455 [05:54<05:41,  1.53s/it][A
 51%|█████     | 233/455 [05:56<05:39,  1.53s/it][A
 51%|█████▏    | 234/455 [05:57<05:36,  1.52s/it][A
 52%|█████▏    | 235/455 [05:59<05:36,  1.53s/it][A
 52%|█████▏    | 236/455 [06:00<05:35,  1.53s/it][A
 52%|█████▏    | 237/455 [06:02<05:34,  1.53s/it][A
 52%|█████▏    | 238/455 [06:03<05:33,  1.54s/it][A
 53%|█████▎    | 239/455 [06:05<05:32,  1.54s/it][A
 53%|█████▎    | 240/455 [06:06<05:28,  1.53s/it][A
 53%|█████▎    | 241/455 [06:08<05:27,  1.53s/it][A
 53%|█████▎    | 242/455 [06:09<05:25,  1.53s/it][A
 53%|█████▎    | 243/455 [06:11<05:27,  1.54s/it][A
 54%|█████▎    | 244/455 [06:13<05:26,  1.55s/it][A
 54%|█████▍    | 245/455 [06:14<05:23,  1.54s/it][A
 54%|█████▍    | 246/455 [06:16<05:22,  1.54s/it][A
 54%|█████▍    | 247/455 [06:17<05:20,  1.54s/it][A
 55%|█████▍    | 248/455 [06:19<05:17,  1.54s/it][A
 55%|█████▍    | 249/455 [06:20<05:16,  1.54s/it][A
 55%|█████▍    | 250/455 [06:22<05:13,  1.53s/it][A
 55%|█████▌    | 251/455 [06:23<05:12,  1.53s/it][A
 55%|█████▌    | 252/455 [06:25<05:11,  1.53s/it][A
 56%|█████▌    | 253/455 [06:26<05:08,  1.53s/it][A
 56%|█████▌    | 254/455 [06:28<05:07,  1.53s/it][A
 56%|█████▌    | 255/455 [06:29<05:07,  1.54s/it][A
 56%|█████▋    | 256/455 [06:31<05:05,  1.54s/it][A
 56%|█████▋    | 257/455 [06:33<05:04,  1.54s/it][A
 57%|█████▋    | 258/455 [06:34<05:02,  1.54s/it][A
 57%|█████▋    | 259/455 [06:36<05:01,  1.54s/it][A
 57%|█████▋    | 260/455 [06:37<05:00,  1.54s/it][A
 57%|█████▋    | 261/455 [06:39<04:58,  1.54s/it][A
 58%|█████▊    | 262/455 [06:40<04:57,  1.54s/it][A
 58%|█████▊    | 263/455 [06:42<04:54,  1.54s/it][A
 58%|█████▊    | 264/455 [06:43<04:52,  1.53s/it][A
 58%|█████▊    | 265/455 [06:45<04:50,  1.53s/it][A
 58%|█████▊    | 266/455 [06:46<04:49,  1.53s/it][A
 59%|█████▊    | 267/455 [06:48<04:49,  1.54s/it][A
 59%|█████▉    | 268/455 [06:49<04:47,  1.54s/it][A
 59%|█████▉    | 269/455 [06:51<04:47,  1.55s/it][A
 59%|█████▉    | 270/455 [06:53<04:46,  1.55s/it][A
 60%|█████▉    | 271/455 [06:54<04:43,  1.54s/it][A
 60%|█████▉    | 272/455 [06:56<04:42,  1.54s/it][A
 60%|██████    | 273/455 [06:57<04:40,  1.54s/it][A
 60%|██████    | 274/455 [06:59<04:38,  1.54s/it][A
 60%|██████    | 275/455 [07:00<04:37,  1.54s/it][A
 61%|██████    | 276/455 [07:02<04:35,  1.54s/it][A
 61%|██████    | 277/455 [07:03<04:34,  1.54s/it][A
 61%|██████    | 278/455 [07:05<04:31,  1.54s/it][A
 61%|██████▏   | 279/455 [07:06<04:30,  1.53s/it][A
 62%|██████▏   | 280/455 [07:08<04:29,  1.54s/it][A
 62%|██████▏   | 281/455 [07:09<04:26,  1.53s/it][A
 62%|██████▏   | 282/455 [07:11<04:25,  1.53s/it][A
 62%|██████▏   | 283/455 [07:13<04:24,  1.54s/it][A
 62%|██████▏   | 284/455 [07:14<04:23,  1.54s/it][A
 63%|██████▎   | 285/455 [07:16<04:22,  1.54s/it][A
 63%|██████▎   | 286/455 [07:17<04:19,  1.54s/it][A
 63%|██████▎   | 287/455 [07:19<04:19,  1.55s/it][A
 63%|██████▎   | 288/455 [07:20<04:17,  1.54s/it][A
 64%|██████▎   | 289/455 [07:22<04:14,  1.54s/it][A
 64%|██████▎   | 290/455 [07:23<04:14,  1.54s/it][A
 64%|██████▍   | 291/455 [07:25<04:12,  1.54s/it][A
 64%|██████▍   | 292/455 [07:26<04:10,  1.53s/it][A
 64%|██████▍   | 293/455 [07:28<04:08,  1.53s/it][A
 65%|██████▍   | 294/455 [07:29<04:07,  1.53s/it][A
 65%|██████▍   | 295/455 [07:31<04:05,  1.53s/it][A
 65%|██████▌   | 296/455 [07:32<04:03,  1.53s/it][A
 65%|██████▌   | 297/455 [07:34<04:01,  1.53s/it][A
 65%|██████▌   | 298/455 [07:36<04:00,  1.53s/it][A
 66%|██████▌   | 299/455 [07:37<03:58,  1.53s/it][A
 66%|██████▌   | 300/455 [07:39<03:57,  1.53s/it][A
 66%|██████▌   | 301/455 [07:40<03:55,  1.53s/it][A
 66%|██████▋   | 302/455 [07:42<03:54,  1.53s/it][A
 67%|██████▋   | 303/455 [07:43<03:52,  1.53s/it][A
 67%|██████▋   | 304/455 [07:45<03:51,  1.53s/it][A
 67%|██████▋   | 305/455 [07:46<03:50,  1.54s/it][A
 67%|██████▋   | 306/455 [07:48<03:49,  1.54s/it][A
 67%|██████▋   | 307/455 [07:49<03:47,  1.54s/it][A
 68%|██████▊   | 308/455 [07:51<03:45,  1.53s/it][A
 68%|██████▊   | 309/455 [07:52<03:44,  1.54s/it][A
 68%|██████▊   | 310/455 [07:54<03:43,  1.54s/it][A
 68%|██████▊   | 311/455 [07:56<03:42,  1.55s/it][A
 69%|██████▊   | 312/455 [07:57<03:40,  1.54s/it][A
 69%|██████▉   | 313/455 [07:59<03:39,  1.54s/it][A
 69%|██████▉   | 314/455 [08:00<03:36,  1.54s/it][A
 69%|██████▉   | 315/455 [08:02<03:34,  1.54s/it][A
 69%|██████▉   | 316/455 [08:03<03:33,  1.53s/it][A
 70%|██████▉   | 317/455 [08:05<03:32,  1.54s/it][A
 70%|██████▉   | 318/455 [08:06<03:30,  1.53s/it][A
 70%|███████   | 319/455 [08:08<03:28,  1.53s/it][A
 70%|███████   | 320/455 [08:09<03:26,  1.53s/it][A
 71%|███████   | 321/455 [08:11<03:25,  1.53s/it][A
 71%|███████   | 322/455 [08:12<03:23,  1.53s/it][A
 71%|███████   | 323/455 [08:14<03:21,  1.53s/it][A
 71%|███████   | 324/455 [08:15<03:20,  1.53s/it][A
 71%|███████▏  | 325/455 [08:17<03:18,  1.53s/it][A
 72%|███████▏  | 326/455 [08:19<03:18,  1.54s/it][A
 72%|███████▏  | 327/455 [08:20<03:16,  1.53s/it][A
 72%|███████▏  | 328/455 [08:22<03:14,  1.53s/it][A
 72%|███████▏  | 329/455 [08:23<03:13,  1.53s/it][A
 73%|███████▎  | 330/455 [08:25<03:11,  1.53s/it][A
 73%|███████▎  | 331/455 [08:26<03:09,  1.53s/it][A
 73%|███████▎  | 332/455 [08:28<03:08,  1.53s/it][A
 73%|███████▎  | 333/455 [08:29<03:07,  1.53s/it][A
 73%|███████▎  | 334/455 [08:31<03:06,  1.54s/it][A
 74%|███████▎  | 335/455 [08:32<03:04,  1.53s/it][A
 74%|███████▍  | 336/455 [08:34<03:02,  1.53s/it][A
 74%|███████▍  | 337/455 [08:35<03:00,  1.53s/it][A
 74%|███████▍  | 338/455 [08:37<02:58,  1.53s/it][A
 75%|███████▍  | 339/455 [08:38<02:57,  1.53s/it][A
 75%|███████▍  | 340/455 [08:40<02:56,  1.53s/it][A
 75%|███████▍  | 341/455 [08:42<02:54,  1.53s/it][A
 75%|███████▌  | 342/455 [08:43<02:53,  1.53s/it][A
 75%|███████▌  | 343/455 [08:45<02:50,  1.52s/it][A
 76%|███████▌  | 344/455 [08:46<02:49,  1.53s/it][A
 76%|███████▌  | 345/455 [08:48<02:48,  1.53s/it][A
 76%|███████▌  | 346/455 [08:49<02:46,  1.53s/it][A
 76%|███████▋  | 347/455 [08:51<02:44,  1.53s/it][A
 76%|███████▋  | 348/455 [08:52<02:43,  1.53s/it][A
 77%|███████▋  | 349/455 [08:54<02:42,  1.53s/it][A
 77%|███████▋  | 350/455 [08:55<02:40,  1.53s/it][A
 77%|███████▋  | 351/455 [08:57<02:39,  1.53s/it][A
 77%|███████▋  | 352/455 [08:58<02:37,  1.53s/it][A
 78%|███████▊  | 353/455 [09:00<02:36,  1.53s/it][A
 78%|███████▊  | 354/455 [09:01<02:34,  1.53s/it][A
 78%|███████▊  | 355/455 [09:03<02:33,  1.54s/it][A
 78%|███████▊  | 356/455 [09:04<02:32,  1.54s/it][A
 78%|███████▊  | 357/455 [09:06<02:30,  1.54s/it][A
 79%|███████▊  | 358/455 [09:08<02:30,  1.55s/it][A
 79%|███████▉  | 359/455 [09:09<02:28,  1.54s/it][A
 79%|███████▉  | 360/455 [09:11<02:26,  1.54s/it][A
 79%|███████▉  | 361/455 [09:12<02:24,  1.54s/it][A
 80%|███████▉  | 362/455 [09:14<02:22,  1.53s/it][A
 80%|███████▉  | 363/455 [09:15<02:20,  1.53s/it][A
 80%|████████  | 364/455 [09:17<02:19,  1.53s/it][A
 80%|████████  | 365/455 [09:18<02:18,  1.53s/it][A
 80%|████████  | 366/455 [09:20<02:16,  1.54s/it][A
 81%|████████  | 367/455 [09:21<02:15,  1.53s/it][A
 81%|████████  | 368/455 [09:23<02:14,  1.54s/it][A
 81%|████████  | 369/455 [09:24<02:12,  1.54s/it][A
 81%|████████▏ | 370/455 [09:26<02:10,  1.54s/it][A
 82%|████████▏ | 371/455 [09:28<02:09,  1.54s/it][A
 82%|████████▏ | 372/455 [09:29<02:07,  1.54s/it][A
 82%|████████▏ | 373/455 [09:31<02:06,  1.54s/it][A
 82%|████████▏ | 374/455 [09:32<02:04,  1.54s/it][A
 82%|████████▏ | 375/455 [09:34<02:02,  1.54s/it][A
 83%|████████▎ | 376/455 [09:35<02:01,  1.54s/it][A
 83%|████████▎ | 377/455 [09:37<02:00,  1.54s/it][A
 83%|████████▎ | 378/455 [09:38<01:58,  1.54s/it][A
 83%|████████▎ | 379/455 [09:40<01:56,  1.54s/it][A
 84%|████████▎ | 380/455 [09:41<01:55,  1.54s/it][A
 84%|████████▎ | 381/455 [09:43<01:53,  1.53s/it][A
 84%|████████▍ | 382/455 [09:44<01:51,  1.53s/it][A
 84%|████████▍ | 383/455 [09:46<01:50,  1.53s/it][A
 84%|████████▍ | 384/455 [09:48<01:49,  1.54s/it][A
 85%|████████▍ | 385/455 [09:49<01:47,  1.53s/it][A
 85%|████████▍ | 386/455 [09:51<01:45,  1.53s/it][A
 85%|████████▌ | 387/455 [09:52<01:43,  1.52s/it][A
 85%|████████▌ | 388/455 [09:54<01:42,  1.53s/it][A
 85%|████████▌ | 389/455 [09:55<01:41,  1.53s/it][A
 86%|████████▌ | 390/455 [09:57<01:39,  1.53s/it][A
 86%|████████▌ | 391/455 [09:58<01:38,  1.53s/it][A
 86%|████████▌ | 392/455 [10:00<01:36,  1.53s/it][A
 86%|████████▋ | 393/455 [10:01<01:35,  1.53s/it][A
 87%|████████▋ | 394/455 [10:03<01:33,  1.54s/it][A
 87%|████████▋ | 395/455 [10:04<01:32,  1.53s/it][A
 87%|████████▋ | 396/455 [10:06<01:30,  1.53s/it][A
 87%|████████▋ | 397/455 [10:07<01:28,  1.52s/it][A
 87%|████████▋ | 398/455 [10:09<01:26,  1.53s/it][A
 88%|████████▊ | 399/455 [10:10<01:25,  1.53s/it][A
 88%|████████▊ | 400/455 [10:12<01:23,  1.52s/it][A
 88%|████████▊ | 401/455 [10:14<01:22,  1.53s/it][A
 88%|████████▊ | 402/455 [10:15<01:21,  1.54s/it][A
 89%|████████▊ | 403/455 [10:17<01:19,  1.54s/it][A
 89%|████████▉ | 404/455 [10:18<01:18,  1.53s/it][A
 89%|████████▉ | 405/455 [10:20<01:16,  1.54s/it][A
 89%|████████▉ | 406/455 [10:21<01:15,  1.54s/it][A
 89%|████████▉ | 407/455 [10:23<01:15,  1.56s/it][A
 90%|████████▉ | 408/455 [10:24<01:13,  1.57s/it][A
 90%|████████▉ | 409/455 [10:26<01:12,  1.57s/it][A
 90%|█████████ | 410/455 [10:28<01:10,  1.56s/it][A
 90%|█████████ | 411/455 [10:29<01:08,  1.55s/it][A
 91%|█████████ | 412/455 [10:31<01:06,  1.54s/it][A
 91%|█████████ | 413/455 [10:32<01:04,  1.54s/it][A
 91%|█████████ | 414/455 [10:34<01:03,  1.54s/it][A
 91%|█████████ | 415/455 [10:35<01:01,  1.54s/it][A
 91%|█████████▏| 416/455 [10:37<01:00,  1.54s/it][A
 92%|█████████▏| 417/455 [10:38<00:58,  1.54s/it][A
 92%|█████████▏| 418/455 [10:40<00:56,  1.54s/it][A
 92%|█████████▏| 419/455 [10:41<00:55,  1.55s/it][A
 92%|█████████▏| 420/455 [10:43<00:54,  1.55s/it][A
 93%|█████████▎| 421/455 [10:44<00:52,  1.55s/it][A
 93%|█████████▎| 422/455 [10:46<00:50,  1.54s/it][A
 93%|█████████▎| 423/455 [10:48<00:49,  1.54s/it][A
 93%|█████████▎| 424/455 [10:49<00:47,  1.54s/it][A
 93%|█████████▎| 425/455 [10:51<00:46,  1.54s/it][A
 94%|█████████▎| 426/455 [10:52<00:44,  1.54s/it][A
 94%|█████████▍| 427/455 [10:54<00:43,  1.54s/it][A
 94%|█████████▍| 428/455 [10:55<00:41,  1.54s/it][A
 94%|█████████▍| 429/455 [10:57<00:40,  1.54s/it][A
 95%|█████████▍| 430/455 [10:58<00:38,  1.53s/it][A
 95%|█████████▍| 431/455 [11:00<00:36,  1.53s/it][A
 95%|█████████▍| 432/455 [11:01<00:35,  1.53s/it][A
 95%|█████████▌| 433/455 [11:03<00:33,  1.53s/it][A
 95%|█████████▌| 434/455 [11:04<00:32,  1.53s/it][A
 96%|█████████▌| 435/455 [11:06<00:30,  1.53s/it][A
 96%|█████████▌| 436/455 [11:07<00:29,  1.53s/it][A
 96%|█████████▌| 437/455 [11:09<00:27,  1.53s/it][A
 96%|█████████▋| 438/455 [11:11<00:26,  1.54s/it][A
 96%|█████████▋| 439/455 [11:12<00:24,  1.54s/it][A
 97%|█████████▋| 440/455 [11:14<00:23,  1.54s/it][A
 97%|█████████▋| 441/455 [11:15<00:21,  1.54s/it][A
 97%|█████████▋| 442/455 [11:17<00:20,  1.54s/it][A
 97%|█████████▋| 443/455 [11:18<00:18,  1.53s/it][A
 98%|█████████▊| 444/455 [11:20<00:16,  1.54s/it][A
 98%|█████████▊| 445/455 [11:21<00:15,  1.53s/it][A
 98%|█████████▊| 446/455 [11:23<00:13,  1.54s/it][A
 98%|█████████▊| 447/455 [11:24<00:12,  1.54s/it][A
 98%|█████████▊| 448/455 [11:26<00:10,  1.54s/it][A
 99%|█████████▊| 449/455 [11:27<00:09,  1.53s/it][A
 99%|█████████▉| 450/455 [11:29<00:07,  1.54s/it][A
 99%|█████████▉| 451/455 [11:31<00:06,  1.53s/it][A
 99%|█████████▉| 452/455 [11:32<00:04,  1.53s/it][A
100%|█████████▉| 453/455 [11:34<00:03,  1.53s/it][A
100%|█████████▉| 454/455 [11:35<00:01,  1.54s/it][A
100%|██████████| 455/455 [11:37<00:00,  1.53s/it][A                                                        
                                                 [A{'eval_loss': 1.779167890548706, 'eval_runtime': 698.7878, 'eval_samples_per_second': 2.6, 'eval_steps_per_second': 0.651, 'epoch': 0.83, 'step': 1500, 'max_steps': 7272}
 21%|██        | 1500/7272 [6:58:51<25:05:38, 15.65s/it]
100%|██████████| 455/455 [11:37<00:00,  1.53s/it][A
                                                 [A 21%|██        | 1501/7272 [6:59:06<361:07:06, 225.27s/it]                                                          {'loss': 1.3988, 'grad_norm': 5.1337456703186035, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1501, 'max_steps': 7272}
 21%|██        | 1501/7272 [6:59:06<361:07:06, 225.27s/it] 21%|██        | 1502/7272 [6:59:22<260:18:59, 162.42s/it]                                                          {'loss': 2.5429, 'grad_norm': 5.701529026031494, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1502, 'max_steps': 7272}
 21%|██        | 1502/7272 [6:59:22<260:18:59, 162.42s/it] 21%|██        | 1503/7272 [6:59:38<189:54:40, 118.51s/it]                                                          {'loss': 0.8461, 'grad_norm': 2.458925485610962, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1503, 'max_steps': 7272}
 21%|██        | 1503/7272 [6:59:38<189:54:40, 118.51s/it] 21%|██        | 1504/7272 [6:59:54<140:39:41, 87.79s/it]                                                          {'loss': 1.895, 'grad_norm': 7.9581685066223145, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1504, 'max_steps': 7272}
 21%|██        | 1504/7272 [6:59:54<140:39:41, 87.79s/it] 21%|██        | 1505/7272 [7:00:11<106:27:39, 66.46s/it]                                                         {'loss': 3.3819, 'grad_norm': 5.963953495025635, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1505, 'max_steps': 7272}
 21%|██        | 1505/7272 [7:00:11<106:27:39, 66.46s/it] 21%|██        | 1506/7272 [7:00:26<82:04:07, 51.24s/it]                                                         {'loss': 1.6986, 'grad_norm': 4.867355823516846, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1506, 'max_steps': 7272}
 21%|██        | 1506/7272 [7:00:26<82:04:07, 51.24s/it] 21%|██        | 1507/7272 [7:00:42<64:49:36, 40.48s/it]                                                        {'loss': 1.4543, 'grad_norm': 5.287318706512451, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1507, 'max_steps': 7272}
 21%|██        | 1507/7272 [7:00:42<64:49:36, 40.48s/it] 21%|██        | 1508/7272 [7:00:58<52:54:49, 33.05s/it]                                                        {'loss': 1.7494, 'grad_norm': 6.079700469970703, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1508, 'max_steps': 7272}
 21%|██        | 1508/7272 [7:00:58<52:54:49, 33.05s/it] 21%|██        | 1509/7272 [7:01:13<44:38:38, 27.89s/it]                                                        {'loss': 1.0827, 'grad_norm': 6.651342868804932, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1509, 'max_steps': 7272}
 21%|██        | 1509/7272 [7:01:13<44:38:38, 27.89s/it] 21%|██        | 1510/7272 [7:01:29<38:42:54, 24.19s/it]                                                        {'loss': 3.2255, 'grad_norm': 11.232661247253418, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1510, 'max_steps': 7272}
 21%|██        | 1510/7272 [7:01:29<38:42:54, 24.19s/it] 21%|██        | 1511/7272 [7:01:45<34:35:48, 21.62s/it]                                                        {'loss': 1.95, 'grad_norm': 8.018462181091309, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1511, 'max_steps': 7272}
 21%|██        | 1511/7272 [7:01:45<34:35:48, 21.62s/it] 21%|██        | 1512/7272 [7:02:01<31:54:45, 19.95s/it]                                                        {'loss': 1.7779, 'grad_norm': 4.406041145324707, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1512, 'max_steps': 7272}
 21%|██        | 1512/7272 [7:02:01<31:54:45, 19.95s/it] 21%|██        | 1513/7272 [7:02:17<30:05:37, 18.81s/it]                                                        {'loss': 1.4249, 'grad_norm': 7.0692057609558105, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1513, 'max_steps': 7272}
 21%|██        | 1513/7272 [7:02:17<30:05:37, 18.81s/it] 21%|██        | 1514/7272 [7:02:32<28:31:38, 17.84s/it]                                                        {'loss': 1.9391, 'grad_norm': 4.420176029205322, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1514, 'max_steps': 7272}
 21%|██        | 1514/7272 [7:02:32<28:31:38, 17.84s/it] 21%|██        | 1515/7272 [7:02:48<27:42:10, 17.32s/it]                                                        {'loss': 0.7578, 'grad_norm': 3.0398662090301514, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1515, 'max_steps': 7272}
 21%|██        | 1515/7272 [7:02:48<27:42:10, 17.32s/it] 21%|██        | 1516/7272 [7:03:04<26:38:31, 16.66s/it]                                                        {'loss': 2.2733, 'grad_norm': 5.469832420349121, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1516, 'max_steps': 7272}
 21%|██        | 1516/7272 [7:03:04<26:38:31, 16.66s/it] 21%|██        | 1517/7272 [7:03:20<26:17:48, 16.45s/it]                                                        {'loss': 2.3774, 'grad_norm': 7.349147319793701, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1517, 'max_steps': 7272}
 21%|██        | 1517/7272 [7:03:20<26:17:48, 16.45s/it] 21%|██        | 1518/7272 [7:03:36<26:07:05, 16.34s/it]                                                        {'loss': 1.6799, 'grad_norm': 5.837640285491943, 'learning_rate': 5e-05, 'epoch': 0.83, 'step': 1518, 'max_steps': 7272}
 21%|██        | 1518/7272 [7:03:36<26:07:05, 16.34s/it] 21%|██        | 1519/7272 [7:03:51<25:51:48, 16.18s/it]                                                        {'loss': 1.5391, 'grad_norm': 7.604325294494629, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1519, 'max_steps': 7272}
 21%|██        | 1519/7272 [7:03:51<25:51:48, 16.18s/it] 21%|██        | 1520/7272 [7:04:07<25:29:00, 15.95s/it]                                                        {'loss': 1.9239, 'grad_norm': 4.878121376037598, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1520, 'max_steps': 7272}
 21%|██        | 1520/7272 [7:04:07<25:29:00, 15.95s/it] 21%|██        | 1521/7272 [7:04:23<25:29:27, 15.96s/it]                                                        {'loss': 1.6761, 'grad_norm': 6.422999858856201, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1521, 'max_steps': 7272}
 21%|██        | 1521/7272 [7:04:23<25:29:27, 15.96s/it] 21%|██        | 1522/7272 [7:04:38<25:18:04, 15.84s/it]                                                        {'loss': 1.3657, 'grad_norm': 3.797506809234619, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1522, 'max_steps': 7272}
 21%|██        | 1522/7272 [7:04:38<25:18:04, 15.84s/it] 21%|██        | 1523/7272 [7:04:54<25:13:13, 15.79s/it]                                                        {'loss': 1.3805, 'grad_norm': 2.8645591735839844, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1523, 'max_steps': 7272}
 21%|██        | 1523/7272 [7:04:54<25:13:13, 15.79s/it] 21%|██        | 1524/7272 [7:05:10<25:12:18, 15.79s/it]                                                        {'loss': 1.316, 'grad_norm': 4.9305877685546875, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1524, 'max_steps': 7272}
 21%|██        | 1524/7272 [7:05:10<25:12:18, 15.79s/it] 21%|██        | 1525/7272 [7:05:26<25:24:56, 15.92s/it]                                                        {'loss': 1.0308, 'grad_norm': 3.580716609954834, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1525, 'max_steps': 7272}
 21%|██        | 1525/7272 [7:05:26<25:24:56, 15.92s/it] 21%|██        | 1526/7272 [7:05:43<25:41:39, 16.10s/it]                                                        {'loss': 1.8208, 'grad_norm': 3.841575860977173, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1526, 'max_steps': 7272}
 21%|██        | 1526/7272 [7:05:43<25:41:39, 16.10s/it] 21%|██        | 1527/7272 [7:05:59<25:53:30, 16.22s/it]                                                        {'loss': 1.9484, 'grad_norm': 7.0779523849487305, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1527, 'max_steps': 7272}
 21%|██        | 1527/7272 [7:05:59<25:53:30, 16.22s/it] 21%|██        | 1528/7272 [7:06:15<25:56:56, 16.26s/it]                                                        {'loss': 1.5455, 'grad_norm': 5.368961811065674, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1528, 'max_steps': 7272}
 21%|██        | 1528/7272 [7:06:15<25:56:56, 16.26s/it] 21%|██        | 1529/7272 [7:06:31<25:44:32, 16.14s/it]                                                        {'loss': 2.3715, 'grad_norm': 5.563370227813721, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1529, 'max_steps': 7272}
 21%|██        | 1529/7272 [7:06:31<25:44:32, 16.14s/it] 21%|██        | 1530/7272 [7:06:47<25:43:42, 16.13s/it]                                                        {'loss': 1.636, 'grad_norm': 11.517354011535645, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1530, 'max_steps': 7272}
 21%|██        | 1530/7272 [7:06:47<25:43:42, 16.13s/it] 21%|██        | 1531/7272 [7:07:03<25:33:43, 16.03s/it]                                                        {'loss': 1.7529, 'grad_norm': 4.815081596374512, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1531, 'max_steps': 7272}
 21%|██        | 1531/7272 [7:07:03<25:33:43, 16.03s/it] 21%|██        | 1532/7272 [7:07:19<25:13:33, 15.82s/it]                                                        {'loss': 2.3246, 'grad_norm': 3.7764086723327637, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1532, 'max_steps': 7272}
 21%|██        | 1532/7272 [7:07:19<25:13:33, 15.82s/it] 21%|██        | 1533/7272 [7:07:34<25:06:15, 15.75s/it]                                                        {'loss': 1.3949, 'grad_norm': 3.491420269012451, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1533, 'max_steps': 7272}
 21%|██        | 1533/7272 [7:07:34<25:06:15, 15.75s/it] 21%|██        | 1534/7272 [7:07:50<25:05:37, 15.74s/it]                                                        {'loss': 1.4407, 'grad_norm': 3.3074417114257812, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1534, 'max_steps': 7272}
 21%|██        | 1534/7272 [7:07:50<25:05:37, 15.74s/it] 21%|██        | 1535/7272 [7:08:05<24:58:19, 15.67s/it]                                                        {'loss': 1.4956, 'grad_norm': 3.476459503173828, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1535, 'max_steps': 7272}
 21%|██        | 1535/7272 [7:08:05<24:58:19, 15.67s/it] 21%|██        | 1536/7272 [7:08:21<25:03:39, 15.73s/it]                                                        {'loss': 1.6653, 'grad_norm': 7.56924295425415, 'learning_rate': 5e-05, 'epoch': 0.84, 'step': 1536, 'max_steps': 7272}
 21%|██        | 1536/7272 [7:08:21<25:03:39, 15.73s/it] 21%|██        | 1537/7272 [7:08:37<25:05:54, 15.75s/it]                                                        {'loss': 1.3972, 'grad_norm': 4.172654151916504, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1537, 'max_steps': 7272}
 21%|██        | 1537/7272 [7:08:37<25:05:54, 15.75s/it] 21%|██        | 1538/7272 [7:08:53<24:57:24, 15.67s/it]                                                        {'loss': 2.1867, 'grad_norm': 10.252628326416016, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1538, 'max_steps': 7272}
 21%|██        | 1538/7272 [7:08:53<24:57:24, 15.67s/it] 21%|██        | 1539/7272 [7:09:08<24:54:31, 15.64s/it]                                                        {'loss': 3.0943, 'grad_norm': 6.008345127105713, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1539, 'max_steps': 7272}
 21%|██        | 1539/7272 [7:09:08<24:54:31, 15.64s/it] 21%|██        | 1540/7272 [7:09:24<25:07:44, 15.78s/it]                                                        {'loss': 1.0376, 'grad_norm': 3.6108007431030273, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1540, 'max_steps': 7272}
 21%|██        | 1540/7272 [7:09:24<25:07:44, 15.78s/it] 21%|██        | 1541/7272 [7:09:41<25:26:01, 15.98s/it]                                                        {'loss': 1.8552, 'grad_norm': 6.472248554229736, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1541, 'max_steps': 7272}
 21%|██        | 1541/7272 [7:09:41<25:26:01, 15.98s/it] 21%|██        | 1542/7272 [7:09:57<25:30:42, 16.03s/it]                                                        {'loss': 2.3345, 'grad_norm': 6.9540581703186035, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1542, 'max_steps': 7272}
 21%|██        | 1542/7272 [7:09:57<25:30:42, 16.03s/it] 21%|██        | 1543/7272 [7:10:13<25:33:35, 16.06s/it]                                                        {'loss': 0.6706, 'grad_norm': 2.2058327198028564, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1543, 'max_steps': 7272}
 21%|██        | 1543/7272 [7:10:13<25:33:35, 16.06s/it] 21%|██        | 1544/7272 [7:10:29<25:25:52, 15.98s/it]                                                        {'loss': 1.3705, 'grad_norm': 3.528701066970825, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1544, 'max_steps': 7272}
 21%|██        | 1544/7272 [7:10:29<25:25:52, 15.98s/it] 21%|██        | 1545/7272 [7:10:44<25:13:13, 15.85s/it]                                                        {'loss': 2.8863, 'grad_norm': 6.366153240203857, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1545, 'max_steps': 7272}
 21%|██        | 1545/7272 [7:10:44<25:13:13, 15.85s/it] 21%|██▏       | 1546/7272 [7:11:00<24:56:30, 15.68s/it]                                                        {'loss': 1.1494, 'grad_norm': 4.786909580230713, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1546, 'max_steps': 7272}
 21%|██▏       | 1546/7272 [7:11:00<24:56:30, 15.68s/it] 21%|██▏       | 1547/7272 [7:11:15<24:48:52, 15.60s/it]                                                        {'loss': 1.4977, 'grad_norm': 2.960082530975342, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1547, 'max_steps': 7272}
 21%|██▏       | 1547/7272 [7:11:15<24:48:52, 15.60s/it] 21%|██▏       | 1548/7272 [7:11:31<24:53:05, 15.65s/it]                                                        {'loss': 2.9355, 'grad_norm': 6.269688129425049, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1548, 'max_steps': 7272}
 21%|██▏       | 1548/7272 [7:11:31<24:53:05, 15.65s/it] 21%|██▏       | 1549/7272 [7:11:46<24:49:40, 15.62s/it]                                                        {'loss': 3.1641, 'grad_norm': 6.7063398361206055, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1549, 'max_steps': 7272}
 21%|██▏       | 1549/7272 [7:11:46<24:49:40, 15.62s/it] 21%|██▏       | 1550/7272 [7:12:02<24:59:16, 15.72s/it]                                                        {'loss': 0.8381, 'grad_norm': 1.711124062538147, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1550, 'max_steps': 7272}
 21%|██▏       | 1550/7272 [7:12:02<24:59:16, 15.72s/it] 21%|██▏       | 1551/7272 [7:12:18<24:57:38, 15.71s/it]                                                        {'loss': 0.7527, 'grad_norm': 3.469395875930786, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1551, 'max_steps': 7272}
 21%|██▏       | 1551/7272 [7:12:18<24:57:38, 15.71s/it] 21%|██▏       | 1552/7272 [7:12:33<24:50:44, 15.64s/it]                                                        {'loss': 2.2105, 'grad_norm': 6.035854816436768, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1552, 'max_steps': 7272}
 21%|██▏       | 1552/7272 [7:12:33<24:50:44, 15.64s/it] 21%|██▏       | 1553/7272 [7:12:49<24:43:58, 15.57s/it]                                                        {'loss': 2.5517, 'grad_norm': 5.232724189758301, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1553, 'max_steps': 7272}
 21%|██▏       | 1553/7272 [7:12:49<24:43:58, 15.57s/it] 21%|██▏       | 1554/7272 [7:13:04<24:43:48, 15.57s/it]                                                        {'loss': 1.6913, 'grad_norm': 3.640568494796753, 'learning_rate': 5e-05, 'epoch': 0.85, 'step': 1554, 'max_steps': 7272}
 21%|██▏       | 1554/7272 [7:13:04<24:43:48, 15.57s/it] 21%|██▏       | 1555/7272 [7:13:20<24:40:44, 15.54s/it]                                                        {'loss': 1.6386, 'grad_norm': 6.851041316986084, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1555, 'max_steps': 7272}
 21%|██▏       | 1555/7272 [7:13:20<24:40:44, 15.54s/it] 21%|██▏       | 1556/7272 [7:13:36<24:44:13, 15.58s/it]                                                        {'loss': 1.3799, 'grad_norm': 7.036347389221191, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1556, 'max_steps': 7272}
 21%|██▏       | 1556/7272 [7:13:36<24:44:13, 15.58s/it] 21%|██▏       | 1557/7272 [7:13:51<24:43:49, 15.58s/it]                                                        {'loss': 1.9569, 'grad_norm': 7.484225749969482, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1557, 'max_steps': 7272}
 21%|██▏       | 1557/7272 [7:13:51<24:43:49, 15.58s/it] 21%|██▏       | 1558/7272 [7:14:07<24:54:19, 15.69s/it]                                                        {'loss': 2.0653, 'grad_norm': 6.259248733520508, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1558, 'max_steps': 7272}
 21%|██▏       | 1558/7272 [7:14:07<24:54:19, 15.69s/it] 21%|██▏       | 1559/7272 [7:14:22<24:46:03, 15.61s/it]                                                        {'loss': 1.944, 'grad_norm': 3.8852579593658447, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1559, 'max_steps': 7272}
 21%|██▏       | 1559/7272 [7:14:22<24:46:03, 15.61s/it] 21%|██▏       | 1560/7272 [7:14:39<25:02:33, 15.78s/it]                                                        {'loss': 0.8554, 'grad_norm': 2.3762354850769043, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1560, 'max_steps': 7272}
 21%|██▏       | 1560/7272 [7:14:39<25:02:33, 15.78s/it] 21%|██▏       | 1561/7272 [7:14:54<24:59:44, 15.76s/it]                                                        {'loss': 1.5291, 'grad_norm': 6.37149715423584, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1561, 'max_steps': 7272}
 21%|██▏       | 1561/7272 [7:14:54<24:59:44, 15.76s/it] 21%|██▏       | 1562/7272 [7:15:10<24:58:28, 15.75s/it]                                                        {'loss': 2.2438, 'grad_norm': 4.2096991539001465, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1562, 'max_steps': 7272}
 21%|██▏       | 1562/7272 [7:15:10<24:58:28, 15.75s/it] 21%|██▏       | 1563/7272 [7:15:26<24:59:21, 15.76s/it]                                                        {'loss': 1.6858, 'grad_norm': 6.016277313232422, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1563, 'max_steps': 7272}
 21%|██▏       | 1563/7272 [7:15:26<24:59:21, 15.76s/it] 22%|██▏       | 1564/7272 [7:15:42<24:56:22, 15.73s/it]                                                        {'loss': 2.0059, 'grad_norm': 7.306929111480713, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1564, 'max_steps': 7272}
 22%|██▏       | 1564/7272 [7:15:42<24:56:22, 15.73s/it] 22%|██▏       | 1565/7272 [7:15:57<25:00:27, 15.77s/it]                                                        {'loss': 1.951, 'grad_norm': 8.145254135131836, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1565, 'max_steps': 7272}
 22%|██▏       | 1565/7272 [7:15:57<25:00:27, 15.77s/it] 22%|██▏       | 1566/7272 [7:16:13<25:00:17, 15.78s/it]                                                        {'loss': 2.0315, 'grad_norm': 3.9659841060638428, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1566, 'max_steps': 7272}
 22%|██▏       | 1566/7272 [7:16:13<25:00:17, 15.78s/it] 22%|██▏       | 1567/7272 [7:16:29<25:06:01, 15.84s/it]                                                        {'loss': 1.3765, 'grad_norm': 3.731658935546875, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1567, 'max_steps': 7272}
 22%|██▏       | 1567/7272 [7:16:29<25:06:01, 15.84s/it] 22%|██▏       | 1568/7272 [7:16:45<25:10:30, 15.89s/it]                                                        {'loss': 2.508, 'grad_norm': 6.669659614562988, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1568, 'max_steps': 7272}
 22%|██▏       | 1568/7272 [7:16:45<25:10:30, 15.89s/it] 22%|██▏       | 1569/7272 [7:17:01<25:01:43, 15.80s/it]                                                        {'loss': 1.4585, 'grad_norm': 3.0540966987609863, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1569, 'max_steps': 7272}
 22%|██▏       | 1569/7272 [7:17:01<25:01:43, 15.80s/it] 22%|██▏       | 1570/7272 [7:17:16<24:50:09, 15.68s/it]                                                        {'loss': 2.0008, 'grad_norm': 2.7662172317504883, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1570, 'max_steps': 7272}
 22%|██▏       | 1570/7272 [7:17:16<24:50:09, 15.68s/it] 22%|██▏       | 1571/7272 [7:17:32<24:47:34, 15.66s/it]                                                        {'loss': 1.1256, 'grad_norm': 7.263264179229736, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1571, 'max_steps': 7272}
 22%|██▏       | 1571/7272 [7:17:32<24:47:34, 15.66s/it] 22%|██▏       | 1572/7272 [7:17:47<24:33:31, 15.51s/it]                                                        {'loss': 1.0948, 'grad_norm': 4.091646671295166, 'learning_rate': 5e-05, 'epoch': 0.86, 'step': 1572, 'max_steps': 7272}
 22%|██▏       | 1572/7272 [7:17:47<24:33:31, 15.51s/it] 22%|██▏       | 1573/7272 [7:18:03<24:36:24, 15.54s/it]                                                        {'loss': 2.427, 'grad_norm': 4.261719226837158, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1573, 'max_steps': 7272}
 22%|██▏       | 1573/7272 [7:18:03<24:36:24, 15.54s/it] 22%|██▏       | 1574/7272 [7:18:18<24:31:56, 15.50s/it]                                                        {'loss': 1.6998, 'grad_norm': 6.876060485839844, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1574, 'max_steps': 7272}
 22%|██▏       | 1574/7272 [7:18:18<24:31:56, 15.50s/it] 22%|██▏       | 1575/7272 [7:18:33<24:26:20, 15.44s/it]                                                        {'loss': 2.3293, 'grad_norm': 4.430927753448486, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1575, 'max_steps': 7272}
 22%|██▏       | 1575/7272 [7:18:33<24:26:20, 15.44s/it] 22%|██▏       | 1576/7272 [7:18:49<24:22:18, 15.40s/it]                                                        {'loss': 0.9285, 'grad_norm': 1.8880058526992798, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1576, 'max_steps': 7272}
 22%|██▏       | 1576/7272 [7:18:49<24:22:18, 15.40s/it] 22%|██▏       | 1577/7272 [7:19:05<24:42:17, 15.62s/it]                                                        {'loss': 1.9496, 'grad_norm': 4.059357166290283, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1577, 'max_steps': 7272}
 22%|██▏       | 1577/7272 [7:19:05<24:42:17, 15.62s/it] 22%|██▏       | 1578/7272 [7:19:21<24:55:13, 15.76s/it]                                                        {'loss': 1.6472, 'grad_norm': 6.690735340118408, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1578, 'max_steps': 7272}
 22%|██▏       | 1578/7272 [7:19:21<24:55:13, 15.76s/it] 22%|██▏       | 1579/7272 [7:19:36<24:52:41, 15.73s/it]                                                        {'loss': 2.4766, 'grad_norm': 8.303089141845703, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1579, 'max_steps': 7272}
 22%|██▏       | 1579/7272 [7:19:36<24:52:41, 15.73s/it] 22%|██▏       | 1580/7272 [7:19:52<24:53:55, 15.75s/it]                                                        {'loss': 1.2985, 'grad_norm': 4.070441246032715, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1580, 'max_steps': 7272}
 22%|██▏       | 1580/7272 [7:19:52<24:53:55, 15.75s/it] 22%|██▏       | 1581/7272 [7:20:08<24:56:57, 15.78s/it]                                                        {'loss': 1.1294, 'grad_norm': 3.8753373622894287, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1581, 'max_steps': 7272}
 22%|██▏       | 1581/7272 [7:20:08<24:56:57, 15.78s/it] 22%|██▏       | 1582/7272 [7:20:24<24:55:58, 15.77s/it]                                                        {'loss': 2.2332, 'grad_norm': 10.888714790344238, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1582, 'max_steps': 7272}
 22%|██▏       | 1582/7272 [7:20:24<24:55:58, 15.77s/it] 22%|██▏       | 1583/7272 [7:20:40<24:57:36, 15.79s/it]                                                        {'loss': 2.3929, 'grad_norm': 34.823814392089844, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1583, 'max_steps': 7272}
 22%|██▏       | 1583/7272 [7:20:40<24:57:36, 15.79s/it] 22%|██▏       | 1584/7272 [7:20:55<24:47:43, 15.69s/it]                                                        {'loss': 1.3938, 'grad_norm': 7.396639823913574, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1584, 'max_steps': 7272}
 22%|██▏       | 1584/7272 [7:20:55<24:47:43, 15.69s/it] 22%|██▏       | 1585/7272 [7:21:11<24:43:57, 15.66s/it]                                                        {'loss': 2.5973, 'grad_norm': 7.614107131958008, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1585, 'max_steps': 7272}
 22%|██▏       | 1585/7272 [7:21:11<24:43:57, 15.66s/it] 22%|██▏       | 1586/7272 [7:21:27<24:57:46, 15.80s/it]                                                        {'loss': 2.7523, 'grad_norm': 4.576042652130127, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1586, 'max_steps': 7272}
 22%|██▏       | 1586/7272 [7:21:27<24:57:46, 15.80s/it] 22%|██▏       | 1587/7272 [7:21:42<24:47:23, 15.70s/it]                                                        {'loss': 1.6649, 'grad_norm': 8.056780815124512, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1587, 'max_steps': 7272}
 22%|██▏       | 1587/7272 [7:21:42<24:47:23, 15.70s/it] 22%|██▏       | 1588/7272 [7:21:57<24:32:28, 15.54s/it]                                                        {'loss': 2.1111, 'grad_norm': 7.083691120147705, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1588, 'max_steps': 7272}
 22%|██▏       | 1588/7272 [7:21:57<24:32:28, 15.54s/it] 22%|██▏       | 1589/7272 [7:22:14<24:45:52, 15.69s/it]                                                        {'loss': 0.9407, 'grad_norm': 2.4541265964508057, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1589, 'max_steps': 7272}
 22%|██▏       | 1589/7272 [7:22:14<24:45:52, 15.69s/it] 22%|██▏       | 1590/7272 [7:22:29<24:44:53, 15.68s/it]                                                        {'loss': 1.7982, 'grad_norm': 8.947032928466797, 'learning_rate': 5e-05, 'epoch': 0.87, 'step': 1590, 'max_steps': 7272}
 22%|██▏       | 1590/7272 [7:22:29<24:44:53, 15.68s/it] 22%|██▏       | 1591/7272 [7:22:45<24:54:28, 15.78s/it]                                                        {'loss': 1.6286, 'grad_norm': 7.491678714752197, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1591, 'max_steps': 7272}
 22%|██▏       | 1591/7272 [7:22:45<24:54:28, 15.78s/it] 22%|██▏       | 1592/7272 [7:23:01<24:51:25, 15.75s/it]                                                        {'loss': 3.1927, 'grad_norm': 11.298664093017578, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1592, 'max_steps': 7272}
 22%|██▏       | 1592/7272 [7:23:01<24:51:25, 15.75s/it] 22%|██▏       | 1593/7272 [7:23:17<24:58:20, 15.83s/it]                                                        {'loss': 1.2674, 'grad_norm': 5.54096794128418, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1593, 'max_steps': 7272}
 22%|██▏       | 1593/7272 [7:23:17<24:58:20, 15.83s/it] 22%|██▏       | 1594/7272 [7:23:32<24:49:00, 15.73s/it]                                                        {'loss': 1.1747, 'grad_norm': 2.4779655933380127, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1594, 'max_steps': 7272}
 22%|██▏       | 1594/7272 [7:23:32<24:49:00, 15.73s/it] 22%|██▏       | 1595/7272 [7:23:48<24:55:20, 15.80s/it]                                                        {'loss': 2.8253, 'grad_norm': 11.286928176879883, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1595, 'max_steps': 7272}
 22%|██▏       | 1595/7272 [7:23:48<24:55:20, 15.80s/it] 22%|██▏       | 1596/7272 [7:24:05<25:12:22, 15.99s/it]                                                        {'loss': 1.8929, 'grad_norm': 5.451780796051025, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1596, 'max_steps': 7272}
 22%|██▏       | 1596/7272 [7:24:05<25:12:22, 15.99s/it] 22%|██▏       | 1597/7272 [7:24:21<25:25:28, 16.13s/it]                                                        {'loss': 1.9058, 'grad_norm': 6.868423938751221, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1597, 'max_steps': 7272}
 22%|██▏       | 1597/7272 [7:24:21<25:25:28, 16.13s/it] 22%|██▏       | 1598/7272 [7:24:37<25:08:41, 15.95s/it]                                                        {'loss': 1.9136, 'grad_norm': 2.598681688308716, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1598, 'max_steps': 7272}
 22%|██▏       | 1598/7272 [7:24:37<25:08:41, 15.95s/it] 22%|██▏       | 1599/7272 [7:24:54<25:32:05, 16.20s/it]                                                        {'loss': 2.5213, 'grad_norm': 8.061707496643066, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1599, 'max_steps': 7272}
 22%|██▏       | 1599/7272 [7:24:54<25:32:05, 16.20s/it] 22%|██▏       | 1600/7272 [7:25:10<25:32:55, 16.22s/it]                                                        {'loss': 1.4414, 'grad_norm': 4.87799596786499, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1600, 'max_steps': 7272}
 22%|██▏       | 1600/7272 [7:25:10<25:32:55, 16.22s/it] 22%|██▏       | 1601/7272 [7:25:26<25:35:14, 16.24s/it]                                                        {'loss': 1.0614, 'grad_norm': 5.185340404510498, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1601, 'max_steps': 7272}
 22%|██▏       | 1601/7272 [7:25:26<25:35:14, 16.24s/it] 22%|██▏       | 1602/7272 [7:25:42<25:29:47, 16.19s/it]                                                        {'loss': 1.5473, 'grad_norm': 3.1132004261016846, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1602, 'max_steps': 7272}
 22%|██▏       | 1602/7272 [7:25:42<25:29:47, 16.19s/it] 22%|██▏       | 1603/7272 [7:25:58<25:24:38, 16.14s/it]                                                        {'loss': 1.5407, 'grad_norm': 11.673665046691895, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1603, 'max_steps': 7272}
 22%|██▏       | 1603/7272 [7:25:58<25:24:38, 16.14s/it] 22%|██▏       | 1604/7272 [7:26:15<25:46:12, 16.37s/it]                                                        {'loss': 1.4056, 'grad_norm': 3.9791624546051025, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1604, 'max_steps': 7272}
 22%|██▏       | 1604/7272 [7:26:15<25:46:12, 16.37s/it] 22%|██▏       | 1605/7272 [7:26:31<25:37:58, 16.28s/it]                                                        {'loss': 1.6939, 'grad_norm': 5.529984474182129, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1605, 'max_steps': 7272}
 22%|██▏       | 1605/7272 [7:26:31<25:37:58, 16.28s/it] 22%|██▏       | 1606/7272 [7:26:48<25:41:48, 16.33s/it]                                                        {'loss': 1.5701, 'grad_norm': 8.547700881958008, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1606, 'max_steps': 7272}
 22%|██▏       | 1606/7272 [7:26:48<25:41:48, 16.33s/it] 22%|██▏       | 1607/7272 [7:27:03<25:15:31, 16.05s/it]                                                        {'loss': 1.6354, 'grad_norm': 5.059540271759033, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1607, 'max_steps': 7272}
 22%|██▏       | 1607/7272 [7:27:03<25:15:31, 16.05s/it] 22%|██▏       | 1608/7272 [7:27:19<25:20:43, 16.11s/it]                                                        {'loss': 1.8602, 'grad_norm': 3.835432291030884, 'learning_rate': 5e-05, 'epoch': 0.88, 'step': 1608, 'max_steps': 7272}
 22%|██▏       | 1608/7272 [7:27:19<25:20:43, 16.11s/it] 22%|██▏       | 1609/7272 [7:27:35<25:06:40, 15.96s/it]                                                        {'loss': 2.4098, 'grad_norm': 6.166453838348389, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1609, 'max_steps': 7272}
 22%|██▏       | 1609/7272 [7:27:35<25:06:40, 15.96s/it] 22%|██▏       | 1610/7272 [7:27:52<25:26:32, 16.18s/it]                                                        {'loss': 2.692, 'grad_norm': 10.326493263244629, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1610, 'max_steps': 7272}
 22%|██▏       | 1610/7272 [7:27:52<25:26:32, 16.18s/it] 22%|██▏       | 1611/7272 [7:28:08<25:29:14, 16.21s/it]                                                        {'loss': 1.5117, 'grad_norm': 2.8124635219573975, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1611, 'max_steps': 7272}
 22%|██▏       | 1611/7272 [7:28:08<25:29:14, 16.21s/it] 22%|██▏       | 1612/7272 [7:28:24<25:30:22, 16.22s/it]                                                        {'loss': 1.1483, 'grad_norm': 4.2827959060668945, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1612, 'max_steps': 7272}
 22%|██▏       | 1612/7272 [7:28:24<25:30:22, 16.22s/it] 22%|██▏       | 1613/7272 [7:28:41<25:40:05, 16.33s/it]                                                        {'loss': 1.6302, 'grad_norm': 3.7262892723083496, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1613, 'max_steps': 7272}
 22%|██▏       | 1613/7272 [7:28:41<25:40:05, 16.33s/it] 22%|██▏       | 1614/7272 [7:28:57<25:35:01, 16.28s/it]                                                        {'loss': 1.6359, 'grad_norm': 2.531200647354126, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1614, 'max_steps': 7272}
 22%|██▏       | 1614/7272 [7:28:57<25:35:01, 16.28s/it] 22%|██▏       | 1615/7272 [7:29:12<25:11:14, 16.03s/it]                                                        {'loss': 2.4009, 'grad_norm': 4.983520030975342, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1615, 'max_steps': 7272}
 22%|██▏       | 1615/7272 [7:29:12<25:11:14, 16.03s/it] 22%|██▏       | 1616/7272 [7:29:28<25:11:08, 16.03s/it]                                                        {'loss': 2.7866, 'grad_norm': 6.294137477874756, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1616, 'max_steps': 7272}
 22%|██▏       | 1616/7272 [7:29:28<25:11:08, 16.03s/it] 22%|██▏       | 1617/7272 [7:29:45<25:23:36, 16.17s/it]                                                        {'loss': 2.1189, 'grad_norm': 6.28357458114624, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1617, 'max_steps': 7272}
 22%|██▏       | 1617/7272 [7:29:45<25:23:36, 16.17s/it] 22%|██▏       | 1618/7272 [7:30:01<25:32:48, 16.27s/it]                                                        {'loss': 2.0109, 'grad_norm': 6.931307315826416, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1618, 'max_steps': 7272}
 22%|██▏       | 1618/7272 [7:30:01<25:32:48, 16.27s/it] 22%|██▏       | 1619/7272 [7:30:17<25:27:06, 16.21s/it]                                                        {'loss': 1.2482, 'grad_norm': 3.1279327869415283, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1619, 'max_steps': 7272}
 22%|██▏       | 1619/7272 [7:30:17<25:27:06, 16.21s/it] 22%|██▏       | 1620/7272 [7:30:34<25:48:06, 16.43s/it]                                                        {'loss': 1.9274, 'grad_norm': 6.942846298217773, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1620, 'max_steps': 7272}
 22%|██▏       | 1620/7272 [7:30:34<25:48:06, 16.43s/it] 22%|██▏       | 1621/7272 [7:30:50<25:33:19, 16.28s/it]                                                        {'loss': 3.1789, 'grad_norm': 5.418003559112549, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1621, 'max_steps': 7272}
 22%|██▏       | 1621/7272 [7:30:50<25:33:19, 16.28s/it] 22%|██▏       | 1622/7272 [7:31:06<25:24:06, 16.19s/it]                                                        {'loss': 3.306, 'grad_norm': 4.928457736968994, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1622, 'max_steps': 7272}
 22%|██▏       | 1622/7272 [7:31:06<25:24:06, 16.19s/it] 22%|██▏       | 1623/7272 [7:31:22<25:21:56, 16.17s/it]                                                        {'loss': 2.4008, 'grad_norm': 6.930261611938477, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1623, 'max_steps': 7272}
 22%|██▏       | 1623/7272 [7:31:22<25:21:56, 16.17s/it] 22%|██▏       | 1624/7272 [7:31:39<25:44:54, 16.41s/it]                                                        {'loss': 2.5113, 'grad_norm': 3.9234983921051025, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1624, 'max_steps': 7272}
 22%|██▏       | 1624/7272 [7:31:39<25:44:54, 16.41s/it] 22%|██▏       | 1625/7272 [7:31:55<25:29:41, 16.25s/it]                                                        {'loss': 2.3375, 'grad_norm': 3.729524850845337, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1625, 'max_steps': 7272}
 22%|██▏       | 1625/7272 [7:31:55<25:29:41, 16.25s/it] 22%|██▏       | 1626/7272 [7:32:12<25:35:58, 16.32s/it]                                                        {'loss': 1.687, 'grad_norm': 2.785996913909912, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1626, 'max_steps': 7272}
 22%|██▏       | 1626/7272 [7:32:12<25:35:58, 16.32s/it] 22%|██▏       | 1627/7272 [7:32:28<25:29:43, 16.26s/it]                                                        {'loss': 1.7497, 'grad_norm': 3.4812746047973633, 'learning_rate': 5e-05, 'epoch': 0.89, 'step': 1627, 'max_steps': 7272}
 22%|██▏       | 1627/7272 [7:32:28<25:29:43, 16.26s/it] 22%|██▏       | 1628/7272 [7:32:44<25:15:16, 16.11s/it]                                                        {'loss': 2.7548, 'grad_norm': 7.966614723205566, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1628, 'max_steps': 7272}
 22%|██▏       | 1628/7272 [7:32:44<25:15:16, 16.11s/it] 22%|██▏       | 1629/7272 [7:33:00<25:15:21, 16.11s/it]                                                        {'loss': 2.7434, 'grad_norm': 12.171910285949707, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1629, 'max_steps': 7272}
 22%|██▏       | 1629/7272 [7:33:00<25:15:21, 16.11s/it] 22%|██▏       | 1630/7272 [7:33:16<25:32:59, 16.30s/it]                                                        {'loss': 0.9586, 'grad_norm': 2.756369113922119, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1630, 'max_steps': 7272}
 22%|██▏       | 1630/7272 [7:33:16<25:32:59, 16.30s/it] 22%|██▏       | 1631/7272 [7:33:33<25:28:35, 16.26s/it]                                                        {'loss': 1.9527, 'grad_norm': 9.342046737670898, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1631, 'max_steps': 7272}
 22%|██▏       | 1631/7272 [7:33:33<25:28:35, 16.26s/it] 22%|██▏       | 1632/7272 [7:33:49<25:26:56, 16.24s/it]                                                        {'loss': 0.9698, 'grad_norm': 2.1499826908111572, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1632, 'max_steps': 7272}
 22%|██▏       | 1632/7272 [7:33:49<25:26:56, 16.24s/it] 22%|██▏       | 1633/7272 [7:34:04<24:57:01, 15.93s/it]                                                        {'loss': 3.3195, 'grad_norm': 6.536986351013184, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1633, 'max_steps': 7272}
 22%|██▏       | 1633/7272 [7:34:04<24:57:01, 15.93s/it] 22%|██▏       | 1634/7272 [7:34:20<24:44:59, 15.80s/it]                                                        {'loss': 1.7705, 'grad_norm': 3.7982726097106934, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1634, 'max_steps': 7272}
 22%|██▏       | 1634/7272 [7:34:20<24:44:59, 15.80s/it] 22%|██▏       | 1635/7272 [7:34:36<24:51:26, 15.87s/it]                                                        {'loss': 1.9655, 'grad_norm': 4.864145278930664, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1635, 'max_steps': 7272}
 22%|██▏       | 1635/7272 [7:34:36<24:51:26, 15.87s/it] 22%|██▏       | 1636/7272 [7:34:51<24:52:29, 15.89s/it]                                                        {'loss': 0.9712, 'grad_norm': 4.40881872177124, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1636, 'max_steps': 7272}
 22%|██▏       | 1636/7272 [7:34:51<24:52:29, 15.89s/it] 23%|██▎       | 1637/7272 [7:35:07<24:43:11, 15.79s/it]                                                        {'loss': 2.2172, 'grad_norm': 5.362698554992676, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1637, 'max_steps': 7272}
 23%|██▎       | 1637/7272 [7:35:07<24:43:11, 15.79s/it] 23%|██▎       | 1638/7272 [7:35:23<24:44:03, 15.80s/it]                                                        {'loss': 1.6892, 'grad_norm': 3.278609275817871, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1638, 'max_steps': 7272}
 23%|██▎       | 1638/7272 [7:35:23<24:44:03, 15.80s/it] 23%|██▎       | 1639/7272 [7:35:39<24:59:51, 15.98s/it]                                                        {'loss': 2.2555, 'grad_norm': 6.28055477142334, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1639, 'max_steps': 7272}
 23%|██▎       | 1639/7272 [7:35:39<24:59:51, 15.98s/it] 23%|██▎       | 1640/7272 [7:35:55<24:53:19, 15.91s/it]                                                        {'loss': 1.6675, 'grad_norm': 3.18882417678833, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1640, 'max_steps': 7272}
 23%|██▎       | 1640/7272 [7:35:55<24:53:19, 15.91s/it] 23%|██▎       | 1641/7272 [7:36:12<25:15:20, 16.15s/it]                                                        {'loss': 1.9408, 'grad_norm': 8.964731216430664, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1641, 'max_steps': 7272}
 23%|██▎       | 1641/7272 [7:36:12<25:15:20, 16.15s/it] 23%|██▎       | 1642/7272 [7:36:28<25:14:06, 16.14s/it]                                                        {'loss': 0.8245, 'grad_norm': 1.8463859558105469, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1642, 'max_steps': 7272}
 23%|██▎       | 1642/7272 [7:36:28<25:14:06, 16.14s/it] 23%|██▎       | 1643/7272 [7:36:43<24:55:22, 15.94s/it]                                                        {'loss': 1.6135, 'grad_norm': 3.663553476333618, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1643, 'max_steps': 7272}
 23%|██▎       | 1643/7272 [7:36:43<24:55:22, 15.94s/it] 23%|██▎       | 1644/7272 [7:36:59<24:44:49, 15.83s/it]                                                        {'loss': 1.1288, 'grad_norm': 9.30410385131836, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1644, 'max_steps': 7272}
 23%|██▎       | 1644/7272 [7:36:59<24:44:49, 15.83s/it] 23%|██▎       | 1645/7272 [7:37:15<24:52:18, 15.91s/it]                                                        {'loss': 1.8103, 'grad_norm': 6.804464817047119, 'learning_rate': 5e-05, 'epoch': 0.9, 'step': 1645, 'max_steps': 7272}
 23%|██▎       | 1645/7272 [7:37:15<24:52:18, 15.91s/it] 23%|██▎       | 1646/7272 [7:37:32<25:26:44, 16.28s/it]                                                        {'loss': 1.4798, 'grad_norm': 5.617953777313232, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1646, 'max_steps': 7272}
 23%|██▎       | 1646/7272 [7:37:32<25:26:44, 16.28s/it] 23%|██▎       | 1647/7272 [7:37:48<25:23:23, 16.25s/it]                                                        {'loss': 3.7564, 'grad_norm': 8.745499610900879, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1647, 'max_steps': 7272}
 23%|██▎       | 1647/7272 [7:37:48<25:23:23, 16.25s/it] 23%|██▎       | 1648/7272 [7:38:05<25:38:11, 16.41s/it]                                                        {'loss': 1.1826, 'grad_norm': 3.8150217533111572, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1648, 'max_steps': 7272}
 23%|██▎       | 1648/7272 [7:38:05<25:38:11, 16.41s/it] 23%|██▎       | 1649/7272 [7:38:23<26:08:42, 16.74s/it]                                                        {'loss': 2.0509, 'grad_norm': 21.677494049072266, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1649, 'max_steps': 7272}
 23%|██▎       | 1649/7272 [7:38:23<26:08:42, 16.74s/it] 23%|██▎       | 1650/7272 [7:38:39<25:46:15, 16.50s/it]                                                        {'loss': 1.3786, 'grad_norm': 5.365796089172363, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1650, 'max_steps': 7272}
 23%|██▎       | 1650/7272 [7:38:39<25:46:15, 16.50s/it] 23%|██▎       | 1651/7272 [7:38:54<25:29:03, 16.32s/it]                                                        {'loss': 1.3814, 'grad_norm': 7.37432336807251, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1651, 'max_steps': 7272}
 23%|██▎       | 1651/7272 [7:38:54<25:29:03, 16.32s/it] 23%|██▎       | 1652/7272 [7:39:10<25:06:14, 16.08s/it]                                                        {'loss': 1.8188, 'grad_norm': 3.9250214099884033, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1652, 'max_steps': 7272}
 23%|██▎       | 1652/7272 [7:39:10<25:06:14, 16.08s/it] 23%|██▎       | 1653/7272 [7:39:26<25:05:03, 16.07s/it]                                                        {'loss': 1.7883, 'grad_norm': 4.398056983947754, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1653, 'max_steps': 7272}
 23%|██▎       | 1653/7272 [7:39:26<25:05:03, 16.07s/it] 23%|██▎       | 1654/7272 [7:39:42<25:14:11, 16.17s/it]                                                        {'loss': 1.4649, 'grad_norm': 6.850945472717285, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1654, 'max_steps': 7272}
 23%|██▎       | 1654/7272 [7:39:42<25:14:11, 16.17s/it] 23%|██▎       | 1655/7272 [7:39:59<25:24:53, 16.29s/it]                                                        {'loss': 2.612, 'grad_norm': 7.616603851318359, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1655, 'max_steps': 7272}
 23%|██▎       | 1655/7272 [7:39:59<25:24:53, 16.29s/it] 23%|██▎       | 1656/7272 [7:40:15<25:17:04, 16.21s/it]                                                        {'loss': 1.6576, 'grad_norm': 5.253880023956299, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1656, 'max_steps': 7272}
 23%|██▎       | 1656/7272 [7:40:15<25:17:04, 16.21s/it] 23%|██▎       | 1657/7272 [7:40:31<25:15:53, 16.20s/it]                                                        {'loss': 1.4387, 'grad_norm': 7.192455291748047, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1657, 'max_steps': 7272}
 23%|██▎       | 1657/7272 [7:40:31<25:15:53, 16.20s/it] 23%|██▎       | 1658/7272 [7:40:47<25:08:58, 16.13s/it]                                                        {'loss': 0.997, 'grad_norm': 4.3879876136779785, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1658, 'max_steps': 7272}
 23%|██▎       | 1658/7272 [7:40:47<25:08:58, 16.13s/it] 23%|██▎       | 1659/7272 [7:41:04<25:16:01, 16.21s/it]                                                        {'loss': 1.3202, 'grad_norm': 4.427716255187988, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1659, 'max_steps': 7272}
 23%|██▎       | 1659/7272 [7:41:04<25:16:01, 16.21s/it] 23%|██▎       | 1660/7272 [7:41:20<25:16:13, 16.21s/it]                                                        {'loss': 3.3639, 'grad_norm': 7.230036735534668, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1660, 'max_steps': 7272}
 23%|██▎       | 1660/7272 [7:41:20<25:16:13, 16.21s/it] 23%|██▎       | 1661/7272 [7:41:36<25:23:18, 16.29s/it]                                                        {'loss': 1.3159, 'grad_norm': 4.646774768829346, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1661, 'max_steps': 7272}
 23%|██▎       | 1661/7272 [7:41:36<25:23:18, 16.29s/it] 23%|██▎       | 1662/7272 [7:41:53<25:35:13, 16.42s/it]                                                        {'loss': 0.833, 'grad_norm': 4.214883804321289, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1662, 'max_steps': 7272}
 23%|██▎       | 1662/7272 [7:41:53<25:35:13, 16.42s/it] 23%|██▎       | 1663/7272 [7:42:09<25:14:38, 16.20s/it]                                                        {'loss': 1.3678, 'grad_norm': 4.565790176391602, 'learning_rate': 5e-05, 'epoch': 0.91, 'step': 1663, 'max_steps': 7272}
 23%|██▎       | 1663/7272 [7:42:09<25:14:38, 16.20s/it] 23%|██▎       | 1664/7272 [7:42:24<25:04:13, 16.09s/it]                                                        {'loss': 1.4947, 'grad_norm': 2.889068603515625, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1664, 'max_steps': 7272}
 23%|██▎       | 1664/7272 [7:42:24<25:04:13, 16.09s/it] 23%|██▎       | 1665/7272 [7:42:40<24:53:50, 15.99s/it]                                                        {'loss': 1.4876, 'grad_norm': 4.453729152679443, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1665, 'max_steps': 7272}
 23%|██▎       | 1665/7272 [7:42:40<24:53:50, 15.99s/it] 23%|██▎       | 1666/7272 [7:42:56<24:57:39, 16.03s/it]                                                        {'loss': 3.5491, 'grad_norm': 8.059836387634277, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1666, 'max_steps': 7272}
 23%|██▎       | 1666/7272 [7:42:56<24:57:39, 16.03s/it] 23%|██▎       | 1667/7272 [7:43:13<25:03:03, 16.09s/it]                                                        {'loss': 1.6925, 'grad_norm': 6.097201824188232, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1667, 'max_steps': 7272}
 23%|██▎       | 1667/7272 [7:43:13<25:03:03, 16.09s/it] 23%|██▎       | 1668/7272 [7:43:28<24:55:29, 16.01s/it]                                                        {'loss': 1.725, 'grad_norm': 6.782871723175049, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1668, 'max_steps': 7272}
 23%|██▎       | 1668/7272 [7:43:28<24:55:29, 16.01s/it] 23%|██▎       | 1669/7272 [7:43:44<24:41:33, 15.87s/it]                                                        {'loss': 2.7739, 'grad_norm': 5.488877296447754, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1669, 'max_steps': 7272}
 23%|██▎       | 1669/7272 [7:43:44<24:41:33, 15.87s/it] 23%|██▎       | 1670/7272 [7:44:00<24:56:46, 16.03s/it]                                                        {'loss': 0.9396, 'grad_norm': 2.201856851577759, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1670, 'max_steps': 7272}
 23%|██▎       | 1670/7272 [7:44:00<24:56:46, 16.03s/it] 23%|██▎       | 1671/7272 [7:44:17<25:12:40, 16.20s/it]                                                        {'loss': 1.199, 'grad_norm': 3.232457399368286, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1671, 'max_steps': 7272}
 23%|██▎       | 1671/7272 [7:44:17<25:12:40, 16.20s/it] 23%|██▎       | 1672/7272 [7:44:34<25:33:17, 16.43s/it]                                                        {'loss': 2.774, 'grad_norm': 8.667047500610352, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1672, 'max_steps': 7272}
 23%|██▎       | 1672/7272 [7:44:34<25:33:17, 16.43s/it] 23%|██▎       | 1673/7272 [7:44:50<25:23:28, 16.33s/it]                                                        {'loss': 2.0646, 'grad_norm': 3.3816487789154053, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1673, 'max_steps': 7272}
 23%|██▎       | 1673/7272 [7:44:50<25:23:28, 16.33s/it] 23%|██▎       | 1674/7272 [7:45:06<25:21:55, 16.31s/it]                                                        {'loss': 1.5489, 'grad_norm': 5.739227294921875, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1674, 'max_steps': 7272}
 23%|██▎       | 1674/7272 [7:45:06<25:21:55, 16.31s/it] 23%|██▎       | 1675/7272 [7:45:22<25:18:43, 16.28s/it]                                                        {'loss': 1.7766, 'grad_norm': 5.757894515991211, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1675, 'max_steps': 7272}
 23%|██▎       | 1675/7272 [7:45:22<25:18:43, 16.28s/it] 23%|██▎       | 1676/7272 [7:45:38<25:11:07, 16.20s/it]                                                        {'loss': 2.6399, 'grad_norm': 3.3965516090393066, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1676, 'max_steps': 7272}
 23%|██▎       | 1676/7272 [7:45:39<25:11:07, 16.20s/it] 23%|██▎       | 1677/7272 [7:45:55<25:22:04, 16.32s/it]                                                        {'loss': 3.9647, 'grad_norm': 10.568164825439453, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1677, 'max_steps': 7272}
 23%|██▎       | 1677/7272 [7:45:55<25:22:04, 16.32s/it] 23%|██▎       | 1678/7272 [7:46:12<25:25:22, 16.36s/it]                                                        {'loss': 1.1751, 'grad_norm': 2.5624160766601562, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1678, 'max_steps': 7272}
 23%|██▎       | 1678/7272 [7:46:12<25:25:22, 16.36s/it] 23%|██▎       | 1679/7272 [7:46:28<25:16:07, 16.26s/it]                                                        {'loss': 2.927, 'grad_norm': 4.514154434204102, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1679, 'max_steps': 7272}
 23%|██▎       | 1679/7272 [7:46:28<25:16:07, 16.26s/it] 23%|██▎       | 1680/7272 [7:46:44<25:08:38, 16.19s/it]                                                        {'loss': 1.6844, 'grad_norm': 6.273184776306152, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1680, 'max_steps': 7272}
 23%|██▎       | 1680/7272 [7:46:44<25:08:38, 16.19s/it] 23%|██▎       | 1681/7272 [7:46:59<24:49:52, 15.99s/it]                                                        {'loss': 3.021, 'grad_norm': 8.522552490234375, 'learning_rate': 5e-05, 'epoch': 0.92, 'step': 1681, 'max_steps': 7272}
 23%|██▎       | 1681/7272 [7:46:59<24:49:52, 15.99s/it] 23%|██▎       | 1682/7272 [7:47:16<25:15:39, 16.27s/it]                                                        {'loss': 1.2051, 'grad_norm': 5.519561767578125, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1682, 'max_steps': 7272}
 23%|██▎       | 1682/7272 [7:47:16<25:15:39, 16.27s/it] 23%|██▎       | 1683/7272 [7:47:33<25:21:40, 16.34s/it]                                                        {'loss': 2.1668, 'grad_norm': 3.487215518951416, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1683, 'max_steps': 7272}
 23%|██▎       | 1683/7272 [7:47:33<25:21:40, 16.34s/it] 23%|██▎       | 1684/7272 [7:47:49<25:26:19, 16.39s/it]                                                        {'loss': 1.7563, 'grad_norm': 4.1304450035095215, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1684, 'max_steps': 7272}
 23%|██▎       | 1684/7272 [7:47:49<25:26:19, 16.39s/it] 23%|██▎       | 1685/7272 [7:48:05<25:20:45, 16.33s/it]                                                        {'loss': 3.0724, 'grad_norm': 6.327668190002441, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1685, 'max_steps': 7272}
 23%|██▎       | 1685/7272 [7:48:05<25:20:45, 16.33s/it] 23%|██▎       | 1686/7272 [7:48:21<25:10:37, 16.23s/it]                                                        {'loss': 1.9944, 'grad_norm': 9.378965377807617, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1686, 'max_steps': 7272}
 23%|██▎       | 1686/7272 [7:48:21<25:10:37, 16.23s/it] 23%|██▎       | 1687/7272 [7:48:38<25:20:49, 16.34s/it]                                                        {'loss': 1.5542, 'grad_norm': 3.9018733501434326, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1687, 'max_steps': 7272}
 23%|██▎       | 1687/7272 [7:48:38<25:20:49, 16.34s/it] 23%|██▎       | 1688/7272 [7:48:55<25:30:18, 16.44s/it]                                                        {'loss': 3.6277, 'grad_norm': 10.447710990905762, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1688, 'max_steps': 7272}
 23%|██▎       | 1688/7272 [7:48:55<25:30:18, 16.44s/it] 23%|██▎       | 1689/7272 [7:49:10<25:15:40, 16.29s/it]                                                        {'loss': 1.3335, 'grad_norm': 3.5817408561706543, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1689, 'max_steps': 7272}
 23%|██▎       | 1689/7272 [7:49:10<25:15:40, 16.29s/it] 23%|██▎       | 1690/7272 [7:49:26<25:05:05, 16.18s/it]                                                        {'loss': 1.3936, 'grad_norm': 3.5938479900360107, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1690, 'max_steps': 7272}
 23%|██▎       | 1690/7272 [7:49:26<25:05:05, 16.18s/it] 23%|██▎       | 1691/7272 [7:49:42<24:49:21, 16.01s/it]                                                        {'loss': 1.2683, 'grad_norm': 11.646767616271973, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1691, 'max_steps': 7272}
 23%|██▎       | 1691/7272 [7:49:42<24:49:21, 16.01s/it] 23%|██▎       | 1692/7272 [7:49:58<24:48:59, 16.01s/it]                                                        {'loss': 1.8717, 'grad_norm': 4.582522869110107, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1692, 'max_steps': 7272}
 23%|██▎       | 1692/7272 [7:49:58<24:48:59, 16.01s/it] 23%|██▎       | 1693/7272 [7:50:15<25:04:11, 16.18s/it]                                                        {'loss': 1.543, 'grad_norm': 4.61692476272583, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1693, 'max_steps': 7272}
 23%|██▎       | 1693/7272 [7:50:15<25:04:11, 16.18s/it] 23%|██▎       | 1694/7272 [7:50:31<25:11:54, 16.26s/it]                                                        {'loss': 1.3305, 'grad_norm': 2.2502808570861816, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1694, 'max_steps': 7272}
 23%|██▎       | 1694/7272 [7:50:31<25:11:54, 16.26s/it] 23%|██▎       | 1695/7272 [7:50:47<25:17:19, 16.32s/it]                                                        {'loss': 2.4225, 'grad_norm': 4.4155592918396, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1695, 'max_steps': 7272}
 23%|██▎       | 1695/7272 [7:50:47<25:17:19, 16.32s/it] 23%|██▎       | 1696/7272 [7:51:04<25:25:51, 16.42s/it]                                                        {'loss': 0.7669, 'grad_norm': 5.398510932922363, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1696, 'max_steps': 7272}
 23%|██▎       | 1696/7272 [7:51:04<25:25:51, 16.42s/it] 23%|██▎       | 1697/7272 [7:51:21<25:28:01, 16.45s/it]                                                        {'loss': 2.5067, 'grad_norm': 7.661420822143555, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1697, 'max_steps': 7272}
 23%|██▎       | 1697/7272 [7:51:21<25:28:01, 16.45s/it] 23%|██▎       | 1698/7272 [7:51:37<25:21:25, 16.38s/it]                                                        {'loss': 2.5979, 'grad_norm': 8.543476104736328, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1698, 'max_steps': 7272}
 23%|██▎       | 1698/7272 [7:51:37<25:21:25, 16.38s/it] 23%|██▎       | 1699/7272 [7:51:53<25:28:03, 16.45s/it]                                                        {'loss': 1.7204, 'grad_norm': 3.0190327167510986, 'learning_rate': 5e-05, 'epoch': 0.93, 'step': 1699, 'max_steps': 7272}
 23%|██▎       | 1699/7272 [7:51:53<25:28:03, 16.45s/it] 23%|██▎       | 1700/7272 [7:52:10<25:30:46, 16.48s/it]                                                        {'loss': 1.9262, 'grad_norm': 10.157635688781738, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1700, 'max_steps': 7272}
 23%|██▎       | 1700/7272 [7:52:10<25:30:46, 16.48s/it] 23%|██▎       | 1701/7272 [7:52:26<25:28:27, 16.46s/it]                                                        {'loss': 1.7335, 'grad_norm': 5.3661394119262695, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1701, 'max_steps': 7272}
 23%|██▎       | 1701/7272 [7:52:26<25:28:27, 16.46s/it] 23%|██▎       | 1702/7272 [7:52:43<25:32:26, 16.51s/it]                                                        {'loss': 2.3075, 'grad_norm': 6.020533561706543, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1702, 'max_steps': 7272}
 23%|██▎       | 1702/7272 [7:52:43<25:32:26, 16.51s/it] 23%|██▎       | 1703/7272 [7:52:59<25:11:46, 16.29s/it]                                                        {'loss': 2.194, 'grad_norm': 8.10461711883545, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1703, 'max_steps': 7272}
 23%|██▎       | 1703/7272 [7:52:59<25:11:46, 16.29s/it] 23%|██▎       | 1704/7272 [7:53:14<24:48:57, 16.04s/it]                                                        {'loss': 1.6241, 'grad_norm': 3.4037299156188965, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1704, 'max_steps': 7272}
 23%|██▎       | 1704/7272 [7:53:14<24:48:57, 16.04s/it] 23%|██▎       | 1705/7272 [7:53:30<24:47:02, 16.03s/it]                                                        {'loss': 2.0984, 'grad_norm': 4.114944934844971, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1705, 'max_steps': 7272}
 23%|██▎       | 1705/7272 [7:53:30<24:47:02, 16.03s/it] 23%|██▎       | 1706/7272 [7:53:47<25:00:33, 16.18s/it]                                                        {'loss': 2.2233, 'grad_norm': 4.487181186676025, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1706, 'max_steps': 7272}
 23%|██▎       | 1706/7272 [7:53:47<25:00:33, 16.18s/it] 23%|██▎       | 1707/7272 [7:54:03<24:58:13, 16.15s/it]                                                        {'loss': 1.4232, 'grad_norm': 2.475877523422241, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1707, 'max_steps': 7272}
 23%|██▎       | 1707/7272 [7:54:03<24:58:13, 16.15s/it] 23%|██▎       | 1708/7272 [7:54:19<24:51:42, 16.09s/it]                                                        {'loss': 3.3176, 'grad_norm': 8.132197380065918, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1708, 'max_steps': 7272}
 23%|██▎       | 1708/7272 [7:54:19<24:51:42, 16.09s/it] 24%|██▎       | 1709/7272 [7:54:35<24:57:27, 16.15s/it]                                                        {'loss': 1.225, 'grad_norm': 5.726413726806641, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1709, 'max_steps': 7272}
 24%|██▎       | 1709/7272 [7:54:35<24:57:27, 16.15s/it] 24%|██▎       | 1710/7272 [7:54:51<24:42:52, 16.00s/it]                                                        {'loss': 2.266, 'grad_norm': 5.7549614906311035, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1710, 'max_steps': 7272}
 24%|██▎       | 1710/7272 [7:54:51<24:42:52, 16.00s/it] 24%|██▎       | 1711/7272 [7:55:07<24:40:39, 15.98s/it]                                                        {'loss': 0.8454, 'grad_norm': 2.2339839935302734, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1711, 'max_steps': 7272}
 24%|██▎       | 1711/7272 [7:55:07<24:40:39, 15.98s/it] 24%|██▎       | 1712/7272 [7:55:22<24:29:22, 15.86s/it]                                                        {'loss': 2.2832, 'grad_norm': 4.194096565246582, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1712, 'max_steps': 7272}
 24%|██▎       | 1712/7272 [7:55:22<24:29:22, 15.86s/it] 24%|██▎       | 1713/7272 [7:55:39<24:51:55, 16.10s/it]                                                        {'loss': 1.8648, 'grad_norm': 4.385946750640869, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1713, 'max_steps': 7272}
 24%|██▎       | 1713/7272 [7:55:39<24:51:55, 16.10s/it] 24%|██▎       | 1714/7272 [7:55:55<24:55:35, 16.15s/it]                                                        {'loss': 2.4259, 'grad_norm': 5.74086856842041, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1714, 'max_steps': 7272}
 24%|██▎       | 1714/7272 [7:55:55<24:55:35, 16.15s/it] 24%|██▎       | 1715/7272 [7:56:12<25:01:36, 16.21s/it]                                                        {'loss': 1.4157, 'grad_norm': 2.732523202896118, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1715, 'max_steps': 7272}
 24%|██▎       | 1715/7272 [7:56:12<25:01:36, 16.21s/it] 24%|██▎       | 1716/7272 [7:56:27<24:44:40, 16.03s/it]                                                        {'loss': 1.5391, 'grad_norm': 4.66072416305542, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1716, 'max_steps': 7272}
 24%|██▎       | 1716/7272 [7:56:27<24:44:40, 16.03s/it] 24%|██▎       | 1717/7272 [7:56:43<24:30:43, 15.89s/it]                                                        {'loss': 2.5454, 'grad_norm': 6.13300085067749, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1717, 'max_steps': 7272}
 24%|██▎       | 1717/7272 [7:56:43<24:30:43, 15.89s/it] 24%|██▎       | 1718/7272 [7:56:58<24:15:35, 15.72s/it]                                                        {'loss': 2.6256, 'grad_norm': 5.7845072746276855, 'learning_rate': 5e-05, 'epoch': 0.94, 'step': 1718, 'max_steps': 7272}
 24%|██▎       | 1718/7272 [7:56:58<24:15:35, 15.72s/it] 24%|██▎       | 1719/7272 [7:57:14<24:07:57, 15.65s/it]                                                        {'loss': 1.1315, 'grad_norm': 2.9238502979278564, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1719, 'max_steps': 7272}
 24%|██▎       | 1719/7272 [7:57:14<24:07:57, 15.65s/it] 24%|██▎       | 1720/7272 [7:57:30<24:21:54, 15.80s/it]                                                        {'loss': 1.9319, 'grad_norm': 4.446560382843018, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1720, 'max_steps': 7272}
 24%|██▎       | 1720/7272 [7:57:30<24:21:54, 15.80s/it] 24%|██▎       | 1721/7272 [7:57:45<24:15:18, 15.73s/it]                                                        {'loss': 0.5349, 'grad_norm': 3.1894280910491943, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1721, 'max_steps': 7272}
 24%|██▎       | 1721/7272 [7:57:45<24:15:18, 15.73s/it] 24%|██▎       | 1722/7272 [7:58:01<24:25:27, 15.84s/it]                                                        {'loss': 0.7403, 'grad_norm': 5.810851573944092, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1722, 'max_steps': 7272}
 24%|██▎       | 1722/7272 [7:58:01<24:25:27, 15.84s/it] 24%|██▎       | 1723/7272 [7:58:17<24:15:45, 15.74s/it]                                                        {'loss': 2.5034, 'grad_norm': 6.275940895080566, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1723, 'max_steps': 7272}
 24%|██▎       | 1723/7272 [7:58:17<24:15:45, 15.74s/it] 24%|██▎       | 1724/7272 [7:58:33<24:17:07, 15.76s/it]                                                        {'loss': 1.2265, 'grad_norm': 3.575282096862793, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1724, 'max_steps': 7272}
 24%|██▎       | 1724/7272 [7:58:33<24:17:07, 15.76s/it] 24%|██▎       | 1725/7272 [7:58:49<24:20:18, 15.80s/it]                                                        {'loss': 1.1149, 'grad_norm': 6.947598457336426, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1725, 'max_steps': 7272}
 24%|██▎       | 1725/7272 [7:58:49<24:20:18, 15.80s/it] 24%|██▎       | 1726/7272 [7:59:05<24:28:16, 15.88s/it]                                                        {'loss': 2.176, 'grad_norm': 12.58285903930664, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1726, 'max_steps': 7272}
 24%|██▎       | 1726/7272 [7:59:05<24:28:16, 15.88s/it] 24%|██▎       | 1727/7272 [7:59:21<24:39:46, 16.01s/it]                                                        {'loss': 1.8458, 'grad_norm': 5.321053504943848, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1727, 'max_steps': 7272}
 24%|██▎       | 1727/7272 [7:59:21<24:39:46, 16.01s/it] 24%|██▍       | 1728/7272 [7:59:37<24:41:08, 16.03s/it]                                                        {'loss': 2.5964, 'grad_norm': 9.286953926086426, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1728, 'max_steps': 7272}
 24%|██▍       | 1728/7272 [7:59:37<24:41:08, 16.03s/it] 24%|██▍       | 1729/7272 [7:59:53<24:44:36, 16.07s/it]                                                        {'loss': 1.1485, 'grad_norm': 7.477842330932617, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1729, 'max_steps': 7272}
 24%|██▍       | 1729/7272 [7:59:53<24:44:36, 16.07s/it] 24%|██▍       | 1730/7272 [8:00:09<24:39:51, 16.02s/it]                                                        {'loss': 0.8143, 'grad_norm': 4.262307167053223, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1730, 'max_steps': 7272}
 24%|██▍       | 1730/7272 [8:00:09<24:39:51, 16.02s/it] 24%|██▍       | 1731/7272 [8:00:25<24:35:48, 15.98s/it]                                                        {'loss': 1.5605, 'grad_norm': 4.911525726318359, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1731, 'max_steps': 7272}
 24%|██▍       | 1731/7272 [8:00:25<24:35:48, 15.98s/it] 24%|██▍       | 1732/7272 [8:00:41<24:42:56, 16.06s/it]                                                        {'loss': 1.4393, 'grad_norm': 2.8099639415740967, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1732, 'max_steps': 7272}
 24%|██▍       | 1732/7272 [8:00:41<24:42:56, 16.06s/it] 24%|██▍       | 1733/7272 [8:00:58<24:48:53, 16.13s/it]                                                        {'loss': 1.4043, 'grad_norm': 6.970824718475342, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1733, 'max_steps': 7272}
 24%|██▍       | 1733/7272 [8:00:58<24:48:53, 16.13s/it] 24%|██▍       | 1734/7272 [8:01:13<24:41:02, 16.05s/it]                                                        {'loss': 1.2813, 'grad_norm': 1.9526516199111938, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1734, 'max_steps': 7272}
 24%|██▍       | 1734/7272 [8:01:13<24:41:02, 16.05s/it] 24%|██▍       | 1735/7272 [8:01:29<24:41:59, 16.06s/it]                                                        {'loss': 1.2766, 'grad_norm': 5.56008768081665, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1735, 'max_steps': 7272}
 24%|██▍       | 1735/7272 [8:01:29<24:41:59, 16.06s/it] 24%|██▍       | 1736/7272 [8:01:45<24:29:48, 15.93s/it]                                                        {'loss': 1.8682, 'grad_norm': 5.9807939529418945, 'learning_rate': 5e-05, 'epoch': 0.95, 'step': 1736, 'max_steps': 7272}
 24%|██▍       | 1736/7272 [8:01:45<24:29:48, 15.93s/it] 24%|██▍       | 1737/7272 [8:02:02<25:03:08, 16.29s/it]                                                        {'loss': 2.5142, 'grad_norm': 5.274502277374268, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1737, 'max_steps': 7272}
 24%|██▍       | 1737/7272 [8:02:02<25:03:08, 16.29s/it] 24%|██▍       | 1738/7272 [8:02:19<25:12:33, 16.40s/it]                                                        {'loss': 2.4647, 'grad_norm': 5.659063339233398, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1738, 'max_steps': 7272}
 24%|██▍       | 1738/7272 [8:02:19<25:12:33, 16.40s/it] 24%|██▍       | 1739/7272 [8:02:36<25:22:09, 16.51s/it]                                                        {'loss': 2.9112, 'grad_norm': 7.02584171295166, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1739, 'max_steps': 7272}
 24%|██▍       | 1739/7272 [8:02:36<25:22:09, 16.51s/it] 24%|██▍       | 1740/7272 [8:02:52<25:17:10, 16.46s/it]                                                        {'loss': 2.6206, 'grad_norm': 8.355829238891602, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1740, 'max_steps': 7272}
 24%|██▍       | 1740/7272 [8:02:52<25:17:10, 16.46s/it] 24%|██▍       | 1741/7272 [8:03:08<25:11:24, 16.40s/it]                                                        {'loss': 1.4583, 'grad_norm': 3.965231418609619, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1741, 'max_steps': 7272}
 24%|██▍       | 1741/7272 [8:03:08<25:11:24, 16.40s/it] 24%|██▍       | 1742/7272 [8:03:25<25:08:34, 16.37s/it]                                                        {'loss': 1.9188, 'grad_norm': 5.085400104522705, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1742, 'max_steps': 7272}
 24%|██▍       | 1742/7272 [8:03:25<25:08:34, 16.37s/it] 24%|██▍       | 1743/7272 [8:03:40<24:43:28, 16.10s/it]                                                        {'loss': 1.1142, 'grad_norm': 2.0631330013275146, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1743, 'max_steps': 7272}
 24%|██▍       | 1743/7272 [8:03:40<24:43:28, 16.10s/it] 24%|██▍       | 1744/7272 [8:03:56<24:38:32, 16.05s/it]                                                        {'loss': 2.1882, 'grad_norm': 5.4502153396606445, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1744, 'max_steps': 7272}
 24%|██▍       | 1744/7272 [8:03:56<24:38:32, 16.05s/it] 24%|██▍       | 1745/7272 [8:04:12<24:37:46, 16.04s/it]                                                        {'loss': 3.0416, 'grad_norm': 12.896197319030762, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1745, 'max_steps': 7272}
 24%|██▍       | 1745/7272 [8:04:12<24:37:46, 16.04s/it] 24%|██▍       | 1746/7272 [8:04:28<24:38:38, 16.05s/it]                                                        {'loss': 0.5376, 'grad_norm': 6.320219993591309, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1746, 'max_steps': 7272}
 24%|██▍       | 1746/7272 [8:04:28<24:38:38, 16.05s/it] 24%|██▍       | 1747/7272 [8:04:44<24:39:45, 16.07s/it]                                                        {'loss': 3.9737, 'grad_norm': 5.553404808044434, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1747, 'max_steps': 7272}
 24%|██▍       | 1747/7272 [8:04:44<24:39:45, 16.07s/it] 24%|██▍       | 1748/7272 [8:05:00<24:41:56, 16.10s/it]                                                        {'loss': 1.9571, 'grad_norm': 4.496304988861084, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1748, 'max_steps': 7272}
 24%|██▍       | 1748/7272 [8:05:00<24:41:56, 16.10s/it] 24%|██▍       | 1749/7272 [8:05:16<24:34:18, 16.02s/it]                                                        {'loss': 1.5767, 'grad_norm': 3.070333480834961, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1749, 'max_steps': 7272}
 24%|██▍       | 1749/7272 [8:05:16<24:34:18, 16.02s/it] 24%|██▍       | 1750/7272 [8:05:32<24:39:15, 16.07s/it]                                                        {'loss': 1.256, 'grad_norm': 4.002686500549316, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1750, 'max_steps': 7272}
 24%|██▍       | 1750/7272 [8:05:32<24:39:15, 16.07s/it] 24%|██▍       | 1751/7272 [8:05:49<24:45:44, 16.15s/it]                                                        {'loss': 1.1908, 'grad_norm': 4.676640033721924, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1751, 'max_steps': 7272}
 24%|██▍       | 1751/7272 [8:05:49<24:45:44, 16.15s/it] 24%|██▍       | 1752/7272 [8:06:04<24:33:40, 16.02s/it]                                                        {'loss': 2.5127, 'grad_norm': 6.4579081535339355, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1752, 'max_steps': 7272}
 24%|██▍       | 1752/7272 [8:06:04<24:33:40, 16.02s/it] 24%|██▍       | 1753/7272 [8:06:21<24:41:32, 16.11s/it]                                                        {'loss': 3.0813, 'grad_norm': 8.415457725524902, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1753, 'max_steps': 7272}
 24%|██▍       | 1753/7272 [8:06:21<24:41:32, 16.11s/it] 24%|██▍       | 1754/7272 [8:06:37<24:45:06, 16.15s/it]                                                        {'loss': 1.2208, 'grad_norm': 6.096221923828125, 'learning_rate': 5e-05, 'epoch': 0.96, 'step': 1754, 'max_steps': 7272}
 24%|██▍       | 1754/7272 [8:06:37<24:45:06, 16.15s/it] 24%|██▍       | 1755/7272 [8:06:52<24:24:08, 15.92s/it]                                                        {'loss': 1.7272, 'grad_norm': 4.620853900909424, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1755, 'max_steps': 7272}
 24%|██▍       | 1755/7272 [8:06:52<24:24:08, 15.92s/it] 24%|██▍       | 1756/7272 [8:07:08<24:22:22, 15.91s/it]                                                        {'loss': 2.2934, 'grad_norm': 4.881285667419434, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1756, 'max_steps': 7272}
 24%|██▍       | 1756/7272 [8:07:08<24:22:22, 15.91s/it] 24%|██▍       | 1757/7272 [8:07:24<24:19:21, 15.88s/it]                                                        {'loss': 1.0273, 'grad_norm': 4.123116493225098, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1757, 'max_steps': 7272}
 24%|██▍       | 1757/7272 [8:07:24<24:19:21, 15.88s/it] 24%|██▍       | 1758/7272 [8:07:40<24:25:05, 15.94s/it]                                                        {'loss': 1.6508, 'grad_norm': 4.135979652404785, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1758, 'max_steps': 7272}
 24%|██▍       | 1758/7272 [8:07:40<24:25:05, 15.94s/it] 24%|██▍       | 1759/7272 [8:07:56<24:27:42, 15.97s/it]                                                        {'loss': 2.0036, 'grad_norm': 3.4179837703704834, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1759, 'max_steps': 7272}
 24%|██▍       | 1759/7272 [8:07:56<24:27:42, 15.97s/it] 24%|██▍       | 1760/7272 [8:08:12<24:24:10, 15.94s/it]                                                        {'loss': 1.1972, 'grad_norm': 3.0271763801574707, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1760, 'max_steps': 7272}
 24%|██▍       | 1760/7272 [8:08:12<24:24:10, 15.94s/it] 24%|██▍       | 1761/7272 [8:08:28<24:20:52, 15.91s/it]                                                        {'loss': 2.8001, 'grad_norm': 3.497279405593872, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1761, 'max_steps': 7272}
 24%|██▍       | 1761/7272 [8:08:28<24:20:52, 15.91s/it] 24%|██▍       | 1762/7272 [8:08:43<24:03:19, 15.72s/it]                                                        {'loss': 2.1785, 'grad_norm': 5.209315776824951, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1762, 'max_steps': 7272}
 24%|██▍       | 1762/7272 [8:08:43<24:03:19, 15.72s/it] 24%|██▍       | 1763/7272 [8:08:59<24:04:02, 15.73s/it]                                                        {'loss': 2.1991, 'grad_norm': 6.969947814941406, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1763, 'max_steps': 7272}
 24%|██▍       | 1763/7272 [8:08:59<24:04:02, 15.73s/it] 24%|██▍       | 1764/7272 [8:09:15<24:15:05, 15.85s/it]                                                        {'loss': 2.4328, 'grad_norm': 4.863127708435059, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1764, 'max_steps': 7272}
 24%|██▍       | 1764/7272 [8:09:15<24:15:05, 15.85s/it] 24%|██▍       | 1765/7272 [8:09:32<24:33:22, 16.05s/it]                                                        {'loss': 1.4541, 'grad_norm': 3.5268518924713135, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1765, 'max_steps': 7272}
 24%|██▍       | 1765/7272 [8:09:32<24:33:22, 16.05s/it] 24%|██▍       | 1766/7272 [8:09:48<24:37:06, 16.10s/it]                                                        {'loss': 2.8947, 'grad_norm': 5.369524955749512, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1766, 'max_steps': 7272}
 24%|██▍       | 1766/7272 [8:09:48<24:37:06, 16.10s/it] 24%|██▍       | 1767/7272 [8:10:04<24:28:29, 16.01s/it]                                                        {'loss': 1.466, 'grad_norm': 2.414259195327759, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1767, 'max_steps': 7272}
 24%|██▍       | 1767/7272 [8:10:04<24:28:29, 16.01s/it] 24%|██▍       | 1768/7272 [8:10:19<24:20:45, 15.92s/it]                                                        {'loss': 1.8214, 'grad_norm': 8.375441551208496, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1768, 'max_steps': 7272}
 24%|██▍       | 1768/7272 [8:10:19<24:20:45, 15.92s/it] 24%|██▍       | 1769/7272 [8:10:35<24:19:48, 15.92s/it]                                                        {'loss': 2.3661, 'grad_norm': 7.134476184844971, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1769, 'max_steps': 7272}
 24%|██▍       | 1769/7272 [8:10:35<24:19:48, 15.92s/it] 24%|██▍       | 1770/7272 [8:10:51<24:30:35, 16.04s/it]                                                        {'loss': 2.2047, 'grad_norm': 4.811856269836426, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1770, 'max_steps': 7272}
 24%|██▍       | 1770/7272 [8:10:51<24:30:35, 16.04s/it] 24%|██▍       | 1771/7272 [8:11:07<24:19:04, 15.91s/it]                                                        {'loss': 2.0256, 'grad_norm': 5.0182881355285645, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1771, 'max_steps': 7272}
 24%|██▍       | 1771/7272 [8:11:07<24:19:04, 15.91s/it] 24%|██▍       | 1772/7272 [8:11:23<24:07:32, 15.79s/it]                                                        {'loss': 1.3325, 'grad_norm': 3.8187026977539062, 'learning_rate': 5e-05, 'epoch': 0.97, 'step': 1772, 'max_steps': 7272}
 24%|██▍       | 1772/7272 [8:11:23<24:07:32, 15.79s/it] 24%|██▍       | 1773/7272 [8:11:38<24:00:15, 15.71s/it]                                                        {'loss': 2.7143, 'grad_norm': 6.608103275299072, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1773, 'max_steps': 7272}
 24%|██▍       | 1773/7272 [8:11:38<24:00:15, 15.71s/it] 24%|██▍       | 1774/7272 [8:11:54<23:55:24, 15.66s/it]                                                        {'loss': 0.9075, 'grad_norm': 2.1973283290863037, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1774, 'max_steps': 7272}
 24%|██▍       | 1774/7272 [8:11:54<23:55:24, 15.66s/it] 24%|██▍       | 1775/7272 [8:12:10<24:05:35, 15.78s/it]                                                        {'loss': 4.3466, 'grad_norm': 11.86558723449707, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1775, 'max_steps': 7272}
 24%|██▍       | 1775/7272 [8:12:10<24:05:35, 15.78s/it] 24%|██▍       | 1776/7272 [8:12:26<24:08:16, 15.81s/it]                                                        {'loss': 3.403, 'grad_norm': 7.764983177185059, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1776, 'max_steps': 7272}
 24%|██▍       | 1776/7272 [8:12:26<24:08:16, 15.81s/it] 24%|██▍       | 1777/7272 [8:12:41<24:04:28, 15.77s/it]                                                        {'loss': 1.1018, 'grad_norm': 2.9006764888763428, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1777, 'max_steps': 7272}
 24%|██▍       | 1777/7272 [8:12:41<24:04:28, 15.77s/it] 24%|██▍       | 1778/7272 [8:12:57<24:15:19, 15.89s/it]                                                        {'loss': 1.9283, 'grad_norm': 5.272212982177734, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1778, 'max_steps': 7272}
 24%|██▍       | 1778/7272 [8:12:57<24:15:19, 15.89s/it] 24%|██▍       | 1779/7272 [8:13:14<24:21:23, 15.96s/it]                                                        {'loss': 1.5197, 'grad_norm': 8.101715087890625, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1779, 'max_steps': 7272}
 24%|██▍       | 1779/7272 [8:13:14<24:21:23, 15.96s/it] 24%|██▍       | 1780/7272 [8:13:30<24:37:14, 16.14s/it]                                                        {'loss': 2.8238, 'grad_norm': 5.147956371307373, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1780, 'max_steps': 7272}
 24%|██▍       | 1780/7272 [8:13:30<24:37:14, 16.14s/it] 24%|██▍       | 1781/7272 [8:13:46<24:33:07, 16.10s/it]                                                        {'loss': 1.4507, 'grad_norm': 5.8453779220581055, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1781, 'max_steps': 7272}
 24%|██▍       | 1781/7272 [8:13:46<24:33:07, 16.10s/it] 25%|██▍       | 1782/7272 [8:14:02<24:18:08, 15.94s/it]                                                        {'loss': 1.9828, 'grad_norm': 6.322286605834961, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1782, 'max_steps': 7272}
 25%|██▍       | 1782/7272 [8:14:02<24:18:08, 15.94s/it] 25%|██▍       | 1783/7272 [8:14:17<24:10:32, 15.86s/it]                                                        {'loss': 1.1977, 'grad_norm': 2.3665289878845215, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1783, 'max_steps': 7272}
 25%|██▍       | 1783/7272 [8:14:17<24:10:32, 15.86s/it] 25%|██▍       | 1784/7272 [8:14:33<24:03:56, 15.79s/it]                                                        {'loss': 2.5035, 'grad_norm': 5.817178249359131, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1784, 'max_steps': 7272}
 25%|██▍       | 1784/7272 [8:14:33<24:03:56, 15.79s/it] 25%|██▍       | 1785/7272 [8:14:49<23:57:17, 15.72s/it]                                                        {'loss': 1.7819, 'grad_norm': 5.031442165374756, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1785, 'max_steps': 7272}
 25%|██▍       | 1785/7272 [8:14:49<23:57:17, 15.72s/it] 25%|██▍       | 1786/7272 [8:15:05<24:04:46, 15.80s/it]                                                        {'loss': 1.5378, 'grad_norm': 5.468018531799316, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1786, 'max_steps': 7272}
 25%|██▍       | 1786/7272 [8:15:05<24:04:46, 15.80s/it] 25%|██▍       | 1787/7272 [8:15:20<23:46:23, 15.60s/it]                                                        {'loss': 1.6993, 'grad_norm': 3.9550790786743164, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1787, 'max_steps': 7272}
 25%|██▍       | 1787/7272 [8:15:20<23:46:23, 15.60s/it] 25%|██▍       | 1788/7272 [8:15:36<23:51:45, 15.66s/it]                                                        {'loss': 2.5755, 'grad_norm': 5.281087398529053, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1788, 'max_steps': 7272}
 25%|██▍       | 1788/7272 [8:15:36<23:51:45, 15.66s/it] 25%|██▍       | 1789/7272 [8:15:51<23:52:33, 15.68s/it]                                                        {'loss': 2.8694, 'grad_norm': 4.242672920227051, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1789, 'max_steps': 7272}
 25%|██▍       | 1789/7272 [8:15:51<23:52:33, 15.68s/it] 25%|██▍       | 1790/7272 [8:16:07<24:05:13, 15.82s/it]                                                        {'loss': 2.3457, 'grad_norm': 5.075769424438477, 'learning_rate': 5e-05, 'epoch': 0.98, 'step': 1790, 'max_steps': 7272}
 25%|██▍       | 1790/7272 [8:16:07<24:05:13, 15.82s/it] 25%|██▍       | 1791/7272 [8:16:23<23:56:27, 15.72s/it]                                                        {'loss': 2.4906, 'grad_norm': 11.17087173461914, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1791, 'max_steps': 7272}
 25%|██▍       | 1791/7272 [8:16:23<23:56:27, 15.72s/it] 25%|██▍       | 1792/7272 [8:16:39<24:03:32, 15.81s/it]                                                        {'loss': 0.7884, 'grad_norm': 3.904224395751953, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1792, 'max_steps': 7272}
 25%|██▍       | 1792/7272 [8:16:39<24:03:32, 15.81s/it] 25%|██▍       | 1793/7272 [8:16:55<24:19:42, 15.99s/it]                                                        {'loss': 1.9182, 'grad_norm': 2.759335517883301, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1793, 'max_steps': 7272}
 25%|██▍       | 1793/7272 [8:16:55<24:19:42, 15.99s/it] 25%|██▍       | 1794/7272 [8:17:12<24:28:07, 16.08s/it]                                                        {'loss': 1.7834, 'grad_norm': 6.549489974975586, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1794, 'max_steps': 7272}
 25%|██▍       | 1794/7272 [8:17:12<24:28:07, 16.08s/it] 25%|██▍       | 1795/7272 [8:17:27<24:14:42, 15.94s/it]                                                        {'loss': 3.0436, 'grad_norm': 9.030142784118652, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1795, 'max_steps': 7272}
 25%|██▍       | 1795/7272 [8:17:27<24:14:42, 15.94s/it] 25%|██▍       | 1796/7272 [8:17:43<24:16:52, 15.96s/it]                                                        {'loss': 2.5649, 'grad_norm': 3.6946752071380615, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1796, 'max_steps': 7272}
 25%|██▍       | 1796/7272 [8:17:43<24:16:52, 15.96s/it] 25%|██▍       | 1797/7272 [8:18:00<24:26:09, 16.07s/it]                                                        {'loss': 1.9671, 'grad_norm': 8.17919635772705, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1797, 'max_steps': 7272}
 25%|██▍       | 1797/7272 [8:18:00<24:26:09, 16.07s/it] 25%|██▍       | 1798/7272 [8:18:16<24:28:37, 16.10s/it]                                                        {'loss': 1.581, 'grad_norm': 5.290982246398926, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1798, 'max_steps': 7272}
 25%|██▍       | 1798/7272 [8:18:16<24:28:37, 16.10s/it] 25%|██▍       | 1799/7272 [8:18:32<24:27:18, 16.09s/it]                                                        {'loss': 1.7881, 'grad_norm': 5.630719184875488, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1799, 'max_steps': 7272}
 25%|██▍       | 1799/7272 [8:18:32<24:27:18, 16.09s/it] 25%|██▍       | 1800/7272 [8:18:47<24:03:58, 15.83s/it]                                                        {'loss': 1.9857, 'grad_norm': 6.893432140350342, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1800, 'max_steps': 7272}
 25%|██▍       | 1800/7272 [8:18:47<24:03:58, 15.83s/it] 25%|██▍       | 1801/7272 [8:19:03<24:09:09, 15.89s/it]                                                        {'loss': 0.8387, 'grad_norm': 4.037173271179199, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1801, 'max_steps': 7272}
 25%|██▍       | 1801/7272 [8:19:03<24:09:09, 15.89s/it] 25%|██▍       | 1802/7272 [8:19:19<24:21:54, 16.04s/it]                                                        {'loss': 0.7177, 'grad_norm': 2.842008352279663, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1802, 'max_steps': 7272}
 25%|██▍       | 1802/7272 [8:19:19<24:21:54, 16.04s/it] 25%|██▍       | 1803/7272 [8:19:35<24:12:48, 15.94s/it]                                                        {'loss': 1.4304, 'grad_norm': 6.383248329162598, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1803, 'max_steps': 7272}
 25%|██▍       | 1803/7272 [8:19:35<24:12:48, 15.94s/it] 25%|██▍       | 1804/7272 [8:19:51<24:09:39, 15.91s/it]                                                        {'loss': 1.7664, 'grad_norm': 4.0250372886657715, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1804, 'max_steps': 7272}
 25%|██▍       | 1804/7272 [8:19:51<24:09:39, 15.91s/it] 25%|██▍       | 1805/7272 [8:20:07<24:05:37, 15.87s/it]                                                        {'loss': 1.7725, 'grad_norm': 4.197216987609863, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1805, 'max_steps': 7272}
 25%|██▍       | 1805/7272 [8:20:07<24:05:37, 15.87s/it] 25%|██▍       | 1806/7272 [8:20:23<24:06:21, 15.88s/it]                                                        {'loss': 1.2893, 'grad_norm': 2.6050288677215576, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1806, 'max_steps': 7272}
 25%|██▍       | 1806/7272 [8:20:23<24:06:21, 15.88s/it] 25%|██▍       | 1807/7272 [8:20:38<24:03:01, 15.84s/it]                                                        {'loss': 2.406, 'grad_norm': 7.75766134262085, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1807, 'max_steps': 7272}
 25%|██▍       | 1807/7272 [8:20:38<24:03:01, 15.84s/it] 25%|██▍       | 1808/7272 [8:20:55<24:25:12, 16.09s/it]                                                        {'loss': 2.4376, 'grad_norm': 5.41814661026001, 'learning_rate': 5e-05, 'epoch': 0.99, 'step': 1808, 'max_steps': 7272}
 25%|██▍       | 1808/7272 [8:20:55<24:25:12, 16.09s/it] 25%|██▍       | 1809/7272 [8:21:11<24:29:46, 16.14s/it]                                                        {'loss': 1.5511, 'grad_norm': 8.406564712524414, 'learning_rate': 5e-05, 'epoch': 1.0, 'step': 1809, 'max_steps': 7272}
 25%|██▍       | 1809/7272 [8:21:11<24:29:46, 16.14s/it] 25%|██▍       | 1810/7272 [8:21:27<24:25:22, 16.10s/it]                                                        {'loss': 3.0618, 'grad_norm': 7.292407035827637, 'learning_rate': 5e-05, 'epoch': 1.0, 'step': 1810, 'max_steps': 7272}
 25%|██▍       | 1810/7272 [8:21:27<24:25:22, 16.10s/it] 25%|██▍       | 1811/7272 [8:21:43<24:17:13, 16.01s/it]                                                        {'loss': 2.4867, 'grad_norm': 6.447118759155273, 'learning_rate': 5e-05, 'epoch': 1.0, 'step': 1811, 'max_steps': 7272}
 25%|██▍       | 1811/7272 [8:21:43<24:17:13, 16.01s/it] 25%|██▍       | 1812/7272 [8:21:59<24:12:23, 15.96s/it]                                                        {'loss': 1.8437, 'grad_norm': 7.7422661781311035, 'learning_rate': 5e-05, 'epoch': 1.0, 'step': 1812, 'max_steps': 7272}
 25%|██▍       | 1812/7272 [8:21:59<24:12:23, 15.96s/it] 25%|██▍       | 1813/7272 [8:22:16<24:30:18, 16.16s/it]                                                        {'loss': 1.7659, 'grad_norm': 6.150758266448975, 'learning_rate': 5e-05, 'epoch': 1.0, 'step': 1813, 'max_steps': 7272}
 25%|██▍       | 1813/7272 [8:22:16<24:30:18, 16.16s/it] 25%|██▍       | 1814/7272 [8:22:31<24:17:26, 16.02s/it]                                                        {'loss': 2.1902, 'grad_norm': 3.47700572013855, 'learning_rate': 5e-05, 'epoch': 1.0, 'step': 1814, 'max_steps': 7272}
 25%|██▍       | 1814/7272 [8:22:31<24:17:26, 16.02s/it] 25%|██▍       | 1815/7272 [8:22:47<24:13:14, 15.98s/it]                                                        {'loss': 1.3929, 'grad_norm': 3.043621301651001, 'learning_rate': 5e-05, 'epoch': 1.0, 'step': 1815, 'max_steps': 7272}
 25%|██▍       | 1815/7272 [8:22:47<24:13:14, 15.98s/it] 25%|██▍       | 1816/7272 [8:23:03<24:17:40, 16.03s/it]                                                        {'loss': 2.7346, 'grad_norm': 5.507726669311523, 'learning_rate': 5e-05, 'epoch': 1.0, 'step': 1816, 'max_steps': 7272}
 25%|██▍       | 1816/7272 [8:23:03<24:17:40, 16.03s/it] 25%|██▍       | 1817/7272 [8:23:19<24:18:16, 16.04s/it]                                                        {'loss': 2.3578, 'grad_norm': 5.627772808074951, 'learning_rate': 5e-05, 'epoch': 1.0, 'step': 1817, 'max_steps': 7272}
 25%|██▍       | 1817/7272 [8:23:19<24:18:16, 16.04s/it] 25%|██▌       | 1818/7272 [8:23:36<24:27:04, 16.14s/it]                                                        {'loss': 1.7622, 'grad_norm': 4.492864608764648, 'learning_rate': 5e-05, 'epoch': 1.0, 'step': 1818, 'max_steps': 7272}
 25%|██▌       | 1818/7272 [8:23:36<24:27:04, 16.14s/it][rank3]: Traceback (most recent call last):
[rank3]:   File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/torch/serialization.py", line 652, in save
[rank3]:     _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)
[rank3]:   File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/torch/serialization.py", line 886, in _save
[rank3]:     zip_file.write_record(name, storage, num_bytes)
[rank3]: RuntimeError: [enforce fail at inline_container.cc:778] . PytorchStreamWriter failed writing file data/3: file write failed

[rank3]: During handling of the above exception, another exception occurred:

[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/train/train.py", line 438, in <module>
[rank3]:     train()
[rank3]:   File huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
 25%|██▌       | 1818/7272 [8:24:29<25:13:27, 16.65s/it]
[2025-01-30 15:35:22,266] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3946385
[2025-01-30 15:35:28,411] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3946397
[2025-01-30 15:35:28,411] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3946399
[2025-01-30 15:35:29,016] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3946421
[2025-01-30 15:35:29,630] [ERROR] [launch.py:325:sigkill_handler] ['/home/donglinbai/miniconda3/envs/sparse/bin/python', '-u', 'train.py', '--local_rank=3', '--model_name_or_path', '/data/wzw/models/Meta-Llama-3-8B', '--data_path', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/datasets/Meta-Llama-3-8B/mix_alpaca_c4_9000.json', '--threshold_path', '../threshold/llama-3-0.7.txt', '--model_max_length', '512', '--output_dir', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/ckpts/Meta-Llama-3-8B/int4-g64/', '--logging_dir', '/home/donglinbai/Projects/wzw/BitDistiller-Q4_0/data/logs/Meta-Llama-3-8B/int4-g64/', '--num_train_epochs', '4', '--bf16', 'True', '--seed', '42', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '1', '--gradient_checkpointing', 'True', '--load_best_model_at_end', 'False', '--save_strategy', 'epoch', '--save_total_limit', '1', '--learning_rate', '5e-5', '--lr_scheduler_type', 'constant', '--weight_decay', '0.', '--logging_steps', '1', '--report_to', 'none', '--deepspeed', 'config/zero3.json', '--bits', '4', '--quant_type', 'Q4_0', '--q_group_size', '64', '--train_kd', 'False', '--kd_loss_type', 'cakld', '--max_train_samples', '999999', '--max_memory', '24000MB', '--evaluation_strategy', 'steps', '--eval_steps', '500'] exits with return code = 1
