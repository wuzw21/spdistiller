                                
{'loss': 0.4376, 'grad_norm': 4.2426042556762695, 'learning_rate': 8e-06, 'epoch': 0.02, 'step': 1, 'max_steps': 280}

  0%|          | 1/280 [00:47<3:33:13, 45.86s/it]
  1%|          | 2/280 [01:27<3:20:23, 43.25s/it]
                                                 
{'loss': 0.4028, 'grad_norm': 2.6887669563293457, 'learning_rate': 8e-06, 'epoch': 0.04, 'step': 2, 'max_steps': 280}

  1%|          | 2/280 [01:27<3:20:23, 43.25s/it]
  1%|          | 3/280 [02:07<3:12:45, 41.75s/it]
                                                 
{'loss': 0.4148, 'grad_norm': 6.078140735626221, 'learning_rate': 8e-06, 'epoch': 0.05, 'step': 3, 'max_steps': 280}

  1%|          | 3/280 [02:07<3:12:45, 41.75s/it]
  1%|▏         | 4/280 [02:47<3:09:08, 41.12s/it]
                                                 
{'loss': 0.4607, 'grad_norm': 5.843574523925781, 'learning_rate': 8e-06, 'epoch': 0.07, 'step': 4, 'max_steps': 280}

  1%|▏         | 4/280 [02:47<3:09:08, 41.12s/it]
  2%|▏         | 5/280 [03:27<3:06:16, 40.64s/it]
                                                 
{'loss': 0.3865, 'grad_norm': 2.6074745655059814, 'learning_rate': 8e-06, 'epoch': 0.09, 'step': 5, 'max_steps': 280}

  2%|▏         | 5/280 [03:27<3:06:16, 40.64s/it]
  2%|▏         | 6/280 [04:07<3:04:24, 40.38s/it]
                                                 
{'loss': 0.3841, 'grad_norm': 2.5702054500579834, 'learning_rate': 8e-06, 'epoch': 0.11, 'step': 6, 'max_steps': 280}

  2%|▏         | 6/280 [04:07<3:04:24, 40.38s/it]
  2%|▎         | 7/280 [04:47<3:04:23, 40.53s/it]
                                                 
{'loss': 0.3959, 'grad_norm': 2.3436899185180664, 'learning_rate': 8e-06, 'epoch': 0.12, 'step': 7, 'max_steps': 280}

  2%|▎         | 7/280 [04:47<3:04:23, 40.53s/it]
  3%|▎         | 8/280 [05:27<3:02:57, 40.36s/it]
                                                 
{'loss': 0.4072, 'grad_norm': 2.4098305702209473, 'learning_rate': 8e-06, 'epoch': 0.14, 'step': 8, 'max_steps': 280}

  3%|▎         | 8/280 [05:27<3:02:57, 40.36s/it]
  3%|▎         | 9/280 [06:07<3:01:11, 40.12s/it]
                                                 
{'loss': 0.4052, 'grad_norm': 2.2224173545837402, 'learning_rate': 8e-06, 'epoch': 0.16, 'step': 9, 'max_steps': 280}

  3%|▎         | 9/280 [06:07<3:01:11, 40.12s/it]
  4%|▎         | 10/280 [06:46<2:59:41, 39.93s/it]
                                                  
{'loss': 0.3979, 'grad_norm': 1.99502432346344, 'learning_rate': 8e-06, 'epoch': 0.18, 'step': 10, 'max_steps': 280}

  4%|▎         | 10/280 [06:46<2:59:41, 39.93s/it]
  4%|▍         | 11/280 [07:26<2:58:15, 39.76s/it]
                                                  
{'loss': 0.3921, 'grad_norm': 1.9210482835769653, 'learning_rate': 8e-06, 'epoch': 0.19, 'step': 11, 'max_steps': 280}

  4%|▍         | 11/280 [07:26<2:58:15, 39.76s/it]
  4%|▍         | 12/280 [08:06<2:57:50, 39.81s/it]
                                                  
{'loss': 0.3316, 'grad_norm': 1.6492711305618286, 'learning_rate': 8e-06, 'epoch': 0.21, 'step': 12, 'max_steps': 280}

  4%|▍         | 12/280 [08:06<2:57:50, 39.81s/it]
  5%|▍         | 13/280 [08:45<2:56:45, 39.72s/it]
                                                  
{'loss': 0.3577, 'grad_norm': 2.152874708175659, 'learning_rate': 8e-06, 'epoch': 0.23, 'step': 13, 'max_steps': 280}

  5%|▍         | 13/280 [08:45<2:56:45, 39.72s/it]
  5%|▌         | 14/280 [09:25<2:55:52, 39.67s/it]
                                                  
{'loss': 0.3421, 'grad_norm': 1.9547173976898193, 'learning_rate': 8e-06, 'epoch': 0.25, 'step': 14, 'max_steps': 280}

  5%|▌         | 14/280 [09:25<2:55:52, 39.67s/it]
  5%|▌         | 15/280 [10:06<2:57:41, 40.23s/it]
                                                  
{'loss': 0.3082, 'grad_norm': 1.6592432260513306, 'learning_rate': 8e-06, 'epoch': 0.26, 'step': 15, 'max_steps': 280}

  5%|▌         | 15/280 [10:06<2:57:41, 40.23s/it]
  6%|▌         | 16/280 [10:46<2:56:01, 40.01s/it]
                                                  
{'loss': 0.3312, 'grad_norm': 1.6381746530532837, 'learning_rate': 8e-06, 'epoch': 0.28, 'step': 16, 'max_steps': 280}

  6%|▌         | 16/280 [10:46<2:56:01, 40.01s/it]
  6%|▌         | 17/280 [11:25<2:54:23, 39.79s/it]
                                                  
{'loss': 0.3689, 'grad_norm': 1.8808574676513672, 'learning_rate': 8e-06, 'epoch': 0.3, 'step': 17, 'max_steps': 280}

  6%|▌         | 17/280 [11:25<2:54:23, 39.79s/it]
  6%|▋         | 18/280 [12:05<2:53:11, 39.66s/it]
                                                  
{'loss': 0.363, 'grad_norm': 2.2803423404693604, 'learning_rate': 8e-06, 'epoch': 0.32, 'step': 18, 'max_steps': 280}

  6%|▋         | 18/280 [12:05<2:53:11, 39.66s/it]
  7%|▋         | 19/280 [12:44<2:52:00, 39.54s/it]
                                                  
{'loss': 0.3825, 'grad_norm': 8.711342811584473, 'learning_rate': 8e-06, 'epoch': 0.33, 'step': 19, 'max_steps': 280}

  7%|▋         | 19/280 [12:44<2:52:00, 39.54s/it]
  7%|▋         | 20/280 [13:24<2:51:59, 39.69s/it]
                                                  
{'loss': 0.3691, 'grad_norm': 2.218085289001465, 'learning_rate': 8e-06, 'epoch': 0.35, 'step': 20, 'max_steps': 280}

  7%|▋         | 20/280 [13:24<2:51:59, 39.69s/it]
  8%|▊         | 21/280 [14:03<2:50:49, 39.57s/it]
                                                  
{'loss': 0.3902, 'grad_norm': 2.177508592605591, 'learning_rate': 8e-06, 'epoch': 0.37, 'step': 21, 'max_steps': 280}

  8%|▊         | 21/280 [14:03<2:50:49, 39.57s/it]
  8%|▊         | 22/280 [14:42<2:49:42, 39.47s/it]
                                                  
{'loss': 0.3745, 'grad_norm': 3.3798282146453857, 'learning_rate': 8e-06, 'epoch': 0.39, 'step': 22, 'max_steps': 280}

  8%|▊         | 22/280 [14:42<2:49:42, 39.47s/it]
  8%|▊         | 23/280 [15:22<2:49:13, 39.51s/it]
                                                  
{'loss': 0.3443, 'grad_norm': 1.7811088562011719, 'learning_rate': 8e-06, 'epoch': 0.4, 'step': 23, 'max_steps': 280}

  8%|▊         | 23/280 [15:22<2:49:13, 39.51s/it]
  9%|▊         | 24/280 [16:01<2:48:28, 39.49s/it]
                                                  
{'loss': 0.337, 'grad_norm': 1.5374550819396973, 'learning_rate': 8e-06, 'epoch': 0.42, 'step': 24, 'max_steps': 280}

  9%|▊         | 24/280 [16:01<2:48:28, 39.49s/it]
  9%|▉         | 25/280 [16:41<2:47:37, 39.44s/it]
                                                  
{'loss': 0.3696, 'grad_norm': 2.22786021232605, 'learning_rate': 8e-06, 'epoch': 0.44, 'step': 25, 'max_steps': 280}

  9%|▉         | 25/280 [16:41<2:47:37, 39.44s/it]
  9%|▉         | 26/280 [17:20<2:47:13, 39.50s/it]
                                                  
{'loss': 0.3698, 'grad_norm': 2.028208017349243, 'learning_rate': 8e-06, 'epoch': 0.46, 'step': 26, 'max_steps': 280}

  9%|▉         | 26/280 [17:20<2:47:13, 39.50s/it]
 10%|▉         | 27/280 [18:00<2:46:27, 39.47s/it]
                                                  
{'loss': 0.4087, 'grad_norm': 2.37538743019104, 'learning_rate': 8e-06, 'epoch': 0.47, 'step': 27, 'max_steps': 280}

 10%|▉         | 27/280 [18:00<2:46:27, 39.47s/it]
 10%|█         | 28/280 [18:39<2:45:40, 39.45s/it]
                                                  
{'loss': 0.3173, 'grad_norm': 1.4135634899139404, 'learning_rate': 8e-06, 'epoch': 0.49, 'step': 28, 'max_steps': 280}

 10%|█         | 28/280 [18:39<2:45:40, 39.45s/it]
 10%|█         | 29/280 [19:18<2:44:49, 39.40s/it]
                                                  
{'loss': 0.3595, 'grad_norm': 1.8384904861450195, 'learning_rate': 8e-06, 'epoch': 0.51, 'step': 29, 'max_steps': 280}

 10%|█         | 29/280 [19:18<2:44:49, 39.40s/it]
 11%|█         | 30/280 [19:58<2:44:04, 39.38s/it]
                                                  
{'loss': 0.3381, 'grad_norm': 1.5924967527389526, 'learning_rate': 8e-06, 'epoch': 0.53, 'step': 30, 'max_steps': 280}

 11%|█         | 30/280 [19:58<2:44:04, 39.38s/it]
 11%|█         | 31/280 [20:37<2:43:27, 39.39s/it]
                                                  
{'loss': 0.3357, 'grad_norm': 1.6182721853256226, 'learning_rate': 8e-06, 'epoch': 0.55, 'step': 31, 'max_steps': 280}

 11%|█         | 31/280 [20:37<2:43:27, 39.39s/it]
 11%|█▏        | 32/280 [21:16<2:42:41, 39.36s/it]
                                                  
{'loss': 0.3507, 'grad_norm': 1.5725653171539307, 'learning_rate': 8e-06, 'epoch': 0.56, 'step': 32, 'max_steps': 280}

 11%|█▏        | 32/280 [21:16<2:42:41, 39.36s/it]
 12%|█▏        | 33/280 [21:56<2:42:02, 39.36s/it]
                                                  
{'loss': 0.3547, 'grad_norm': 1.8690825700759888, 'learning_rate': 8e-06, 'epoch': 0.58, 'step': 33, 'max_steps': 280}

 12%|█▏        | 33/280 [21:56<2:42:02, 39.36s/it]
 12%|█▏        | 34/280 [22:35<2:41:19, 39.35s/it]
                                                  
{'loss': 0.3626, 'grad_norm': 1.8543205261230469, 'learning_rate': 8e-06, 'epoch': 0.6, 'step': 34, 'max_steps': 280}

 12%|█▏        | 34/280 [22:35<2:41:19, 39.35s/it]
 12%|█▎        | 35/280 [23:15<2:40:39, 39.35s/it]
                                                  
{'loss': 0.3408, 'grad_norm': 1.752589464187622, 'learning_rate': 8e-06, 'epoch': 0.62, 'step': 35, 'max_steps': 280}

 12%|█▎        | 35/280 [23:15<2:40:39, 39.35s/it]
 13%|█▎        | 36/280 [23:55<2:41:04, 39.61s/it]
                                                  
{'loss': 0.3287, 'grad_norm': 1.6394517421722412, 'learning_rate': 8e-06, 'epoch': 0.63, 'step': 36, 'max_steps': 280}

 13%|█▎        | 36/280 [23:55<2:41:04, 39.61s/it]
 13%|█▎        | 37/280 [24:34<2:40:04, 39.53s/it]
                                                  
{'loss': 0.3646, 'grad_norm': 1.8143757581710815, 'learning_rate': 8e-06, 'epoch': 0.65, 'step': 37, 'max_steps': 280}

 13%|█▎        | 37/280 [24:34<2:40:04, 39.53s/it]
 14%|█▎        | 38/280 [25:35<3:05:09, 45.91s/it]
                                                  
{'loss': 0.3594, 'grad_norm': 2.3911068439483643, 'learning_rate': 8e-06, 'epoch': 0.67, 'step': 38, 'max_steps': 280}

 14%|█▎        | 38/280 [25:35<3:05:09, 45.91s/it]
 14%|█▍        | 39/280 [26:15<2:56:52, 44.04s/it]
                                                  
{'loss': 0.3599, 'grad_norm': 6.899051666259766, 'learning_rate': 8e-06, 'epoch': 0.69, 'step': 39, 'max_steps': 280}

 14%|█▍        | 39/280 [26:15<2:56:52, 44.04s/it]
 14%|█▍        | 40/280 [26:54<2:50:53, 42.72s/it]
                                                  
{'loss': 0.3356, 'grad_norm': 1.806917428970337, 'learning_rate': 8e-06, 'epoch': 0.7, 'step': 40, 'max_steps': 280}

 14%|█▍        | 40/280 [26:54<2:50:53, 42.72s/it]
 15%|█▍        | 41/280 [27:34<2:46:36, 41.83s/it]
                                                  
{'loss': 0.3323, 'grad_norm': 2.5172905921936035, 'learning_rate': 8e-06, 'epoch': 0.72, 'step': 41, 'max_steps': 280}

 15%|█▍        | 41/280 [27:34<2:46:36, 41.83s/it]
 15%|█▌        | 42/280 [28:13<2:43:06, 41.12s/it]
                                                  
{'loss': 0.399, 'grad_norm': 2.635148286819458, 'learning_rate': 8e-06, 'epoch': 0.74, 'step': 42, 'max_steps': 280}

 15%|█▌        | 42/280 [28:13<2:43:06, 41.12s/it]
 15%|█▌        | 43/280 [28:54<2:41:49, 40.97s/it]
                                                  
{'loss': 0.3297, 'grad_norm': 1.9276922941207886, 'learning_rate': 8e-06, 'epoch': 0.76, 'step': 43, 'max_steps': 280}

 15%|█▌        | 43/280 [28:54<2:41:49, 40.97s/it]
 16%|█▌        | 44/280 [29:34<2:39:27, 40.54s/it]
                                                  
{'loss': 0.3507, 'grad_norm': 1.8729748725891113, 'learning_rate': 8e-06, 'epoch': 0.77, 'step': 44, 'max_steps': 280}

 16%|█▌        | 44/280 [29:34<2:39:27, 40.54s/it]
 16%|█▌        | 45/280 [30:13<2:37:42, 40.26s/it]
                                                  
{'loss': 0.3394, 'grad_norm': 1.900446891784668, 'learning_rate': 8e-06, 'epoch': 0.79, 'step': 45, 'max_steps': 280}

 16%|█▌        | 45/280 [30:13<2:37:42, 40.26s/it]
 16%|█▋        | 46/280 [30:55<2:38:35, 40.67s/it]
                                                  
{'loss': 0.4196, 'grad_norm': 2.2736401557922363, 'learning_rate': 8e-06, 'epoch': 0.81, 'step': 46, 'max_steps': 280}

 16%|█▋        | 46/280 [30:55<2:38:35, 40.67s/it]
 17%|█▋        | 47/280 [31:34<2:36:32, 40.31s/it]
                                                  
{'loss': 0.3896, 'grad_norm': 2.814223289489746, 'learning_rate': 8e-06, 'epoch': 0.83, 'step': 47, 'max_steps': 280}

 17%|█▋        | 47/280 [31:34<2:36:32, 40.31s/it]
 17%|█▋        | 48/280 [32:14<2:34:57, 40.08s/it]
                                                  
{'loss': 0.3544, 'grad_norm': 2.117494821548462, 'learning_rate': 8e-06, 'epoch': 0.84, 'step': 48, 'max_steps': 280}

 17%|█▋        | 48/280 [32:14<2:34:57, 40.08s/it]
 18%|█▊        | 49/280 [32:53<2:33:49, 39.95s/it]
                                                  
{'loss': 0.3642, 'grad_norm': 1.699248194694519, 'learning_rate': 8e-06, 'epoch': 0.86, 'step': 49, 'max_steps': 280}

 18%|█▊        | 49/280 [32:53<2:33:49, 39.95s/it]
 18%|█▊        | 50/280 [33:33<2:32:34, 39.80s/it]
                                                  
{'loss': 0.3462, 'grad_norm': 1.9815318584442139, 'learning_rate': 8e-06, 'epoch': 0.88, 'step': 50, 'max_steps': 280}

 18%|█▊        | 50/280 [33:33<2:32:34, 39.80s/it]
 18%|█▊        | 51/280 [34:13<2:32:30, 39.96s/it]
                                                  
{'loss': 0.3855, 'grad_norm': 2.442932367324829, 'learning_rate': 8e-06, 'epoch': 0.9, 'step': 51, 'max_steps': 280}

 18%|█▊        | 51/280 [34:13<2:32:30, 39.96s/it]
 19%|█▊        | 52/280 [34:53<2:31:30, 39.87s/it]
                                                  
{'loss': 0.3362, 'grad_norm': 1.6998169422149658, 'learning_rate': 8e-06, 'epoch': 0.91, 'step': 52, 'max_steps': 280}

 19%|█▊        | 52/280 [34:53<2:31:30, 39.87s/it]
 19%|█▉        | 53/280 [35:33<2:31:00, 39.91s/it]
                                                  
{'loss': 0.4293, 'grad_norm': 2.844297170639038, 'learning_rate': 8e-06, 'epoch': 0.93, 'step': 53, 'max_steps': 280}

 19%|█▉        | 53/280 [35:33<2:31:00, 39.91s/it]
 19%|█▉        | 54/280 [36:14<2:31:41, 40.27s/it]
                                                  
{'loss': 0.3907, 'grad_norm': 2.367685079574585, 'learning_rate': 8e-06, 'epoch': 0.95, 'step': 54, 'max_steps': 280}

 19%|█▉        | 54/280 [36:14<2:31:41, 40.27s/it]
 20%|█▉        | 55/280 [36:54<2:30:08, 40.04s/it]
                                                  
{'loss': 0.3391, 'grad_norm': 1.7552525997161865, 'learning_rate': 8e-06, 'epoch': 0.97, 'step': 55, 'max_steps': 280}

 20%|█▉        | 55/280 [36:54<2:30:08, 40.04s/it]
 20%|██        | 56/280 [37:33<2:28:57, 39.90s/it]
                                                  
{'loss': 0.3591, 'grad_norm': 2.1932718753814697, 'learning_rate': 8e-06, 'epoch': 0.98, 'step': 56, 'max_steps': 280}

 20%|██        | 56/280 [37:33<2:28:57, 39.90s/it]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(

 20%|██        | 57/280 [41:15<5:51:38, 94.61s/it]
                                                  
{'loss': 0.3431, 'grad_norm': 1.9221936464309692, 'learning_rate': 8e-06, 'epoch': 1.0, 'step': 57, 'max_steps': 280}

 20%|██        | 57/280 [41:15<5:51:38, 94.61s/it]
 21%|██        | 58/280 [41:55<4:49:20, 78.20s/it]
                                                  
{'loss': 0.2193, 'grad_norm': 2.0232183933258057, 'learning_rate': 8e-06, 'epoch': 1.02, 'step': 58, 'max_steps': 280}

 21%|██        | 58/280 [41:55<4:49:20, 78.20s/it]
 21%|██        | 59/280 [42:35<4:05:27, 66.64s/it]
                                                  
{'loss': 0.2255, 'grad_norm': 1.8089064359664917, 'learning_rate': 8e-06, 'epoch': 1.04, 'step': 59, 'max_steps': 280}

 21%|██        | 59/280 [42:35<4:05:27, 66.64s/it]
 21%|██▏       | 60/280 [43:15<3:34:47, 58.58s/it]
                                                  
{'loss': 0.226, 'grad_norm': 1.6505357027053833, 'learning_rate': 8e-06, 'epoch': 1.05, 'step': 60, 'max_steps': 280}

 21%|██▏       | 60/280 [43:15<3:34:47, 58.58s/it]
 22%|██▏       | 61/280 [43:54<3:13:09, 52.92s/it]
                                                  
{'loss': 0.235, 'grad_norm': 1.5789721012115479, 'learning_rate': 8e-06, 'epoch': 1.07, 'step': 61, 'max_steps': 280}

 22%|██▏       | 61/280 [43:54<3:13:09, 52.92s/it]
 22%|██▏       | 62/280 [44:35<2:58:42, 49.19s/it]
                                                  
{'loss': 0.2346, 'grad_norm': 1.696595549583435, 'learning_rate': 8e-06, 'epoch': 1.09, 'step': 62, 'max_steps': 280}

 22%|██▏       | 62/280 [44:35<2:58:42, 49.19s/it]
 22%|██▎       | 63/280 [45:15<2:47:47, 46.39s/it]
                                                  
{'loss': 0.228, 'grad_norm': 1.5811699628829956, 'learning_rate': 8e-06, 'epoch': 1.11, 'step': 63, 'max_steps': 280}

 22%|██▎       | 63/280 [45:15<2:47:47, 46.39s/it]
 23%|██▎       | 64/280 [45:55<2:39:54, 44.42s/it]
                                                  
{'loss': 0.25, 'grad_norm': 1.778904676437378, 'learning_rate': 8e-06, 'epoch': 1.13, 'step': 64, 'max_steps': 280}

 23%|██▎       | 64/280 [45:55<2:39:54, 44.42s/it]
 23%|██▎       | 65/280 [46:35<2:34:50, 43.21s/it]
                                                  
{'loss': 0.2482, 'grad_norm': 1.7343534231185913, 'learning_rate': 8e-06, 'epoch': 1.14, 'step': 65, 'max_steps': 280}

 23%|██▎       | 65/280 [46:35<2:34:50, 43.21s/it]
 24%|██▎       | 66/280 [47:15<2:30:17, 42.14s/it]
                                                  
{'loss': 0.2468, 'grad_norm': 2.241018056869507, 'learning_rate': 8e-06, 'epoch': 1.16, 'step': 66, 'max_steps': 280}

 24%|██▎       | 66/280 [47:15<2:30:17, 42.14s/it]
 24%|██▍       | 67/280 [47:54<2:26:45, 41.34s/it]
                                                  
{'loss': 0.2375, 'grad_norm': 1.562948226928711, 'learning_rate': 8e-06, 'epoch': 1.18, 'step': 67, 'max_steps': 280}

 24%|██▍       | 67/280 [47:54<2:26:45, 41.34s/it]
 24%|██▍       | 68/280 [48:34<2:24:09, 40.80s/it]
                                                  
{'loss': 0.1962, 'grad_norm': 1.2097647190093994, 'learning_rate': 8e-06, 'epoch': 1.2, 'step': 68, 'max_steps': 280}

 24%|██▍       | 68/280 [48:34<2:24:09, 40.80s/it]
 25%|██▍       | 69/280 [49:13<2:22:05, 40.40s/it]
                                                  
{'loss': 0.2616, 'grad_norm': 1.551035761833191, 'learning_rate': 8e-06, 'epoch': 1.21, 'step': 69, 'max_steps': 280}

 25%|██▍       | 69/280 [49:13<2:22:05, 40.40s/it]
 25%|██▌       | 70/280 [49:54<2:21:42, 40.49s/it]
                                                  
{'loss': 0.223, 'grad_norm': 1.3965827226638794, 'learning_rate': 8e-06, 'epoch': 1.23, 'step': 70, 'max_steps': 280}

 25%|██▌       | 70/280 [49:54<2:21:42, 40.49s/it]
 25%|██▌       | 71/280 [50:33<2:20:01, 40.20s/it]
                                                  
{'loss': 0.2325, 'grad_norm': 1.7227978706359863, 'learning_rate': 8e-06, 'epoch': 1.25, 'step': 71, 'max_steps': 280}

 25%|██▌       | 71/280 [50:33<2:20:01, 40.20s/it]
 26%|██▌       | 72/280 [51:13<2:18:38, 39.99s/it]
                                                  
{'loss': 0.2148, 'grad_norm': 1.5393153429031372, 'learning_rate': 8e-06, 'epoch': 1.27, 'step': 72, 'max_steps': 280}

 26%|██▌       | 72/280 [51:13<2:18:38, 39.99s/it]
 26%|██▌       | 73/280 [51:54<2:19:42, 40.49s/it]
                                                  
{'loss': 0.2332, 'grad_norm': 1.5297297239303589, 'learning_rate': 8e-06, 'epoch': 1.28, 'step': 73, 'max_steps': 280}

 26%|██▌       | 73/280 [51:54<2:19:42, 40.49s/it]
 26%|██▋       | 74/280 [52:34<2:17:55, 40.17s/it]
                                                  
{'loss': 0.2004, 'grad_norm': 1.7177025079727173, 'learning_rate': 8e-06, 'epoch': 1.3, 'step': 74, 'max_steps': 280}

 26%|██▋       | 74/280 [52:34<2:17:55, 40.17s/it]
 27%|██▋       | 75/280 [53:13<2:16:33, 39.97s/it]
                                                  
{'loss': 0.2205, 'grad_norm': 1.3875552415847778, 'learning_rate': 8e-06, 'epoch': 1.32, 'step': 75, 'max_steps': 280}

 27%|██▋       | 75/280 [53:13<2:16:33, 39.97s/it]
 27%|██▋       | 76/280 [53:53<2:15:27, 39.84s/it]
                                                  
{'loss': 0.2137, 'grad_norm': 1.3533921241760254, 'learning_rate': 8e-06, 'epoch': 1.34, 'step': 76, 'max_steps': 280}

 27%|██▋       | 76/280 [53:53<2:15:27, 39.84s/it]
 28%|██▊       | 77/280 [54:33<2:14:33, 39.77s/it]
                                                  
{'loss': 0.2372, 'grad_norm': 2.4732325077056885, 'learning_rate': 8e-06, 'epoch': 1.35, 'step': 77, 'max_steps': 280}

 28%|██▊       | 77/280 [54:33<2:14:33, 39.77s/it]
 28%|██▊       | 78/280 [55:12<2:13:52, 39.76s/it]
                                                  
{'loss': 0.2209, 'grad_norm': 1.5445079803466797, 'learning_rate': 8e-06, 'epoch': 1.37, 'step': 78, 'max_steps': 280}

 28%|██▊       | 78/280 [55:12<2:13:52, 39.76s/it]
 28%|██▊       | 79/280 [55:52<2:12:55, 39.68s/it]
                                                  
{'loss': 0.2333, 'grad_norm': 1.2722831964492798, 'learning_rate': 8e-06, 'epoch': 1.39, 'step': 79, 'max_steps': 280}

 28%|██▊       | 79/280 [55:52<2:12:55, 39.68s/it]
 29%|██▊       | 80/280 [56:31<2:12:17, 39.69s/it]
                                                  
{'loss': 0.2359, 'grad_norm': 1.7487056255340576, 'learning_rate': 8e-06, 'epoch': 1.41, 'step': 80, 'max_steps': 280}

 29%|██▊       | 80/280 [56:31<2:12:17, 39.69s/it]
 29%|██▉       | 81/280 [57:14<2:13:59, 40.40s/it]
                                                  
{'loss': 0.2235, 'grad_norm': 1.3655402660369873, 'learning_rate': 8e-06, 'epoch': 1.42, 'step': 81, 'max_steps': 280}

 29%|██▉       | 81/280 [57:14<2:13:59, 40.40s/it]
 29%|██▉       | 82/280 [57:53<2:12:44, 40.22s/it]
                                                  
{'loss': 0.2193, 'grad_norm': 1.8096649646759033, 'learning_rate': 8e-06, 'epoch': 1.44, 'step': 82, 'max_steps': 280}

 29%|██▉       | 82/280 [57:53<2:12:44, 40.22s/it]
 30%|██▉       | 83/280 [58:33<2:11:29, 40.05s/it]
                                                  
{'loss': 0.2116, 'grad_norm': 1.2922999858856201, 'learning_rate': 8e-06, 'epoch': 1.46, 'step': 83, 'max_steps': 280}

 30%|██▉       | 83/280 [58:33<2:11:29, 40.05s/it]
 30%|███       | 84/280 [59:13<2:10:43, 40.02s/it]
                                                  
{'loss': 0.2598, 'grad_norm': 1.6716439723968506, 'learning_rate': 8e-06, 'epoch': 1.48, 'step': 84, 'max_steps': 280}

 30%|███       | 84/280 [59:13<2:10:43, 40.02s/it]
 30%|███       | 85/280 [59:53<2:09:45, 39.92s/it]
                                                  
{'loss': 0.2295, 'grad_norm': 1.4459744691848755, 'learning_rate': 8e-06, 'epoch': 1.49, 'step': 85, 'max_steps': 280}

 30%|███       | 85/280 [59:53<2:09:45, 39.92s/it]
 31%|███       | 86/280 [1:00:34<2:10:27, 40.35s/it]
                                                    
{'loss': 0.2245, 'grad_norm': 1.6455198526382446, 'learning_rate': 8e-06, 'epoch': 1.51, 'step': 86, 'max_steps': 280}

 31%|███       | 86/280 [1:00:34<2:10:27, 40.35s/it]
 31%|███       | 87/280 [1:01:14<2:09:12, 40.17s/it]
                                                    
{'loss': 0.2262, 'grad_norm': 1.5139362812042236, 'learning_rate': 8e-06, 'epoch': 1.53, 'step': 87, 'max_steps': 280}

 31%|███       | 87/280 [1:01:14<2:09:12, 40.17s/it]
 31%|███▏      | 88/280 [1:01:54<2:08:35, 40.19s/it]
                                                    
{'loss': 0.2209, 'grad_norm': 1.53433358669281, 'learning_rate': 8e-06, 'epoch': 1.55, 'step': 88, 'max_steps': 280}

 31%|███▏      | 88/280 [1:01:54<2:08:35, 40.19s/it]
 32%|███▏      | 89/280 [1:02:36<2:09:45, 40.76s/it]
                                                    
{'loss': 0.2446, 'grad_norm': 1.9097026586532593, 'learning_rate': 8e-06, 'epoch': 1.56, 'step': 89, 'max_steps': 280}

 32%|███▏      | 89/280 [1:02:36<2:09:45, 40.76s/it]
 32%|███▏      | 90/280 [1:03:16<2:08:11, 40.48s/it]
                                                    
{'loss': 0.2312, 'grad_norm': 1.3440864086151123, 'learning_rate': 8e-06, 'epoch': 1.58, 'step': 90, 'max_steps': 280}

 32%|███▏      | 90/280 [1:03:16<2:08:11, 40.48s/it]
 32%|███▎      | 91/280 [1:03:55<2:06:40, 40.22s/it]
                                                    
{'loss': 0.196, 'grad_norm': 1.1774414777755737, 'learning_rate': 8e-06, 'epoch': 1.6, 'step': 91, 'max_steps': 280}

 32%|███▎      | 91/280 [1:03:55<2:06:40, 40.22s/it]
 33%|███▎      | 92/280 [1:04:35<2:05:29, 40.05s/it]
                                                    
{'loss': 0.2285, 'grad_norm': 1.5868785381317139, 'learning_rate': 8e-06, 'epoch': 1.62, 'step': 92, 'max_steps': 280}

 33%|███▎      | 92/280 [1:04:35<2:05:29, 40.05s/it]
 33%|███▎      | 93/280 [1:05:15<2:04:41, 40.01s/it]
                                                    
{'loss': 0.2196, 'grad_norm': 1.1812926530838013, 'learning_rate': 8e-06, 'epoch': 1.64, 'step': 93, 'max_steps': 280}

 33%|███▎      | 93/280 [1:05:15<2:04:41, 40.01s/it]
 34%|███▎      | 94/280 [1:05:55<2:03:41, 39.90s/it]
                                                    
{'loss': 0.2318, 'grad_norm': 1.4275705814361572, 'learning_rate': 8e-06, 'epoch': 1.65, 'step': 94, 'max_steps': 280}

 34%|███▎      | 94/280 [1:05:55<2:03:41, 39.90s/it]
 34%|███▍      | 95/280 [1:06:34<2:02:33, 39.75s/it]
                                                    
{'loss': 0.2464, 'grad_norm': 1.3743035793304443, 'learning_rate': 8e-06, 'epoch': 1.67, 'step': 95, 'max_steps': 280}

 34%|███▍      | 95/280 [1:06:34<2:02:33, 39.75s/it]
 34%|███▍      | 96/280 [1:07:14<2:01:44, 39.70s/it]
                                                    
{'loss': 0.2284, 'grad_norm': 1.5317190885543823, 'learning_rate': 8e-06, 'epoch': 1.69, 'step': 96, 'max_steps': 280}

 34%|███▍      | 96/280 [1:07:14<2:01:44, 39.70s/it]
 35%|███▍      | 97/280 [1:07:55<2:02:10, 40.06s/it]
                                                    
{'loss': 0.1996, 'grad_norm': 1.3052326440811157, 'learning_rate': 8e-06, 'epoch': 1.71, 'step': 97, 'max_steps': 280}

 35%|███▍      | 97/280 [1:07:55<2:02:10, 40.06s/it]
 35%|███▌      | 98/280 [1:08:35<2:01:31, 40.07s/it]
                                                    
{'loss': 0.2452, 'grad_norm': 1.5839154720306396, 'learning_rate': 8e-06, 'epoch': 1.72, 'step': 98, 'max_steps': 280}

 35%|███▌      | 98/280 [1:08:35<2:01:31, 40.07s/it]
 35%|███▌      | 99/280 [1:09:15<2:00:50, 40.06s/it]
                                                    
{'loss': 0.2117, 'grad_norm': 1.4547905921936035, 'learning_rate': 8e-06, 'epoch': 1.74, 'step': 99, 'max_steps': 280}

 35%|███▌      | 99/280 [1:09:15<2:00:50, 40.06s/it]
 36%|███▌      | 100/280 [1:09:54<1:59:40, 39.89s/it]
                                                     
{'loss': 0.2266, 'grad_norm': 1.5848071575164795, 'learning_rate': 8e-06, 'epoch': 1.76, 'step': 100, 'max_steps': 280}

 36%|███▌      | 100/280 [1:09:54<1:59:40, 39.89s/it]
 36%|███▌      | 101/280 [1:10:34<1:58:37, 39.76s/it]
                                                     
{'loss': 0.2115, 'grad_norm': 1.2673795223236084, 'learning_rate': 8e-06, 'epoch': 1.78, 'step': 101, 'max_steps': 280}

 36%|███▌      | 101/280 [1:10:34<1:58:37, 39.76s/it]
 36%|███▋      | 102/280 [1:11:14<1:58:22, 39.90s/it]
                                                     
{'loss': 0.2275, 'grad_norm': 1.3309965133666992, 'learning_rate': 8e-06, 'epoch': 1.79, 'step': 102, 'max_steps': 280}

 36%|███▋      | 102/280 [1:11:14<1:58:22, 39.90s/it]
 37%|███▋      | 103/280 [1:11:53<1:57:14, 39.74s/it]
                                                     
{'loss': 0.2119, 'grad_norm': 1.471133828163147, 'learning_rate': 8e-06, 'epoch': 1.81, 'step': 103, 'max_steps': 280}

 37%|███▋      | 103/280 [1:11:53<1:57:14, 39.74s/it]
 37%|███▋      | 104/280 [1:12:32<1:56:01, 39.55s/it]
                                                     
{'loss': 0.2276, 'grad_norm': 1.622365951538086, 'learning_rate': 8e-06, 'epoch': 1.83, 'step': 104, 'max_steps': 280}

 37%|███▋      | 104/280 [1:12:32<1:56:01, 39.55s/it]
 38%|███▊      | 105/280 [1:13:12<1:55:10, 39.49s/it]
                                                     
{'loss': 0.2263, 'grad_norm': 1.7223255634307861, 'learning_rate': 8e-06, 'epoch': 1.85, 'step': 105, 'max_steps': 280}

 38%|███▊      | 105/280 [1:13:12<1:55:10, 39.49s/it]
 38%|███▊      | 106/280 [1:13:51<1:54:24, 39.45s/it]
                                                     
{'loss': 0.2097, 'grad_norm': 1.3780819177627563, 'learning_rate': 8e-06, 'epoch': 1.86, 'step': 106, 'max_steps': 280}

 38%|███▊      | 106/280 [1:13:51<1:54:24, 39.45s/it]
 38%|███▊      | 107/280 [1:14:30<1:53:36, 39.40s/it]
                                                     
{'loss': 0.2343, 'grad_norm': 1.5672279596328735, 'learning_rate': 8e-06, 'epoch': 1.88, 'step': 107, 'max_steps': 280}

 38%|███▊      | 107/280 [1:14:30<1:53:36, 39.40s/it]
 39%|███▊      | 108/280 [1:15:10<1:53:03, 39.44s/it]
                                                     
{'loss': 0.2296, 'grad_norm': 1.2986761331558228, 'learning_rate': 8e-06, 'epoch': 1.9, 'step': 108, 'max_steps': 280}

 39%|███▊      | 108/280 [1:15:10<1:53:03, 39.44s/it]
 39%|███▉      | 109/280 [1:15:49<1:52:21, 39.42s/it]
                                                     
{'loss': 0.2435, 'grad_norm': 2.0064685344696045, 'learning_rate': 8e-06, 'epoch': 1.92, 'step': 109, 'max_steps': 280}

 39%|███▉      | 109/280 [1:15:49<1:52:21, 39.42s/it]
 39%|███▉      | 110/280 [1:16:29<1:52:07, 39.58s/it]
                                                     
{'loss': 0.2316, 'grad_norm': 1.379011631011963, 'learning_rate': 8e-06, 'epoch': 1.93, 'step': 110, 'max_steps': 280}

 39%|███▉      | 110/280 [1:16:29<1:52:07, 39.58s/it]
 40%|███▉      | 111/280 [1:17:09<1:51:25, 39.56s/it]
                                                     
{'loss': 0.2042, 'grad_norm': 1.1722800731658936, 'learning_rate': 8e-06, 'epoch': 1.95, 'step': 111, 'max_steps': 280}

 40%|███▉      | 111/280 [1:17:09<1:51:25, 39.56s/it]
 40%|████      | 112/280 [1:17:48<1:50:34, 39.49s/it]
                                                     
{'loss': 0.2024, 'grad_norm': 1.308740496635437, 'learning_rate': 8e-06, 'epoch': 1.97, 'step': 112, 'max_steps': 280}

 40%|████      | 112/280 [1:17:48<1:50:34, 39.49s/it]
 40%|████      | 113/280 [1:18:28<1:49:59, 39.52s/it]
                                                     
{'loss': 0.2334, 'grad_norm': 1.4327691793441772, 'learning_rate': 8e-06, 'epoch': 1.99, 'step': 113, 'max_steps': 280}

 40%|████      | 113/280 [1:18:28<1:49:59, 39.52s/it]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(

 41%|████      | 114/280 [1:23:19<5:17:57, 114.92s/it]
                                                      
{'loss': 0.2111, 'grad_norm': 1.4328608512878418, 'learning_rate': 8e-06, 'epoch': 2.0, 'step': 114, 'max_steps': 280}

 41%|████      | 114/280 [1:23:19<5:17:57, 114.92s/it]
 41%|████      | 115/280 [1:23:58<4:13:41, 92.25s/it] 
                                                     
{'loss': 0.1661, 'grad_norm': 1.1289515495300293, 'learning_rate': 8e-06, 'epoch': 2.02, 'step': 115, 'max_steps': 280}

 41%|████      | 115/280 [1:23:58<4:13:41, 92.25s/it]
 41%|████▏     | 116/280 [1:24:37<3:28:45, 76.37s/it]
                                                     
{'loss': 0.149, 'grad_norm': 0.9990601539611816, 'learning_rate': 8e-06, 'epoch': 2.04, 'step': 116, 'max_steps': 280}

 41%|████▏     | 116/280 [1:24:37<3:28:45, 76.37s/it]
 42%|████▏     | 117/280 [1:25:17<2:57:44, 65.43s/it]
                                                     
{'loss': 0.1533, 'grad_norm': 1.1264289617538452, 'learning_rate': 8e-06, 'epoch': 2.06, 'step': 117, 'max_steps': 280}

 42%|████▏     | 117/280 [1:25:17<2:57:44, 65.43s/it]
 42%|████▏     | 118/280 [1:25:57<2:35:40, 57.66s/it]
                                                     
{'loss': 0.1562, 'grad_norm': 1.079787015914917, 'learning_rate': 8e-06, 'epoch': 2.07, 'step': 118, 'max_steps': 280}

 42%|████▏     | 118/280 [1:25:57<2:35:40, 57.66s/it]
 42%|████▎     | 119/280 [1:26:38<2:21:28, 52.72s/it]
                                                     
{'loss': 0.1381, 'grad_norm': 1.2053767442703247, 'learning_rate': 8e-06, 'epoch': 2.09, 'step': 119, 'max_steps': 280}

 42%|████▎     | 119/280 [1:26:38<2:21:28, 52.72s/it]
 43%|████▎     | 120/280 [1:27:17<2:09:55, 48.72s/it]
                                                     
{'loss': 0.1434, 'grad_norm': 1.1553703546524048, 'learning_rate': 8e-06, 'epoch': 2.11, 'step': 120, 'max_steps': 280}

 43%|████▎     | 120/280 [1:27:17<2:09:55, 48.72s/it]
 43%|████▎     | 121/280 [1:27:57<2:01:44, 45.94s/it]
                                                     
{'loss': 0.1463, 'grad_norm': 1.230086088180542, 'learning_rate': 8e-06, 'epoch': 2.13, 'step': 121, 'max_steps': 280}

 43%|████▎     | 121/280 [1:27:57<2:01:44, 45.94s/it]
 44%|████▎     | 122/280 [1:28:38<1:57:25, 44.59s/it]
                                                     
{'loss': 0.1475, 'grad_norm': 1.3725402355194092, 'learning_rate': 8e-06, 'epoch': 2.15, 'step': 122, 'max_steps': 280}

 44%|████▎     | 122/280 [1:28:38<1:57:25, 44.59s/it]
 44%|████▍     | 123/280 [1:29:17<1:52:35, 43.03s/it]
                                                     
{'loss': 0.1285, 'grad_norm': 1.8570164442062378, 'learning_rate': 8e-06, 'epoch': 2.16, 'step': 123, 'max_steps': 280}

 44%|████▍     | 123/280 [1:29:17<1:52:35, 43.03s/it]
 44%|████▍     | 124/280 [1:29:57<1:48:49, 41.86s/it]
                                                     
{'loss': 0.153, 'grad_norm': 1.4555065631866455, 'learning_rate': 8e-06, 'epoch': 2.18, 'step': 124, 'max_steps': 280}

 44%|████▍     | 124/280 [1:29:57<1:48:49, 41.86s/it]
 45%|████▍     | 125/280 [1:30:36<1:46:18, 41.15s/it]
                                                     
{'loss': 0.1434, 'grad_norm': 1.1855268478393555, 'learning_rate': 8e-06, 'epoch': 2.2, 'step': 125, 'max_steps': 280}

 45%|████▍     | 125/280 [1:30:36<1:46:18, 41.15s/it]
 45%|████▌     | 126/280 [1:31:16<1:44:17, 40.63s/it]
                                                     
{'loss': 0.1623, 'grad_norm': 1.3687571287155151, 'learning_rate': 8e-06, 'epoch': 2.22, 'step': 126, 'max_steps': 280}

 45%|████▌     | 126/280 [1:31:16<1:44:17, 40.63s/it]
 45%|████▌     | 127/280 [1:31:56<1:43:21, 40.53s/it]
                                                     
{'loss': 0.1544, 'grad_norm': 1.2490136623382568, 'learning_rate': 8e-06, 'epoch': 2.23, 'step': 127, 'max_steps': 280}

 45%|████▌     | 127/280 [1:31:56<1:43:21, 40.53s/it]
 46%|████▌     | 128/280 [1:32:36<1:42:06, 40.30s/it]
                                                     
{'loss': 0.16, 'grad_norm': 1.5462948083877563, 'learning_rate': 8e-06, 'epoch': 2.25, 'step': 128, 'max_steps': 280}

 46%|████▌     | 128/280 [1:32:36<1:42:06, 40.30s/it]
 46%|████▌     | 129/280 [1:33:15<1:40:35, 39.97s/it]
                                                     
{'loss': 0.154, 'grad_norm': 1.3517839908599854, 'learning_rate': 8e-06, 'epoch': 2.27, 'step': 129, 'max_steps': 280}

 46%|████▌     | 129/280 [1:33:15<1:40:35, 39.97s/it]
 46%|████▋     | 130/280 [1:33:56<1:40:58, 40.39s/it]
                                                     
{'loss': 0.1517, 'grad_norm': 1.2650641202926636, 'learning_rate': 8e-06, 'epoch': 2.29, 'step': 130, 'max_steps': 280}

 46%|████▋     | 130/280 [1:33:56<1:40:58, 40.39s/it]
 47%|████▋     | 131/280 [1:34:35<1:39:21, 40.01s/it]
                                                     
{'loss': 0.1472, 'grad_norm': 1.1829771995544434, 'learning_rate': 8e-06, 'epoch': 2.3, 'step': 131, 'max_steps': 280}

 47%|████▋     | 131/280 [1:34:35<1:39:21, 40.01s/it]
 47%|████▋     | 132/280 [1:35:15<1:38:19, 39.86s/it]
                                                     
{'loss': 0.1406, 'grad_norm': 1.1882054805755615, 'learning_rate': 8e-06, 'epoch': 2.32, 'step': 132, 'max_steps': 280}

 47%|████▋     | 132/280 [1:35:15<1:38:19, 39.86s/it]
 48%|████▊     | 133/280 [1:35:54<1:37:10, 39.66s/it]
                                                     
{'loss': 0.151, 'grad_norm': 1.1824405193328857, 'learning_rate': 8e-06, 'epoch': 2.34, 'step': 133, 'max_steps': 280}

 48%|████▊     | 133/280 [1:35:54<1:37:10, 39.66s/it]
 48%|████▊     | 134/280 [1:36:33<1:36:08, 39.51s/it]
                                                     
{'loss': 0.152, 'grad_norm': 1.242319107055664, 'learning_rate': 8e-06, 'epoch': 2.36, 'step': 134, 'max_steps': 280}

 48%|████▊     | 134/280 [1:36:33<1:36:08, 39.51s/it]
 48%|████▊     | 135/280 [1:37:14<1:36:37, 39.98s/it]
                                                     
{'loss': 0.1654, 'grad_norm': 1.515005350112915, 'learning_rate': 8e-06, 'epoch': 2.37, 'step': 135, 'max_steps': 280}

 48%|████▊     | 135/280 [1:37:14<1:36:37, 39.98s/it]
 49%|████▊     | 136/280 [1:37:54<1:35:38, 39.85s/it]
                                                     
{'loss': 0.1548, 'grad_norm': 1.4393293857574463, 'learning_rate': 8e-06, 'epoch': 2.39, 'step': 136, 'max_steps': 280}

 49%|████▊     | 136/280 [1:37:54<1:35:38, 39.85s/it]
 49%|████▉     | 137/280 [1:38:33<1:34:37, 39.70s/it]
                                                     
{'loss': 0.1763, 'grad_norm': 1.3643659353256226, 'learning_rate': 8e-06, 'epoch': 2.41, 'step': 137, 'max_steps': 280}

 49%|████▉     | 137/280 [1:38:33<1:34:37, 39.70s/it]
 49%|████▉     | 138/280 [1:39:13<1:33:51, 39.66s/it]
                                                     
{'loss': 0.1497, 'grad_norm': 1.111523151397705, 'learning_rate': 8e-06, 'epoch': 2.43, 'step': 138, 'max_steps': 280}

 49%|████▉     | 138/280 [1:39:13<1:33:51, 39.66s/it]
 50%|████▉     | 139/280 [1:39:52<1:33:00, 39.57s/it]
                                                     
{'loss': 0.153, 'grad_norm': 1.0472368001937866, 'learning_rate': 8e-06, 'epoch': 2.44, 'step': 139, 'max_steps': 280}

 50%|████▉     | 139/280 [1:39:52<1:33:00, 39.57s/it]
 50%|█████     | 140/280 [1:40:32<1:32:16, 39.55s/it]
                                                     
{'loss': 0.1446, 'grad_norm': 1.1219958066940308, 'learning_rate': 8e-06, 'epoch': 2.46, 'step': 140, 'max_steps': 280}

 50%|█████     | 140/280 [1:40:32<1:32:16, 39.55s/it]
 50%|█████     | 141/280 [1:41:11<1:31:30, 39.50s/it]
                                                     
{'loss': 0.1623, 'grad_norm': 1.3552709817886353, 'learning_rate': 8e-06, 'epoch': 2.48, 'step': 141, 'max_steps': 280}

 50%|█████     | 141/280 [1:41:11<1:31:30, 39.50s/it]
 51%|█████     | 142/280 [1:41:50<1:30:37, 39.40s/it]
                                                     
{'loss': 0.1496, 'grad_norm': 1.1440891027450562, 'learning_rate': 8e-06, 'epoch': 2.5, 'step': 142, 'max_steps': 280}

 51%|█████     | 142/280 [1:41:50<1:30:37, 39.40s/it]
 51%|█████     | 143/280 [1:42:30<1:30:01, 39.42s/it]
                                                     
{'loss': 0.1444, 'grad_norm': 1.3069301843643188, 'learning_rate': 8e-06, 'epoch': 2.51, 'step': 143, 'max_steps': 280}

 51%|█████     | 143/280 [1:42:30<1:30:01, 39.42s/it]
 51%|█████▏    | 144/280 [1:43:09<1:29:21, 39.42s/it]
                                                     
{'loss': 0.1531, 'grad_norm': 1.5112937688827515, 'learning_rate': 8e-06, 'epoch': 2.53, 'step': 144, 'max_steps': 280}

 51%|█████▏    | 144/280 [1:43:09<1:29:21, 39.42s/it]
 52%|█████▏    | 145/280 [1:43:49<1:28:59, 39.55s/it]
                                                     
{'loss': 0.148, 'grad_norm': 1.1968858242034912, 'learning_rate': 8e-06, 'epoch': 2.55, 'step': 145, 'max_steps': 280}

 52%|█████▏    | 145/280 [1:43:49<1:28:59, 39.55s/it]
 52%|█████▏    | 146/280 [1:44:30<1:29:37, 40.13s/it]
                                                     
{'loss': 0.1434, 'grad_norm': 1.3330155611038208, 'learning_rate': 8e-06, 'epoch': 2.57, 'step': 146, 'max_steps': 280}

 52%|█████▏    | 146/280 [1:44:30<1:29:37, 40.13s/it]
 52%|█████▎    | 147/280 [1:45:09<1:28:13, 39.80s/it]
                                                     
{'loss': 0.162, 'grad_norm': 1.5313777923583984, 'learning_rate': 8e-06, 'epoch': 2.58, 'step': 147, 'max_steps': 280}

 52%|█████▎    | 147/280 [1:45:09<1:28:13, 39.80s/it]
 53%|█████▎    | 148/280 [1:45:49<1:27:17, 39.68s/it]
                                                     
{'loss': 0.155, 'grad_norm': 1.4109094142913818, 'learning_rate': 8e-06, 'epoch': 2.6, 'step': 148, 'max_steps': 280}

 53%|█████▎    | 148/280 [1:45:49<1:27:17, 39.68s/it]
 53%|█████▎    | 149/280 [1:46:29<1:26:44, 39.73s/it]
                                                     
{'loss': 0.1698, 'grad_norm': 1.4670506715774536, 'learning_rate': 8e-06, 'epoch': 2.62, 'step': 149, 'max_steps': 280}

 53%|█████▎    | 149/280 [1:46:29<1:26:44, 39.73s/it]
 54%|█████▎    | 150/280 [1:47:08<1:25:53, 39.64s/it]
                                                     
{'loss': 0.1478, 'grad_norm': 1.1748919486999512, 'learning_rate': 8e-06, 'epoch': 2.64, 'step': 150, 'max_steps': 280}

 54%|█████▎    | 150/280 [1:47:08<1:25:53, 39.64s/it]
 54%|█████▍    | 151/280 [1:47:48<1:25:36, 39.82s/it]
                                                     
{'loss': 0.1421, 'grad_norm': 1.1810609102249146, 'learning_rate': 8e-06, 'epoch': 2.65, 'step': 151, 'max_steps': 280}

 54%|█████▍    | 151/280 [1:47:48<1:25:36, 39.82s/it]
 54%|█████▍    | 152/280 [1:48:28<1:24:39, 39.69s/it]
                                                     
{'loss': 0.1715, 'grad_norm': 1.2263908386230469, 'learning_rate': 8e-06, 'epoch': 2.67, 'step': 152, 'max_steps': 280}

 54%|█████▍    | 152/280 [1:48:28<1:24:39, 39.69s/it]
 55%|█████▍    | 153/280 [1:49:07<1:23:56, 39.66s/it]
                                                     
{'loss': 0.1504, 'grad_norm': 1.0988785028457642, 'learning_rate': 8e-06, 'epoch': 2.69, 'step': 153, 'max_steps': 280}

 55%|█████▍    | 153/280 [1:49:07<1:23:56, 39.66s/it]
 55%|█████▌    | 154/280 [1:49:49<1:24:35, 40.28s/it]
                                                     
{'loss': 0.16, 'grad_norm': 1.300096035003662, 'learning_rate': 8e-06, 'epoch': 2.71, 'step': 154, 'max_steps': 280}

 55%|█████▌    | 154/280 [1:49:49<1:24:35, 40.28s/it]
 55%|█████▌    | 155/280 [1:50:29<1:23:28, 40.06s/it]
                                                     
{'loss': 0.1534, 'grad_norm': 1.2016950845718384, 'learning_rate': 8e-06, 'epoch': 2.73, 'step': 155, 'max_steps': 280}

 55%|█████▌    | 155/280 [1:50:29<1:23:28, 40.06s/it]
 56%|█████▌    | 156/280 [1:51:08<1:22:30, 39.93s/it]
                                                     
{'loss': 0.1737, 'grad_norm': 1.4622770547866821, 'learning_rate': 8e-06, 'epoch': 2.74, 'step': 156, 'max_steps': 280}

 56%|█████▌    | 156/280 [1:51:08<1:22:30, 39.93s/it]
 56%|█████▌    | 157/280 [1:51:48<1:21:34, 39.79s/it]
                                                     
{'loss': 0.1652, 'grad_norm': 1.3075355291366577, 'learning_rate': 8e-06, 'epoch': 2.76, 'step': 157, 'max_steps': 280}

 56%|█████▌    | 157/280 [1:51:48<1:21:34, 39.79s/it]
 56%|█████▋    | 158/280 [1:52:27<1:20:47, 39.73s/it]
                                                     
{'loss': 0.1494, 'grad_norm': 1.2460581064224243, 'learning_rate': 8e-06, 'epoch': 2.78, 'step': 158, 'max_steps': 280}

 56%|█████▋    | 158/280 [1:52:27<1:20:47, 39.73s/it]
 57%|█████▋    | 159/280 [1:53:07<1:20:12, 39.77s/it]
                                                     
{'loss': 0.167, 'grad_norm': 2.410064220428467, 'learning_rate': 8e-06, 'epoch': 2.8, 'step': 159, 'max_steps': 280}

 57%|█████▋    | 159/280 [1:53:07<1:20:12, 39.77s/it]
 57%|█████▋    | 160/280 [1:53:46<1:19:18, 39.66s/it]
                                                     
{'loss': 0.1707, 'grad_norm': 1.4148725271224976, 'learning_rate': 8e-06, 'epoch': 2.81, 'step': 160, 'max_steps': 280}

 57%|█████▋    | 160/280 [1:53:46<1:19:18, 39.66s/it]
 57%|█████▊    | 161/280 [1:54:26<1:18:26, 39.55s/it]
                                                     
{'loss': 0.1675, 'grad_norm': 1.5287601947784424, 'learning_rate': 8e-06, 'epoch': 2.83, 'step': 161, 'max_steps': 280}

 57%|█████▊    | 161/280 [1:54:26<1:18:26, 39.55s/it]
 58%|█████▊    | 162/280 [1:55:05<1:17:50, 39.58s/it]
                                                     
{'loss': 0.1512, 'grad_norm': 1.1591367721557617, 'learning_rate': 8e-06, 'epoch': 2.85, 'step': 162, 'max_steps': 280}

 58%|█████▊    | 162/280 [1:55:05<1:17:50, 39.58s/it]
 58%|█████▊    | 163/280 [1:55:45<1:17:04, 39.53s/it]
                                                     
{'loss': 0.1529, 'grad_norm': 1.368312120437622, 'learning_rate': 8e-06, 'epoch': 2.87, 'step': 163, 'max_steps': 280}

 58%|█████▊    | 163/280 [1:55:45<1:17:04, 39.53s/it]
 59%|█████▊    | 164/280 [1:56:24<1:16:24, 39.52s/it]
                                                     
{'loss': 0.1452, 'grad_norm': 1.0950618982315063, 'learning_rate': 8e-06, 'epoch': 2.88, 'step': 164, 'max_steps': 280}

 59%|█████▊    | 164/280 [1:56:24<1:16:24, 39.52s/it]
 59%|█████▉    | 165/280 [1:57:04<1:15:33, 39.43s/it]
                                                     
{'loss': 0.152, 'grad_norm': 1.2724915742874146, 'learning_rate': 8e-06, 'epoch': 2.9, 'step': 165, 'max_steps': 280}

 59%|█████▉    | 165/280 [1:57:04<1:15:33, 39.43s/it]
 59%|█████▉    | 166/280 [1:57:43<1:14:48, 39.37s/it]
                                                     
{'loss': 0.1705, 'grad_norm': 1.3620294332504272, 'learning_rate': 8e-06, 'epoch': 2.92, 'step': 166, 'max_steps': 280}

 59%|█████▉    | 166/280 [1:57:43<1:14:48, 39.37s/it]
 60%|█████▉    | 167/280 [1:58:23<1:14:40, 39.65s/it]
                                                     
{'loss': 0.1259, 'grad_norm': 1.1324623823165894, 'learning_rate': 8e-06, 'epoch': 2.94, 'step': 167, 'max_steps': 280}

 60%|█████▉    | 167/280 [1:58:23<1:14:40, 39.65s/it]
 60%|██████    | 168/280 [1:59:03<1:13:52, 39.58s/it]
                                                     
{'loss': 0.1538, 'grad_norm': 1.2900766134262085, 'learning_rate': 8e-06, 'epoch': 2.95, 'step': 168, 'max_steps': 280}

 60%|██████    | 168/280 [1:59:03<1:13:52, 39.58s/it]
 60%|██████    | 169/280 [1:59:42<1:13:09, 39.54s/it]
                                                     
{'loss': 0.1367, 'grad_norm': 1.1649513244628906, 'learning_rate': 8e-06, 'epoch': 2.97, 'step': 169, 'max_steps': 280}

 60%|██████    | 169/280 [1:59:42<1:13:09, 39.54s/it]
 61%|██████    | 170/280 [2:00:22<1:12:35, 39.60s/it]
                                                     
{'loss': 0.1521, 'grad_norm': 1.1596652269363403, 'learning_rate': 8e-06, 'epoch': 2.99, 'step': 170, 'max_steps': 280}

 61%|██████    | 170/280 [2:00:22<1:12:35, 39.60s/it]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(

 61%|██████    | 171/280 [2:05:19<3:32:25, 116.93s/it]
                                                      
{'loss': 0.1391, 'grad_norm': 1.4384102821350098, 'learning_rate': 8e-06, 'epoch': 3.01, 'step': 171, 'max_steps': 280}

 61%|██████    | 171/280 [2:05:19<3:32:25, 116.93s/it]
 61%|██████▏   | 172/280 [2:05:59<2:48:37, 93.68s/it] 
                                                     
{'loss': 0.1009, 'grad_norm': 1.0573548078536987, 'learning_rate': 8e-06, 'epoch': 3.02, 'step': 172, 'max_steps': 280}

 61%|██████▏   | 172/280 [2:05:59<2:48:37, 93.68s/it]
 62%|██████▏   | 173/280 [2:06:38<2:18:04, 77.43s/it]
                                                     
{'loss': 0.0919, 'grad_norm': 1.0616710186004639, 'learning_rate': 8e-06, 'epoch': 3.04, 'step': 173, 'max_steps': 280}

 62%|██████▏   | 173/280 [2:06:38<2:18:04, 77.43s/it]
 62%|██████▏   | 174/280 [2:07:18<1:56:55, 66.19s/it]
                                                     
{'loss': 0.0937, 'grad_norm': 1.016875147819519, 'learning_rate': 8e-06, 'epoch': 3.06, 'step': 174, 'max_steps': 280}

 62%|██████▏   | 174/280 [2:07:18<1:56:55, 66.19s/it]
 62%|██████▎   | 175/280 [2:07:58<1:41:55, 58.24s/it]
                                                     
{'loss': 0.0909, 'grad_norm': 1.0272473096847534, 'learning_rate': 8e-06, 'epoch': 3.08, 'step': 175, 'max_steps': 280}

 62%|██████▎   | 175/280 [2:07:58<1:41:55, 58.24s/it]
 63%|██████▎   | 176/280 [2:08:37<1:31:13, 52.63s/it]
                                                     
{'loss': 0.0869, 'grad_norm': 1.201371192932129, 'learning_rate': 8e-06, 'epoch': 3.09, 'step': 176, 'max_steps': 280}

 63%|██████▎   | 176/280 [2:08:37<1:31:13, 52.63s/it]
 63%|██████▎   | 177/280 [2:09:17<1:23:42, 48.76s/it]
                                                     
{'loss': 0.0935, 'grad_norm': 1.170560359954834, 'learning_rate': 8e-06, 'epoch': 3.11, 'step': 177, 'max_steps': 280}

 63%|██████▎   | 177/280 [2:09:17<1:23:42, 48.76s/it]
 64%|██████▎   | 178/280 [2:09:56<1:18:10, 45.98s/it]
                                                     
{'loss': 0.0989, 'grad_norm': 1.378710150718689, 'learning_rate': 8e-06, 'epoch': 3.13, 'step': 178, 'max_steps': 280}

 64%|██████▎   | 178/280 [2:09:56<1:18:10, 45.98s/it]
 64%|██████▍   | 179/280 [2:10:37<1:14:41, 44.37s/it]
                                                     
{'loss': 0.0886, 'grad_norm': 1.2550673484802246, 'learning_rate': 8e-06, 'epoch': 3.15, 'step': 179, 'max_steps': 280}

 64%|██████▍   | 179/280 [2:10:37<1:14:41, 44.37s/it]
 64%|██████▍   | 180/280 [2:11:16<1:11:23, 42.84s/it]
                                                     
{'loss': 0.0999, 'grad_norm': 1.5166993141174316, 'learning_rate': 8e-06, 'epoch': 3.16, 'step': 180, 'max_steps': 280}

 64%|██████▍   | 180/280 [2:11:16<1:11:23, 42.84s/it]
 65%|██████▍   | 181/280 [2:11:55<1:08:52, 41.74s/it]
                                                     
{'loss': 0.0974, 'grad_norm': 1.3036404848098755, 'learning_rate': 8e-06, 'epoch': 3.18, 'step': 181, 'max_steps': 280}

 65%|██████▍   | 181/280 [2:11:55<1:08:52, 41.74s/it]
 65%|██████▌   | 182/280 [2:12:35<1:07:04, 41.06s/it]
                                                     
{'loss': 0.0885, 'grad_norm': 1.2194950580596924, 'learning_rate': 8e-06, 'epoch': 3.2, 'step': 182, 'max_steps': 280}

 65%|██████▌   | 182/280 [2:12:35<1:07:04, 41.06s/it]
 65%|██████▌   | 183/280 [2:13:14<1:05:32, 40.54s/it]
                                                     
{'loss': 0.0977, 'grad_norm': 1.1178550720214844, 'learning_rate': 8e-06, 'epoch': 3.22, 'step': 183, 'max_steps': 280}

 65%|██████▌   | 183/280 [2:13:14<1:05:32, 40.54s/it]
 66%|██████▌   | 184/280 [2:13:54<1:04:33, 40.35s/it]
                                                     
{'loss': 0.1008, 'grad_norm': 1.1630901098251343, 'learning_rate': 8e-06, 'epoch': 3.24, 'step': 184, 'max_steps': 280}

 66%|██████▌   | 184/280 [2:13:54<1:04:33, 40.35s/it]
 66%|██████▌   | 185/280 [2:14:33<1:03:19, 40.00s/it]
                                                     
{'loss': 0.1088, 'grad_norm': 1.2877823114395142, 'learning_rate': 8e-06, 'epoch': 3.25, 'step': 185, 'max_steps': 280}

 66%|██████▌   | 185/280 [2:14:33<1:03:19, 40.00s/it]
 66%|██████▋   | 186/280 [2:15:12<1:02:14, 39.72s/it]
                                                     
{'loss': 0.1083, 'grad_norm': 1.1809338331222534, 'learning_rate': 8e-06, 'epoch': 3.27, 'step': 186, 'max_steps': 280}

 66%|██████▋   | 186/280 [2:15:12<1:02:14, 39.72s/it]
 67%|██████▋   | 187/280 [2:15:52<1:01:31, 39.69s/it]
                                                     
{'loss': 0.11, 'grad_norm': 1.5394132137298584, 'learning_rate': 8e-06, 'epoch': 3.29, 'step': 187, 'max_steps': 280}

 67%|██████▋   | 187/280 [2:15:52<1:01:31, 39.69s/it]
 67%|██████▋   | 188/280 [2:16:32<1:00:45, 39.63s/it]
                                                     
{'loss': 0.0911, 'grad_norm': 1.0346177816390991, 'learning_rate': 8e-06, 'epoch': 3.31, 'step': 188, 'max_steps': 280}

 67%|██████▋   | 188/280 [2:16:32<1:00:45, 39.63s/it]
 68%|██████▊   | 189/280 [2:17:11<59:52, 39.48s/it]  
                                                   
{'loss': 0.1081, 'grad_norm': 2.4879000186920166, 'learning_rate': 8e-06, 'epoch': 3.32, 'step': 189, 'max_steps': 280}

 68%|██████▊   | 189/280 [2:17:11<59:52, 39.48s/it]
 68%|██████▊   | 190/280 [2:17:50<59:10, 39.45s/it]
                                                   
{'loss': 0.0982, 'grad_norm': 1.1683229207992554, 'learning_rate': 8e-06, 'epoch': 3.34, 'step': 190, 'max_steps': 280}

 68%|██████▊   | 190/280 [2:17:50<59:10, 39.45s/it]
 68%|██████▊   | 191/280 [2:18:29<58:27, 39.41s/it]
                                                   
{'loss': 0.1003, 'grad_norm': 1.2367407083511353, 'learning_rate': 8e-06, 'epoch': 3.36, 'step': 191, 'max_steps': 280}

 68%|██████▊   | 191/280 [2:18:29<58:27, 39.41s/it]
 69%|██████▊   | 192/280 [2:19:10<58:08, 39.65s/it]
                                                   
{'loss': 0.0936, 'grad_norm': 1.1229225397109985, 'learning_rate': 8e-06, 'epoch': 3.38, 'step': 192, 'max_steps': 280}

 69%|██████▊   | 192/280 [2:19:10<58:08, 39.65s/it]
 69%|██████▉   | 193/280 [2:19:49<57:25, 39.61s/it]
                                                   
{'loss': 0.0932, 'grad_norm': 1.1306281089782715, 'learning_rate': 8e-06, 'epoch': 3.39, 'step': 193, 'max_steps': 280}

 69%|██████▉   | 193/280 [2:19:49<57:25, 39.61s/it]
 69%|██████▉   | 194/280 [2:20:29<56:43, 39.58s/it]
                                                   
{'loss': 0.0996, 'grad_norm': 1.4624179601669312, 'learning_rate': 8e-06, 'epoch': 3.41, 'step': 194, 'max_steps': 280}

 69%|██████▉   | 194/280 [2:20:29<56:43, 39.58s/it]
 70%|██████▉   | 195/280 [2:21:08<56:03, 39.57s/it]
                                                   
{'loss': 0.0895, 'grad_norm': 1.0260556936264038, 'learning_rate': 8e-06, 'epoch': 3.43, 'step': 195, 'max_steps': 280}

 70%|██████▉   | 195/280 [2:21:08<56:03, 39.57s/it]
 70%|███████   | 196/280 [2:21:47<55:16, 39.48s/it]
                                                   
{'loss': 0.0932, 'grad_norm': 1.240631341934204, 'learning_rate': 8e-06, 'epoch': 3.45, 'step': 196, 'max_steps': 280}

 70%|███████   | 196/280 [2:21:47<55:16, 39.48s/it]
 70%|███████   | 197/280 [2:22:27<54:35, 39.46s/it]
                                                   
{'loss': 0.0782, 'grad_norm': 0.9600278735160828, 'learning_rate': 8e-06, 'epoch': 3.46, 'step': 197, 'max_steps': 280}

 70%|███████   | 197/280 [2:22:27<54:35, 39.46s/it]
 71%|███████   | 198/280 [2:23:06<53:57, 39.48s/it]
                                                   
{'loss': 0.0853, 'grad_norm': 1.079609990119934, 'learning_rate': 8e-06, 'epoch': 3.48, 'step': 198, 'max_steps': 280}

 71%|███████   | 198/280 [2:23:06<53:57, 39.48s/it]
 71%|███████   | 199/280 [2:23:46<53:11, 39.40s/it]
                                                   
{'loss': 0.0935, 'grad_norm': 1.151700735092163, 'learning_rate': 8e-06, 'epoch': 3.5, 'step': 199, 'max_steps': 280}

 71%|███████   | 199/280 [2:23:46<53:11, 39.40s/it]
 71%|███████▏  | 200/280 [2:24:25<52:27, 39.34s/it]
                                                   
{'loss': 0.1125, 'grad_norm': 2.027142286300659, 'learning_rate': 8e-06, 'epoch': 3.52, 'step': 200, 'max_steps': 280}

 71%|███████▏  | 200/280 [2:24:25<52:27, 39.34s/it]
 72%|███████▏  | 201/280 [2:25:04<51:53, 39.41s/it]
                                                   
{'loss': 0.0977, 'grad_norm': 1.16148042678833, 'learning_rate': 8e-06, 'epoch': 3.53, 'step': 201, 'max_steps': 280}

 72%|███████▏  | 201/280 [2:25:04<51:53, 39.41s/it]
 72%|███████▏  | 202/280 [2:25:44<51:16, 39.45s/it]
                                                   
{'loss': 0.1026, 'grad_norm': 1.1837403774261475, 'learning_rate': 8e-06, 'epoch': 3.55, 'step': 202, 'max_steps': 280}

 72%|███████▏  | 202/280 [2:25:44<51:16, 39.45s/it]
 72%|███████▎  | 203/280 [2:26:23<50:38, 39.46s/it]
                                                   
{'loss': 0.1096, 'grad_norm': 1.3666375875473022, 'learning_rate': 8e-06, 'epoch': 3.57, 'step': 203, 'max_steps': 280}

 72%|███████▎  | 203/280 [2:26:23<50:38, 39.46s/it]
 73%|███████▎  | 204/280 [2:27:03<49:59, 39.46s/it]
                                                   
{'loss': 0.0945, 'grad_norm': 1.2254847288131714, 'learning_rate': 8e-06, 'epoch': 3.59, 'step': 204, 'max_steps': 280}

 73%|███████▎  | 204/280 [2:27:03<49:59, 39.46s/it]
 73%|███████▎  | 205/280 [2:27:42<49:22, 39.50s/it]
                                                   
{'loss': 0.0998, 'grad_norm': 1.1349598169326782, 'learning_rate': 8e-06, 'epoch': 3.6, 'step': 205, 'max_steps': 280}

 73%|███████▎  | 205/280 [2:27:42<49:22, 39.50s/it]
 74%|███████▎  | 206/280 [2:28:22<48:39, 39.46s/it]
                                                   
{'loss': 0.0973, 'grad_norm': 1.1459001302719116, 'learning_rate': 8e-06, 'epoch': 3.62, 'step': 206, 'max_steps': 280}

 74%|███████▎  | 206/280 [2:28:22<48:39, 39.46s/it]
 74%|███████▍  | 207/280 [2:29:01<48:01, 39.47s/it]
                                                   
{'loss': 0.0973, 'grad_norm': 1.1210548877716064, 'learning_rate': 8e-06, 'epoch': 3.64, 'step': 207, 'max_steps': 280}

 74%|███████▍  | 207/280 [2:29:01<48:01, 39.47s/it]
 74%|███████▍  | 208/280 [2:29:42<47:38, 39.70s/it]
                                                   
{'loss': 0.1047, 'grad_norm': 1.1876355409622192, 'learning_rate': 8e-06, 'epoch': 3.66, 'step': 208, 'max_steps': 280}

 74%|███████▍  | 208/280 [2:29:42<47:38, 39.70s/it]
 75%|███████▍  | 209/280 [2:30:21<47:01, 39.74s/it]
                                                   
{'loss': 0.112, 'grad_norm': 1.20466947555542, 'learning_rate': 8e-06, 'epoch': 3.67, 'step': 209, 'max_steps': 280}

 75%|███████▍  | 209/280 [2:30:21<47:01, 39.74s/it]
 75%|███████▌  | 210/280 [2:31:01<46:14, 39.64s/it]
                                                   
{'loss': 0.1117, 'grad_norm': 1.4818276166915894, 'learning_rate': 8e-06, 'epoch': 3.69, 'step': 210, 'max_steps': 280}

 75%|███████▌  | 210/280 [2:31:01<46:14, 39.64s/it]
 75%|███████▌  | 211/280 [2:31:42<46:09, 40.13s/it]
                                                   
{'loss': 0.0888, 'grad_norm': 1.0801745653152466, 'learning_rate': 8e-06, 'epoch': 3.71, 'step': 211, 'max_steps': 280}

 75%|███████▌  | 211/280 [2:31:42<46:09, 40.13s/it]
 76%|███████▌  | 212/280 [2:32:22<45:16, 39.94s/it]
                                                   
{'loss': 0.0891, 'grad_norm': 1.1154006719589233, 'learning_rate': 8e-06, 'epoch': 3.73, 'step': 212, 'max_steps': 280}

 76%|███████▌  | 212/280 [2:32:22<45:16, 39.94s/it]
 76%|███████▌  | 213/280 [2:33:01<44:26, 39.80s/it]
                                                   
{'loss': 0.0913, 'grad_norm': 1.0452872514724731, 'learning_rate': 8e-06, 'epoch': 3.75, 'step': 213, 'max_steps': 280}

 76%|███████▌  | 213/280 [2:33:01<44:26, 39.80s/it]
 76%|███████▋  | 214/280 [2:33:41<43:41, 39.72s/it]
                                                   
{'loss': 0.1138, 'grad_norm': 2.723195791244507, 'learning_rate': 8e-06, 'epoch': 3.76, 'step': 214, 'max_steps': 280}

 76%|███████▋  | 214/280 [2:33:41<43:41, 39.72s/it]
 77%|███████▋  | 215/280 [2:34:20<42:53, 39.60s/it]
                                                   
{'loss': 0.0964, 'grad_norm': 1.110839605331421, 'learning_rate': 8e-06, 'epoch': 3.78, 'step': 215, 'max_steps': 280}

 77%|███████▋  | 215/280 [2:34:20<42:53, 39.60s/it]
 77%|███████▋  | 216/280 [2:35:00<42:16, 39.64s/it]
                                                   
{'loss': 0.0974, 'grad_norm': 1.0866153240203857, 'learning_rate': 8e-06, 'epoch': 3.8, 'step': 216, 'max_steps': 280}

 77%|███████▋  | 216/280 [2:35:00<42:16, 39.64s/it]
 78%|███████▊  | 217/280 [2:35:39<41:32, 39.56s/it]
                                                   
{'loss': 0.0994, 'grad_norm': 1.2013740539550781, 'learning_rate': 8e-06, 'epoch': 3.82, 'step': 217, 'max_steps': 280}

 78%|███████▊  | 217/280 [2:35:39<41:32, 39.56s/it]
 78%|███████▊  | 218/280 [2:36:19<40:56, 39.62s/it]
                                                   
{'loss': 0.1137, 'grad_norm': 1.7293658256530762, 'learning_rate': 8e-06, 'epoch': 3.83, 'step': 218, 'max_steps': 280}

 78%|███████▊  | 218/280 [2:36:19<40:56, 39.62s/it]
 78%|███████▊  | 219/280 [2:36:58<40:15, 39.60s/it]
                                                   
{'loss': 0.1019, 'grad_norm': 1.1694632768630981, 'learning_rate': 8e-06, 'epoch': 3.85, 'step': 219, 'max_steps': 280}

 78%|███████▊  | 219/280 [2:36:58<40:15, 39.60s/it]
 79%|███████▊  | 220/280 [2:37:38<39:31, 39.53s/it]
                                                   
{'loss': 0.0888, 'grad_norm': 1.0021443367004395, 'learning_rate': 8e-06, 'epoch': 3.87, 'step': 220, 'max_steps': 280}

 79%|███████▊  | 220/280 [2:37:38<39:31, 39.53s/it]
 79%|███████▉  | 221/280 [2:38:17<38:50, 39.51s/it]
                                                   
{'loss': 0.095, 'grad_norm': 0.9908245205879211, 'learning_rate': 8e-06, 'epoch': 3.89, 'step': 221, 'max_steps': 280}

 79%|███████▉  | 221/280 [2:38:17<38:50, 39.51s/it]
 79%|███████▉  | 222/280 [2:38:56<38:08, 39.46s/it]
                                                   
{'loss': 0.1086, 'grad_norm': 1.146715521812439, 'learning_rate': 8e-06, 'epoch': 3.9, 'step': 222, 'max_steps': 280}

 79%|███████▉  | 222/280 [2:38:56<38:08, 39.46s/it]
 80%|███████▉  | 223/280 [2:39:36<37:28, 39.44s/it]
                                                   
{'loss': 0.0913, 'grad_norm': 1.0628926753997803, 'learning_rate': 8e-06, 'epoch': 3.92, 'step': 223, 'max_steps': 280}

 80%|███████▉  | 223/280 [2:39:36<37:28, 39.44s/it]
 80%|████████  | 224/280 [2:40:16<36:54, 39.55s/it]
                                                   
{'loss': 0.1064, 'grad_norm': 1.2760186195373535, 'learning_rate': 8e-06, 'epoch': 3.94, 'step': 224, 'max_steps': 280}

 80%|████████  | 224/280 [2:40:16<36:54, 39.55s/it]
 80%|████████  | 225/280 [2:40:55<36:18, 39.60s/it]
                                                   
{'loss': 0.0987, 'grad_norm': 1.172914743423462, 'learning_rate': 8e-06, 'epoch': 3.96, 'step': 225, 'max_steps': 280}

 80%|████████  | 225/280 [2:40:55<36:18, 39.60s/it]
 81%|████████  | 226/280 [2:41:35<35:37, 39.59s/it]
                                                   
{'loss': 0.0961, 'grad_norm': 1.1036157608032227, 'learning_rate': 8e-06, 'epoch': 3.97, 'step': 226, 'max_steps': 280}

 81%|████████  | 226/280 [2:41:35<35:37, 39.59s/it]
 81%|████████  | 227/280 [2:42:16<35:25, 40.10s/it]
                                                   
{'loss': 0.1091, 'grad_norm': 1.3016462326049805, 'learning_rate': 8e-06, 'epoch': 3.99, 'step': 227, 'max_steps': 280}

 81%|████████  | 227/280 [2:42:16<35:25, 40.10s/it]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(

 81%|████████▏ | 228/280 [2:46:52<1:36:03, 110.83s/it]
                                                      
{'loss': 0.0757, 'grad_norm': 1.194139838218689, 'learning_rate': 8e-06, 'epoch': 4.01, 'step': 228, 'max_steps': 280}

 81%|████████▏ | 228/280 [2:46:52<1:36:03, 110.83s/it]
 82%|████████▏ | 229/280 [2:47:32<1:16:04, 89.49s/it] 
                                                     
{'loss': 0.0618, 'grad_norm': 0.9530806541442871, 'learning_rate': 8e-06, 'epoch': 4.03, 'step': 229, 'max_steps': 280}

 82%|████████▏ | 229/280 [2:47:32<1:16:04, 89.49s/it]
 82%|████████▏ | 230/280 [2:48:11<1:02:01, 74.44s/it]
                                                     
{'loss': 0.0593, 'grad_norm': 0.9933780431747437, 'learning_rate': 8e-06, 'epoch': 4.04, 'step': 230, 'max_steps': 280}

 82%|████████▏ | 230/280 [2:48:11<1:02:01, 74.44s/it]
 82%|████████▎ | 231/280 [2:48:51<52:18, 64.05s/it]  
                                                   
{'loss': 0.0815, 'grad_norm': 1.4253612756729126, 'learning_rate': 8e-06, 'epoch': 4.06, 'step': 231, 'max_steps': 280}

 82%|████████▎ | 231/280 [2:48:51<52:18, 64.05s/it]
 83%|████████▎ | 232/280 [2:49:31<45:26, 56.80s/it]
                                                   
{'loss': 0.0543, 'grad_norm': 1.2280927896499634, 'learning_rate': 8e-06, 'epoch': 4.08, 'step': 232, 'max_steps': 280}

 83%|████████▎ | 232/280 [2:49:31<45:26, 56.80s/it]
 83%|████████▎ | 233/280 [2:50:11<40:29, 51.70s/it]
                                                   
{'loss': 0.0598, 'grad_norm': 1.0042145252227783, 'learning_rate': 8e-06, 'epoch': 4.1, 'step': 233, 'max_steps': 280}

 83%|████████▎ | 233/280 [2:50:11<40:29, 51.70s/it]
 84%|████████▎ | 234/280 [2:50:50<36:50, 48.06s/it]
                                                   
{'loss': 0.0626, 'grad_norm': 1.0679208040237427, 'learning_rate': 8e-06, 'epoch': 4.11, 'step': 234, 'max_steps': 280}

 84%|████████▎ | 234/280 [2:50:50<36:50, 48.06s/it]
 84%|████████▍ | 235/280 [2:51:30<34:06, 45.49s/it]
                                                   
{'loss': 0.0607, 'grad_norm': 1.1481430530548096, 'learning_rate': 8e-06, 'epoch': 4.13, 'step': 235, 'max_steps': 280}

 84%|████████▍ | 235/280 [2:51:30<34:06, 45.49s/it]
 84%|████████▍ | 236/280 [2:52:09<32:04, 43.75s/it]
                                                   
{'loss': 0.0591, 'grad_norm': 0.9988183379173279, 'learning_rate': 8e-06, 'epoch': 4.15, 'step': 236, 'max_steps': 280}

 84%|████████▍ | 236/280 [2:52:09<32:04, 43.75s/it]
 85%|████████▍ | 237/280 [2:52:50<30:41, 42.84s/it]
                                                   
{'loss': 0.0638, 'grad_norm': 1.1415588855743408, 'learning_rate': 8e-06, 'epoch': 4.17, 'step': 237, 'max_steps': 280}

 85%|████████▍ | 237/280 [2:52:50<30:41, 42.84s/it]
 85%|████████▌ | 238/280 [2:53:30<29:18, 41.86s/it]
                                                   
{'loss': 0.0622, 'grad_norm': 1.0618653297424316, 'learning_rate': 8e-06, 'epoch': 4.18, 'step': 238, 'max_steps': 280}

 85%|████████▌ | 238/280 [2:53:30<29:18, 41.86s/it]
 85%|████████▌ | 239/280 [2:54:09<28:08, 41.17s/it]
                                                   
{'loss': 0.0582, 'grad_norm': 0.9638361930847168, 'learning_rate': 8e-06, 'epoch': 4.2, 'step': 239, 'max_steps': 280}

 85%|████████▌ | 239/280 [2:54:09<28:08, 41.17s/it]
 86%|████████▌ | 240/280 [2:54:49<27:07, 40.69s/it]
                                                   
{'loss': 0.0583, 'grad_norm': 0.9656031131744385, 'learning_rate': 8e-06, 'epoch': 4.22, 'step': 240, 'max_steps': 280}

 86%|████████▌ | 240/280 [2:54:49<27:07, 40.69s/it]
 86%|████████▌ | 241/280 [2:55:29<26:16, 40.42s/it]
                                                   
{'loss': 0.0636, 'grad_norm': 1.031817078590393, 'learning_rate': 8e-06, 'epoch': 4.24, 'step': 241, 'max_steps': 280}

 86%|████████▌ | 241/280 [2:55:29<26:16, 40.42s/it]
 86%|████████▋ | 242/280 [2:56:09<25:40, 40.53s/it]
                                                   
{'loss': 0.0625, 'grad_norm': 0.8999708890914917, 'learning_rate': 8e-06, 'epoch': 4.25, 'step': 242, 'max_steps': 280}

 86%|████████▋ | 242/280 [2:56:09<25:40, 40.53s/it]
 87%|████████▋ | 243/280 [2:56:49<24:51, 40.32s/it]
                                                   
{'loss': 0.0602, 'grad_norm': 0.9733834266662598, 'learning_rate': 8e-06, 'epoch': 4.27, 'step': 243, 'max_steps': 280}

 87%|████████▋ | 243/280 [2:56:49<24:51, 40.32s/it]
 87%|████████▋ | 244/280 [2:57:29<24:03, 40.09s/it]
                                                   
{'loss': 0.0954, 'grad_norm': 4.8390727043151855, 'learning_rate': 8e-06, 'epoch': 4.29, 'step': 244, 'max_steps': 280}

 87%|████████▋ | 244/280 [2:57:29<24:03, 40.09s/it]
 88%|████████▊ | 245/280 [2:58:09<23:20, 40.01s/it]
                                                   
{'loss': 0.0635, 'grad_norm': 3.2689499855041504, 'learning_rate': 8e-06, 'epoch': 4.31, 'step': 245, 'max_steps': 280}

 88%|████████▊ | 245/280 [2:58:09<23:20, 40.01s/it]
 88%|████████▊ | 246/280 [2:58:48<22:36, 39.90s/it]
                                                   
{'loss': 0.0547, 'grad_norm': 0.8102134466171265, 'learning_rate': 8e-06, 'epoch': 4.33, 'step': 246, 'max_steps': 280}

 88%|████████▊ | 246/280 [2:58:48<22:36, 39.90s/it]
 88%|████████▊ | 247/280 [2:59:28<21:56, 39.89s/it]
                                                   
{'loss': 0.0713, 'grad_norm': 1.1719762086868286, 'learning_rate': 8e-06, 'epoch': 4.34, 'step': 247, 'max_steps': 280}

 88%|████████▊ | 247/280 [2:59:28<21:56, 39.89s/it]
 89%|████████▊ | 248/280 [3:00:08<21:15, 39.85s/it]
                                                   
{'loss': 0.06, 'grad_norm': 0.9256847500801086, 'learning_rate': 8e-06, 'epoch': 4.36, 'step': 248, 'max_steps': 280}

 89%|████████▊ | 248/280 [3:00:08<21:15, 39.85s/it]
 89%|████████▉ | 249/280 [3:00:47<20:31, 39.73s/it]
                                                   
{'loss': 0.0638, 'grad_norm': 0.9329568147659302, 'learning_rate': 8e-06, 'epoch': 4.38, 'step': 249, 'max_steps': 280}

 89%|████████▉ | 249/280 [3:00:47<20:31, 39.73s/it]
 89%|████████▉ | 250/280 [3:01:28<20:02, 40.07s/it]
                                                   
{'loss': 0.0558, 'grad_norm': 0.889514148235321, 'learning_rate': 8e-06, 'epoch': 4.4, 'step': 250, 'max_steps': 280}

 89%|████████▉ | 250/280 [3:01:28<20:02, 40.07s/it]
 90%|████████▉ | 251/280 [3:02:08<19:18, 39.95s/it]
                                                   
{'loss': 0.0709, 'grad_norm': 1.1181913614273071, 'learning_rate': 8e-06, 'epoch': 4.41, 'step': 251, 'max_steps': 280}

 90%|████████▉ | 251/280 [3:02:08<19:18, 39.95s/it]
 90%|█████████ | 252/280 [3:02:48<18:37, 39.92s/it]
                                                   
{'loss': 0.0636, 'grad_norm': 1.0758248567581177, 'learning_rate': 8e-06, 'epoch': 4.43, 'step': 252, 'max_steps': 280}

 90%|█████████ | 252/280 [3:02:48<18:37, 39.92s/it]
 90%|█████████ | 253/280 [3:03:28<17:58, 39.95s/it]
                                                   
{'loss': 0.0622, 'grad_norm': 1.1869866847991943, 'learning_rate': 8e-06, 'epoch': 4.45, 'step': 253, 'max_steps': 280}

 90%|█████████ | 253/280 [3:03:28<17:58, 39.95s/it]
 91%|█████████ | 254/280 [3:04:07<17:15, 39.82s/it]
                                                   
{'loss': 0.0601, 'grad_norm': 1.0032222270965576, 'learning_rate': 8e-06, 'epoch': 4.47, 'step': 254, 'max_steps': 280}

 91%|█████████ | 254/280 [3:04:07<17:15, 39.82s/it]
 91%|█████████ | 255/280 [3:04:47<16:33, 39.75s/it]
                                                   
{'loss': 0.0818, 'grad_norm': 2.438694477081299, 'learning_rate': 8e-06, 'epoch': 4.48, 'step': 255, 'max_steps': 280}

 91%|█████████ | 255/280 [3:04:47<16:33, 39.75s/it]
 91%|█████████▏| 256/280 [3:05:26<15:52, 39.69s/it]
                                                   
{'loss': 0.0795, 'grad_norm': 1.5917333364486694, 'learning_rate': 8e-06, 'epoch': 4.5, 'step': 256, 'max_steps': 280}

 91%|█████████▏| 256/280 [3:05:26<15:52, 39.69s/it]
 92%|█████████▏| 257/280 [3:06:07<15:18, 39.92s/it]
                                                   
{'loss': 0.0609, 'grad_norm': 0.9254310131072998, 'learning_rate': 8e-06, 'epoch': 4.52, 'step': 257, 'max_steps': 280}

 92%|█████████▏| 257/280 [3:06:07<15:18, 39.92s/it]
 92%|█████████▏| 258/280 [3:06:46<14:35, 39.79s/it]
                                                   
{'loss': 0.0648, 'grad_norm': 1.020689845085144, 'learning_rate': 8e-06, 'epoch': 4.54, 'step': 258, 'max_steps': 280}

 92%|█████████▏| 258/280 [3:06:46<14:35, 39.79s/it]
 92%|█████████▎| 259/280 [3:07:26<13:53, 39.67s/it]
                                                   
{'loss': 0.0609, 'grad_norm': 0.8503847122192383, 'learning_rate': 8e-06, 'epoch': 4.55, 'step': 259, 'max_steps': 280}

 92%|█████████▎| 259/280 [3:07:26<13:53, 39.67s/it]
 93%|█████████▎| 260/280 [3:08:05<13:13, 39.66s/it]
                                                   
{'loss': 0.0605, 'grad_norm': 0.9948534369468689, 'learning_rate': 8e-06, 'epoch': 4.57, 'step': 260, 'max_steps': 280}

 93%|█████████▎| 260/280 [3:08:05<13:13, 39.66s/it]
 93%|█████████▎| 261/280 [3:08:46<12:37, 39.86s/it]
                                                   
{'loss': 0.0552, 'grad_norm': 0.9087187051773071, 'learning_rate': 8e-06, 'epoch': 4.59, 'step': 261, 'max_steps': 280}

 93%|█████████▎| 261/280 [3:08:46<12:37, 39.86s/it]
 94%|█████████▎| 262/280 [3:09:25<11:56, 39.82s/it]
                                                   
{'loss': 0.0674, 'grad_norm': 1.0530396699905396, 'learning_rate': 8e-06, 'epoch': 4.61, 'step': 262, 'max_steps': 280}

 94%|█████████▎| 262/280 [3:09:25<11:56, 39.82s/it]
 94%|█████████▍| 263/280 [3:10:05<11:16, 39.77s/it]
                                                   
{'loss': 0.0625, 'grad_norm': 0.9008730053901672, 'learning_rate': 8e-06, 'epoch': 4.62, 'step': 263, 'max_steps': 280}

 94%|█████████▍| 263/280 [3:10:05<11:16, 39.77s/it]
 94%|█████████▍| 264/280 [3:10:44<10:34, 39.65s/it]
                                                   
{'loss': 0.0724, 'grad_norm': 1.072214126586914, 'learning_rate': 8e-06, 'epoch': 4.64, 'step': 264, 'max_steps': 280}

 94%|█████████▍| 264/280 [3:10:44<10:34, 39.65s/it]
 95%|█████████▍| 265/280 [3:11:25<09:57, 39.82s/it]
                                                   
{'loss': 0.0685, 'grad_norm': 0.9992793202400208, 'learning_rate': 8e-06, 'epoch': 4.66, 'step': 265, 'max_steps': 280}

 95%|█████████▍| 265/280 [3:11:25<09:57, 39.82s/it]
 95%|█████████▌| 266/280 [3:12:04<09:16, 39.78s/it]
                                                   
{'loss': 0.0666, 'grad_norm': 1.0226664543151855, 'learning_rate': 8e-06, 'epoch': 4.68, 'step': 266, 'max_steps': 280}

 95%|█████████▌| 266/280 [3:12:04<09:16, 39.78s/it]
 95%|█████████▌| 267/280 [3:12:44<08:36, 39.77s/it]
                                                   
{'loss': 0.0629, 'grad_norm': 0.9311314225196838, 'learning_rate': 8e-06, 'epoch': 4.69, 'step': 267, 'max_steps': 280}

 95%|█████████▌| 267/280 [3:12:44<08:36, 39.77s/it]
 96%|█████████▌| 268/280 [3:13:24<07:56, 39.70s/it]
                                                   
{'loss': 0.0715, 'grad_norm': 1.135952115058899, 'learning_rate': 8e-06, 'epoch': 4.71, 'step': 268, 'max_steps': 280}

 96%|█████████▌| 268/280 [3:13:24<07:56, 39.70s/it]
 96%|█████████▌| 269/280 [3:14:04<07:20, 40.05s/it]
                                                   
{'loss': 0.0688, 'grad_norm': 1.033393144607544, 'learning_rate': 8e-06, 'epoch': 4.73, 'step': 269, 'max_steps': 280}

 96%|█████████▌| 269/280 [3:14:04<07:20, 40.05s/it]
 96%|█████████▋| 270/280 [3:14:44<06:39, 39.92s/it]
                                                   
{'loss': 0.0642, 'grad_norm': 0.8982027173042297, 'learning_rate': 8e-06, 'epoch': 4.75, 'step': 270, 'max_steps': 280}

 96%|█████████▋| 270/280 [3:14:44<06:39, 39.92s/it]
 97%|█████████▋| 271/280 [3:15:23<05:57, 39.76s/it]
                                                   
{'loss': 0.0675, 'grad_norm': 0.8951985836029053, 'learning_rate': 8e-06, 'epoch': 4.76, 'step': 271, 'max_steps': 280}

 97%|█████████▋| 271/280 [3:15:23<05:57, 39.76s/it]
 97%|█████████▋| 272/280 [3:16:03<05:17, 39.73s/it]
                                                   
{'loss': 0.067, 'grad_norm': 0.9418995380401611, 'learning_rate': 8e-06, 'epoch': 4.78, 'step': 272, 'max_steps': 280}

 97%|█████████▋| 272/280 [3:16:03<05:17, 39.73s/it]
 98%|█████████▊| 273/280 [3:16:44<04:40, 40.11s/it]
                                                   
{'loss': 0.068, 'grad_norm': 1.227455496788025, 'learning_rate': 8e-06, 'epoch': 4.8, 'step': 273, 'max_steps': 280}

 98%|█████████▊| 273/280 [3:16:44<04:40, 40.11s/it]
 98%|█████████▊| 274/280 [3:17:24<03:59, 39.91s/it]
                                                   
{'loss': 0.0657, 'grad_norm': 0.9993261694908142, 'learning_rate': 8e-06, 'epoch': 4.82, 'step': 274, 'max_steps': 280}

 98%|█████████▊| 274/280 [3:17:24<03:59, 39.91s/it]
 98%|█████████▊| 275/280 [3:18:03<03:19, 39.90s/it]
                                                   
{'loss': 0.0616, 'grad_norm': 0.9715917110443115, 'learning_rate': 8e-06, 'epoch': 4.84, 'step': 275, 'max_steps': 280}

 98%|█████████▊| 275/280 [3:18:03<03:19, 39.90s/it]
 99%|█████████▊| 276/280 [3:18:44<02:40, 40.04s/it]
                                                   
{'loss': 0.0619, 'grad_norm': 0.8903725147247314, 'learning_rate': 8e-06, 'epoch': 4.85, 'step': 276, 'max_steps': 280}

 99%|█████████▊| 276/280 [3:18:44<02:40, 40.04s/it]
 99%|█████████▉| 277/280 [3:19:23<01:59, 39.90s/it]
                                                   
{'loss': 0.06, 'grad_norm': 0.8777966499328613, 'learning_rate': 8e-06, 'epoch': 4.87, 'step': 277, 'max_steps': 280}

 99%|█████████▉| 277/280 [3:19:23<01:59, 39.90s/it]
 99%|█████████▉| 278/280 [3:20:02<01:19, 39.65s/it]
                                                   
{'loss': 0.0644, 'grad_norm': 0.884422242641449, 'learning_rate': 8e-06, 'epoch': 4.89, 'step': 278, 'max_steps': 280}

 99%|█████████▉| 278/280 [3:20:02<01:19, 39.65s/it]
100%|█████████▉| 279/280 [3:20:42<00:39, 39.53s/it]
                                                   
{'loss': 0.0633, 'grad_norm': 0.8972037434577942, 'learning_rate': 8e-06, 'epoch': 4.91, 'step': 279, 'max_steps': 280}

100%|█████████▉| 279/280 [3:20:42<00:39, 39.53s/it]
100%|██████████| 280/280 [3:21:21<00:00, 39.55s/it]
                                                   
{'loss': 0.0647, 'grad_norm': 0.8994230628013611, 'learning_rate': 8e-06, 'epoch': 4.92, 'step': 280, 'max_steps': 280}

100%|██████████| 280/280 [3:21:21<00:00, 39.55s/it]