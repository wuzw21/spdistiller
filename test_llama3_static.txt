nohup: ignoring input
Model: Meta-Llama-3-8B
CUDA device: 
Model: /data/wzw/model/Meta-Llama-3-0.7-static
loading llm model /data/wzw/model/Meta-Llama-3-0.7-static
Meta-Llama-3-8B
Create and load preditor...
Local device: cuda:0
Init Reset
Init sparsity: attn 0.0, mlp 0.0, w 0.0
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.03it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.01it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.37it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.20it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
max_memory: {0: '32GiB', 1: '32GiB', 2: '32GiB', 'cpu': '128GiB'}
load_time: 0.000 sec
model.hf_device_map: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 1, 'model.layers.6': 1, 'model.layers.7': 1, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 2, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 2, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.norm': 3, 'model.weight_predictors': 3, 'lm_head': 3}
Quantizing:   0%|          | 0/32 [00:00<?, ?it/s]Quantizing:  34%|███▍      | 11/32 [00:00<00:00, 109.63it/s]Quantizing: 100%|██████████| 32/32 [00:00<00:00, 169.12it/s]
2025-02-18:02:31:40,187 WARNING  [huggingface.py:122] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
2025-02-18:02:31:40,218 WARNING  [huggingface.py:329] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
2025-02-18:02:31:40,220 INFO     [evaluator.py:152] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2025-02-18:02:31:40,220 INFO     [evaluator.py:203] Using pre-initialized model
task: eval
task_name: mmlu
0.7 0
sp_configs:  [(0.7, 0.7, 0.0, 0)]
sp_config:  (0.7, 0.7, 0.0, 0) num_shot:  0
Init Reset
Set sparsity: attn 0.7, mlp 0.7, w 0.0
Set pre-prediction: 0
threshold_path ../threshold/Meta-Llama-3-8B/Meta-Llama-3-8B-0.7.txt
sparsity_strategy :  Static
sparsity_strategy:  Static
tasks :  ['mmlu', 'wikitext']
Traceback (most recent call last):
  File "/data/wzw/wzw/BitDistiller-Q4_0/train/test_task.py", line 324, in <module>
    main()
  File "/data/wzw/wzw/BitDistiller-Q4_0/train/test_task.py", line 320, in main
    eval_for_sp_config(args.model, model, tokenizer, task_list, num_shot, limit, sp_config, args.file_path, args.sparse_strategy)
  File "/data/wzw/wzw/BitDistiller-Q4_0/train/test_task.py", line 272, in eval_for_sp_config
    results = eval(
  File "/data/wzw/wzw/BitDistiller-Q4_0/train/test_task.py", line 239, in eval
    results = evaluator.simple_evaluate(
  File "/home/donglinbai/Projects/wzw/lm-evaluation-harness-v0.4.3/lm_eval/utils.py", line 395, in _wrapper
    return fn(*args, **kwargs)
  File "/home/donglinbai/Projects/wzw/lm-evaluation-harness-v0.4.3/lm_eval/evaluator.py", line 221, in simple_evaluate
    task_dict = get_task_dict(tasks, task_manager)
  File "/home/donglinbai/Projects/wzw/lm-evaluation-harness-v0.4.3/lm_eval/tasks/__init__.py", line 444, in get_task_dict
    task_name_from_string_dict = task_manager.load_task_or_group(
  File "/home/donglinbai/Projects/wzw/lm-evaluation-harness-v0.4.3/lm_eval/tasks/__init__.py", line 287, in load_task_or_group
    collections.ChainMap(*map(self._load_individual_task_or_group, task_list))
  File "/home/donglinbai/Projects/wzw/lm-evaluation-harness-v0.4.3/lm_eval/tasks/__init__.py", line 270, in _load_individual_task_or_group
    **dict(collections.ChainMap(*map(fn, subtask_list))),
  File "/home/donglinbai/Projects/wzw/lm-evaluation-harness-v0.4.3/lm_eval/tasks/__init__.py", line 270, in _load_individual_task_or_group
    **dict(collections.ChainMap(*map(fn, subtask_list))),
  File "/home/donglinbai/Projects/wzw/lm-evaluation-harness-v0.4.3/lm_eval/tasks/__init__.py", line 178, in _load_individual_task_or_group
    return load_task(task_config, task=name_or_config, group=parent_name)
  File "/home/donglinbai/Projects/wzw/lm-evaluation-harness-v0.4.3/lm_eval/tasks/__init__.py", line 167, in load_task
    task_object = ConfigurableTask(config=config)
  File "/home/donglinbai/Projects/wzw/lm-evaluation-harness-v0.4.3/lm_eval/api/task.py", line 810, in __init__
    self.download(self.config.dataset_kwargs)
  File "/home/donglinbai/Projects/wzw/lm-evaluation-harness-v0.4.3/lm_eval/api/task.py", line 917, in download
    self.dataset = datasets.load_dataset(
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/datasets/load.py", line 1849, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/datasets/load.py", line 1666, in dataset_module_factory
    out = HubDatasetModuleFactoryWithParquetExport(
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/datasets/load.py", line 1180, in get_module
    exported_parquet_files = _dataset_viewer.get_exported_parquet_files(
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/datasets/utils/_dataset_viewer.py", line 35, in get_exported_parquet_files
    parquet_data_files_response = get_session().get(
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/huggingface_hub/utils/_http.py", line 93, in send
    return super().send(request, *args, **kwargs)
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/http/client.py", line 1377, in getresponse
    response.begin()
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/http/client.py", line 320, in begin
    version, status, reason = self._read_status()
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/http/client.py", line 281, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/socket.py", line 716, in readinto
    return self._sock.recv_into(b)
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/ssl.py", line 1275, in recv_into
    return self.read(nbytes, buffer)
  File "/home/donglinbai/miniconda3/envs/sparse/lib/python3.9/ssl.py", line 1133, in read
    return self._sslobj.read(len, buffer)
KeyboardInterrupt
